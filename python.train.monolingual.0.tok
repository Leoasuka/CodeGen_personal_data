 try : NEW_LINE INDENT import jsonresults NEW_LINE from jsonresults import * NEW_LINE DEDENT except ImportError : NEW_LINE INDENT print " ERROR : ▁ Add ▁ the ▁ TestResultServer , ▁ google _ appengine ▁ and ▁ yaml / lib ▁ directories ▁ to ▁ your ▁ PYTHONPATH " NEW_LINE raise NEW_LINE DEDENT import json NEW_LINE import logging NEW_LINE import unittest NEW_LINE FULL_RESULT_EXAMPLE = """ ADD _ RESULTS ( { STRNEWLINE ▁ ▁ ▁ ▁ " seconds _ since _ epoch " : ▁ 1368146629 , STRNEWLINE ▁ ▁ ▁ ▁ " tests " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " media " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media - v2 - events . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " bugs " : ▁ [ " crbug . com / 1234 " ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 6.0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " encrypted - media - v2 - syntax . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " progress - events - generated - correctly . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS ▁ FAIL ▁ IMAGE ▁ TIMEOUT ▁ CRASH ▁ MISSING " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " TIMEOUT " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 6.0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " W3C " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " audio " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src _ removal _ does _ not _ trigger _ loadstart . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 3.5 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " video " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " src _ removal _ does _ not _ trigger _ loadstart . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 1.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " notrun . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " NOTRUN " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " SKIP " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 1.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " unexpected - skip . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " SKIP " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " unexpected - fail . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " FAIL " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " flaky - failed . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " PASS ▁ FAIL " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " FAIL " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " media - document - audio - repaint . html " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " expected " : ▁ " IMAGE " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " actual " : ▁ " IMAGE " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " time " : ▁ 0.1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ " skipped " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ regressions " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ " build _ number " : ▁ " 3 " , STRNEWLINE ▁ ▁ ▁ ▁ " interrupted " : ▁ false , STRNEWLINE ▁ ▁ ▁ ▁ " layout _ tests _ dir " : ▁ " \ / tmp\ / cr\ / src\ / third _ party\ / WebKit\ / LayoutTests " , STRNEWLINE ▁ ▁ ▁ ▁ " version " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ " builder _ name " : ▁ " Webkit " , STRNEWLINE ▁ ▁ ▁ ▁ " num _ passes " : ▁ 10 , STRNEWLINE ▁ ▁ ▁ ▁ " pixel _ tests _ enabled " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " blink _ revision " : ▁ " 1234 " , STRNEWLINE ▁ ▁ ▁ ▁ " has _ pretty _ patch " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " fixable " : ▁ 25 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ flaky " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ " num _ failures _ by _ type " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " CRASH " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " MISSING " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " TEXT " : ▁ 3 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " IMAGE " : ▁ 1 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " PASS " : ▁ 10 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " SKIP " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " TIMEOUT " : ▁ 16 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " IMAGE + TEXT " : ▁ 0 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " FAIL " : ▁ 2 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " AUDIO " : ▁ 0 STRNEWLINE ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ " has _ wdiff " : ▁ true , STRNEWLINE ▁ ▁ ▁ ▁ " chromium _ revision " : ▁ " 5678 " STRNEWLINE } ) ; """ NEW_LINE JSON_RESULTS_OLD_TEMPLATE = ( ' { " [ BUILDER _ NAME ] " : { ' ' " allFixableCount " : [ [ TESTDATA _ COUNT ] ] , ' ' " blinkRevision " : [ [ TESTDATA _ WEBKITREVISION ] ] , ' ' " buildNumbers " : [ [ TESTDATA _ BUILDNUMBERS ] ] , ' ' " chromeRevision " : [ [ TESTDATA _ CHROMEREVISION ] ] , ' ' " failure _ map " : ▁ % s , ' ' " fixableCount " : [ [ TESTDATA _ COUNT ] ] , ' ' " fixableCounts " : [ [ TESTDATA _ COUNTS ] ] , ' ' " secondsSinceEpoch " : [ [ TESTDATA _ TIMES ] ] , ' ' " tests " : { [ TESTDATA _ TESTS ] } ' ' } , ' ' " version " : [ VERSION ] ' ' } ' ) % json . dumps ( CHAR_TO_FAILURE ) NEW_LINE JSON_RESULTS_COUNTS = ' { " ' + ' " : [ [ TESTDATA _ COUNT ] ] , " ' . join ( [ char for char in CHAR_TO_FAILURE . values ( ) ] ) + ' " : [ [ TESTDATA _ COUNT ] ] } ' NEW_LINE JSON_RESULTS_TEMPLATE = ( ' { " [ BUILDER _ NAME ] " : { ' ' " blinkRevision " : [ [ TESTDATA _ WEBKITREVISION ] ] , ' ' " buildNumbers " : [ [ TESTDATA _ BUILDNUMBERS ] ] , ' ' " chromeRevision " : [ [ TESTDATA _ CHROMEREVISION ] ] , ' ' " failure _ map " : ▁ % s , ' ' " num _ failures _ by _ type " : % s , ' ' " secondsSinceEpoch " : [ [ TESTDATA _ TIMES ] ] , ' ' " tests " : { [ TESTDATA _ TESTS ] } ' ' } , ' ' " version " : [ VERSION ] ' ' } ' ) % ( json . dumps ( CHAR_TO_FAILURE ) , JSON_RESULTS_COUNTS ) NEW_LINE JSON_RESULTS_COUNTS_TEMPLATE = ' { " ' + ' " : [ TESTDATA ] , " ' . join ( [ char for char in CHAR_TO_FAILURE ] ) + ' " : [ TESTDATA ] } ' NEW_LINE JSON_RESULTS_TEST_LIST_TEMPLATE = ' { " Webkit " : { " tests " : { [ TESTDATA _ TESTS ] } } } ' NEW_LINE class MockFile ( object ) : NEW_LINE INDENT def __init__ ( self , name = ' results . json ' , data = ' ' ) : NEW_LINE INDENT self . master = ' MockMasterName ' NEW_LINE self . builder = ' MockBuilderName ' NEW_LINE self . test_type = ' MockTestType ' NEW_LINE self . name = name NEW_LINE self . data = data NEW_LINE DEDENT def save ( self , data ) : NEW_LINE INDENT self . data = data NEW_LINE return True NEW_LINE DEDENT DEDENT class JsonResultsTest ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . _builder = " Webkit " NEW_LINE self . old_log_level = logging . root . level NEW_LINE logging . root . setLevel ( logging . ERROR ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT logging . root . setLevel ( self . old_log_level ) NEW_LINE DEDENT def assert_json_equal ( self , a , b ) : NEW_LINE INDENT self . maxDiff = None NEW_LINE a = json . loads ( a ) if isinstance ( a , str ) else a NEW_LINE b = json . loads ( b ) if isinstance ( b , str ) else b NEW_LINE self . assertEqual ( a , b ) NEW_LINE DEDENT def test_strip_prefix_suffix ( self ) : NEW_LINE INDENT json = " [ ' contents ' ] " NEW_LINE self . assertEqual ( JsonResults . _strip_prefix_suffix ( " ADD _ RESULTS ( " + json + " ) ; " ) , json ) NEW_LINE self . assertEqual ( JsonResults . _strip_prefix_suffix ( json ) , json ) NEW_LINE DEDENT def _make_test_json ( self , test_data , json_string = JSON_RESULTS_TEMPLATE , builder_name = " Webkit " ) : NEW_LINE INDENT if not test_data : NEW_LINE INDENT return " " NEW_LINE DEDENT builds = test_data [ " builds " ] NEW_LINE tests = test_data [ " tests " ] NEW_LINE if not builds or not tests : NEW_LINE INDENT return " " NEW_LINE DEDENT counts = [ ] NEW_LINE build_numbers = [ ] NEW_LINE webkit_revision = [ ] NEW_LINE chrome_revision = [ ] NEW_LINE times = [ ] NEW_LINE for build in builds : NEW_LINE INDENT counts . append ( JSON_RESULTS_COUNTS_TEMPLATE . replace ( " [ TESTDATA ] " , build ) ) NEW_LINE build_numbers . append ( "1000 % s " % build ) NEW_LINE webkit_revision . append ( "2000 % s " % build ) NEW_LINE chrome_revision . append ( "3000 % s " % build ) NEW_LINE times . append ( "100000 % s000" % build ) NEW_LINE DEDENT json_string = json_string . replace ( " [ BUILDER _ NAME ] " , builder_name ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ COUNTS ] " , " , " . join ( counts ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ COUNT ] " , " , " . join ( builds ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ BUILDNUMBERS ] " , " , " . join ( build_numbers ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ WEBKITREVISION ] " , " , " . join ( webkit_revision ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ CHROMEREVISION ] " , " , " . join ( chrome_revision ) ) NEW_LINE json_string = json_string . replace ( " [ TESTDATA _ TIMES ] " , " , " . join ( times ) ) NEW_LINE version = str ( test_data [ " version " ] ) if " version " in test_data else "4" NEW_LINE json_string = json_string . replace ( " [ VERSION ] " , version ) NEW_LINE json_string = json_string . replace ( " { [ TESTDATA _ TESTS ] } " , json . dumps ( tests , separators = ( ' , ' , ' : ' ) , sort_keys = True ) ) NEW_LINE return json_string NEW_LINE DEDENT def _test_merge ( self , aggregated_data , incremental_data , expected_data , max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS ) : NEW_LINE INDENT aggregated_results = self . _make_test_json ( aggregated_data , builder_name = self . _builder ) NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , self . _make_test_json ( incremental_data , builder_name = self . _builder ) , is_full_results_format = False ) NEW_LINE merged_results , status_code = JsonResults . merge ( self . _builder , aggregated_results , incremental_json , num_runs = max_builds , sort_keys = True ) NEW_LINE if expected_data : NEW_LINE INDENT expected_results = self . _make_test_json ( expected_data , builder_name = self . _builder ) NEW_LINE self . assert_json_equal ( merged_results , expected_results ) NEW_LINE self . assertEqual ( status_code , 200 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertTrue ( status_code != 200 ) NEW_LINE DEDENT DEDENT def _test_get_test_list ( self , input_data , expected_data ) : NEW_LINE INDENT input_results = self . _make_test_json ( input_data ) NEW_LINE expected_results = JSON_RESULTS_TEST_LIST_TEMPLATE . replace ( " { [ TESTDATA _ TESTS ] } " , json . dumps ( expected_data , separators = ( ' , ' , ' : ' ) ) ) NEW_LINE actual_results = JsonResults . get_test_list ( self . _builder , input_results ) NEW_LINE self . assert_json_equal ( actual_results , expected_results ) NEW_LINE DEDENT def test_update_files_empty_aggregate_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE incremental_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE incremental_string = self . _make_test_json ( incremental_data , builder_name = small_file . builder ) NEW_LINE self . assertTrue ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) ) NEW_LINE self . assert_json_equal ( small_file . data , incremental_string ) NEW_LINE self . assert_json_equal ( large_file . data , incremental_string ) NEW_LINE DEDENT def test_update_files_null_incremental_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE aggregated_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE aggregated_string = self . _make_test_json ( aggregated_data , builder_name = small_file . builder ) NEW_LINE small_file . data = large_file . data = aggregated_string NEW_LINE incremental_string = " " NEW_LINE self . assertEqual ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) , ( ' No ▁ incremental ▁ JSON ▁ data ▁ to ▁ merge . ' , 403 ) ) NEW_LINE self . assert_json_equal ( small_file . data , aggregated_string ) NEW_LINE self . assert_json_equal ( large_file . data , aggregated_string ) NEW_LINE DEDENT def test_update_files_empty_incremental_data ( self ) : NEW_LINE INDENT small_file = MockFile ( name = ' results - small . json ' ) NEW_LINE large_file = MockFile ( name = ' results . json ' ) NEW_LINE aggregated_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE aggregated_string = self . _make_test_json ( aggregated_data , builder_name = small_file . builder ) NEW_LINE small_file . data = large_file . data = aggregated_string NEW_LINE incremental_data = { " builds " : [ ] , " tests " : { } } NEW_LINE incremental_string = self . _make_test_json ( incremental_data , builder_name = small_file . builder ) NEW_LINE self . assertEqual ( JsonResults . update_files ( small_file . builder , incremental_string , small_file , large_file , is_full_results_format = False ) , ( ' No ▁ incremental ▁ JSON ▁ data ▁ to ▁ merge . ' , 403 ) ) NEW_LINE self . assert_json_equal ( small_file . data , aggregated_string ) NEW_LINE self . assert_json_equal ( large_file . data , aggregated_string ) NEW_LINE DEDENT def test_merge_with_empty_aggregated_results ( self ) : NEW_LINE INDENT incremental_data = { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] , } } } NEW_LINE incremental_results , _ = JsonResults . _get_incremental_json ( self . _builder , self . _make_test_json ( incremental_data ) , is_full_results_format = False ) NEW_LINE aggregated_results = " " NEW_LINE merged_results , _ = JsonResults . merge ( self . _builder , aggregated_results , incremental_results , num_runs = jsonresults . JSON_RESULTS_MAX_BUILDS , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , incremental_results ) NEW_LINE DEDENT def test_failures_by_type_added ( self ) : NEW_LINE INDENT aggregated_results = self . _make_test_json ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 100 , TEXT ] , [ 100 , FAIL ] ] , " times " : [ [ 200 , 0 ] ] , } } } , json_string = JSON_RESULTS_OLD_TEMPLATE ) NEW_LINE incremental_results = self . _make_test_json ( { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] , } } } , json_string = JSON_RESULTS_OLD_TEMPLATE ) NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , incremental_results , is_full_results_format = False ) NEW_LINE merged_results , _ = JsonResults . merge ( self . _builder , aggregated_results , incremental_json , num_runs = 201 , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , self . _make_test_json ( { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 101 , TEXT ] , [ 100 , FAIL ] ] , " times " : [ [ 201 , 0 ] ] , } } } ) ) NEW_LINE DEDENT def test_merge_full_results_format ( self ) : NEW_LINE INDENT expected_incremental_results = { " Webkit " : { " blinkRevision " : [ "1234" ] , " buildNumbers " : [ "3" ] , " chromeRevision " : [ "5678" ] , " failure _ map " : CHAR_TO_FAILURE , " num _ failures _ by _ type " : { " AUDIO " : [ 0 ] , " CRASH " : [ 3 ] , " FAIL " : [ 2 ] , " IMAGE " : [ 1 ] , " IMAGE + TEXT " : [ 0 ] , " MISSING " : [ 0 ] , " PASS " : [ 10 ] , " SKIP " : [ 2 ] , " TEXT " : [ 3 ] , " TIMEOUT " : [ 16 ] } , " secondsSinceEpoch " : [ 1368146629 ] , " tests " : { " media " : { " W3C " : { " audio " : { " src " : { " src _ removal _ does _ not _ trigger _ loadstart . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 4 ] ] , } } } } , " encrypted - media " : { " encrypted - media - v2 - events . html " : { " bugs " : [ " crbug . com / 1234" ] , " expected " : " TIMEOUT " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 6 ] ] , } , " encrypted - media - v2 - syntax . html " : { " expected " : " TIMEOUT " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 0 ] ] , } } , " media - document - audio - repaint . html " : { " expected " : " IMAGE " , " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] , } , " progress - events - generated - correctly . html " : { " expected " : " PASS ▁ FAIL ▁ IMAGE ▁ TIMEOUT ▁ CRASH ▁ MISSING " , " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 6 ] ] , } , " flaky - failed . html " : { " expected " : " PASS ▁ FAIL " , " results " : [ [ 1 , FAIL ] ] , " times " : [ [ 1 , 0 ] ] , } , " unexpected - fail . html " : { " results " : [ [ 1 , FAIL ] ] , " times " : [ [ 1 , 0 ] ] , } , } } } , " version " : 4 } NEW_LINE aggregated_results = " " NEW_LINE incremental_json , _ = JsonResults . _get_incremental_json ( self . _builder , FULL_RESULT_EXAMPLE , is_full_results_format = True ) NEW_LINE merged_results , _ = JsonResults . merge ( " Webkit " , aggregated_results , incremental_json , num_runs = jsonresults . JSON_RESULTS_MAX_BUILDS , sort_keys = True ) NEW_LINE self . assert_json_equal ( merged_results , expected_incremental_results ) NEW_LINE DEDENT def test_merge_empty_aggregated_results ( self ) : NEW_LINE INDENT self . _test_merge ( None , { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_duplicate_build_number ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 100 , TEXT ] ] , " times " : [ [ 100 , 0 ] ] } } } , { " builds " : [ "2" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , None ) NEW_LINE DEDENT def test_merge_incremental_single_test_single_run_same_result ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_single_run_different_result ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_single_run_result_changed ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] , [ 10 , IMAGE ] ] , " times " : [ [ 200 , 0 ] , [ 10 , 1 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , IMAGE ] , [ 200 , TEXT ] , [ 10 , IMAGE ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 0 ] , [ 10 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_single_run ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 1 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_single_run_one_no_result ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 1 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 1 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , NO_DATA ] , [ 200 , TEXT ] ] , " times " : [ [ 201 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 1 ] ] } } } ) NEW_LINE DEDENT def test_merge_single_test_multiple_runs ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } } } , { " builds " : [ "4" , "3" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] , [ 1 , FAIL ] ] , " times " : [ [ 3 , 2 ] ] } } } , { " builds " : [ "4" , "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , FAIL ] , [ 2 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 3 , 2 ] , [ 200 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_multiple_tests_multiple_runs ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 10 , IMAGE_PLUS_TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , { " builds " : [ "4" , "3" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] ] , " times " : [ [ 2 , 2 ] ] } , "002 . html " : { " results " : [ [ 1 , CRASH ] ] , " times " : [ [ 1 , 1 ] ] } } } , { " builds " : [ "4" , "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , IMAGE ] , [ 200 , TEXT ] ] , " times " : [ [ 2 , 2 ] , [ 200 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , CRASH ] , [ 10 , IMAGE_PLUS_TEXT ] ] , " times " : [ [ 1 , 1 ] , [ 10 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_incremental_result_older_build ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "3" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 5 , TEXT ] ] , " times " : [ [ 5 , 0 ] ] } } } , { " builds " : [ "2" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , { " builds " : [ "2" , "3" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 6 , TEXT ] ] , " times " : [ [ 6 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_incremental_result_same_build ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 5 , TEXT ] ] , " times " : [ [ 5 , 0 ] ] } } } , { " builds " : [ "3" , "2" ] , " tests " : { "001 . html " : { " results " : [ [ 2 , TEXT ] ] , " times " : [ [ 2 , 0 ] ] } } } , { " builds " : [ "3" , "2" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 7 , TEXT ] ] , " times " : [ [ 7 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_remove_new_test ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 199 , TEXT ] ] , " times " : [ [ 199 , 0 ] ] } , } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , " notrun . html " : { " results " : [ [ 1 , NOTRUN ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , NO_DATA ] ] , " times " : [ [ 1 , 0 ] ] } , } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_remove_test ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } } } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } , "003 . html " : { " results " : [ [ 190 , PASS ] , [ 9 , NO_DATA ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , { " builds " : [ "3" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } } } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_updates_expected ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { " directory " : { " directory " : { "001 . html " : { " expected " : " FAIL " , " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } } } , "002 . html " : { " bugs " : [ " crbug . com / 1234" ] , " expected " : " FAIL " , " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } , "003 . html " : { " expected " : " FAIL " , " results " : [ [ 190 , PASS ] , [ 9 , NO_DATA ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , "004 . html " : { " results " : [ [ 199 , PASS ] , [ 1 , TEXT ] ] , " times " : [ [ 200 , 0 ] ] } , } } , { " builds " : [ "3" ] , " tests " : { "002 . html " : { " expected " : " PASS " , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " expected " : " TIMEOUT " , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "004 . html " : { " bugs " : [ " crbug . com / 1234" ] , " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } , "003 . html " : { " expected " : " TIMEOUT " , " results " : [ [ 191 , PASS ] , [ 9 , NO_DATA ] ] , " times " : [ [ 200 , 0 ] ] } , "004 . html " : { " bugs " : [ " crbug . com / 1234" ] , " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } , } } , max_builds = 200 ) NEW_LINE DEDENT def test_merge_keep_test_with_all_pass_but_slow_time ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 1 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , PASS ] ] , " times " : [ [ 1 , 1 ] , [ 200 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_pruning_slow_tests_for_debug_builders ( self ) : NEW_LINE INDENT self . _builder = " MockBuilder ( dbg ) " NEW_LINE self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 3 * jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 1 ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , 0 ] ] } , "003 . html " : { " results " : [ [ 1 , PASS ] ] , " times " : [ [ 1 , jsonresults . JSON_RESULTS_MIN_TIME ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 201 , PASS ] ] , " times " : [ [ 1 , 1 ] , [ 200 , 3 * jsonresults . JSON_RESULTS_MIN_TIME ] ] } , "002 . html " : { " results " : [ [ 1 , PASS ] , [ 10 , TEXT ] ] , " times " : [ [ 11 , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_prune_extra_results ( self ) : NEW_LINE INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS NEW_LINE self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , IMAGE ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 1 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] , [ max_builds , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ max_builds , 0 ] ] } } } ) NEW_LINE DEDENT def test_merge_prune_extra_results_small ( self ) : NEW_LINE INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS_SMALL NEW_LINE self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , IMAGE ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] ] , " times " : [ [ 1 , 1 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TIMEOUT ] , [ max_builds , TEXT ] ] , " times " : [ [ 1 , 1 ] , [ max_builds , 0 ] ] } } } , int ( max_builds ) ) NEW_LINE DEDENT def test_merge_prune_extra_results_with_new_result_of_same_type ( self ) : NEW_LINE INDENT max_builds = jsonresults . JSON_RESULTS_MAX_BUILDS_SMALL NEW_LINE self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] , [ 1 , NO_DATA ] ] , " times " : [ [ max_builds , 0 ] , [ 1 , 1 ] ] } } } , { " builds " : [ "3" ] , " tests " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } } } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { "001 . html " : { " results " : [ [ max_builds , TEXT ] ] , " times " : [ [ max_builds , 0 ] ] } } } , int ( max_builds ) ) NEW_LINE DEDENT def test_merge_build_directory_hierarchy ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { " bar " : { " baz " : { "003 . html " : { " results " : [ [ 25 , TEXT ] ] , " times " : [ [ 25 , 0 ] ] } } } , " foo " : { "001 . html " : { " results " : [ [ 50 , TEXT ] ] , " times " : [ [ 50 , 0 ] ] } , "002 . html " : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 0 ] ] } } } , " version " : 4 } , { " builds " : [ "3" ] , " tests " : { " baz " : { "004 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } , " foo " : { "001 . html " : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } } , " version " : 4 } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { " bar " : { " baz " : { "003 . html " : { " results " : [ [ 1 , NO_DATA ] , [ 25 , TEXT ] ] , " times " : [ [ 26 , 0 ] ] } } } , " baz " : { "004 . html " : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } } , " foo " : { "001 . html " : { " results " : [ [ 51 , TEXT ] ] , " times " : [ [ 51 , 0 ] ] } , "002 . html " : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 0 ] ] } } } , " version " : 4 } ) NEW_LINE DEDENT def test_get_test_name_list ( self ) : NEW_LINE INDENT self . _test_get_test_list ( { " builds " : [ "3" , "2" , "1" ] , " tests " : { " foo " : { "001 . html " : { " results " : [ [ 200 , PASS ] ] , " times " : [ [ 200 , 0 ] ] } , " results " : [ [ 1 , NO_DATA ] ] , " times " : [ [ 1 , 0 ] ] } , "002 . html " : { " results " : [ [ 10 , TEXT ] ] , " times " : [ [ 10 , 0 ] ] } } } , { " foo " : { "001 . html " : { } } , "002 . html " : { } } ) NEW_LINE DEDENT def test_gtest ( self ) : NEW_LINE INDENT self . _test_merge ( { " builds " : [ "2" , "1" ] , " tests " : { " foo . bar " : { " results " : [ [ 50 , TEXT ] ] , " times " : [ [ 50 , 0 ] ] } , " foo . bar2" : { " results " : [ [ 100 , IMAGE ] ] , " times " : [ [ 100 , 0 ] ] } , " test . failed " : { " results " : [ [ 5 , FAIL ] ] , " times " : [ [ 5 , 0 ] ] } , } , " version " : 3 } , { " builds " : [ "3" ] , " tests " : { " foo . bar2" : { " results " : [ [ 1 , IMAGE ] ] , " times " : [ [ 1 , 0 ] ] } , " foo . bar3" : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , " test . failed " : { " results " : [ [ 5 , FAIL ] ] , " times " : [ [ 5 , 0 ] ] } , } , " version " : 4 } , { " builds " : [ "3" , "2" , "1" ] , " tests " : { " foo . bar " : { " results " : [ [ 1 , NO_DATA ] , [ 50 , TEXT ] ] , " times " : [ [ 51 , 0 ] ] } , " foo . bar2" : { " results " : [ [ 101 , IMAGE ] ] , " times " : [ [ 101 , 0 ] ] } , " foo . bar3" : { " results " : [ [ 1 , TEXT ] ] , " times " : [ [ 1 , 0 ] ] } , " test . failed " : { " results " : [ [ 10 , FAIL ] ] , " times " : [ [ 10 , 0 ] ] } , } , " version " : 4 } ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT unittest . main ( ) NEW_LINE DEDENT
 def parseEntity ( entityLine ) : NEW_LINE INDENT result = entityLine . split ( ) NEW_LINE entity_name = result [ 1 ] NEW_LINE particle = ' GenericParticle ' NEW_LINE if len ( result ) == 3 : NEW_LINE INDENT attributes = result [ 2 ] NEW_LINE attributes = attributes . replace ( ' gender ' , ' color ' ) NEW_LINE attributes = attributes . replace ( ' female ' , ' pink ' ) NEW_LINE attributes = attributes . replace ( ' male ' , ' blue ' ) NEW_LINE attributes = attributes . replace ( ' photo ' , ' pic ' ) NEW_LINE attributes = attributes + ' , type = ' + result [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT attributes = ' type = ' + result [ 0 ] NEW_LINE DEDENT return " ADD ▁ NODE ▁ % s ▁ % s ▁ auto ▁ % s ▁ % s " % ( entity_name , entity_name , particle , attributes ) NEW_LINE DEDENT def parseUpdatedEntity ( entityLine ) : NEW_LINE INDENT result = entityLine . split ( ) NEW_LINE entity_name = result [ 1 ] NEW_LINE if len ( result ) == 3 : NEW_LINE INDENT attributes = result [ 2 ] NEW_LINE attributes = attributes . replace ( ' gender ' , ' color ' ) NEW_LINE attributes = attributes . replace ( ' female ' , ' pink ' ) NEW_LINE attributes = attributes . replace ( ' male ' , ' blue ' ) NEW_LINE attributes = attributes . replace ( ' photo ' , ' pic ' ) NEW_LINE attributes = attributes . replace ( ' name ' , ' label ' ) NEW_LINE DEDENT else : NEW_LINE INDENT attributes = ' label = ' + entity_name NEW_LINE DEDENT return " UPDATE ▁ NODE ▁ % s ▁ % s " % ( entity_name , attributes ) NEW_LINE DEDENT def parseRelation ( relationLine ) : NEW_LINE INDENT result = relationLine . split ( ' ( ' ) NEW_LINE relation = result [ 0 ] . strip ( ) NEW_LINE entities_str = result [ 1 ] . rstrip ( ' ) ' ) NEW_LINE entities_list = entities_str . split ( ' , ' ) NEW_LINE src = entities_list [ 0 ] . strip ( ) NEW_LINE dst = entities_list [ 1 ] . strip ( ) NEW_LINE return " ADD ▁ LINK ▁ % s ▁ % s ▁ % s " % ( src , dst , relation ) NEW_LINE DEDENT import re NEW_LINE import Axon NEW_LINE from Axon . Ipc import producerFinished , shutdownMicroprocess NEW_LINE class RelationAttributeParser ( Axon . Component . component ) : NEW_LINE INDENT def shutdown ( self ) : NEW_LINE INDENT while self . dataReady ( " control " ) : NEW_LINE INDENT data = self . recv ( " control " ) NEW_LINE if isinstance ( data , producerFinished ) or isinstance ( data , shutdownMicroprocess ) : NEW_LINE INDENT self . shutdown_mess = data NEW_LINE return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def main ( self ) : NEW_LINE INDENT previousNodes = [ ] NEW_LINE while not self . shutdown ( ) : NEW_LINE INDENT X = [ ] NEW_LINE links = [ ] NEW_LINE nodes = [ ] NEW_LINE updatedNodes = [ ] NEW_LINE while not self . anyReady ( ) : NEW_LINE INDENT self . pause ( ) NEW_LINE yield 1 NEW_LINE DEDENT while self . dataReady ( " inbox " ) : NEW_LINE INDENT L = self . recv ( " inbox " ) NEW_LINE if L . strip ( ) == " " : NEW_LINE INDENT continue NEW_LINE DEDENT if L . lstrip ( ) [ 0 ] == " # " : NEW_LINE INDENT continue NEW_LINE DEDENT X . append ( L . strip ( ) ) NEW_LINE DEDENT for item in X : NEW_LINE INDENT if re . match ( ' ( . + ) \ ( ( . + ) , ( . + ) \ ) ' , item ) : NEW_LINE INDENT command = parseRelation ( item ) NEW_LINE links . append ( command ) NEW_LINE DEDENT else : NEW_LINE INDENT isRepeated = False NEW_LINE for node in previousNodes : NEW_LINE INDENT if item . split ( ) [ 1 ] == node . split ( ) [ 2 ] : NEW_LINE INDENT isRepeated = True NEW_LINE DEDENT DEDENT if not isRepeated : NEW_LINE INDENT command = parseEntity ( item ) NEW_LINE nodes . append ( command ) NEW_LINE previousNodes . append ( command ) NEW_LINE DEDENT else : NEW_LINE INDENT command = parseUpdatedEntity ( item ) NEW_LINE updatedNodes . append ( command ) NEW_LINE DEDENT DEDENT DEDENT for node in nodes : NEW_LINE INDENT self . send ( node , " outbox " ) NEW_LINE DEDENT for updatedNode in updatedNodes : NEW_LINE INDENT self . send ( updatedNode , " outbox " ) NEW_LINE DEDENT for link in links : NEW_LINE INDENT self . send ( link , " outbox " ) NEW_LINE DEDENT yield 1 NEW_LINE DEDENT self . send ( self . shutdown_mess , " signal " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT from Kamaelia . Util . DataSource import DataSource NEW_LINE from Kamaelia . Visualisation . PhysicsGraph . lines_to_tokenlists import lines_to_tokenlists NEW_LINE from Kamaelia . Util . Console import ConsoleReader , ConsoleEchoer NEW_LINE from GenericTopologyViewer import GenericTopologyViewer NEW_LINE from Kamaelia . Chassis . Graphline import Graphline NEW_LINE Graphline ( CONSOLEREADER = ConsoleReader ( ) , DATASOURCE = DataSource ( [ " ▁ ▁ person ▁ ▁ mum ▁ ▁ ▁ gender = female , photo = . . / Files / mum . jpg , width = 80 , height = 80 ▁ " , ' ▁ ▁ ' , """ ▁ ▁ ▁ STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ """ , ' person ▁ dad ▁ gender = male , shape = rect , width = 80 , height = 80' , ' ▁ ▁ person ▁ ▁ son ▁ ▁ ▁ gender = male , photo = . . / Files / son . gif , width = 60 , height = 60' , ' person ▁ son ▁ photo = . . / Files / son1 . gif ' , ' person ▁ daughter ▁ radius = 20' , ' person ▁ daughter ▁ radius = 100' , ' ▁ childof ▁ ▁ ( ▁ ▁ mum ▁ ▁ , ▁ son ▁ ▁ ) ▁ ' , ' childof ( mum , ▁ daughter ) ' , ' childof ( dad , ▁ son ) ' , ' childof ( dad , ▁ daughter ) ' ] ) , PARSER = RelationAttributeParser ( ) , TOKENS = lines_to_tokenlists ( ) , VIEWER = GenericTopologyViewer ( ) , CONSOLEECHOER = ConsoleEchoer ( ) , linkages = { ( " CONSOLEREADER " , " outbox " ) : ( " PARSER " , " inbox " ) , ( " DATASOURCE " , " outbox " ) : ( " PARSER " , " inbox " ) , ( " PARSER " , " outbox " ) : ( " TOKENS " , " inbox " ) , ( " TOKENS " , " outbox " ) : ( " VIEWER " , " inbox " ) , ( " VIEWER " , " outbox " ) : ( " CONSOLEECHOER " , " inbox " ) , } ) . run ( ) NEW_LINE DEDENT
 import os NEW_LINE import mailroom2 as mailroom NEW_LINE mailroom . donor_db = mailroom . get_donor_db ( ) NEW_LINE def test_list_donors ( ) : NEW_LINE INDENT listing = mailroom . list_donors ( ) NEW_LINE assert listing . startswith ( " Donor ▁ list : \n " ) NEW_LINE assert " Jeff ▁ Bezos " in listing NEW_LINE assert " William ▁ Gates ▁ III " in listing NEW_LINE assert len ( listing . split ( ' \n ' ) ) == 5 NEW_LINE DEDENT def test_find_donor ( ) : NEW_LINE INDENT donor = mailroom . find_donor ( " jefF ▁ beZos ▁ " ) NEW_LINE assert donor [ 0 ] == " Jeff ▁ Bezos " NEW_LINE DEDENT def test_find_donor_not ( ) : NEW_LINE INDENT donor = mailroom . find_donor ( " Jeff ▁ Bzos " ) NEW_LINE assert donor is None NEW_LINE DEDENT def test_gen_letter ( ) : NEW_LINE INDENT donor = ( " Fred ▁ Flintstone " , [ 432.45 , 65.45 , 230.0 ] ) NEW_LINE letter = mailroom . gen_letter ( donor ) NEW_LINE assert letter . startswith ( " Dear ▁ Fred ▁ Flintstone " ) NEW_LINE assert letter . endswith ( " - The ▁ Team \n " ) NEW_LINE assert " donation ▁ of ▁ $ 230.00" in letter NEW_LINE DEDENT def test_add_donor ( ) : NEW_LINE INDENT name = " Fred ▁ Flintstone ▁ ▁ " NEW_LINE donor = mailroom . add_donor ( name ) NEW_LINE donor [ 1 ] . append ( 300 ) NEW_LINE assert donor [ 0 ] == " Fred ▁ Flintstone " NEW_LINE assert donor [ 1 ] == [ 300 ] NEW_LINE assert mailroom . find_donor ( name ) == donor NEW_LINE DEDENT def test_generate_donor_report ( ) : NEW_LINE INDENT report = mailroom . generate_donor_report ( ) NEW_LINE print ( report ) NEW_LINE assert report . startswith ( " Donor ▁ Name ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ | ▁ Total ▁ Given ▁ | ▁ Num ▁ Gifts ▁ | ▁ Average ▁ Gift " ) NEW_LINE assert " Jeff ▁ Bezos ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ $ ▁ ▁ ▁ ▁ 877.33 ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ 1 ▁ ▁ ▁ $ ▁ ▁ ▁ ▁ ▁ 877.33" in report NEW_LINE DEDENT def test_save_letters_to_disk ( ) : NEW_LINE INDENT mailroom . save_letters_to_disk ( ) NEW_LINE assert os . path . isfile ( ' Jeff _ Bezos . txt ' ) NEW_LINE assert os . path . isfile ( ' William _ Gates _ III . txt ' ) NEW_LINE with open ( ' William _ Gates _ III . txt ' ) as f : NEW_LINE INDENT size = len ( f . read ( ) ) NEW_LINE DEDENT assert size > 0 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT test_list_donors ( ) NEW_LINE test_find_donor ( ) NEW_LINE test_find_donor_not ( ) NEW_LINE test_gen_letter ( ) NEW_LINE test_add_donor ( ) NEW_LINE test_generate_donor_report ( ) NEW_LINE test_save_letters_to_disk ( ) NEW_LINE print ( " All ▁ tests ▁ Passed " ) NEW_LINE DEDENT
 import argparse NEW_LINE import json NEW_LINE import os NEW_LINE import signal NEW_LINE import socket NEW_LINE import sys NEW_LINE import threading NEW_LINE import time NEW_LINE import traceback NEW_LINE import urllib2 NEW_LINE import uuid NEW_LINE from collections import defaultdict , OrderedDict NEW_LINE from multiprocessing import Process , Event NEW_LINE from . . import localpaths NEW_LINE import sslutils NEW_LINE from wptserve import server as wptserve , handlers NEW_LINE from wptserve import stash NEW_LINE from wptserve . logger import set_logger NEW_LINE from mod_pywebsocket import standalone as pywebsocket NEW_LINE repo_root = localpaths . repo_root NEW_LINE class WorkersHandler ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . handler = handlers . handler ( self . handle_request ) NEW_LINE DEDENT def __call__ ( self , request , response ) : NEW_LINE INDENT return self . handler ( request , response ) NEW_LINE DEDENT def handle_request ( self , request , response ) : NEW_LINE INDENT worker_path = request . url_parts . path . replace ( " . worker " , " . worker . js " ) NEW_LINE return """ < ! doctype ▁ html > STRNEWLINE < meta ▁ charset = utf - 8 > STRNEWLINE < script ▁ src = " / resources / testharness . js " > < / script > STRNEWLINE < script ▁ src = " / resources / testharnessreport . js " > < / script > STRNEWLINE < div ▁ id = log > < / div > STRNEWLINE < script > STRNEWLINE fetch _ tests _ from _ worker ( new ▁ Worker ( " % s " ) ) ; STRNEWLINE < / script > STRNEWLINE """ % ( worker_path , ) NEW_LINE DEDENT DEDENT rewrites = [ ( " GET " , " / resources / WebIDLParser . js " , " / resources / webidl2 / lib / webidl2 . js " ) ] NEW_LINE subdomains = [ u" www " , u" www1" , u" www2" , u" 天気の良い日 " , u" élève " ] NEW_LINE class RoutesBuilder ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . forbidden_override = [ ( " GET " , " / tools / runner / * " , handlers . file_handler ) , ( " POST " , " / tools / runner / update _ manifest . py " , handlers . python_script_handler ) ] NEW_LINE self . forbidden = [ ( " * " , " / _ certs / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " / tools / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " { spec } / tools / * " , handlers . ErrorHandler ( 404 ) ) , ( " * " , " / serve . py " , handlers . ErrorHandler ( 404 ) ) ] NEW_LINE self . static = [ ( " GET " , " * . worker " , WorkersHandler ( ) ) ] NEW_LINE self . mountpoint_routes = OrderedDict ( ) NEW_LINE self . add_mount_point ( " / " , None ) NEW_LINE DEDENT def get_routes ( self ) : NEW_LINE INDENT routes = self . forbidden_override + self . forbidden + self . static NEW_LINE for item in reversed ( self . mountpoint_routes . values ( ) ) : NEW_LINE INDENT routes . extend ( item ) NEW_LINE DEDENT return routes NEW_LINE DEDENT def add_static ( self , path , format_args , content_type , route ) : NEW_LINE INDENT handler = handlers . StaticHandler ( path , format_args , content_type ) NEW_LINE self . static . append ( ( b" GET " , str ( route ) , handler ) ) NEW_LINE DEDENT def add_mount_point ( self , url_base , path ) : NEW_LINE INDENT url_base = " / % s / " % url_base . strip ( " / " ) if url_base != " / " else " / " NEW_LINE self . mountpoint_routes [ url_base ] = [ ] NEW_LINE routes = [ ( " GET " , " * . asis " , handlers . AsIsHandler ) , ( " * " , " * . py " , handlers . PythonScriptHandler ) , ( " GET " , " * " , handlers . FileHandler ) ] NEW_LINE for ( method , suffix , handler_cls ) in routes : NEW_LINE INDENT self . mountpoint_routes [ url_base ] . append ( ( method , b" % s % s " % ( str ( url_base ) if url_base != " / " else " " , str ( suffix ) ) , handler_cls ( base_path = path , url_base = url_base ) ) ) NEW_LINE DEDENT DEDENT DEDENT def default_routes ( ) : NEW_LINE INDENT return RoutesBuilder ( ) . get_routes ( ) NEW_LINE DEDENT def setup_logger ( level ) : NEW_LINE INDENT import logging NEW_LINE global logger NEW_LINE logger = logging . getLogger ( " web - platform - tests " ) NEW_LINE logging . basicConfig ( level = getattr ( logging , level . upper ( ) ) ) NEW_LINE set_logger ( logger ) NEW_LINE DEDENT def open_socket ( port ) : NEW_LINE INDENT sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) NEW_LINE if port != 0 : NEW_LINE INDENT sock . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) NEW_LINE DEDENT sock . bind ( ( '127.0.0.1' , port ) ) NEW_LINE sock . listen ( 5 ) NEW_LINE return sock NEW_LINE DEDENT def get_port ( ) : NEW_LINE INDENT free_socket = open_socket ( 0 ) NEW_LINE port = free_socket . getsockname ( ) [ 1 ] NEW_LINE logger . debug ( " Going ▁ to ▁ use ▁ port ▁ % s " % port ) NEW_LINE free_socket . close ( ) NEW_LINE return port NEW_LINE DEDENT class ServerProc ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . proc = None NEW_LINE self . daemon = None NEW_LINE self . stop = Event ( ) NEW_LINE DEDENT def start ( self , init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT self . proc = Process ( target = self . create_daemon , args = ( init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config ) ) NEW_LINE self . proc . daemon = True NEW_LINE self . proc . start ( ) NEW_LINE DEDENT def create_daemon ( self , init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT try : NEW_LINE INDENT self . daemon = init_func ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE DEDENT except socket . error : NEW_LINE INDENT print >> sys . stderr , " Socket ▁ error ▁ on ▁ port ▁ % s " % port NEW_LINE raise NEW_LINE DEDENT except : NEW_LINE INDENT print >> sys . stderr , traceback . format_exc ( ) NEW_LINE raise NEW_LINE DEDENT if self . daemon : NEW_LINE INDENT try : NEW_LINE INDENT self . daemon . start ( block = False ) NEW_LINE try : NEW_LINE INDENT self . stop . wait ( ) NEW_LINE DEDENT except KeyboardInterrupt : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT print >> sys . stderr , traceback . format_exc ( ) NEW_LINE raise NEW_LINE DEDENT DEDENT DEDENT def wait ( self ) : NEW_LINE INDENT self . stop . set ( ) NEW_LINE self . proc . join ( ) NEW_LINE DEDENT def kill ( self ) : NEW_LINE INDENT self . stop . set ( ) NEW_LINE self . proc . terminate ( ) NEW_LINE self . proc . join ( ) NEW_LINE DEDENT def is_alive ( self ) : NEW_LINE INDENT return self . proc . is_alive ( ) NEW_LINE DEDENT DEDENT def check_subdomains ( host , paths , bind_hostname , ssl_config ) : NEW_LINE INDENT port = get_port ( ) NEW_LINE subdomains = get_subdomains ( host ) NEW_LINE wrapper = ServerProc ( ) NEW_LINE wrapper . start ( start_http_server , host , port , paths , default_routes ( ) , bind_hostname , None , ssl_config ) NEW_LINE connected = False NEW_LINE for i in range ( 10 ) : NEW_LINE INDENT try : NEW_LINE INDENT urllib2 . urlopen ( " http : / / % s : % d / " % ( host , port ) ) NEW_LINE connected = True NEW_LINE break NEW_LINE DEDENT except urllib2 . URLError : NEW_LINE INDENT time . sleep ( 1 ) NEW_LINE DEDENT DEDENT if not connected : NEW_LINE INDENT logger . critical ( " Failed ▁ to ▁ connect ▁ to ▁ test ▁ server ▁ on ▁ http : / / % s : % s ▁ You ▁ may ▁ need ▁ to ▁ edit ▁ / etc / hosts ▁ or ▁ similar " % ( host , port ) ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT for subdomain , ( punycode , host ) in subdomains . iteritems ( ) : NEW_LINE INDENT domain = " % s . % s " % ( punycode , host ) NEW_LINE try : NEW_LINE INDENT urllib2 . urlopen ( " http : / / % s : % d / " % ( domain , port ) ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT logger . critical ( " Failed ▁ probing ▁ domain ▁ % s . ▁ You ▁ may ▁ need ▁ to ▁ edit ▁ / etc / hosts ▁ or ▁ similar . " % domain ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT DEDENT wrapper . wait ( ) NEW_LINE DEDENT def get_subdomains ( host ) : NEW_LINE INDENT return { subdomain : ( subdomain . encode ( " idna " ) , host ) for subdomain in subdomains } NEW_LINE DEDENT def start_servers ( host , ports , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT servers = defaultdict ( list ) NEW_LINE for scheme , ports in ports . iteritems ( ) : NEW_LINE INDENT assert len ( ports ) == { " http " : 2 } . get ( scheme , 1 ) NEW_LINE for port in ports : NEW_LINE INDENT if port is None : NEW_LINE INDENT continue NEW_LINE DEDENT init_func = { " http " : start_http_server , " https " : start_https_server , " ws " : start_ws_server , " wss " : start_wss_server } [ scheme ] NEW_LINE server_proc = ServerProc ( ) NEW_LINE server_proc . start ( init_func , host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE servers [ scheme ] . append ( ( port , server_proc ) ) NEW_LINE DEDENT DEDENT return servers NEW_LINE DEDENT def start_http_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return wptserve . WebTestHttpd ( host = host , port = port , doc_root = paths [ " doc _ root " ] , routes = routes , rewrites = rewrites , bind_hostname = bind_hostname , config = external_config , use_ssl = False , key_file = None , certificate = None , latency = kwargs . get ( " latency " ) ) NEW_LINE DEDENT def start_https_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return wptserve . WebTestHttpd ( host = host , port = port , doc_root = paths [ " doc _ root " ] , routes = routes , rewrites = rewrites , bind_hostname = bind_hostname , config = external_config , use_ssl = True , key_file = ssl_config [ " key _ path " ] , certificate = ssl_config [ " cert _ path " ] , encrypt_after_connect = ssl_config [ " encrypt _ after _ connect " ] , latency = kwargs . get ( " latency " ) ) NEW_LINE DEDENT class WebSocketDaemon ( object ) : NEW_LINE INDENT def __init__ ( self , host , port , doc_root , handlers_root , log_level , bind_hostname , ssl_config ) : NEW_LINE INDENT self . host = host NEW_LINE cmd_args = [ " - p " , port , " - d " , doc_root , " - w " , handlers_root , " - - log - level " , log_level ] NEW_LINE if ssl_config is not None : NEW_LINE INDENT if pywebsocket . _import_ssl ( ) : NEW_LINE INDENT tls_module = pywebsocket . _TLS_BY_STANDARD_MODULE NEW_LINE DEDENT elif pywebsocket . _import_pyopenssl ( ) : NEW_LINE INDENT tls_module = pywebsocket . _TLS_BY_PYOPENSSL NEW_LINE DEDENT else : NEW_LINE INDENT print " No ▁ SSL ▁ module ▁ available " NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT cmd_args += [ " - - tls " , " - - private - key " , ssl_config [ " key _ path " ] , " - - certificate " , ssl_config [ " cert _ path " ] , " - - tls - module " , tls_module ] NEW_LINE DEDENT if ( bind_hostname ) : NEW_LINE INDENT cmd_args = [ " - H " , host ] + cmd_args NEW_LINE DEDENT opts , args = pywebsocket . _parse_args_and_config ( cmd_args ) NEW_LINE opts . cgi_directories = [ ] NEW_LINE opts . is_executable_method = None NEW_LINE self . server = pywebsocket . WebSocketServer ( opts ) NEW_LINE ports = [ item [ 0 ] . getsockname ( ) [ 1 ] for item in self . server . _sockets ] NEW_LINE assert all ( item == ports [ 0 ] for item in ports ) NEW_LINE self . port = ports [ 0 ] NEW_LINE self . started = False NEW_LINE self . server_thread = None NEW_LINE DEDENT def start ( self , block = False ) : NEW_LINE INDENT self . started = True NEW_LINE if block : NEW_LINE INDENT self . server . serve_forever ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . server_thread = threading . Thread ( target = self . server . serve_forever ) NEW_LINE self . server_thread . setDaemon ( True ) NEW_LINE self . server_thread . start ( ) NEW_LINE DEDENT DEDENT def stop ( self ) : NEW_LINE INDENT if self . started : NEW_LINE INDENT try : NEW_LINE INDENT self . server . shutdown ( ) NEW_LINE self . server . server_close ( ) NEW_LINE self . server_thread . join ( ) NEW_LINE self . server_thread = None NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT pass NEW_LINE DEDENT self . started = False NEW_LINE DEDENT self . server = None NEW_LINE DEDENT DEDENT def start_ws_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return WebSocketDaemon ( host , str ( port ) , repo_root , paths [ " ws _ doc _ root " ] , " debug " , bind_hostname , ssl_config = None ) NEW_LINE DEDENT def start_wss_server ( host , port , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) : NEW_LINE INDENT return WebSocketDaemon ( host , str ( port ) , repo_root , paths [ " ws _ doc _ root " ] , " debug " , bind_hostname , ssl_config ) NEW_LINE DEDENT def get_ports ( config , ssl_environment ) : NEW_LINE INDENT rv = defaultdict ( list ) NEW_LINE for scheme , ports in config [ " ports " ] . iteritems ( ) : NEW_LINE INDENT for i , port in enumerate ( ports ) : NEW_LINE INDENT if scheme in [ " wss " , " https " ] and not ssl_environment . ssl_enabled : NEW_LINE INDENT port = None NEW_LINE DEDENT if port == " auto " : NEW_LINE INDENT port = get_port ( ) NEW_LINE DEDENT else : NEW_LINE INDENT port = port NEW_LINE DEDENT rv [ scheme ] . append ( port ) NEW_LINE DEDENT DEDENT return rv NEW_LINE DEDENT def normalise_config ( config , ports ) : NEW_LINE INDENT host = config [ " external _ host " ] if config [ " external _ host " ] else config [ " host " ] NEW_LINE domains = get_subdomains ( host ) NEW_LINE ports_ = { } NEW_LINE for scheme , ports_used in ports . iteritems ( ) : NEW_LINE INDENT ports_ [ scheme ] = ports_used NEW_LINE DEDENT for key , value in domains . iteritems ( ) : NEW_LINE INDENT domains [ key ] = " . " . join ( value ) NEW_LINE DEDENT domains [ " " ] = host NEW_LINE ports_ = { } NEW_LINE for scheme , ports_used in ports . iteritems ( ) : NEW_LINE INDENT ports_ [ scheme ] = ports_used NEW_LINE DEDENT return { " host " : host , " domains " : domains , " ports " : ports_ } NEW_LINE DEDENT def get_ssl_config ( config , external_domains , ssl_environment ) : NEW_LINE INDENT key_path , cert_path = ssl_environment . host_cert_path ( external_domains ) NEW_LINE return { " key _ path " : key_path , " cert _ path " : cert_path , " encrypt _ after _ connect " : config [ " ssl " ] [ " encrypt _ after _ connect " ] } NEW_LINE DEDENT def start ( config , ssl_environment , routes , ** kwargs ) : NEW_LINE INDENT host = config [ " host " ] NEW_LINE domains = get_subdomains ( host ) NEW_LINE ports = get_ports ( config , ssl_environment ) NEW_LINE bind_hostname = config [ " bind _ hostname " ] NEW_LINE paths = { " doc _ root " : config [ " doc _ root " ] , " ws _ doc _ root " : config [ " ws _ doc _ root " ] } NEW_LINE external_config = normalise_config ( config , ports ) NEW_LINE ssl_config = get_ssl_config ( config , external_config [ " domains " ] . values ( ) , ssl_environment ) NEW_LINE if config [ " check _ subdomains " ] : NEW_LINE INDENT check_subdomains ( host , paths , bind_hostname , ssl_config ) NEW_LINE DEDENT servers = start_servers ( host , ports , paths , routes , bind_hostname , external_config , ssl_config , ** kwargs ) NEW_LINE return external_config , servers NEW_LINE DEDENT def iter_procs ( servers ) : NEW_LINE INDENT for servers in servers . values ( ) : NEW_LINE INDENT for port , server in servers : NEW_LINE INDENT yield server . proc NEW_LINE DEDENT DEDENT DEDENT def value_set ( config , key ) : NEW_LINE INDENT return key in config and config [ key ] is not None NEW_LINE DEDENT def get_value_or_default ( config , key , default = None ) : NEW_LINE INDENT return config [ key ] if value_set ( config , key ) else default NEW_LINE DEDENT def set_computed_defaults ( config ) : NEW_LINE INDENT if not value_set ( config , " doc _ root " ) : NEW_LINE INDENT config [ " doc _ root " ] = repo_root NEW_LINE DEDENT if not value_set ( config , " ws _ doc _ root " ) : NEW_LINE INDENT root = get_value_or_default ( config , " doc _ root " , default = repo_root ) NEW_LINE config [ " ws _ doc _ root " ] = os . path . join ( root , " websockets " , " handlers " ) NEW_LINE DEDENT DEDENT def merge_json ( base_obj , override_obj ) : NEW_LINE INDENT rv = { } NEW_LINE for key , value in base_obj . iteritems ( ) : NEW_LINE INDENT if key not in override_obj : NEW_LINE INDENT rv [ key ] = value NEW_LINE DEDENT else : NEW_LINE INDENT if isinstance ( value , dict ) : NEW_LINE INDENT rv [ key ] = merge_json ( value , override_obj [ key ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rv [ key ] = override_obj [ key ] NEW_LINE DEDENT DEDENT DEDENT return rv NEW_LINE DEDENT def get_ssl_environment ( config ) : NEW_LINE INDENT implementation_type = config [ " ssl " ] [ " type " ] NEW_LINE cls = sslutils . environments [ implementation_type ] NEW_LINE try : NEW_LINE INDENT kwargs = config [ " ssl " ] [ implementation_type ] . copy ( ) NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ValueError ( " % s ▁ is ▁ not ▁ a ▁ vaid ▁ ssl ▁ type . " % implementation_type ) NEW_LINE DEDENT return cls ( logger , ** kwargs ) NEW_LINE DEDENT def load_config ( default_path , override_path = None , ** kwargs ) : NEW_LINE INDENT if os . path . exists ( default_path ) : NEW_LINE INDENT with open ( default_path ) as f : NEW_LINE INDENT base_obj = json . load ( f ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise ValueError ( " Config ▁ path ▁ % s ▁ does ▁ not ▁ exist " % default_path ) NEW_LINE DEDENT if os . path . exists ( override_path ) : NEW_LINE INDENT with open ( override_path ) as f : NEW_LINE INDENT override_obj = json . load ( f ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT override_obj = { } NEW_LINE DEDENT rv = merge_json ( base_obj , override_obj ) NEW_LINE if kwargs . get ( " config _ path " ) : NEW_LINE INDENT other_path = os . path . abspath ( os . path . expanduser ( kwargs . get ( " config _ path " ) ) ) NEW_LINE if os . path . exists ( other_path ) : NEW_LINE INDENT base_obj = rv NEW_LINE with open ( other_path ) as f : NEW_LINE INDENT override_obj = json . load ( f ) NEW_LINE DEDENT rv = merge_json ( base_obj , override_obj ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( " Config ▁ path ▁ % s ▁ does ▁ not ▁ exist " % other_path ) NEW_LINE DEDENT DEDENT overriding_path_args = [ ( " doc _ root " , " Document ▁ root " ) , ( " ws _ doc _ root " , " WebSockets ▁ document ▁ root " ) ] NEW_LINE for key , title in overriding_path_args : NEW_LINE INDENT value = kwargs . get ( key ) NEW_LINE if value is None : NEW_LINE INDENT continue NEW_LINE DEDENT value = os . path . abspath ( os . path . expanduser ( value ) ) NEW_LINE if not os . path . exists ( value ) : NEW_LINE INDENT raise ValueError ( " % s ▁ path ▁ % s ▁ does ▁ not ▁ exist " % ( title , value ) ) NEW_LINE DEDENT rv [ key ] = value NEW_LINE DEDENT set_computed_defaults ( rv ) NEW_LINE return rv NEW_LINE DEDENT def get_parser ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( ) NEW_LINE parser . add_argument ( " - - latency " , type = int , help = " Artificial ▁ latency ▁ to ▁ add ▁ before ▁ sending ▁ http ▁ responses , ▁ in ▁ ms " ) NEW_LINE parser . add_argument ( " - - config " , action = " store " , dest = " config _ path " , help = " Path ▁ to ▁ external ▁ config ▁ file " ) NEW_LINE parser . add_argument ( " - - doc _ root " , action = " store " , dest = " doc _ root " , help = " Path ▁ to ▁ document ▁ root . ▁ Overrides ▁ config . " ) NEW_LINE parser . add_argument ( " - - ws _ doc _ root " , action = " store " , dest = " ws _ doc _ root " , help = " Path ▁ to ▁ WebSockets ▁ document ▁ root . ▁ Overrides ▁ config . " ) NEW_LINE return parser NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT kwargs = vars ( get_parser ( ) . parse_args ( ) ) NEW_LINE config = load_config ( " config . default . json " , " config . json " , ** kwargs ) NEW_LINE setup_logger ( config [ " log _ level " ] ) NEW_LINE with stash . StashServer ( ( config [ " host " ] , get_port ( ) ) , authkey = str ( uuid . uuid4 ( ) ) ) : NEW_LINE INDENT with get_ssl_environment ( config ) as ssl_env : NEW_LINE INDENT config_ , servers = start ( config , ssl_env , default_routes ( ) , ** kwargs ) NEW_LINE try : NEW_LINE INDENT while any ( item . is_alive ( ) for item in iter_procs ( servers ) ) : NEW_LINE INDENT for item in iter_procs ( servers ) : NEW_LINE INDENT item . join ( 1 ) NEW_LINE DEDENT DEDENT DEDENT except KeyboardInterrupt : NEW_LINE INDENT logger . info ( " Shutting ▁ down " ) NEW_LINE DEDENT DEDENT DEDENT DEDENT
 from __future__ import ( unicode_literals , absolute_import , print_function , division , ) NEW_LINE import argparse NEW_LINE import sys NEW_LINE import textwrap NEW_LINE import warnings NEW_LINE import webbrowser NEW_LINE from gpiozero import pi_info NEW_LINE class PinoutTool ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . parser = argparse . ArgumentParser ( description = __doc__ ) NEW_LINE self . parser . add_argument ( ' - r ' , ' - - revision ' , dest = ' revision ' , default = ' ' , help = ' RPi ▁ revision . ▁ Default ▁ is ▁ to ▁ autodetect ▁ revision ▁ of ▁ current ▁ device ' ) NEW_LINE self . parser . add_argument ( ' - c ' , ' - - color ' , action = " store _ true " , default = None , help = ' Force ▁ colored ▁ output ▁ ( by ▁ default , ▁ the ▁ output ▁ will ▁ include ▁ ANSI ' ' color ▁ codes ▁ if ▁ run ▁ in ▁ a ▁ color - capable ▁ terminal ) . ▁ See ▁ also ▁ - - monochrome ' ) NEW_LINE self . parser . add_argument ( ' - m ' , ' - - monochrome ' , dest = ' color ' , action = ' store _ false ' , help = ' Force ▁ monochrome ▁ output . ▁ See ▁ also ▁ - - color ' ) NEW_LINE self . parser . add_argument ( ' - x ' , ' - - xyz ' , dest = ' xyz ' , action = ' store _ true ' , help = ' Open ▁ pinout . xyz ▁ in ▁ the ▁ default ▁ web ▁ browser ' ) NEW_LINE DEDENT def __call__ ( self , args = None ) : NEW_LINE INDENT if args is None : NEW_LINE INDENT args = sys . argv [ 1 : ] NEW_LINE DEDENT try : NEW_LINE INDENT return self . main ( self . parser . parse_args ( args ) ) or 0 NEW_LINE DEDENT except argparse . ArgumentError as e : NEW_LINE INDENT raise e NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT raise NEW_LINE self . parser . exit ( 1 , ' { prog } : ▁ error : ▁ { message } \n ' . format ( prog = self . parser . prog , message = e ) ) NEW_LINE DEDENT DEDENT def main ( self , args ) : NEW_LINE INDENT warnings . simplefilter ( ' ignore ' ) NEW_LINE if args . xyz : NEW_LINE INDENT webbrowser . open ( ' https : / / pinout . xyz ' ) NEW_LINE DEDENT else : NEW_LINE INDENT if args . revision == ' ' : NEW_LINE INDENT try : NEW_LINE INDENT pi_info ( ) . pprint ( color = args . color ) NEW_LINE DEDENT except ImportError : NEW_LINE INDENT formatter = self . parser . _get_formatter ( ) NEW_LINE formatter . add_text ( " Unable ▁ to ▁ initialize ▁ GPIO ▁ Zero . ▁ This ▁ usually ▁ means ▁ " " that ▁ you ▁ are ▁ not ▁ running ▁ % ( prog ) s ▁ on ▁ a ▁ Raspberry ▁ Pi . ▁ " " If ▁ you ▁ still ▁ wish ▁ to ▁ run ▁ % ( prog ) s , ▁ set ▁ the ▁ " " GPIOZERO _ PIN _ FACTORY ▁ environment ▁ variable ▁ to ▁ ' mock ' ▁ " " and ▁ retry , ▁ or ▁ refer ▁ to ▁ the ▁ Remote ▁ GPIO ▁ section ▁ of ▁ " " the ▁ manual * ▁ to ▁ configure ▁ your ▁ environment ▁ to ▁ " " remotely ▁ access ▁ your ▁ Pi . " ) NEW_LINE formatter . add_text ( " * ▁ https : / / gpiozero . readthedocs . io / en / stable / " " remote _ gpio . html " ) NEW_LINE sys . stderr . write ( formatter . format_help ( ) ) NEW_LINE DEDENT except IOError : NEW_LINE INDENT raise IOError ( ' This ▁ device ▁ is ▁ not ▁ a ▁ Raspberry ▁ Pi ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT pi_info ( args . revision ) . pprint ( color = args . color ) NEW_LINE DEDENT formatter = self . parser . _get_formatter ( ) NEW_LINE formatter . add_text ( " For ▁ further ▁ information , ▁ please ▁ refer ▁ to ▁ " " https : / / pinout . xyz / " ) NEW_LINE sys . stdout . write ( ' \n ' ) NEW_LINE sys . stdout . write ( formatter . format_help ( ) ) NEW_LINE DEDENT DEDENT DEDENT main = PinoutTool ( ) NEW_LINE
 import Utils NEW_LINE from Element import Element NEW_LINE import Colors NEW_LINE from Constants import CONNECTOR_ARROW_BASE , CONNECTOR_ARROW_HEIGHT NEW_LINE class Connection ( Element ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT Element . __init__ ( self ) NEW_LINE DEDENT def get_coordinate ( self ) : NEW_LINE INDENT return ( 0 , 0 ) NEW_LINE DEDENT def get_rotation ( self ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT def create_shapes ( self ) : NEW_LINE INDENT Element . create_shapes ( self ) NEW_LINE self . _sink_rot = None NEW_LINE self . _source_rot = None NEW_LINE self . _sink_coor = None NEW_LINE self . _source_coor = None NEW_LINE connector_length = self . get_source ( ) . get_connector_length ( ) NEW_LINE self . x1 , self . y1 = Utils . get_rotated_coordinate ( ( connector_length , 0 ) , self . get_source ( ) . get_rotation ( ) ) NEW_LINE connector_length = self . get_sink ( ) . get_connector_length ( ) + CONNECTOR_ARROW_HEIGHT NEW_LINE self . x2 , self . y2 = Utils . get_rotated_coordinate ( ( - connector_length , 0 ) , self . get_sink ( ) . get_rotation ( ) ) NEW_LINE self . arrow = [ ( 0 , 0 ) , Utils . get_rotated_coordinate ( ( - CONNECTOR_ARROW_HEIGHT , - CONNECTOR_ARROW_BASE / 2 ) , self . get_sink ( ) . get_rotation ( ) ) , Utils . get_rotated_coordinate ( ( - CONNECTOR_ARROW_HEIGHT , CONNECTOR_ARROW_BASE / 2 ) , self . get_sink ( ) . get_rotation ( ) ) , ] NEW_LINE self . _update_after_move ( ) NEW_LINE if not self . get_enabled ( ) : NEW_LINE INDENT self . _arrow_color = Colors . CONNECTION_DISABLED_COLOR NEW_LINE DEDENT elif not self . is_valid ( ) : NEW_LINE INDENT self . _arrow_color = Colors . CONNECTION_ERROR_COLOR NEW_LINE DEDENT else : NEW_LINE INDENT self . _arrow_color = Colors . CONNECTION_ENABLED_COLOR NEW_LINE DEDENT DEDENT def _update_after_move ( self ) : NEW_LINE INDENT self . clear ( ) NEW_LINE source = self . get_source ( ) NEW_LINE X , Y = source . get_connector_coordinate ( ) NEW_LINE x1 , y1 = self . x1 + X , self . y1 + Y NEW_LINE self . add_line ( ( x1 , y1 ) , ( X , Y ) ) NEW_LINE sink = self . get_sink ( ) NEW_LINE X , Y = sink . get_connector_coordinate ( ) NEW_LINE x2 , y2 = self . x2 + X , self . y2 + Y NEW_LINE self . add_line ( ( x2 , y2 ) , ( X , Y ) ) NEW_LINE self . _arrow = [ ( x + X , y + Y ) for x , y in self . arrow ] NEW_LINE if abs ( source . get_connector_direction ( ) - sink . get_connector_direction ( ) ) == 180 : NEW_LINE INDENT mid_x , mid_y = ( x1 + x2 ) / 2.0 , ( y1 + y2 ) / 2.0 NEW_LINE points = [ ( ( mid_x , y1 ) , ( mid_x , y2 ) ) , ( ( x1 , mid_y ) , ( x2 , mid_y ) ) ] NEW_LINE if Utils . get_angle_from_coordinates ( ( x1 , y1 ) , points [ 0 ] [ 0 ] ) != source . get_connector_direction ( ) : NEW_LINE INDENT points . reverse ( ) NEW_LINE DEDENT if Utils . get_angle_from_coordinates ( points [ 0 ] [ 0 ] , ( x2 , y2 ) ) == sink . get_connector_direction ( ) : NEW_LINE INDENT points . reverse ( ) NEW_LINE DEDENT if Utils . get_angle_from_coordinates ( points [ 0 ] [ 0 ] , ( x1 , y1 ) ) == source . get_connector_direction ( ) : NEW_LINE INDENT points . reverse ( ) NEW_LINE DEDENT p1 , p2 = map ( int , points [ 0 ] [ 0 ] ) , map ( int , points [ 0 ] [ 1 ] ) NEW_LINE self . add_line ( ( x1 , y1 ) , p1 ) NEW_LINE self . add_line ( p1 , p2 ) NEW_LINE self . add_line ( ( x2 , y2 ) , p2 ) NEW_LINE DEDENT else : NEW_LINE INDENT points = [ ( x1 , y2 ) , ( x2 , y1 ) ] NEW_LINE if Utils . get_angle_from_coordinates ( ( x1 , y1 ) , points [ 0 ] ) != source . get_connector_direction ( ) : NEW_LINE INDENT points . reverse ( ) NEW_LINE DEDENT if Utils . get_angle_from_coordinates ( points [ 0 ] , ( x2 , y2 ) ) == sink . get_connector_direction ( ) : NEW_LINE INDENT points . reverse ( ) NEW_LINE DEDENT if Utils . get_angle_from_coordinates ( points [ 0 ] , ( x1 , y1 ) ) == source . get_connector_direction ( ) : NEW_LINE INDENT points . reverse ( ) NEW_LINE DEDENT self . add_line ( ( x1 , y1 ) , points [ 0 ] ) NEW_LINE self . add_line ( ( x2 , y2 ) , points [ 0 ] ) NEW_LINE DEDENT DEDENT def draw ( self , gc , window ) : NEW_LINE INDENT sink = self . get_sink ( ) NEW_LINE source = self . get_source ( ) NEW_LINE if self . _sink_rot != sink . get_rotation ( ) or self . _source_rot != source . get_rotation ( ) : NEW_LINE INDENT self . create_shapes ( ) NEW_LINE DEDENT elif self . _sink_coor != sink . get_coordinate ( ) or self . _source_coor != source . get_coordinate ( ) : NEW_LINE INDENT self . _update_after_move ( ) NEW_LINE DEDENT self . _sink_rot = sink . get_rotation ( ) NEW_LINE self . _source_rot = source . get_rotation ( ) NEW_LINE self . _sink_coor = sink . get_coordinate ( ) NEW_LINE self . _source_coor = source . get_coordinate ( ) NEW_LINE if self . is_highlighted ( ) : NEW_LINE INDENT border_color = Colors . HIGHLIGHT_COLOR NEW_LINE DEDENT elif self . get_enabled ( ) : NEW_LINE INDENT border_color = Colors . CONNECTION_ENABLED_COLOR NEW_LINE DEDENT else : NEW_LINE INDENT border_color = Colors . CONNECTION_DISABLED_COLOR NEW_LINE DEDENT Element . draw ( self , gc , window , bg_color = None , border_color = border_color ) NEW_LINE gc . set_foreground ( self . _arrow_color ) NEW_LINE window . draw_polygon ( gc , True , self . _arrow ) NEW_LINE DEDENT DEDENT
 import codecs NEW_LINE class Codec ( codecs . Codec ) : NEW_LINE INDENT def encode ( self , input , errors = ' strict ' ) : NEW_LINE INDENT return codecs . charmap_encode ( input , errors , encoding_table ) NEW_LINE DEDENT def decode ( self , input , errors = ' strict ' ) : NEW_LINE INDENT return codecs . charmap_decode ( input , errors , decoding_table ) NEW_LINE DEDENT DEDENT class IncrementalEncoder ( codecs . IncrementalEncoder ) : NEW_LINE INDENT def encode ( self , input , final = False ) : NEW_LINE INDENT return codecs . charmap_encode ( input , self . errors , encoding_table ) [ 0 ] NEW_LINE DEDENT DEDENT class IncrementalDecoder ( codecs . IncrementalDecoder ) : NEW_LINE INDENT def decode ( self , input , final = False ) : NEW_LINE INDENT return codecs . charmap_decode ( input , self . errors , decoding_table ) [ 0 ] NEW_LINE DEDENT DEDENT class StreamWriter ( Codec , codecs . StreamWriter ) : NEW_LINE INDENT pass NEW_LINE DEDENT class StreamReader ( Codec , codecs . StreamReader ) : NEW_LINE INDENT pass NEW_LINE DEDENT def getregentry ( ) : NEW_LINE INDENT return codecs . CodecInfo ( name = ' cp1006' , encode = Codec ( ) . encode , decode = Codec ( ) . decode , incrementalencoder = IncrementalEncoder , incrementaldecoder = IncrementalDecoder , streamreader = StreamReader , streamwriter = StreamWriter , ) NEW_LINE DEDENT decoding_table = ( ' \x00' ' \x01' ' \x02' ' \x03' ' \x04' ' \x05' ' \x06' ' \x07' ' \x08' ' \t ' ' \n ' ' \x0b ' ' \x0c ' ' \r ' ' \x0e ' ' \x0f ' ' \x10' ' \x11' ' \x12' ' \x13' ' \x14' ' \x15' ' \x16' ' \x17' ' \x18' ' \x19' ' \x1a ' ' \x1b ' ' \x1c ' ' \x1d ' ' \x1e ' ' \x1f ' ' ▁ ' ' ! ' ' " ' ' # ' ' $ ' ' % ' ' & ' " ' " ' ( ' ' ) ' ' * ' ' + ' ' , ' ' - ' ' . ' ' / ' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' ' : ' ' ; ' ' < ' ' = ' ' > ' ' ? ' ' @ ' ' A ' ' B ' ' C ' ' D ' ' E ' ' F ' ' G ' ' H ' ' I ' ' J ' ' K ' ' L ' ' M ' ' N ' ' O ' ' P ' ' Q ' ' R ' ' S ' ' T ' ' U ' ' V ' ' W ' ' X ' ' Y ' ' Z ' ' [ ' ' \\ ' ' ] ' ' ^ ' ' _ ' ' ` ' ' a ' ' b ' ' c ' ' d ' ' e ' ' f ' ' g ' ' h ' ' i ' ' j ' ' k ' ' l ' ' m ' ' n ' ' o ' ' p ' ' q ' ' r ' ' s ' ' t ' ' u ' ' v ' ' w ' ' x ' ' y ' ' z ' ' { ' ' | ' ' } ' ' ~ ' ' \x7f ' ' \x80' ' \x81' ' \x82' ' \x83' ' \x84' ' \x85' ' \x86' ' \x87' ' \x88' ' \x89' ' \x8a ' ' \x8b ' ' \x8c ' ' \x8d ' ' \x8e ' ' \x8f ' ' \x90' ' \x91' ' \x92' ' \x93' ' \x94' ' \x95' ' \x96' ' \x97' ' \x98' ' \x99' ' \x9a ' ' \x9b ' ' \x9c ' ' \x9d ' ' \x9e ' ' \x9f ' ' \xa0' ' \u06f0' ' \u06f1' ' \u06f2' ' \u06f3' ' \u06f4' ' \u06f5' ' \u06f6' ' \u06f7' ' \u06f8' ' \u06f9' ' \u060c ' ' \u061b ' ' \xad ' ' \u061f ' ' \ufe81' ' \ufe8d ' ' \ufe8e ' ' \ufe8e ' ' \ufe8f ' ' \ufe91' ' \ufb56' ' \ufb58' ' \ufe93' ' \ufe95' ' \ufe97' ' \ufb66' ' \ufb68' ' \ufe99' ' \ufe9b ' ' \ufe9d ' ' \ufe9f ' ' \ufb7a ' ' \ufb7c ' ' \ufea1' ' \ufea3' ' \ufea5' ' \ufea7' ' \ufea9' ' \ufb84' ' \ufeab ' ' \ufead ' ' \ufb8c ' ' \ufeaf ' ' \ufb8a ' ' \ufeb1' ' \ufeb3' ' \ufeb5' ' \ufeb7' ' \ufeb9' ' \ufebb ' ' \ufebd ' ' \ufebf ' ' \ufec1' ' \ufec5' ' \ufec9' ' \ufeca ' ' \ufecb ' ' \ufecc ' ' \ufecd ' ' \ufece ' ' \ufecf ' ' \ufed0' ' \ufed1' ' \ufed3' ' \ufed5' ' \ufed7' ' \ufed9' ' \ufedb ' ' \ufb92' ' \ufb94' ' \ufedd ' ' \ufedf ' ' \ufee0' ' \ufee1' ' \ufee3' ' \ufb9e ' ' \ufee5' ' \ufee7' ' \ufe85' ' \ufeed ' ' \ufba6' ' \ufba8' ' \ufba9' ' \ufbaa ' ' \ufe80' ' \ufe89' ' \ufe8a ' ' \ufe8b ' ' \ufef1' ' \ufef2' ' \ufef3' ' \ufbb0' ' \ufbae ' ' \ufe7c ' ' \ufe7d ' ) NEW_LINE encoding_table = codecs . charmap_build ( decoding_table ) NEW_LINE
 from __future__ import absolute_import , division , unicode_literals NEW_LINE try : NEW_LINE INDENT from collections import OrderedDict NEW_LINE DEDENT except ImportError : NEW_LINE INDENT try : NEW_LINE INDENT from ordereddict import OrderedDict NEW_LINE DEDENT except ImportError : NEW_LINE INDENT OrderedDict = dict NEW_LINE DEDENT DEDENT import re NEW_LINE from six import string_types NEW_LINE from . import _base NEW_LINE from . . utils import moduleFactoryFactory NEW_LINE tag_regexp = re . compile ( " { ( [ ^ } ] * ) } ( . * ) " ) NEW_LINE def getETreeBuilder ( ElementTreeImplementation ) : NEW_LINE INDENT ElementTree = ElementTreeImplementation NEW_LINE ElementTreeCommentType = ElementTree . Comment ( " asd " ) . tag NEW_LINE class TreeWalker ( _base . NonRecursiveTreeWalker ) : NEW_LINE INDENT def getNodeDetails ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT elt , key , parents , flag = node NEW_LINE if flag in ( " text " , " tail " ) : NEW_LINE INDENT return _base . TEXT , getattr ( elt , flag ) NEW_LINE DEDENT else : NEW_LINE INDENT node = elt NEW_LINE DEDENT DEDENT if not ( hasattr ( node , " tag " ) ) : NEW_LINE INDENT node = node . getroot ( ) NEW_LINE DEDENT if node . tag in ( " DOCUMENT _ ROOT " , " DOCUMENT _ FRAGMENT " ) : NEW_LINE INDENT return ( _base . DOCUMENT , ) NEW_LINE DEDENT elif node . tag == " < ! DOCTYPE > " : NEW_LINE INDENT return ( _base . DOCTYPE , node . text , node . get ( " publicId " ) , node . get ( " systemId " ) ) NEW_LINE DEDENT elif node . tag == ElementTreeCommentType : NEW_LINE INDENT return _base . COMMENT , node . text NEW_LINE DEDENT else : NEW_LINE INDENT assert isinstance ( node . tag , string_types ) , type ( node . tag ) NEW_LINE match = tag_regexp . match ( node . tag ) NEW_LINE if match : NEW_LINE INDENT namespace , tag = match . groups ( ) NEW_LINE DEDENT else : NEW_LINE INDENT namespace = None NEW_LINE tag = node . tag NEW_LINE DEDENT attrs = OrderedDict ( ) NEW_LINE for name , value in list ( node . attrib . items ( ) ) : NEW_LINE INDENT match = tag_regexp . match ( name ) NEW_LINE if match : NEW_LINE INDENT attrs [ ( match . group ( 1 ) , match . group ( 2 ) ) ] = value NEW_LINE DEDENT else : NEW_LINE INDENT attrs [ ( None , name ) ] = value NEW_LINE DEDENT DEDENT return ( _base . ELEMENT , namespace , tag , attrs , len ( node ) or node . text ) NEW_LINE DEDENT DEDENT def getFirstChild ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT element , key , parents , flag = node , None , [ ] , None NEW_LINE DEDENT if flag in ( " text " , " tail " ) : NEW_LINE INDENT return None NEW_LINE DEDENT else : NEW_LINE INDENT if element . text : NEW_LINE INDENT return element , key , parents , " text " NEW_LINE DEDENT elif len ( element ) : NEW_LINE INDENT parents . append ( element ) NEW_LINE return element [ 0 ] , 0 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT DEDENT def getNextSibling ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT if flag == " text " : NEW_LINE INDENT if len ( element ) : NEW_LINE INDENT parents . append ( element ) NEW_LINE return element [ 0 ] , 0 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if element . tail and flag != " tail " : NEW_LINE INDENT return element , key , parents , " tail " NEW_LINE DEDENT elif key < len ( parents [ - 1 ] ) - 1 : NEW_LINE INDENT return parents [ - 1 ] [ key + 1 ] , key + 1 , parents , None NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT DEDENT def getParentNode ( self , node ) : NEW_LINE INDENT if isinstance ( node , tuple ) : NEW_LINE INDENT element , key , parents , flag = node NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT if flag == " text " : NEW_LINE INDENT if not parents : NEW_LINE INDENT return element NEW_LINE DEDENT else : NEW_LINE INDENT return element , key , parents , None NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT parent = parents . pop ( ) NEW_LINE if not parents : NEW_LINE INDENT return parent NEW_LINE DEDENT else : NEW_LINE INDENT return parent , list ( parents [ - 1 ] ) . index ( parent ) , parents , None NEW_LINE DEDENT DEDENT DEDENT DEDENT return locals ( ) NEW_LINE DEDENT getETreeModule = moduleFactoryFactory ( getETreeBuilder ) NEW_LINE
 from __future__ import absolute_import NEW_LINE import functools NEW_LINE import itertools NEW_LINE import operator NEW_LINE import sys NEW_LINE import types NEW_LINE __author__ = " Benjamin ▁ Peterson ▁ < benjamin @ python . org > " NEW_LINE __version__ = "1.10.0" NEW_LINE PY2 = sys . version_info [ 0 ] == 2 NEW_LINE PY3 = sys . version_info [ 0 ] == 3 NEW_LINE PY34 = sys . version_info [ 0 : 2 ] >= ( 3 , 4 ) NEW_LINE if PY3 : NEW_LINE INDENT string_types = str , NEW_LINE integer_types = int , NEW_LINE class_types = type , NEW_LINE text_type = str NEW_LINE binary_type = bytes NEW_LINE MAXSIZE = sys . maxsize NEW_LINE DEDENT else : NEW_LINE INDENT string_types = basestring , NEW_LINE integer_types = ( int , long ) NEW_LINE class_types = ( type , types . ClassType ) NEW_LINE text_type = unicode NEW_LINE binary_type = str NEW_LINE if sys . platform . startswith ( " java " ) : NEW_LINE INDENT MAXSIZE = int ( ( 1 << 31 ) - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT class X ( object ) : NEW_LINE INDENT def __len__ ( self ) : NEW_LINE INDENT return 1 << 31 NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT len ( X ( ) ) NEW_LINE DEDENT except OverflowError : NEW_LINE INDENT MAXSIZE = int ( ( 1 << 31 ) - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT MAXSIZE = int ( ( 1 << 63 ) - 1 ) NEW_LINE DEDENT del X NEW_LINE DEDENT DEDENT def _add_doc ( func , doc ) : NEW_LINE INDENT func . __doc__ = doc NEW_LINE DEDENT def _import_module ( name ) : NEW_LINE INDENT __import__ ( name ) NEW_LINE return sys . modules [ name ] NEW_LINE DEDENT class _LazyDescr ( object ) : NEW_LINE INDENT def __init__ ( self , name ) : NEW_LINE INDENT self . name = name NEW_LINE DEDENT def __get__ ( self , obj , tp ) : NEW_LINE INDENT result = self . _resolve ( ) NEW_LINE setattr ( obj , self . name , result ) NEW_LINE try : NEW_LINE INDENT delattr ( obj . __class__ , self . name ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT pass NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT class MovedModule ( _LazyDescr ) : NEW_LINE INDENT def __init__ ( self , name , old , new = None ) : NEW_LINE INDENT super ( MovedModule , self ) . __init__ ( name ) NEW_LINE if PY3 : NEW_LINE INDENT if new is None : NEW_LINE INDENT new = name NEW_LINE DEDENT self . mod = new NEW_LINE DEDENT else : NEW_LINE INDENT self . mod = old NEW_LINE DEDENT DEDENT def _resolve ( self ) : NEW_LINE INDENT return _import_module ( self . mod ) NEW_LINE DEDENT def __getattr__ ( self , attr ) : NEW_LINE INDENT _module = self . _resolve ( ) NEW_LINE value = getattr ( _module , attr ) NEW_LINE setattr ( self , attr , value ) NEW_LINE return value NEW_LINE DEDENT DEDENT class _LazyModule ( types . ModuleType ) : NEW_LINE INDENT def __init__ ( self , name ) : NEW_LINE INDENT super ( _LazyModule , self ) . __init__ ( name ) NEW_LINE self . __doc__ = self . __class__ . __doc__ NEW_LINE DEDENT def __dir__ ( self ) : NEW_LINE INDENT attrs = [ " _ _ doc _ _ " , " _ _ name _ _ " ] NEW_LINE attrs += [ attr . name for attr in self . _moved_attributes ] NEW_LINE return attrs NEW_LINE DEDENT _moved_attributes = [ ] NEW_LINE DEDENT class MovedAttribute ( _LazyDescr ) : NEW_LINE INDENT def __init__ ( self , name , old_mod , new_mod , old_attr = None , new_attr = None ) : NEW_LINE INDENT super ( MovedAttribute , self ) . __init__ ( name ) NEW_LINE if PY3 : NEW_LINE INDENT if new_mod is None : NEW_LINE INDENT new_mod = name NEW_LINE DEDENT self . mod = new_mod NEW_LINE if new_attr is None : NEW_LINE INDENT if old_attr is None : NEW_LINE INDENT new_attr = name NEW_LINE DEDENT else : NEW_LINE INDENT new_attr = old_attr NEW_LINE DEDENT DEDENT self . attr = new_attr NEW_LINE DEDENT else : NEW_LINE INDENT self . mod = old_mod NEW_LINE if old_attr is None : NEW_LINE INDENT old_attr = name NEW_LINE DEDENT self . attr = old_attr NEW_LINE DEDENT DEDENT def _resolve ( self ) : NEW_LINE INDENT module = _import_module ( self . mod ) NEW_LINE return getattr ( module , self . attr ) NEW_LINE DEDENT DEDENT class _SixMetaPathImporter ( object ) : NEW_LINE INDENT def __init__ ( self , six_module_name ) : NEW_LINE INDENT self . name = six_module_name NEW_LINE self . known_modules = { } NEW_LINE DEDENT def _add_module ( self , mod , * fullnames ) : NEW_LINE INDENT for fullname in fullnames : NEW_LINE INDENT self . known_modules [ self . name + " . " + fullname ] = mod NEW_LINE DEDENT DEDENT def _get_module ( self , fullname ) : NEW_LINE INDENT return self . known_modules [ self . name + " . " + fullname ] NEW_LINE DEDENT def find_module ( self , fullname , path = None ) : NEW_LINE INDENT if fullname in self . known_modules : NEW_LINE INDENT return self NEW_LINE DEDENT return None NEW_LINE DEDENT def __get_module ( self , fullname ) : NEW_LINE INDENT try : NEW_LINE INDENT return self . known_modules [ fullname ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ImportError ( " This ▁ loader ▁ does ▁ not ▁ know ▁ module ▁ " + fullname ) NEW_LINE DEDENT DEDENT def load_module ( self , fullname ) : NEW_LINE INDENT try : NEW_LINE INDENT return sys . modules [ fullname ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT pass NEW_LINE DEDENT mod = self . __get_module ( fullname ) NEW_LINE if isinstance ( mod , MovedModule ) : NEW_LINE INDENT mod = mod . _resolve ( ) NEW_LINE DEDENT else : NEW_LINE INDENT mod . __loader__ = self NEW_LINE DEDENT sys . modules [ fullname ] = mod NEW_LINE return mod NEW_LINE DEDENT def is_package ( self , fullname ) : NEW_LINE INDENT return hasattr ( self . __get_module ( fullname ) , " _ _ path _ _ " ) NEW_LINE DEDENT def get_code ( self , fullname ) : NEW_LINE INDENT self . __get_module ( fullname ) NEW_LINE return None NEW_LINE DEDENT get_source = get_code NEW_LINE DEDENT _importer = _SixMetaPathImporter ( __name__ ) NEW_LINE class _MovedItems ( _LazyModule ) : NEW_LINE INDENT __path__ = [ ] NEW_LINE DEDENT _moved_attributes = [ MovedAttribute ( " cStringIO " , " cStringIO " , " io " , " StringIO " ) , MovedAttribute ( " filter " , " itertools " , " builtins " , " ifilter " , " filter " ) , MovedAttribute ( " filterfalse " , " itertools " , " itertools " , " ifilterfalse " , " filterfalse " ) , MovedAttribute ( " input " , " _ _ builtin _ _ " , " builtins " , " raw _ input " , " input " ) , MovedAttribute ( " intern " , " _ _ builtin _ _ " , " sys " ) , MovedAttribute ( " map " , " itertools " , " builtins " , " imap " , " map " ) , MovedAttribute ( " getcwd " , " os " , " os " , " getcwdu " , " getcwd " ) , MovedAttribute ( " getcwdb " , " os " , " os " , " getcwd " , " getcwdb " ) , MovedAttribute ( " range " , " _ _ builtin _ _ " , " builtins " , " xrange " , " range " ) , MovedAttribute ( " reload _ module " , " _ _ builtin _ _ " , " importlib " if PY34 else " imp " , " reload " ) , MovedAttribute ( " reduce " , " _ _ builtin _ _ " , " functools " ) , MovedAttribute ( " shlex _ quote " , " pipes " , " shlex " , " quote " ) , MovedAttribute ( " StringIO " , " StringIO " , " io " ) , MovedAttribute ( " UserDict " , " UserDict " , " collections " ) , MovedAttribute ( " UserList " , " UserList " , " collections " ) , MovedAttribute ( " UserString " , " UserString " , " collections " ) , MovedAttribute ( " xrange " , " _ _ builtin _ _ " , " builtins " , " xrange " , " range " ) , MovedAttribute ( " zip " , " itertools " , " builtins " , " izip " , " zip " ) , MovedAttribute ( " zip _ longest " , " itertools " , " itertools " , " izip _ longest " , " zip _ longest " ) , MovedModule ( " builtins " , " _ _ builtin _ _ " ) , MovedModule ( " configparser " , " ConfigParser " ) , MovedModule ( " copyreg " , " copy _ reg " ) , MovedModule ( " dbm _ gnu " , " gdbm " , " dbm . gnu " ) , MovedModule ( " _ dummy _ thread " , " dummy _ thread " , " _ dummy _ thread " ) , MovedModule ( " http _ cookiejar " , " cookielib " , " http . cookiejar " ) , MovedModule ( " http _ cookies " , " Cookie " , " http . cookies " ) , MovedModule ( " html _ entities " , " htmlentitydefs " , " html . entities " ) , MovedModule ( " html _ parser " , " HTMLParser " , " html . parser " ) , MovedModule ( " http _ client " , " httplib " , " http . client " ) , MovedModule ( " email _ mime _ multipart " , " email . MIMEMultipart " , " email . mime . multipart " ) , MovedModule ( " email _ mime _ nonmultipart " , " email . MIMENonMultipart " , " email . mime . nonmultipart " ) , MovedModule ( " email _ mime _ text " , " email . MIMEText " , " email . mime . text " ) , MovedModule ( " email _ mime _ base " , " email . MIMEBase " , " email . mime . base " ) , MovedModule ( " BaseHTTPServer " , " BaseHTTPServer " , " http . server " ) , MovedModule ( " CGIHTTPServer " , " CGIHTTPServer " , " http . server " ) , MovedModule ( " SimpleHTTPServer " , " SimpleHTTPServer " , " http . server " ) , MovedModule ( " cPickle " , " cPickle " , " pickle " ) , MovedModule ( " queue " , " Queue " ) , MovedModule ( " reprlib " , " repr " ) , MovedModule ( " socketserver " , " SocketServer " ) , MovedModule ( " _ thread " , " thread " , " _ thread " ) , MovedModule ( " tkinter " , " Tkinter " ) , MovedModule ( " tkinter _ dialog " , " Dialog " , " tkinter . dialog " ) , MovedModule ( " tkinter _ filedialog " , " FileDialog " , " tkinter . filedialog " ) , MovedModule ( " tkinter _ scrolledtext " , " ScrolledText " , " tkinter . scrolledtext " ) , MovedModule ( " tkinter _ simpledialog " , " SimpleDialog " , " tkinter . simpledialog " ) , MovedModule ( " tkinter _ tix " , " Tix " , " tkinter . tix " ) , MovedModule ( " tkinter _ ttk " , " ttk " , " tkinter . ttk " ) , MovedModule ( " tkinter _ constants " , " Tkconstants " , " tkinter . constants " ) , MovedModule ( " tkinter _ dnd " , " Tkdnd " , " tkinter . dnd " ) , MovedModule ( " tkinter _ colorchooser " , " tkColorChooser " , " tkinter . colorchooser " ) , MovedModule ( " tkinter _ commondialog " , " tkCommonDialog " , " tkinter . commondialog " ) , MovedModule ( " tkinter _ tkfiledialog " , " tkFileDialog " , " tkinter . filedialog " ) , MovedModule ( " tkinter _ font " , " tkFont " , " tkinter . font " ) , MovedModule ( " tkinter _ messagebox " , " tkMessageBox " , " tkinter . messagebox " ) , MovedModule ( " tkinter _ tksimpledialog " , " tkSimpleDialog " , " tkinter . simpledialog " ) , MovedModule ( " urllib _ parse " , __name__ + " . moves . urllib _ parse " , " urllib . parse " ) , MovedModule ( " urllib _ error " , __name__ + " . moves . urllib _ error " , " urllib . error " ) , MovedModule ( " urllib " , __name__ + " . moves . urllib " , __name__ + " . moves . urllib " ) , MovedModule ( " urllib _ robotparser " , " robotparser " , " urllib . robotparser " ) , MovedModule ( " xmlrpc _ client " , " xmlrpclib " , " xmlrpc . client " ) , MovedModule ( " xmlrpc _ server " , " SimpleXMLRPCServer " , " xmlrpc . server " ) , ] NEW_LINE if sys . platform == " win32" : NEW_LINE INDENT _moved_attributes += [ MovedModule ( " winreg " , " _ winreg " ) , ] NEW_LINE DEDENT for attr in _moved_attributes : NEW_LINE INDENT setattr ( _MovedItems , attr . name , attr ) NEW_LINE if isinstance ( attr , MovedModule ) : NEW_LINE INDENT _importer . _add_module ( attr , " moves . " + attr . name ) NEW_LINE DEDENT DEDENT del attr NEW_LINE _MovedItems . _moved_attributes = _moved_attributes NEW_LINE moves = _MovedItems ( __name__ + " . moves " ) NEW_LINE _importer . _add_module ( moves , " moves " ) NEW_LINE class Module_six_moves_urllib_parse ( _LazyModule ) : NEW_LINE INDENT pass NEW_LINE DEDENT _urllib_parse_moved_attributes = [ MovedAttribute ( " ParseResult " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " SplitResult " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " parse _ qs " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " parse _ qsl " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urldefrag " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urljoin " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlparse " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlsplit " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlunparse " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " urlunsplit " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " quote " , " urllib " , " urllib . parse " ) , MovedAttribute ( " quote _ plus " , " urllib " , " urllib . parse " ) , MovedAttribute ( " unquote " , " urllib " , " urllib . parse " ) , MovedAttribute ( " unquote _ plus " , " urllib " , " urllib . parse " ) , MovedAttribute ( " urlencode " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splitquery " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splittag " , " urllib " , " urllib . parse " ) , MovedAttribute ( " splituser " , " urllib " , " urllib . parse " ) , MovedAttribute ( " uses _ fragment " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ netloc " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ params " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ query " , " urlparse " , " urllib . parse " ) , MovedAttribute ( " uses _ relative " , " urlparse " , " urllib . parse " ) , ] NEW_LINE for attr in _urllib_parse_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_parse , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_parse . _moved_attributes = _urllib_parse_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_parse ( __name__ + " . moves . urllib _ parse " ) , " moves . urllib _ parse " , " moves . urllib . parse " ) NEW_LINE class Module_six_moves_urllib_error ( _LazyModule ) : NEW_LINE INDENT pass NEW_LINE DEDENT _urllib_error_moved_attributes = [ MovedAttribute ( " URLError " , " urllib2" , " urllib . error " ) , MovedAttribute ( " HTTPError " , " urllib2" , " urllib . error " ) , MovedAttribute ( " ContentTooShortError " , " urllib " , " urllib . error " ) , ] NEW_LINE for attr in _urllib_error_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_error , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_error . _moved_attributes = _urllib_error_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_error ( __name__ + " . moves . urllib . error " ) , " moves . urllib _ error " , " moves . urllib . error " ) NEW_LINE class Module_six_moves_urllib_request ( _LazyModule ) : NEW_LINE INDENT pass NEW_LINE DEDENT _urllib_request_moved_attributes = [ MovedAttribute ( " urlopen " , " urllib2" , " urllib . request " ) , MovedAttribute ( " install _ opener " , " urllib2" , " urllib . request " ) , MovedAttribute ( " build _ opener " , " urllib2" , " urllib . request " ) , MovedAttribute ( " pathname2url " , " urllib " , " urllib . request " ) , MovedAttribute ( " url2pathname " , " urllib " , " urllib . request " ) , MovedAttribute ( " getproxies " , " urllib " , " urllib . request " ) , MovedAttribute ( " Request " , " urllib2" , " urllib . request " ) , MovedAttribute ( " OpenerDirector " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPDefaultErrorHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPRedirectHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPCookieProcessor " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " BaseHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPPasswordMgr " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPPasswordMgrWithDefaultRealm " , " urllib2" , " urllib . request " ) , MovedAttribute ( " AbstractBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyBasicAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " AbstractDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " ProxyDigestAuthHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPSHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " FileHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " FTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " CacheFTPHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " UnknownHandler " , " urllib2" , " urllib . request " ) , MovedAttribute ( " HTTPErrorProcessor " , " urllib2" , " urllib . request " ) , MovedAttribute ( " urlretrieve " , " urllib " , " urllib . request " ) , MovedAttribute ( " urlcleanup " , " urllib " , " urllib . request " ) , MovedAttribute ( " URLopener " , " urllib " , " urllib . request " ) , MovedAttribute ( " FancyURLopener " , " urllib " , " urllib . request " ) , MovedAttribute ( " proxy _ bypass " , " urllib " , " urllib . request " ) , ] NEW_LINE for attr in _urllib_request_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_request , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_request . _moved_attributes = _urllib_request_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_request ( __name__ + " . moves . urllib . request " ) , " moves . urllib _ request " , " moves . urllib . request " ) NEW_LINE class Module_six_moves_urllib_response ( _LazyModule ) : NEW_LINE INDENT pass NEW_LINE DEDENT _urllib_response_moved_attributes = [ MovedAttribute ( " addbase " , " urllib " , " urllib . response " ) , MovedAttribute ( " addclosehook " , " urllib " , " urllib . response " ) , MovedAttribute ( " addinfo " , " urllib " , " urllib . response " ) , MovedAttribute ( " addinfourl " , " urllib " , " urllib . response " ) , ] NEW_LINE for attr in _urllib_response_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_response , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_response . _moved_attributes = _urllib_response_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_response ( __name__ + " . moves . urllib . response " ) , " moves . urllib _ response " , " moves . urllib . response " ) NEW_LINE class Module_six_moves_urllib_robotparser ( _LazyModule ) : NEW_LINE INDENT pass NEW_LINE DEDENT _urllib_robotparser_moved_attributes = [ MovedAttribute ( " RobotFileParser " , " robotparser " , " urllib . robotparser " ) , ] NEW_LINE for attr in _urllib_robotparser_moved_attributes : NEW_LINE INDENT setattr ( Module_six_moves_urllib_robotparser , attr . name , attr ) NEW_LINE DEDENT del attr NEW_LINE Module_six_moves_urllib_robotparser . _moved_attributes = _urllib_robotparser_moved_attributes NEW_LINE _importer . _add_module ( Module_six_moves_urllib_robotparser ( __name__ + " . moves . urllib . robotparser " ) , " moves . urllib _ robotparser " , " moves . urllib . robotparser " ) NEW_LINE class Module_six_moves_urllib ( types . ModuleType ) : NEW_LINE INDENT __path__ = [ ] NEW_LINE parse = _importer . _get_module ( " moves . urllib _ parse " ) NEW_LINE error = _importer . _get_module ( " moves . urllib _ error " ) NEW_LINE request = _importer . _get_module ( " moves . urllib _ request " ) NEW_LINE response = _importer . _get_module ( " moves . urllib _ response " ) NEW_LINE robotparser = _importer . _get_module ( " moves . urllib _ robotparser " ) NEW_LINE def __dir__ ( self ) : NEW_LINE INDENT return [ ' parse ' , ' error ' , ' request ' , ' response ' , ' robotparser ' ] NEW_LINE DEDENT DEDENT _importer . _add_module ( Module_six_moves_urllib ( __name__ + " . moves . urllib " ) , " moves . urllib " ) NEW_LINE def add_move ( move ) : NEW_LINE INDENT setattr ( _MovedItems , move . name , move ) NEW_LINE DEDENT def remove_move ( name ) : NEW_LINE INDENT try : NEW_LINE INDENT delattr ( _MovedItems , name ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT try : NEW_LINE INDENT del moves . __dict__ [ name ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise AttributeError ( " no ▁ such ▁ move , ▁ % r " % ( name , ) ) NEW_LINE DEDENT DEDENT DEDENT if PY3 : NEW_LINE INDENT _meth_func = " _ _ func _ _ " NEW_LINE _meth_self = " _ _ self _ _ " NEW_LINE _func_closure = " _ _ closure _ _ " NEW_LINE _func_code = " _ _ code _ _ " NEW_LINE _func_defaults = " _ _ defaults _ _ " NEW_LINE _func_globals = " _ _ globals _ _ " NEW_LINE DEDENT else : NEW_LINE INDENT _meth_func = " im _ func " NEW_LINE _meth_self = " im _ self " NEW_LINE _func_closure = " func _ closure " NEW_LINE _func_code = " func _ code " NEW_LINE _func_defaults = " func _ defaults " NEW_LINE _func_globals = " func _ globals " NEW_LINE DEDENT try : NEW_LINE INDENT advance_iterator = next NEW_LINE DEDENT except NameError : NEW_LINE INDENT def advance_iterator ( it ) : NEW_LINE INDENT return it . next ( ) NEW_LINE DEDENT DEDENT next = advance_iterator NEW_LINE try : NEW_LINE INDENT callable = callable NEW_LINE DEDENT except NameError : NEW_LINE INDENT def callable ( obj ) : NEW_LINE INDENT return any ( " _ _ call _ _ " in klass . __dict__ for klass in type ( obj ) . __mro__ ) NEW_LINE DEDENT DEDENT if PY3 : NEW_LINE INDENT def get_unbound_function ( unbound ) : NEW_LINE INDENT return unbound NEW_LINE DEDENT create_bound_method = types . MethodType NEW_LINE def create_unbound_method ( func , cls ) : NEW_LINE INDENT return func NEW_LINE DEDENT Iterator = object NEW_LINE DEDENT else : NEW_LINE INDENT def get_unbound_function ( unbound ) : NEW_LINE INDENT return unbound . im_func NEW_LINE DEDENT def create_bound_method ( func , obj ) : NEW_LINE INDENT return types . MethodType ( func , obj , obj . __class__ ) NEW_LINE DEDENT def create_unbound_method ( func , cls ) : NEW_LINE INDENT return types . MethodType ( func , None , cls ) NEW_LINE DEDENT class Iterator ( object ) : NEW_LINE INDENT def next ( self ) : NEW_LINE INDENT return type ( self ) . __next__ ( self ) NEW_LINE DEDENT DEDENT callable = callable NEW_LINE DEDENT _add_doc ( get_unbound_function , """ Get ▁ the ▁ function ▁ out ▁ of ▁ a ▁ possibly ▁ unbound ▁ function """ ) NEW_LINE get_method_function = operator . attrgetter ( _meth_func ) NEW_LINE get_method_self = operator . attrgetter ( _meth_self ) NEW_LINE get_function_closure = operator . attrgetter ( _func_closure ) NEW_LINE get_function_code = operator . attrgetter ( _func_code ) NEW_LINE get_function_defaults = operator . attrgetter ( _func_defaults ) NEW_LINE get_function_globals = operator . attrgetter ( _func_globals ) NEW_LINE if PY3 : NEW_LINE INDENT def iterkeys ( d , ** kw ) : NEW_LINE INDENT return iter ( d . keys ( ** kw ) ) NEW_LINE DEDENT def itervalues ( d , ** kw ) : NEW_LINE INDENT return iter ( d . values ( ** kw ) ) NEW_LINE DEDENT def iteritems ( d , ** kw ) : NEW_LINE INDENT return iter ( d . items ( ** kw ) ) NEW_LINE DEDENT def iterlists ( d , ** kw ) : NEW_LINE INDENT return iter ( d . lists ( ** kw ) ) NEW_LINE DEDENT viewkeys = operator . methodcaller ( " keys " ) NEW_LINE viewvalues = operator . methodcaller ( " values " ) NEW_LINE viewitems = operator . methodcaller ( " items " ) NEW_LINE DEDENT else : NEW_LINE INDENT def iterkeys ( d , ** kw ) : NEW_LINE INDENT return d . iterkeys ( ** kw ) NEW_LINE DEDENT def itervalues ( d , ** kw ) : NEW_LINE INDENT return d . itervalues ( ** kw ) NEW_LINE DEDENT def iteritems ( d , ** kw ) : NEW_LINE INDENT return d . iteritems ( ** kw ) NEW_LINE DEDENT def iterlists ( d , ** kw ) : NEW_LINE INDENT return d . iterlists ( ** kw ) NEW_LINE DEDENT viewkeys = operator . methodcaller ( " viewkeys " ) NEW_LINE viewvalues = operator . methodcaller ( " viewvalues " ) NEW_LINE viewitems = operator . methodcaller ( " viewitems " ) NEW_LINE DEDENT _add_doc ( iterkeys , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ keys ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( itervalues , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ values ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( iteritems , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ ( key , ▁ value ) ▁ pairs ▁ of ▁ a ▁ dictionary . " ) NEW_LINE _add_doc ( iterlists , " Return ▁ an ▁ iterator ▁ over ▁ the ▁ ( key , ▁ [ values ] ) ▁ pairs ▁ of ▁ a ▁ dictionary . " ) NEW_LINE if PY3 : NEW_LINE INDENT def b ( s ) : NEW_LINE INDENT return s . encode ( " latin - 1" ) NEW_LINE DEDENT def u ( s ) : NEW_LINE INDENT return s NEW_LINE DEDENT unichr = chr NEW_LINE import struct NEW_LINE int2byte = struct . Struct ( " > B " ) . pack NEW_LINE del struct NEW_LINE byte2int = operator . itemgetter ( 0 ) NEW_LINE indexbytes = operator . getitem NEW_LINE iterbytes = iter NEW_LINE import io NEW_LINE StringIO = io . StringIO NEW_LINE BytesIO = io . BytesIO NEW_LINE _assertCountEqual = " assertCountEqual " NEW_LINE if sys . version_info [ 1 ] <= 1 : NEW_LINE INDENT _assertRaisesRegex = " assertRaisesRegexp " NEW_LINE _assertRegex = " assertRegexpMatches " NEW_LINE DEDENT else : NEW_LINE INDENT _assertRaisesRegex = " assertRaisesRegex " NEW_LINE _assertRegex = " assertRegex " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT def b ( s ) : NEW_LINE INDENT return s NEW_LINE DEDENT def u ( s ) : NEW_LINE INDENT return unicode ( s . replace ( r' \\ ' , r' \\\\ ' ) , " unicode _ escape " ) NEW_LINE DEDENT unichr = unichr NEW_LINE int2byte = chr NEW_LINE def byte2int ( bs ) : NEW_LINE INDENT return ord ( bs [ 0 ] ) NEW_LINE DEDENT def indexbytes ( buf , i ) : NEW_LINE INDENT return ord ( buf [ i ] ) NEW_LINE DEDENT iterbytes = functools . partial ( itertools . imap , ord ) NEW_LINE import StringIO NEW_LINE StringIO = BytesIO = StringIO . StringIO NEW_LINE _assertCountEqual = " assertItemsEqual " NEW_LINE _assertRaisesRegex = " assertRaisesRegexp " NEW_LINE _assertRegex = " assertRegexpMatches " NEW_LINE DEDENT _add_doc ( b , """ Byte ▁ literal """ ) NEW_LINE _add_doc ( u , """ Text ▁ literal """ ) NEW_LINE def assertCountEqual ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertCountEqual ) ( * args , ** kwargs ) NEW_LINE DEDENT def assertRaisesRegex ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertRaisesRegex ) ( * args , ** kwargs ) NEW_LINE DEDENT def assertRegex ( self , * args , ** kwargs ) : NEW_LINE INDENT return getattr ( self , _assertRegex ) ( * args , ** kwargs ) NEW_LINE DEDENT if PY3 : NEW_LINE INDENT exec_ = getattr ( moves . builtins , " exec " ) NEW_LINE def reraise ( tp , value , tb = None ) : NEW_LINE INDENT if value is None : NEW_LINE INDENT value = tp ( ) NEW_LINE DEDENT if value . __traceback__ is not tb : NEW_LINE INDENT raise value . with_traceback ( tb ) NEW_LINE DEDENT raise value NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT def exec_ ( _code_ , _globs_ = None , _locs_ = None ) : NEW_LINE INDENT if _globs_ is None : NEW_LINE INDENT frame = sys . _getframe ( 1 ) NEW_LINE _globs_ = frame . f_globals NEW_LINE if _locs_ is None : NEW_LINE INDENT _locs_ = frame . f_locals NEW_LINE DEDENT del frame NEW_LINE DEDENT elif _locs_ is None : NEW_LINE INDENT _locs_ = _globs_ NEW_LINE DEDENT exec ( """ exec ▁ _ code _ ▁ in ▁ _ globs _ , ▁ _ locs _ """ ) NEW_LINE DEDENT exec_ ( """ def ▁ reraise ( tp , ▁ value , ▁ tb = None ) : STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ tp , ▁ value , ▁ tb STRNEWLINE """ ) NEW_LINE DEDENT if sys . version_info [ : 2 ] == ( 3 , 2 ) : NEW_LINE INDENT exec_ ( """ def ▁ raise _ from ( value , ▁ from _ value ) : STRNEWLINE ▁ ▁ ▁ ▁ if ▁ from _ value ▁ is ▁ None : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ raise ▁ value STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ value ▁ from ▁ from _ value STRNEWLINE """ ) NEW_LINE DEDENT elif sys . version_info [ : 2 ] > ( 3 , 2 ) : NEW_LINE INDENT exec_ ( """ def ▁ raise _ from ( value , ▁ from _ value ) : STRNEWLINE ▁ ▁ ▁ ▁ raise ▁ value ▁ from ▁ from _ value STRNEWLINE """ ) NEW_LINE DEDENT else : NEW_LINE INDENT def raise_from ( value , from_value ) : NEW_LINE INDENT raise value NEW_LINE DEDENT DEDENT print_ = getattr ( moves . builtins , " print " , None ) NEW_LINE if print_ is None : NEW_LINE INDENT def print_ ( * args , ** kwargs ) : NEW_LINE INDENT fp = kwargs . pop ( " file " , sys . stdout ) NEW_LINE if fp is None : NEW_LINE INDENT return NEW_LINE DEDENT def write ( data ) : NEW_LINE INDENT if not isinstance ( data , basestring ) : NEW_LINE INDENT data = str ( data ) NEW_LINE DEDENT if ( isinstance ( fp , file ) and isinstance ( data , unicode ) and fp . encoding is not None ) : NEW_LINE INDENT errors = getattr ( fp , " errors " , None ) NEW_LINE if errors is None : NEW_LINE INDENT errors = " strict " NEW_LINE DEDENT data = data . encode ( fp . encoding , errors ) NEW_LINE DEDENT fp . write ( data ) NEW_LINE DEDENT want_unicode = False NEW_LINE sep = kwargs . pop ( " sep " , None ) NEW_LINE if sep is not None : NEW_LINE INDENT if isinstance ( sep , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE DEDENT elif not isinstance ( sep , str ) : NEW_LINE INDENT raise TypeError ( " sep ▁ must ▁ be ▁ None ▁ or ▁ a ▁ string " ) NEW_LINE DEDENT DEDENT end = kwargs . pop ( " end " , None ) NEW_LINE if end is not None : NEW_LINE INDENT if isinstance ( end , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE DEDENT elif not isinstance ( end , str ) : NEW_LINE INDENT raise TypeError ( " end ▁ must ▁ be ▁ None ▁ or ▁ a ▁ string " ) NEW_LINE DEDENT DEDENT if kwargs : NEW_LINE INDENT raise TypeError ( " invalid ▁ keyword ▁ arguments ▁ to ▁ print ( ) " ) NEW_LINE DEDENT if not want_unicode : NEW_LINE INDENT for arg in args : NEW_LINE INDENT if isinstance ( arg , unicode ) : NEW_LINE INDENT want_unicode = True NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT if want_unicode : NEW_LINE INDENT newline = unicode ( " \n " ) NEW_LINE space = unicode ( " ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT newline = " \n " NEW_LINE space = " ▁ " NEW_LINE DEDENT if sep is None : NEW_LINE INDENT sep = space NEW_LINE DEDENT if end is None : NEW_LINE INDENT end = newline NEW_LINE DEDENT for i , arg in enumerate ( args ) : NEW_LINE INDENT if i : NEW_LINE INDENT write ( sep ) NEW_LINE DEDENT write ( arg ) NEW_LINE DEDENT write ( end ) NEW_LINE DEDENT DEDENT if sys . version_info [ : 2 ] < ( 3 , 3 ) : NEW_LINE INDENT _print = print_ NEW_LINE def print_ ( * args , ** kwargs ) : NEW_LINE INDENT fp = kwargs . get ( " file " , sys . stdout ) NEW_LINE flush = kwargs . pop ( " flush " , False ) NEW_LINE _print ( * args , ** kwargs ) NEW_LINE if flush and fp is not None : NEW_LINE INDENT fp . flush ( ) NEW_LINE DEDENT DEDENT DEDENT _add_doc ( reraise , """ Reraise ▁ an ▁ exception . """ ) NEW_LINE if sys . version_info [ 0 : 2 ] < ( 3 , 4 ) : NEW_LINE INDENT def wraps ( wrapped , assigned = functools . WRAPPER_ASSIGNMENTS , updated = functools . WRAPPER_UPDATES ) : NEW_LINE INDENT def wrapper ( f ) : NEW_LINE INDENT f = functools . wraps ( wrapped , assigned , updated ) ( f ) NEW_LINE f . __wrapped__ = wrapped NEW_LINE return f NEW_LINE DEDENT return wrapper NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT wraps = functools . wraps NEW_LINE DEDENT def with_metaclass ( meta , * bases ) : NEW_LINE INDENT class metaclass ( meta ) : NEW_LINE INDENT def __new__ ( cls , name , this_bases , d ) : NEW_LINE INDENT return meta ( name , bases , d ) NEW_LINE DEDENT DEDENT return type . __new__ ( metaclass , ' temporary _ class ' , ( ) , { } ) NEW_LINE DEDENT def add_metaclass ( metaclass ) : NEW_LINE INDENT def wrapper ( cls ) : NEW_LINE INDENT orig_vars = cls . __dict__ . copy ( ) NEW_LINE slots = orig_vars . get ( ' _ _ slots _ _ ' ) NEW_LINE if slots is not None : NEW_LINE INDENT if isinstance ( slots , str ) : NEW_LINE INDENT slots = [ slots ] NEW_LINE DEDENT for slots_var in slots : NEW_LINE INDENT orig_vars . pop ( slots_var ) NEW_LINE DEDENT DEDENT orig_vars . pop ( ' _ _ dict _ _ ' , None ) NEW_LINE orig_vars . pop ( ' _ _ weakref _ _ ' , None ) NEW_LINE return metaclass ( cls . __name__ , cls . __bases__ , orig_vars ) NEW_LINE DEDENT return wrapper NEW_LINE DEDENT def python_2_unicode_compatible ( klass ) : NEW_LINE INDENT if PY2 : NEW_LINE INDENT if ' _ _ str _ _ ' not in klass . __dict__ : NEW_LINE INDENT raise ValueError ( " @ python _ 2 _ unicode _ compatible ▁ cannot ▁ be ▁ applied ▁ " " to ▁ % s ▁ because ▁ it ▁ doesn ' t ▁ define ▁ _ _ str _ _ ( ) . " % klass . __name__ ) NEW_LINE DEDENT klass . __unicode__ = klass . __str__ NEW_LINE klass . __str__ = lambda self : self . __unicode__ ( ) . encode ( ' utf - 8' ) NEW_LINE DEDENT return klass NEW_LINE DEDENT __path__ = [ ] NEW_LINE __package__ = __name__ NEW_LINE if globals ( ) . get ( " _ _ spec _ _ " ) is not None : NEW_LINE INDENT __spec__ . submodule_search_locations = [ ] NEW_LINE DEDENT if sys . meta_path : NEW_LINE INDENT for i , importer in enumerate ( sys . meta_path ) : NEW_LINE INDENT if ( type ( importer ) . __name__ == " _ SixMetaPathImporter " and importer . name == __name__ ) : NEW_LINE INDENT del sys . meta_path [ i ] NEW_LINE break NEW_LINE DEDENT DEDENT del i , importer NEW_LINE DEDENT sys . meta_path . append ( _importer ) NEW_LINE
 __all__ = [ " ParseError " , " parse _ nested _ list " ] NEW_LINE class ParseError ( Exception ) : NEW_LINE INDENT pass NEW_LINE DEDENT def parse_nested_list ( input_file ) : NEW_LINE INDENT tokens = tokenize ( input_file ) NEW_LINE next_token = tokens . next ( ) NEW_LINE if next_token != " ( " : NEW_LINE INDENT raise ParseError ( " Expected ▁ ' ( ' , ▁ got ▁ % s . " % next_token ) NEW_LINE DEDENT result = list ( parse_list_aux ( tokens ) ) NEW_LINE for tok in tokens : NEW_LINE INDENT raise ParseError ( " Unexpected ▁ token : ▁ % s . " % tok ) NEW_LINE DEDENT return result NEW_LINE DEDENT def tokenize ( input ) : NEW_LINE INDENT for line in input : NEW_LINE INDENT line = line . split ( " ; " , 1 ) [ 0 ] NEW_LINE line = line . replace ( " ( " , " ▁ ( ▁ " ) . replace ( " ) " , " ▁ ) ▁ " ) . replace ( " ? " , " ▁ ? " ) NEW_LINE for token in line . split ( ) : NEW_LINE INDENT yield token . lower ( ) NEW_LINE DEDENT DEDENT DEDENT def parse_list_aux ( tokenstream ) : NEW_LINE INDENT while True : NEW_LINE INDENT try : NEW_LINE INDENT token = tokenstream . next ( ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT raise ParseError ( ) NEW_LINE DEDENT if token == " ) " : NEW_LINE INDENT return NEW_LINE DEDENT elif token == " ( " : NEW_LINE INDENT yield list ( parse_list_aux ( tokenstream ) ) NEW_LINE DEDENT else : NEW_LINE INDENT yield token NEW_LINE DEDENT DEDENT DEDENT
 from __future__ import absolute_import NEW_LINE import logging NEW_LINE import cgi NEW_LINE from collections import namedtuple NEW_LINE import itertools NEW_LINE import sys NEW_LINE import os NEW_LINE import re NEW_LINE import mimetypes NEW_LINE import posixpath NEW_LINE import warnings NEW_LINE from pip . _vendor . six . moves . urllib import parse as urllib_parse NEW_LINE from pip . _vendor . six . moves . urllib import request as urllib_request NEW_LINE from pip . compat import ipaddress NEW_LINE from pip . utils import ( Inf , cached_property , normalize_name , splitext , normalize_path , ARCHIVE_EXTENSIONS , SUPPORTED_EXTENSIONS ) NEW_LINE from pip . utils . deprecation import RemovedInPip8Warning NEW_LINE from pip . utils . logging import indent_log NEW_LINE from pip . exceptions import ( DistributionNotFound , BestVersionAlreadyInstalled , InvalidWheelFilename , UnsupportedWheel , ) NEW_LINE from pip . download import HAS_TLS , url_to_path , path_to_url NEW_LINE from pip . models import PyPI NEW_LINE from pip . wheel import Wheel , wheel_ext NEW_LINE from pip . pep425tags import supported_tags , supported_tags_noarch , get_platform NEW_LINE from pip . _vendor import html5lib , requests , pkg_resources , six NEW_LINE from pip . _vendor . packaging . version import parse as parse_version NEW_LINE from pip . _vendor . requests . exceptions import SSLError NEW_LINE __all__ = [ ' FormatControl ' , ' fmt _ ctl _ handle _ mutual _ exclude ' , ' PackageFinder ' ] NEW_LINE SECURE_ORIGINS = [ ( " https " , " * " , " * " ) , ( " * " , " localhost " , " * " ) , ( " * " , "127.0.0.0/8" , " * " ) , ( " * " , " : :1/128" , " * " ) , ( " file " , " * " , None ) , ] NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE class InstallationCandidate ( object ) : NEW_LINE INDENT def __init__ ( self , project , version , location ) : NEW_LINE INDENT self . project = project NEW_LINE self . version = parse_version ( version ) NEW_LINE self . location = location NEW_LINE self . _key = ( self . project , self . version , self . location ) NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT return " < InstallationCandidate ( {0 ! r } , ▁ { 1 ! r } , ▁ { 2 ! r } ) > " . format ( self . project , self . version , self . location , ) NEW_LINE DEDENT def __hash__ ( self ) : NEW_LINE INDENT return hash ( self . _key ) NEW_LINE DEDENT def __lt__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s < o ) NEW_LINE DEDENT def __le__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s <= o ) NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s == o ) NEW_LINE DEDENT def __ge__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s >= o ) NEW_LINE DEDENT def __gt__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s > o ) NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT return self . _compare ( other , lambda s , o : s != o ) NEW_LINE DEDENT def _compare ( self , other , method ) : NEW_LINE INDENT if not isinstance ( other , InstallationCandidate ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return method ( self . _key , other . _key ) NEW_LINE DEDENT DEDENT class PackageFinder ( object ) : NEW_LINE INDENT def __init__ ( self , find_links , index_urls , allow_external = ( ) , allow_unverified = ( ) , allow_all_external = False , allow_all_prereleases = False , trusted_hosts = None , process_dependency_links = False , session = None , format_control = None ) : NEW_LINE INDENT if session is None : NEW_LINE INDENT raise TypeError ( " PackageFinder ( ) ▁ missing ▁ 1 ▁ required ▁ keyword ▁ argument : ▁ " " ' session ' " ) NEW_LINE DEDENT self . find_links = [ ] NEW_LINE for link in find_links : NEW_LINE INDENT if link . startswith ( ' ~ ' ) : NEW_LINE INDENT new_link = normalize_path ( link ) NEW_LINE if os . path . exists ( new_link ) : NEW_LINE INDENT link = new_link NEW_LINE DEDENT DEDENT self . find_links . append ( link ) NEW_LINE DEDENT self . index_urls = index_urls NEW_LINE self . dependency_links = [ ] NEW_LINE self . logged_links = set ( ) NEW_LINE self . format_control = format_control or FormatControl ( set ( ) , set ( ) ) NEW_LINE self . allow_external = set ( normalize_name ( n ) for n in allow_external ) NEW_LINE self . allow_unverified = set ( normalize_name ( n ) for n in allow_unverified ) NEW_LINE self . allow_external |= self . allow_unverified NEW_LINE self . allow_all_external = allow_all_external NEW_LINE self . secure_origins = [ ( " * " , host , " * " ) for host in ( trusted_hosts if trusted_hosts else [ ] ) ] NEW_LINE self . need_warn_external = False NEW_LINE self . need_warn_unverified = False NEW_LINE self . allow_all_prereleases = allow_all_prereleases NEW_LINE self . process_dependency_links = process_dependency_links NEW_LINE self . session = session NEW_LINE if not HAS_TLS : NEW_LINE INDENT for link in itertools . chain ( self . index_urls , self . find_links ) : NEW_LINE INDENT parsed = urllib_parse . urlparse ( link ) NEW_LINE if parsed . scheme == " https " : NEW_LINE INDENT logger . warning ( " pip ▁ is ▁ configured ▁ with ▁ locations ▁ that ▁ require ▁ " " TLS / SSL , ▁ however ▁ the ▁ ssl ▁ module ▁ in ▁ Python ▁ is ▁ not ▁ " " available . " ) NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT DEDENT def add_dependency_links ( self , links ) : NEW_LINE INDENT if self . process_dependency_links : NEW_LINE INDENT warnings . warn ( " Dependency ▁ Links ▁ processing ▁ has ▁ been ▁ deprecated ▁ and ▁ will ▁ be ▁ " " removed ▁ in ▁ a ▁ future ▁ release . " , RemovedInPip8Warning , ) NEW_LINE self . dependency_links . extend ( links ) NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def _sort_locations ( locations , expand_dir = False ) : NEW_LINE INDENT files = [ ] NEW_LINE urls = [ ] NEW_LINE def sort_path ( path ) : NEW_LINE INDENT url = path_to_url ( path ) NEW_LINE if mimetypes . guess_type ( url , strict = False ) [ 0 ] == ' text / html ' : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT else : NEW_LINE INDENT files . append ( url ) NEW_LINE DEDENT DEDENT for url in locations : NEW_LINE INDENT is_local_path = os . path . exists ( url ) NEW_LINE is_file_url = url . startswith ( ' file : ' ) NEW_LINE if is_local_path or is_file_url : NEW_LINE INDENT if is_local_path : NEW_LINE INDENT path = url NEW_LINE DEDENT else : NEW_LINE INDENT path = url_to_path ( url ) NEW_LINE DEDENT if os . path . isdir ( path ) : NEW_LINE INDENT if expand_dir : NEW_LINE INDENT path = os . path . realpath ( path ) NEW_LINE for item in os . listdir ( path ) : NEW_LINE INDENT sort_path ( os . path . join ( path , item ) ) NEW_LINE DEDENT DEDENT elif is_file_url : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT DEDENT elif os . path . isfile ( path ) : NEW_LINE INDENT sort_path ( path ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT urls . append ( url ) NEW_LINE DEDENT DEDENT return files , urls NEW_LINE DEDENT def _candidate_sort_key ( self , candidate ) : NEW_LINE INDENT support_num = len ( supported_tags ) NEW_LINE if candidate . location == INSTALLED_VERSION : NEW_LINE INDENT pri = 1 NEW_LINE DEDENT elif candidate . location . is_wheel : NEW_LINE INDENT wheel = Wheel ( candidate . location . filename ) NEW_LINE if not wheel . supported ( ) : NEW_LINE INDENT raise UnsupportedWheel ( " % s ▁ is ▁ not ▁ a ▁ supported ▁ wheel ▁ for ▁ this ▁ platform . ▁ It ▁ " " can ' t ▁ be ▁ sorted . " % wheel . filename ) NEW_LINE DEDENT pri = - ( wheel . support_index_min ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT pri = - ( support_num ) NEW_LINE DEDENT return ( candidate . version , pri ) NEW_LINE DEDENT def _sort_versions ( self , applicable_versions ) : NEW_LINE INDENT return sorted ( applicable_versions , key = self . _candidate_sort_key , reverse = True ) NEW_LINE DEDENT def _validate_secure_origin ( self , logger , location ) : NEW_LINE INDENT parsed = urllib_parse . urlparse ( str ( location ) ) NEW_LINE origin = ( parsed . scheme , parsed . hostname , parsed . port ) NEW_LINE for secure_origin in ( SECURE_ORIGINS + self . secure_origins ) : NEW_LINE INDENT if origin [ 0 ] != secure_origin [ 0 ] and secure_origin [ 0 ] != " * " : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE INDENT addr = ipaddress . ip_address ( origin [ 1 ] if ( isinstance ( origin [ 1 ] , six . text_type ) or origin [ 1 ] is None ) else origin [ 1 ] . decode ( " utf8" ) ) NEW_LINE network = ipaddress . ip_network ( secure_origin [ 1 ] if isinstance ( secure_origin [ 1 ] , six . text_type ) else secure_origin [ 1 ] . decode ( " utf8" ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT if origin [ 1 ] != secure_origin [ 1 ] and secure_origin [ 1 ] != " * " : NEW_LINE INDENT continue NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if addr not in network : NEW_LINE INDENT continue NEW_LINE DEDENT DEDENT if ( origin [ 2 ] != secure_origin [ 2 ] and secure_origin [ 2 ] != " * " and secure_origin [ 2 ] is not None ) : NEW_LINE INDENT continue NEW_LINE DEDENT return True NEW_LINE DEDENT logger . warning ( " The ▁ repository ▁ located ▁ at ▁ % s ▁ is ▁ not ▁ a ▁ trusted ▁ or ▁ secure ▁ host ▁ and ▁ " " is ▁ being ▁ ignored . ▁ If ▁ this ▁ repository ▁ is ▁ available ▁ via ▁ HTTPS ▁ it ▁ " " is ▁ recommended ▁ to ▁ use ▁ HTTPS ▁ instead , ▁ otherwise ▁ you ▁ may ▁ silence ▁ " " this ▁ warning ▁ and ▁ allow ▁ it ▁ anyways ▁ with ▁ ' - - trusted - host ▁ % s ' . " , parsed . hostname , parsed . hostname , ) NEW_LINE return False NEW_LINE DEDENT def _get_index_urls_locations ( self , project_name ) : NEW_LINE INDENT def mkurl_pypi_url ( url ) : NEW_LINE INDENT loc = posixpath . join ( url , project_url_name ) NEW_LINE if not loc . endswith ( ' / ' ) : NEW_LINE INDENT loc = loc + ' / ' NEW_LINE DEDENT return loc NEW_LINE DEDENT project_url_name = urllib_parse . quote ( project_name . lower ( ) ) NEW_LINE if self . index_urls : NEW_LINE INDENT main_index_url = Link ( mkurl_pypi_url ( self . index_urls [ 0 ] ) , trusted = True , ) NEW_LINE page = self . _get_page ( main_index_url ) NEW_LINE if page is None and PyPI . netloc not in str ( main_index_url ) : NEW_LINE INDENT warnings . warn ( " Failed ▁ to ▁ find ▁ % r ▁ at ▁ % s . ▁ It ▁ is ▁ suggested ▁ to ▁ upgrade ▁ " " your ▁ index ▁ to ▁ support ▁ normalized ▁ names ▁ as ▁ the ▁ name ▁ in ▁ " " / simple / { name } . " % ( project_name , main_index_url ) , RemovedInPip8Warning , ) NEW_LINE project_url_name = self . _find_url_name ( Link ( self . index_urls [ 0 ] , trusted = True ) , project_url_name , ) or project_url_name NEW_LINE DEDENT DEDENT if project_url_name is not None : NEW_LINE INDENT return [ mkurl_pypi_url ( url ) for url in self . index_urls ] NEW_LINE DEDENT return [ ] NEW_LINE DEDENT def _find_all_versions ( self , project_name ) : NEW_LINE INDENT index_locations = self . _get_index_urls_locations ( project_name ) NEW_LINE index_file_loc , index_url_loc = self . _sort_locations ( index_locations ) NEW_LINE fl_file_loc , fl_url_loc = self . _sort_locations ( self . find_links , expand_dir = True ) NEW_LINE dep_file_loc , dep_url_loc = self . _sort_locations ( self . dependency_links ) NEW_LINE file_locations = ( Link ( url ) for url in itertools . chain ( index_file_loc , fl_file_loc , dep_file_loc ) ) NEW_LINE url_locations = [ link for link in itertools . chain ( ( Link ( url , trusted = True ) for url in index_url_loc ) , ( Link ( url , trusted = True ) for url in fl_url_loc ) , ( Link ( url ) for url in dep_url_loc ) , ) if self . _validate_secure_origin ( logger , link ) ] NEW_LINE logger . debug ( ' % d ▁ location ( s ) ▁ to ▁ search ▁ for ▁ versions ▁ of ▁ % s : ' , len ( url_locations ) , project_name ) NEW_LINE for location in url_locations : NEW_LINE INDENT logger . debug ( ' * ▁ % s ' , location ) NEW_LINE DEDENT canonical_name = pkg_resources . safe_name ( project_name ) . lower ( ) NEW_LINE formats = fmt_ctl_formats ( self . format_control , canonical_name ) NEW_LINE search = Search ( project_name . lower ( ) , canonical_name , formats ) NEW_LINE find_links_versions = self . _package_versions ( ( Link ( url , ' - f ' , trusted = True ) for url in self . find_links ) , search ) NEW_LINE page_versions = [ ] NEW_LINE for page in self . _get_pages ( url_locations , project_name ) : NEW_LINE INDENT logger . debug ( ' Analyzing ▁ links ▁ from ▁ page ▁ % s ' , page . url ) NEW_LINE with indent_log ( ) : NEW_LINE INDENT page_versions . extend ( self . _package_versions ( page . links , search ) ) NEW_LINE DEDENT DEDENT dependency_versions = self . _package_versions ( ( Link ( url ) for url in self . dependency_links ) , search ) NEW_LINE if dependency_versions : NEW_LINE INDENT logger . debug ( ' dependency _ links ▁ found : ▁ % s ' , ' , ▁ ' . join ( [ version . location . url for version in dependency_versions ] ) ) NEW_LINE DEDENT file_versions = self . _package_versions ( file_locations , search ) NEW_LINE if file_versions : NEW_LINE INDENT file_versions . sort ( reverse = True ) NEW_LINE logger . debug ( ' Local ▁ files ▁ found : ▁ % s ' , ' , ▁ ' . join ( [ url_to_path ( candidate . location . url ) for candidate in file_versions ] ) ) NEW_LINE DEDENT return ( file_versions + find_links_versions + page_versions + dependency_versions ) NEW_LINE DEDENT def find_requirement ( self , req , upgrade ) : NEW_LINE INDENT all_versions = self . _find_all_versions ( req . name ) NEW_LINE _versions = set ( req . specifier . filter ( [ str ( x . version ) for x in all_versions ] , prereleases = ( self . allow_all_prereleases if self . allow_all_prereleases else None ) , ) ) NEW_LINE applicable_versions = [ x for x in all_versions if str ( x . version ) in _versions ] NEW_LINE if req . satisfied_by is not None : NEW_LINE INDENT applicable_versions . insert ( 0 , InstallationCandidate ( req . name , req . satisfied_by . version , INSTALLED_VERSION , ) ) NEW_LINE existing_applicable = True NEW_LINE DEDENT else : NEW_LINE INDENT existing_applicable = False NEW_LINE DEDENT applicable_versions = self . _sort_versions ( applicable_versions ) NEW_LINE if not upgrade and existing_applicable : NEW_LINE INDENT if applicable_versions [ 0 ] . location is INSTALLED_VERSION : NEW_LINE INDENT logger . debug ( ' Existing ▁ installed ▁ version ▁ ( % s ) ▁ is ▁ most ▁ up - to - date ▁ and ▁ ' ' satisfies ▁ requirement ' , req . satisfied_by . version , ) NEW_LINE DEDENT else : NEW_LINE INDENT logger . debug ( ' Existing ▁ installed ▁ version ▁ ( % s ) ▁ satisfies ▁ requirement ▁ ' ' ( most ▁ up - to - date ▁ version ▁ is ▁ % s ) ' , req . satisfied_by . version , applicable_versions [ 0 ] [ 2 ] , ) NEW_LINE DEDENT return None NEW_LINE DEDENT if not applicable_versions : NEW_LINE INDENT logger . critical ( ' Could ▁ not ▁ find ▁ a ▁ version ▁ that ▁ satisfies ▁ the ▁ requirement ▁ % s ▁ ' ' ( from ▁ versions : ▁ % s ) ' , req , ' , ▁ ' . join ( sorted ( set ( str ( i . version ) for i in all_versions ) , key = parse_version , ) ) ) NEW_LINE if self . need_warn_external : NEW_LINE INDENT logger . warning ( " Some ▁ externally ▁ hosted ▁ files ▁ were ▁ ignored ▁ as ▁ access ▁ to ▁ " " them ▁ may ▁ be ▁ unreliable ▁ ( use ▁ - - allow - external ▁ % s ▁ to ▁ " " allow ) . " , req . name , ) NEW_LINE DEDENT if self . need_warn_unverified : NEW_LINE INDENT logger . warning ( " Some ▁ insecure ▁ and ▁ unverifiable ▁ files ▁ were ▁ ignored " " ▁ ( use ▁ - - allow - unverified ▁ % s ▁ to ▁ allow ) . " , req . name , ) NEW_LINE DEDENT raise DistributionNotFound ( ' No ▁ matching ▁ distribution ▁ found ▁ for ▁ % s ' % req ) NEW_LINE DEDENT if applicable_versions [ 0 ] . location is INSTALLED_VERSION : NEW_LINE INDENT logger . debug ( ' Installed ▁ version ▁ ( % s ) ▁ is ▁ most ▁ up - to - date ▁ ( past ▁ versions : ▁ ' ' % s ) ' , req . satisfied_by . version , ' , ▁ ' . join ( str ( i . version ) for i in applicable_versions [ 1 : ] ) or " none " , ) NEW_LINE raise BestVersionAlreadyInstalled NEW_LINE DEDENT if len ( applicable_versions ) > 1 : NEW_LINE INDENT logger . debug ( ' Using ▁ version ▁ % s ▁ ( newest ▁ of ▁ versions : ▁ % s ) ' , applicable_versions [ 0 ] . version , ' , ▁ ' . join ( str ( i . version ) for i in applicable_versions ) ) NEW_LINE DEDENT selected_version = applicable_versions [ 0 ] . location NEW_LINE if ( selected_version . verifiable is not None and not selected_version . verifiable ) : NEW_LINE INDENT logger . warning ( " % s ▁ is ▁ potentially ▁ insecure ▁ and ▁ unverifiable . " , req . name , ) NEW_LINE DEDENT return selected_version NEW_LINE DEDENT def _find_url_name ( self , index_url , url_name ) : NEW_LINE INDENT if not index_url . url . endswith ( ' / ' ) : NEW_LINE INDENT index_url . url += ' / ' NEW_LINE DEDENT page = self . _get_page ( index_url ) NEW_LINE if page is None : NEW_LINE INDENT logger . critical ( ' Cannot ▁ fetch ▁ index ▁ base ▁ URL ▁ % s ' , index_url ) NEW_LINE return NEW_LINE DEDENT norm_name = normalize_name ( url_name ) NEW_LINE for link in page . links : NEW_LINE INDENT base = posixpath . basename ( link . path . rstrip ( ' / ' ) ) NEW_LINE if norm_name == normalize_name ( base ) : NEW_LINE INDENT logger . debug ( ' Real ▁ name ▁ of ▁ requirement ▁ % s ▁ is ▁ % s ' , url_name , base , ) NEW_LINE return base NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def _get_pages ( self , locations , project_name ) : NEW_LINE INDENT all_locations = list ( locations ) NEW_LINE seen = set ( ) NEW_LINE normalized = normalize_name ( project_name ) NEW_LINE while all_locations : NEW_LINE INDENT location = all_locations . pop ( 0 ) NEW_LINE if location in seen : NEW_LINE INDENT continue NEW_LINE DEDENT seen . add ( location ) NEW_LINE page = self . _get_page ( location ) NEW_LINE if page is None : NEW_LINE INDENT continue NEW_LINE DEDENT yield page NEW_LINE for link in page . rel_links ( ) : NEW_LINE INDENT if ( normalized not in self . allow_external and not self . allow_all_external ) : NEW_LINE INDENT self . need_warn_external = True NEW_LINE logger . debug ( " Not ▁ searching ▁ % s ▁ for ▁ files ▁ because ▁ external ▁ " " urls ▁ are ▁ disallowed . " , link , ) NEW_LINE continue NEW_LINE DEDENT if ( link . trusted is not None and not link . trusted and normalized not in self . allow_unverified ) : NEW_LINE INDENT logger . debug ( " Not ▁ searching ▁ % s ▁ for ▁ urls , ▁ it ▁ is ▁ an ▁ " " untrusted ▁ link ▁ and ▁ cannot ▁ produce ▁ safe ▁ or ▁ " " verifiable ▁ files . " , link , ) NEW_LINE self . need_warn_unverified = True NEW_LINE continue NEW_LINE DEDENT all_locations . append ( link ) NEW_LINE DEDENT DEDENT DEDENT _py_version_re = re . compile ( r' - py ( [123 ] \ . ? [ 0-9 ] ? ) $ ' ) NEW_LINE def _sort_links ( self , links ) : NEW_LINE INDENT eggs , no_eggs = [ ] , [ ] NEW_LINE seen = set ( ) NEW_LINE for link in links : NEW_LINE INDENT if link not in seen : NEW_LINE INDENT seen . add ( link ) NEW_LINE if link . egg_fragment : NEW_LINE INDENT eggs . append ( link ) NEW_LINE DEDENT else : NEW_LINE INDENT no_eggs . append ( link ) NEW_LINE DEDENT DEDENT DEDENT return no_eggs + eggs NEW_LINE DEDENT def _package_versions ( self , links , search ) : NEW_LINE INDENT result = [ ] NEW_LINE for link in self . _sort_links ( links ) : NEW_LINE INDENT v = self . _link_package_versions ( link , search ) NEW_LINE if v is not None : NEW_LINE INDENT result . append ( v ) NEW_LINE DEDENT DEDENT return result NEW_LINE DEDENT def _log_skipped_link ( self , link , reason ) : NEW_LINE INDENT if link not in self . logged_links : NEW_LINE INDENT logger . debug ( ' Skipping ▁ link ▁ % s ; ▁ % s ' , link , reason ) NEW_LINE self . logged_links . add ( link ) NEW_LINE DEDENT DEDENT def _link_package_versions ( self , link , search ) : NEW_LINE INDENT platform = get_platform ( ) NEW_LINE version = None NEW_LINE if link . egg_fragment : NEW_LINE INDENT egg_info = link . egg_fragment NEW_LINE ext = link . ext NEW_LINE DEDENT else : NEW_LINE INDENT egg_info , ext = link . splitext ( ) NEW_LINE if not ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' not ▁ a ▁ file ' ) NEW_LINE return NEW_LINE DEDENT if ext not in SUPPORTED_EXTENSIONS : NEW_LINE INDENT self . _log_skipped_link ( link , ' unsupported ▁ archive ▁ format : ▁ % s ' % ext ) NEW_LINE return NEW_LINE DEDENT if " binary " not in search . formats and ext == wheel_ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' No ▁ binaries ▁ permitted ▁ for ▁ % s ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if " macosx10" in link . path and ext == ' . zip ' : NEW_LINE INDENT self . _log_skipped_link ( link , ' macosx10 ▁ one ' ) NEW_LINE return NEW_LINE DEDENT if ext == wheel_ext : NEW_LINE INDENT try : NEW_LINE INDENT wheel = Wheel ( link . filename ) NEW_LINE DEDENT except InvalidWheelFilename : NEW_LINE INDENT self . _log_skipped_link ( link , ' invalid ▁ wheel ▁ filename ' ) NEW_LINE return NEW_LINE DEDENT if ( pkg_resources . safe_name ( wheel . name ) . lower ( ) != search . canonical ) : NEW_LINE INDENT self . _log_skipped_link ( link , ' wrong ▁ project ▁ name ▁ ( not ▁ % s ) ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if not wheel . supported ( ) : NEW_LINE INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ not ▁ compatible ▁ with ▁ this ▁ Python ' ) NEW_LINE return NEW_LINE DEDENT comes_from = getattr ( link , " comes _ from " , None ) NEW_LINE if ( ( not platform . startswith ( ' win ' ) and not platform . startswith ( ' macosx ' ) and not platform == ' cli ' ) and comes_from is not None and urllib_parse . urlparse ( comes_from . url ) . netloc . endswith ( PyPI . netloc ) ) : NEW_LINE INDENT if not wheel . supported ( tags = supported_tags_noarch ) : NEW_LINE INDENT self . _log_skipped_link ( link , " it ▁ is ▁ a ▁ pypi - hosted ▁ binary ▁ " " Wheel ▁ on ▁ an ▁ unsupported ▁ platform " , ) NEW_LINE return NEW_LINE DEDENT DEDENT version = wheel . version NEW_LINE DEDENT DEDENT if " source " not in search . formats and ext != wheel_ext : NEW_LINE INDENT self . _log_skipped_link ( link , ' No ▁ sources ▁ permitted ▁ for ▁ % s ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if not version : NEW_LINE INDENT version = egg_info_matches ( egg_info , search . supplied , link ) NEW_LINE DEDENT if version is None : NEW_LINE INDENT self . _log_skipped_link ( link , ' wrong ▁ project ▁ name ▁ ( not ▁ % s ) ' % search . supplied ) NEW_LINE return NEW_LINE DEDENT if ( link . internal is not None and not link . internal and not normalize_name ( search . supplied ) . lower ( ) in self . allow_external and not self . allow_all_external ) : NEW_LINE INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ externally ▁ hosted ' ) NEW_LINE self . need_warn_external = True NEW_LINE return NEW_LINE DEDENT if ( link . verifiable is not None and not link . verifiable and not ( normalize_name ( search . supplied ) . lower ( ) in self . allow_unverified ) ) : NEW_LINE INDENT self . _log_skipped_link ( link , ' it ▁ is ▁ an ▁ insecure ▁ and ▁ unverifiable ▁ file ' ) NEW_LINE self . need_warn_unverified = True NEW_LINE return NEW_LINE DEDENT match = self . _py_version_re . search ( version ) NEW_LINE if match : NEW_LINE INDENT version = version [ : match . start ( ) ] NEW_LINE py_version = match . group ( 1 ) NEW_LINE if py_version != sys . version [ : 3 ] : NEW_LINE INDENT self . _log_skipped_link ( link , ' Python ▁ version ▁ is ▁ incorrect ' ) NEW_LINE return NEW_LINE DEDENT DEDENT logger . debug ( ' Found ▁ link ▁ % s , ▁ version : ▁ % s ' , link , version ) NEW_LINE return InstallationCandidate ( search . supplied , version , link ) NEW_LINE DEDENT def _get_page ( self , link ) : NEW_LINE INDENT return HTMLPage . get_page ( link , session = self . session ) NEW_LINE DEDENT DEDENT def egg_info_matches ( egg_info , search_name , link , _egg_info_re = re . compile ( r' ( [ a - z0-9 _ . ] + ) - ( [ a - z0-9 _ . ! + - ] + ) ' , re . I ) ) : NEW_LINE INDENT match = _egg_info_re . search ( egg_info ) NEW_LINE if not match : NEW_LINE INDENT logger . debug ( ' Could ▁ not ▁ parse ▁ version ▁ from ▁ link : ▁ % s ' , link ) NEW_LINE return None NEW_LINE DEDENT if search_name is None : NEW_LINE INDENT full_match = match . group ( 0 ) NEW_LINE return full_match [ full_match . index ( ' - ' ) : ] NEW_LINE DEDENT name = match . group ( 0 ) . lower ( ) NEW_LINE name = name . replace ( ' _ ' , ' - ' ) NEW_LINE look_for = search_name . lower ( ) + " - " NEW_LINE if name . startswith ( look_for ) : NEW_LINE INDENT return match . group ( 0 ) [ len ( look_for ) : ] NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT class HTMLPage ( object ) : NEW_LINE INDENT def __init__ ( self , content , url , headers = None , trusted = None ) : NEW_LINE INDENT encoding = None NEW_LINE if headers and " Content - Type " in headers : NEW_LINE INDENT content_type , params = cgi . parse_header ( headers [ " Content - Type " ] ) NEW_LINE if " charset " in params : NEW_LINE INDENT encoding = params [ ' charset ' ] NEW_LINE DEDENT DEDENT self . content = content NEW_LINE self . parsed = html5lib . parse ( self . content , encoding = encoding , namespaceHTMLElements = False , ) NEW_LINE self . url = url NEW_LINE self . headers = headers NEW_LINE self . trusted = trusted NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return self . url NEW_LINE DEDENT @ classmethod NEW_LINE def get_page ( cls , link , skip_archives = True , session = None ) : NEW_LINE INDENT if session is None : NEW_LINE INDENT raise TypeError ( " get _ page ( ) ▁ missing ▁ 1 ▁ required ▁ keyword ▁ argument : ▁ ' session ' " ) NEW_LINE DEDENT url = link . url NEW_LINE url = url . split ( ' # ' , 1 ) [ 0 ] NEW_LINE from pip . vcs import VcsSupport NEW_LINE for scheme in VcsSupport . schemes : NEW_LINE INDENT if url . lower ( ) . startswith ( scheme ) and url [ len ( scheme ) ] in ' + : ' : NEW_LINE INDENT logger . debug ( ' Cannot ▁ look ▁ at ▁ % s ▁ URL ▁ % s ' , scheme , link ) NEW_LINE return None NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT if skip_archives : NEW_LINE INDENT filename = link . filename NEW_LINE for bad_ext in ARCHIVE_EXTENSIONS : NEW_LINE INDENT if filename . endswith ( bad_ext ) : NEW_LINE INDENT content_type = cls . _get_content_type ( url , session = session , ) NEW_LINE if content_type . lower ( ) . startswith ( ' text / html ' ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT logger . debug ( ' Skipping ▁ page ▁ % s ▁ because ▁ of ▁ Content - Type : ▁ % s ' , link , content_type , ) NEW_LINE return NEW_LINE DEDENT DEDENT DEDENT DEDENT logger . debug ( ' Getting ▁ page ▁ % s ' , url ) NEW_LINE ( scheme , netloc , path , params , query , fragment ) = \NEW_LINE urllib_parse . urlparse ( url ) NEW_LINE if ( scheme == ' file ' and os . path . isdir ( urllib_request . url2pathname ( path ) ) ) : NEW_LINE INDENT if not url . endswith ( ' / ' ) : NEW_LINE INDENT url += ' / ' NEW_LINE DEDENT url = urllib_parse . urljoin ( url , ' index . html ' ) NEW_LINE logger . debug ( ' ▁ file : ▁ URL ▁ is ▁ directory , ▁ getting ▁ % s ' , url ) NEW_LINE DEDENT resp = session . get ( url , headers = { " Accept " : " text / html " , " Cache - Control " : " max - age = 600" , } , ) NEW_LINE resp . raise_for_status ( ) NEW_LINE content_type = resp . headers . get ( ' Content - Type ' , ' unknown ' ) NEW_LINE if not content_type . lower ( ) . startswith ( " text / html " ) : NEW_LINE INDENT logger . debug ( ' Skipping ▁ page ▁ % s ▁ because ▁ of ▁ Content - Type : ▁ % s ' , link , content_type , ) NEW_LINE return NEW_LINE DEDENT inst = cls ( resp . content , resp . url , resp . headers , trusted = link . trusted , ) NEW_LINE DEDENT except requests . HTTPError as exc : NEW_LINE INDENT level = 2 if exc . response . status_code == 404 else 1 NEW_LINE cls . _handle_fail ( link , exc , url , level = level ) NEW_LINE DEDENT except requests . ConnectionError as exc : NEW_LINE INDENT cls . _handle_fail ( link , " connection ▁ error : ▁ % s " % exc , url ) NEW_LINE DEDENT except requests . Timeout : NEW_LINE INDENT cls . _handle_fail ( link , " timed ▁ out " , url ) NEW_LINE DEDENT except SSLError as exc : NEW_LINE INDENT reason = ( " There ▁ was ▁ a ▁ problem ▁ confirming ▁ the ▁ ssl ▁ certificate : ▁ " " % s " % exc ) NEW_LINE cls . _handle_fail ( link , reason , url , level = 2 , meth = logger . info ) NEW_LINE DEDENT else : NEW_LINE INDENT return inst NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def _handle_fail ( link , reason , url , level = 1 , meth = None ) : NEW_LINE INDENT if meth is None : NEW_LINE INDENT meth = logger . debug NEW_LINE DEDENT meth ( " Could ▁ not ▁ fetch ▁ URL ▁ % s : ▁ % s ▁ - ▁ skipping " , link , reason ) NEW_LINE DEDENT @ staticmethod NEW_LINE def _get_content_type ( url , session ) : NEW_LINE INDENT scheme , netloc , path , query , fragment = urllib_parse . urlsplit ( url ) NEW_LINE if scheme not in ( ' http ' , ' https ' ) : NEW_LINE INDENT return ' ' NEW_LINE DEDENT resp = session . head ( url , allow_redirects = True ) NEW_LINE resp . raise_for_status ( ) NEW_LINE return resp . headers . get ( " Content - Type " , " " ) NEW_LINE DEDENT @ cached_property NEW_LINE def api_version ( self ) : NEW_LINE INDENT metas = [ x for x in self . parsed . findall ( " . / / meta " ) if x . get ( " name " , " " ) . lower ( ) == " api - version " ] NEW_LINE if metas : NEW_LINE INDENT try : NEW_LINE INDENT return int ( metas [ 0 ] . get ( " value " , None ) ) NEW_LINE DEDENT except ( TypeError , ValueError ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT @ cached_property NEW_LINE def base_url ( self ) : NEW_LINE INDENT bases = [ x for x in self . parsed . findall ( " . / / base " ) if x . get ( " href " ) is not None ] NEW_LINE if bases and bases [ 0 ] . get ( " href " ) : NEW_LINE INDENT return bases [ 0 ] . get ( " href " ) NEW_LINE DEDENT else : NEW_LINE INDENT return self . url NEW_LINE DEDENT DEDENT @ property NEW_LINE def links ( self ) : NEW_LINE INDENT for anchor in self . parsed . findall ( " . / / a " ) : NEW_LINE INDENT if anchor . get ( " href " ) : NEW_LINE INDENT href = anchor . get ( " href " ) NEW_LINE url = self . clean_link ( urllib_parse . urljoin ( self . base_url , href ) ) NEW_LINE internal = None NEW_LINE if self . api_version and self . api_version >= 2 : NEW_LINE INDENT internal = bool ( anchor . get ( " rel " ) and " internal " in anchor . get ( " rel " ) . split ( ) ) NEW_LINE DEDENT yield Link ( url , self , internal = internal ) NEW_LINE DEDENT DEDENT DEDENT def rel_links ( self , rels = ( ' homepage ' , ' download ' ) ) : NEW_LINE INDENT rels = set ( rels ) NEW_LINE for anchor in self . parsed . findall ( " . / / a " ) : NEW_LINE INDENT if anchor . get ( " rel " ) and anchor . get ( " href " ) : NEW_LINE INDENT found_rels = set ( anchor . get ( " rel " ) . split ( ) ) NEW_LINE if found_rels & rels : NEW_LINE INDENT href = anchor . get ( " href " ) NEW_LINE url = self . clean_link ( urllib_parse . urljoin ( self . base_url , href ) ) NEW_LINE yield Link ( url , self , trusted = False ) NEW_LINE DEDENT DEDENT DEDENT DEDENT _clean_re = re . compile ( r' [ ^ a - z0-9 $ & + , / : ; = ? @ . # % _ \\ | - ] ' , re . I ) NEW_LINE def clean_link ( self , url ) : NEW_LINE INDENT return self . _clean_re . sub ( lambda match : ' % % % 2x ' % ord ( match . group ( 0 ) ) , url ) NEW_LINE DEDENT DEDENT class Link ( object ) : NEW_LINE INDENT def __init__ ( self , url , comes_from = None , internal = None , trusted = None ) : NEW_LINE INDENT if url != Inf and url . startswith ( ' \\\\ ' ) : NEW_LINE INDENT url = path_to_url ( url ) NEW_LINE DEDENT self . url = url NEW_LINE self . comes_from = comes_from NEW_LINE self . internal = internal NEW_LINE self . trusted = trusted NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT if self . comes_from : NEW_LINE INDENT return ' % s ▁ ( from ▁ % s ) ' % ( self . url , self . comes_from ) NEW_LINE DEDENT else : NEW_LINE INDENT return str ( self . url ) NEW_LINE DEDENT DEDENT def __repr__ ( self ) : NEW_LINE INDENT return ' < Link ▁ % s > ' % self NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url == other . url NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url != other . url NEW_LINE DEDENT def __lt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url < other . url NEW_LINE DEDENT def __le__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url <= other . url NEW_LINE DEDENT def __gt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url > other . url NEW_LINE DEDENT def __ge__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Link ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . url >= other . url NEW_LINE DEDENT def __hash__ ( self ) : NEW_LINE INDENT return hash ( self . url ) NEW_LINE DEDENT @ property NEW_LINE def filename ( self ) : NEW_LINE INDENT _ , netloc , path , _ , _ = urllib_parse . urlsplit ( self . url ) NEW_LINE name = posixpath . basename ( path . rstrip ( ' / ' ) ) or netloc NEW_LINE name = urllib_parse . unquote ( name ) NEW_LINE assert name , ( ' URL ▁ % r ▁ produced ▁ no ▁ filename ' % self . url ) NEW_LINE return name NEW_LINE DEDENT @ property NEW_LINE def scheme ( self ) : NEW_LINE INDENT return urllib_parse . urlsplit ( self . url ) [ 0 ] NEW_LINE DEDENT @ property NEW_LINE def netloc ( self ) : NEW_LINE INDENT return urllib_parse . urlsplit ( self . url ) [ 1 ] NEW_LINE DEDENT @ property NEW_LINE def path ( self ) : NEW_LINE INDENT return urllib_parse . unquote ( urllib_parse . urlsplit ( self . url ) [ 2 ] ) NEW_LINE DEDENT def splitext ( self ) : NEW_LINE INDENT return splitext ( posixpath . basename ( self . path . rstrip ( ' / ' ) ) ) NEW_LINE DEDENT @ property NEW_LINE def ext ( self ) : NEW_LINE INDENT return self . splitext ( ) [ 1 ] NEW_LINE DEDENT @ property NEW_LINE def url_without_fragment ( self ) : NEW_LINE INDENT scheme , netloc , path , query , fragment = urllib_parse . urlsplit ( self . url ) NEW_LINE return urllib_parse . urlunsplit ( ( scheme , netloc , path , query , None ) ) NEW_LINE DEDENT _egg_fragment_re = re . compile ( r' # egg = ( [ ^ & ] * ) ' ) NEW_LINE @ property NEW_LINE def egg_fragment ( self ) : NEW_LINE INDENT match = self . _egg_fragment_re . search ( self . url ) NEW_LINE if not match : NEW_LINE INDENT return None NEW_LINE DEDENT return match . group ( 1 ) NEW_LINE DEDENT _hash_re = re . compile ( r' ( sha1 | sha224 | sha384 | sha256 | sha512 | md5 ) = ( [ a - f0-9 ] + ) ' ) NEW_LINE @ property NEW_LINE def hash ( self ) : NEW_LINE INDENT match = self . _hash_re . search ( self . url ) NEW_LINE if match : NEW_LINE INDENT return match . group ( 2 ) NEW_LINE DEDENT return None NEW_LINE DEDENT @ property NEW_LINE def hash_name ( self ) : NEW_LINE INDENT match = self . _hash_re . search ( self . url ) NEW_LINE if match : NEW_LINE INDENT return match . group ( 1 ) NEW_LINE DEDENT return None NEW_LINE DEDENT @ property NEW_LINE def show_url ( self ) : NEW_LINE INDENT return posixpath . basename ( self . url . split ( ' # ' , 1 ) [ 0 ] . split ( ' ? ' , 1 ) [ 0 ] ) NEW_LINE DEDENT @ property NEW_LINE def verifiable ( self ) : NEW_LINE INDENT trusted = self . trusted or getattr ( self . comes_from , " trusted " , None ) NEW_LINE if trusted is not None and trusted : NEW_LINE INDENT try : NEW_LINE INDENT api_version = getattr ( self . comes_from , " api _ version " , None ) NEW_LINE api_version = int ( api_version ) NEW_LINE DEDENT except ( ValueError , TypeError ) : NEW_LINE INDENT api_version = None NEW_LINE DEDENT if api_version is None or api_version <= 1 : NEW_LINE INDENT return NEW_LINE DEDENT if self . hash : NEW_LINE INDENT return True NEW_LINE DEDENT else : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT elif trusted is not None : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT @ property NEW_LINE def is_wheel ( self ) : NEW_LINE INDENT return self . ext == wheel_ext NEW_LINE DEDENT @ property NEW_LINE def is_artifact ( self ) : NEW_LINE INDENT from pip . vcs import vcs NEW_LINE if self . scheme in vcs . all_schemes : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE DEDENT DEDENT INSTALLED_VERSION = Link ( Inf ) NEW_LINE FormatControl = namedtuple ( ' FormatControl ' , ' no _ binary ▁ only _ binary ' ) NEW_LINE def fmt_ctl_handle_mutual_exclude ( value , target , other ) : NEW_LINE INDENT new = value . split ( ' , ' ) NEW_LINE while ' : all : ' in new : NEW_LINE INDENT other . clear ( ) NEW_LINE target . clear ( ) NEW_LINE target . add ( ' : all : ' ) NEW_LINE del new [ : new . index ( ' : all : ' ) + 1 ] NEW_LINE if ' : none : ' not in new : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT for name in new : NEW_LINE INDENT if name == ' : none : ' : NEW_LINE INDENT target . clear ( ) NEW_LINE continue NEW_LINE DEDENT name = pkg_resources . safe_name ( name ) . lower ( ) NEW_LINE other . discard ( name ) NEW_LINE target . add ( name ) NEW_LINE DEDENT DEDENT def fmt_ctl_formats ( fmt_ctl , canonical_name ) : NEW_LINE INDENT result = set ( [ " binary " , " source " ] ) NEW_LINE if canonical_name in fmt_ctl . only_binary : NEW_LINE INDENT result . discard ( ' source ' ) NEW_LINE DEDENT elif canonical_name in fmt_ctl . no_binary : NEW_LINE INDENT result . discard ( ' binary ' ) NEW_LINE DEDENT elif ' : all : ' in fmt_ctl . only_binary : NEW_LINE INDENT result . discard ( ' source ' ) NEW_LINE DEDENT elif ' : all : ' in fmt_ctl . no_binary : NEW_LINE INDENT result . discard ( ' binary ' ) NEW_LINE DEDENT return frozenset ( result ) NEW_LINE DEDENT def fmt_ctl_no_binary ( fmt_ctl ) : NEW_LINE INDENT fmt_ctl_handle_mutual_exclude ( ' : all : ' , fmt_ctl . no_binary , fmt_ctl . only_binary ) NEW_LINE DEDENT def fmt_ctl_no_use_wheel ( fmt_ctl ) : NEW_LINE INDENT fmt_ctl_no_binary ( fmt_ctl ) NEW_LINE warnings . warn ( ' - - no - use - wheel ▁ is ▁ deprecated ▁ and ▁ will ▁ be ▁ removed ▁ in ▁ the ▁ future . ▁ ' ' ▁ Please ▁ use ▁ - - no - binary ▁ : all : ▁ instead . ' , DeprecationWarning , stacklevel = 2 ) NEW_LINE DEDENT Search = namedtuple ( ' Search ' , ' supplied ▁ canonical ▁ formats ' ) NEW_LINE
 from __future__ import division NEW_LINE from collections import deque NEW_LINE from datetime import timedelta NEW_LINE from math import ceil NEW_LINE from sys import stderr NEW_LINE from time import time NEW_LINE __version__ = '1.2' NEW_LINE class Infinite ( object ) : NEW_LINE INDENT file = stderr NEW_LINE sma_window = 10 NEW_LINE def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT self . index = 0 NEW_LINE self . start_ts = time ( ) NEW_LINE self . _ts = self . start_ts NEW_LINE self . _dt = deque ( maxlen = self . sma_window ) NEW_LINE for key , val in kwargs . items ( ) : NEW_LINE INDENT setattr ( self , key , val ) NEW_LINE DEDENT DEDENT def __getitem__ ( self , key ) : NEW_LINE INDENT if key . startswith ( ' _ ' ) : NEW_LINE INDENT return None NEW_LINE DEDENT return getattr ( self , key , None ) NEW_LINE DEDENT @ property NEW_LINE def avg ( self ) : NEW_LINE INDENT return sum ( self . _dt ) / len ( self . _dt ) if self . _dt else 0 NEW_LINE DEDENT @ property NEW_LINE def elapsed ( self ) : NEW_LINE INDENT return int ( time ( ) - self . start_ts ) NEW_LINE DEDENT @ property NEW_LINE def elapsed_td ( self ) : NEW_LINE INDENT return timedelta ( seconds = self . elapsed ) NEW_LINE DEDENT def update ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def start ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def finish ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def next ( self , n = 1 ) : NEW_LINE INDENT if n > 0 : NEW_LINE INDENT now = time ( ) NEW_LINE dt = ( now - self . _ts ) / n NEW_LINE self . _dt . append ( dt ) NEW_LINE self . _ts = now NEW_LINE DEDENT self . index = self . index + n NEW_LINE self . update ( ) NEW_LINE DEDENT def iter ( self , it ) : NEW_LINE INDENT for x in it : NEW_LINE INDENT yield x NEW_LINE self . next ( ) NEW_LINE DEDENT self . finish ( ) NEW_LINE DEDENT DEDENT class Progress ( Infinite ) : NEW_LINE INDENT def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT super ( Progress , self ) . __init__ ( * args , ** kwargs ) NEW_LINE self . max = kwargs . get ( ' max ' , 100 ) NEW_LINE DEDENT @ property NEW_LINE def eta ( self ) : NEW_LINE INDENT return int ( ceil ( self . avg * self . remaining ) ) NEW_LINE DEDENT @ property NEW_LINE def eta_td ( self ) : NEW_LINE INDENT return timedelta ( seconds = self . eta ) NEW_LINE DEDENT @ property NEW_LINE def percent ( self ) : NEW_LINE INDENT return self . progress * 100 NEW_LINE DEDENT @ property NEW_LINE def progress ( self ) : NEW_LINE INDENT return min ( 1 , self . index / self . max ) NEW_LINE DEDENT @ property NEW_LINE def remaining ( self ) : NEW_LINE INDENT return max ( self . max - self . index , 0 ) NEW_LINE DEDENT def start ( self ) : NEW_LINE INDENT self . update ( ) NEW_LINE DEDENT def goto ( self , index ) : NEW_LINE INDENT incr = index - self . index NEW_LINE self . next ( incr ) NEW_LINE DEDENT def iter ( self , it ) : NEW_LINE INDENT try : NEW_LINE INDENT self . max = len ( it ) NEW_LINE DEDENT except TypeError : NEW_LINE INDENT pass NEW_LINE DEDENT for x in it : NEW_LINE INDENT yield x NEW_LINE self . next ( ) NEW_LINE DEDENT self . finish ( ) NEW_LINE DEDENT DEDENT
 __all__ = [ ' enum ' , ' degreesToRadians ' , ' radiansToDegrees ' ] NEW_LINE import numpy as np NEW_LINE from pygaia . astrometry . constants import auKmYearPerSec NEW_LINE def enum ( typename , field_names ) : NEW_LINE INDENT if isinstance ( field_names , str ) : NEW_LINE INDENT field_names = field_names . replace ( ' , ' , ' ▁ ' ) . split ( ) NEW_LINE DEDENT d = dict ( ( reversed ( nv ) for nv in enumerate ( field_names ) ) , __slots__ = ( ) ) NEW_LINE return type ( typename , ( object , ) , d ) ( ) NEW_LINE DEDENT def degreesToRadians ( angle ) : NEW_LINE INDENT return angle / 180.0 * np . pi NEW_LINE DEDENT def radiansToDegrees ( angle ) : NEW_LINE INDENT return angle / np . pi * 180.0 NEW_LINE DEDENT def construct_covariance_matrix ( cvec , parallax , radial_velocity , radial_velocity_error ) : NEW_LINE INDENT if np . ndim ( cvec ) == 1 : NEW_LINE INDENT cmat = np . zeros ( ( 1 , 6 , 6 ) ) NEW_LINE nsources = 1 NEW_LINE cv = np . atleast_2d ( cvec ) NEW_LINE DEDENT else : NEW_LINE INDENT nsources = cvec . shape [ 0 ] NEW_LINE cmat = np . zeros ( ( nsources , 6 , 6 ) ) NEW_LINE cv = cvec NEW_LINE DEDENT for k in range ( nsources ) : NEW_LINE INDENT cmat [ k , 0 : 5 , 0 : 5 ] = cv [ k , 0 : 5 ] ** 2 NEW_LINE DEDENT iu = np . triu_indices ( 5 , k = 1 ) NEW_LINE for k in range ( 10 ) : NEW_LINE INDENT i = iu [ 0 ] [ k ] NEW_LINE j = iu [ 1 ] [ k ] NEW_LINE cmat [ : , i , j ] = cv [ : , i ] * cv [ : , j ] * cv [ : , k + 5 ] NEW_LINE cmat [ : , j , i ] = cmat [ : , i , j ] NEW_LINE DEDENT for k in range ( nsources ) : NEW_LINE INDENT cmat [ k , 0 : 5 , 5 ] = cmat [ k , 0 : 5 , 2 ] * np . atleast_1d ( radial_velocity ) [ k ] / auKmYearPerSec NEW_LINE DEDENT cmat [ : , 5 , 0 : 5 ] = cmat [ : , 0 : 5 , 5 ] NEW_LINE cmat [ : , 5 , 5 ] = cmat [ : , 2 , 2 ] * ( radial_velocity ** 2 + radial_velocity_error ** 2 ) / auKmYearPerSec ** 2 + \NEW_LINE ( parallax * radial_velocity_error / auKmYearPerSec ) ** 2 NEW_LINE return np . squeeze ( cmat ) NEW_LINE DEDENT
 import os NEW_LINE import sys NEW_LINE import pytest NEW_LINE import flask NEW_LINE from flask . _compat import PY2 NEW_LINE def test_explicit_instance_paths ( modules_tmpdir ) : NEW_LINE INDENT with pytest . raises ( ValueError ) as excinfo : NEW_LINE INDENT flask . Flask ( __name__ , instance_path = ' instance ' ) NEW_LINE DEDENT assert ' must ▁ be ▁ absolute ' in str ( excinfo . value ) NEW_LINE app = flask . Flask ( __name__ , instance_path = str ( modules_tmpdir ) ) NEW_LINE assert app . instance_path == str ( modules_tmpdir ) NEW_LINE DEDENT def test_main_module_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' main _ app . py ' ) NEW_LINE app . write ( ' import ▁ flask \n \n app ▁ = ▁ flask . Flask ( " _ _ main _ _ " ) ' ) NEW_LINE purge_module ( ' main _ app ' ) NEW_LINE from main_app import app NEW_LINE here = os . path . abspath ( os . getcwd ( ) ) NEW_LINE assert app . instance_path == os . path . join ( here , ' instance ' ) NEW_LINE DEDENT def test_uninstalled_module_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' config _ module _ app . py ' ) . write ( ' import ▁ os \n ' ' import ▁ flask \n ' ' here ▁ = ▁ os . path . abspath ( os . path . dirname ( _ _ file _ _ ) ) \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' config _ module _ app ' ) NEW_LINE from config_module_app import app NEW_LINE assert app . instance_path == str ( modules_tmpdir . join ( ' instance ' ) ) NEW_LINE DEDENT def test_uninstalled_package_paths ( modules_tmpdir , purge_module ) : NEW_LINE INDENT app = modules_tmpdir . mkdir ( ' config _ package _ app ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ os \n ' ' import ▁ flask \n ' ' here ▁ = ▁ os . path . abspath ( os . path . dirname ( _ _ file _ _ ) ) \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' config _ package _ app ' ) NEW_LINE from config_package_app import app NEW_LINE assert app . instance_path == str ( modules_tmpdir . join ( ' instance ' ) ) NEW_LINE DEDENT def test_installed_module_paths ( modules_tmpdir , modules_tmpdir_prefix , purge_module , site_packages , limit_loader ) : NEW_LINE INDENT site_packages . join ( ' site _ app . py ' ) . write ( ' import ▁ flask \n ' ' app ▁ = ▁ flask . Flask ( _ _ name _ _ ) \n ' ) NEW_LINE purge_module ( ' site _ app ' ) NEW_LINE from site_app import app NEW_LINE assert app . instance_path == \NEW_LINE modules_tmpdir . join ( ' var ' ) . join ( ' site _ app - instance ' ) NEW_LINE DEDENT def test_installed_package_paths ( limit_loader , modules_tmpdir , modules_tmpdir_prefix , purge_module , monkeypatch ) : NEW_LINE INDENT installed_path = modules_tmpdir . mkdir ( ' path ' ) NEW_LINE monkeypatch . syspath_prepend ( installed_path ) NEW_LINE app = installed_path . mkdir ( ' installed _ package ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE purge_module ( ' installed _ package ' ) NEW_LINE from installed_package import app NEW_LINE assert app . instance_path == \NEW_LINE modules_tmpdir . join ( ' var ' ) . join ( ' installed _ package - instance ' ) NEW_LINE DEDENT def test_prefix_package_paths ( limit_loader , modules_tmpdir , modules_tmpdir_prefix , purge_module , site_packages ) : NEW_LINE INDENT app = site_packages . mkdir ( ' site _ package ' ) NEW_LINE init = app . join ( ' _ _ init _ _ . py ' ) NEW_LINE init . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE purge_module ( ' site _ package ' ) NEW_LINE import site_package NEW_LINE assert site_package . app . instance_path == \NEW_LINE modules_tmpdir . join ( ' var ' ) . join ( ' site _ package - instance ' ) NEW_LINE DEDENT def test_egg_installed_paths ( install_egg , modules_tmpdir , modules_tmpdir_prefix ) : NEW_LINE INDENT modules_tmpdir . mkdir ( ' site _ egg ' ) . join ( ' _ _ init _ _ . py ' ) . write ( ' import ▁ flask \n \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE install_egg ( ' site _ egg ' ) NEW_LINE try : NEW_LINE INDENT import site_egg NEW_LINE assert site_egg . app . instance_path == \NEW_LINE str ( modules_tmpdir . join ( ' var / ' ) . join ( ' site _ egg - instance ' ) ) NEW_LINE DEDENT finally : NEW_LINE INDENT if ' site _ egg ' in sys . modules : NEW_LINE INDENT del sys . modules [ ' site _ egg ' ] NEW_LINE DEDENT DEDENT DEDENT @ pytest . mark . skipif ( not PY2 , reason = ' This ▁ only ▁ works ▁ under ▁ Python ▁ 2 . ' ) NEW_LINE def test_meta_path_loader_without_is_package ( request , modules_tmpdir ) : NEW_LINE INDENT app = modules_tmpdir . join ( ' unimportable . py ' ) NEW_LINE app . write ( ' import ▁ flask \n app ▁ = ▁ flask . Flask ( _ _ name _ _ ) ' ) NEW_LINE class Loader ( object ) : NEW_LINE INDENT def find_module ( self , name , path = None ) : NEW_LINE INDENT return self NEW_LINE DEDENT DEDENT sys . meta_path . append ( Loader ( ) ) NEW_LINE request . addfinalizer ( sys . meta_path . pop ) NEW_LINE with pytest . raises ( AttributeError ) : NEW_LINE INDENT import unimportable NEW_LINE DEDENT DEDENT
 from insights . tests import context_wrap NEW_LINE from insights . parsers . foreman_log import SatelliteLog , ProductionLog NEW_LINE from insights . parsers . foreman_log import CandlepinLog , ProxyLog NEW_LINE PRODUCTION_LOG = """ STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 1783ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 172.9ms ) STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : V2 : : RepositoriesController # sync _ complete ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " call _ report " = > " [ FILTERED ] " , ▁ " event _ type " = > " repo . sync . finish " , ▁ " payload " = > { " importer _ id " = > " yum _ importer " , ▁ " exception " = > nil , ▁ " repo _ id " = > " 1 - Gulfstream _ Aerospace _ Corp _ - Red _ Hat _ Enterprise _ Linux _ Server - Red _ Hat _ Satellite _ Tools _ 6_1 _ for _ RHEL _ 6 _ Server _ RPMs _ i386 " , ▁ " traceback " = > nil , ▁ " started " = > " 2015-11-13T08:30:00Z " , ▁ " _ ns " = > " repo _ sync _ results " , ▁ " completed " = > " 2015-11-13T08:30:06Z " , ▁ " importer _ type _ id " = > " yum _ importer " , ▁ " error _ message " = > nil , ▁ " summary " = > { " content " = > { " state " = > " FINISHED " } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " state " = > " FINISHED " } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " added _ count " = > 0 , ▁ " result " = > " success " , ▁ " updated _ count " = > 3 , ▁ " details " = > { " content " = > { " size _ total " = > 0 , ▁ " items _ left " = > 0 , ▁ " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " size _ left " = > 0 , ▁ " details " = > { " rpm _ total " = > 0 , ▁ " rpm _ done " = > 0 , ▁ " drpm _ total " = > 0 , ▁ " drpm _ done " = > 0 } , ▁ " error _ details " = > [ ] } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " error _ details " = > [ ] , ▁ " items _ left " = > 0 } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " id " = > " 56459f8ef301a213bbfd87bb " , ▁ " removed _ count " = > 0 } , ▁ " token " = > " oQumn3XsKrdRkijuvpCNhKF2PDWZt6az " , ▁ " api _ version " = > " v2 " , ▁ " repository " = > { } } STRNEWLINE 2015-11-13 ▁ 03:30:07 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ Red ▁ Hat ▁ Satellite ▁ Tools ▁ 6.1 ▁ for ▁ RHEL ▁ 6 ▁ Server ▁ RPMs ▁ i386 , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:30:09 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 1995ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 81.5ms ) STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : V2 : : RepositoriesController # sync _ complete ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " call _ report " = > " [ FILTERED ] " , ▁ " event _ type " = > " repo . sync . finish " , ▁ " payload " = > { " importer _ id " = > " yum _ importer " , ▁ " exception " = > nil , ▁ " repo _ id " = > " 1 - Gulfstream _ Aerospace _ Corp _ - Red _ Hat _ Enterprise _ Linux _ Server - Red _ Hat _ Satellite _ Tools _ 6_1 _ for _ RHEL _ 5 _ Server _ RPMs _ i386 " , ▁ " traceback " = > nil , ▁ " started " = > " 2015-11-13T08:30:05Z " , ▁ " _ ns " = > " repo _ sync _ results " , ▁ " completed " = > " 2015-11-13T08:30:10Z " , ▁ " importer _ type _ id " = > " yum _ importer " , ▁ " error _ message " = > nil , ▁ " summary " = > { " content " = > { " state " = > " FINISHED " } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " state " = > " FINISHED " } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " added _ count " = > 0 , ▁ " result " = > " success " , ▁ " updated _ count " = > 3 , ▁ " details " = > { " content " = > { " size _ total " = > 0 , ▁ " items _ left " = > 0 , ▁ " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " size _ left " = > 0 , ▁ " details " = > { " rpm _ total " = > 0 , ▁ " rpm _ done " = > 0 , ▁ " drpm _ total " = > 0 , ▁ " drpm _ done " = > 0 } , ▁ " error _ details " = > [ ] } , ▁ " comps " = > { " state " = > " FINISHED " } , ▁ " distribution " = > { " items _ total " = > 0 , ▁ " state " = > " FINISHED " , ▁ " error _ details " = > [ ] , ▁ " items _ left " = > 0 } , ▁ " errata " = > { " state " = > " FINISHED " } , ▁ " metadata " = > { " state " = > " FINISHED " } } , ▁ " id " = > " 56459f92f301a2137cd6b802 " , ▁ " removed _ count " = > 0 } , ▁ " token " = > " oQumn3XsKrdRkijuvpCNhKF2PDWZt6az " , ▁ " api _ version " = > " v2 " , ▁ " repository " = > { } } STRNEWLINE 2015-11-13 ▁ 03:30:10 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ Red ▁ Hat ▁ Satellite ▁ Tools ▁ 6.1 ▁ for ▁ RHEL ▁ 5 ▁ Server ▁ RPMs ▁ i386 , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:11 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 818ms ▁ ( Views : ▁ 0.2ms ▁ | ▁ ActiveRecord : ▁ 77.2ms ) STRNEWLINE 2015-11-13 ▁ 03:30:17 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 03:30:26 ▁ [ I ] ▁ Sync _ complete ▁ called ▁ for ▁ RHN ▁ Tools ▁ for ▁ Red ▁ Hat ▁ Enterprise ▁ Linux ▁ 5 ▁ Server ▁ RPMs ▁ x86_64 ▁ 5Server , ▁ running ▁ after _ sync . STRNEWLINE 2015-11-13 ▁ 03:50:46 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 2583ms ▁ ( Views : ▁ 2.7ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 06:58:25 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 06:58:25 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 249ms ▁ ( Views : ▁ 3.1ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 06:59:26 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 84ms ▁ ( Views : ▁ 3.1ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:12 ▁ [ I ] ▁ Connecting ▁ to ▁ database ▁ specified ▁ by ▁ database . yml STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:00:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " facts " = > " [ FILTERED ] " , ▁ " name " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " certname " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " apiv " = > " v2 " , ▁ : host = > { " name " = > " infrhnpl002 . gac . gulfaero . com " , ▁ " certname " = > " infrhnpl002 . gac . gulfaero . com " } } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Import ▁ facts ▁ for ▁ ' infrhnpl002 . gac . gulfaero . com ' ▁ completed . ▁ Added : ▁ 0 , ▁ Updated : ▁ 6 , ▁ Deleted ▁ 0 ▁ facts STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 201 ▁ Created ▁ in ▁ 251ms ▁ ( Views : ▁ 179.3ms ▁ | ▁ ActiveRecord : ▁ 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Processing ▁ by ▁ HostsController # externalNodes ▁ as ▁ YML STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " name " = > " infrhnpl002 . gac . gulfaero . com " } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Rendered ▁ text ▁ template ▁ ( 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 48ms ▁ ( Views : ▁ 0.5ms ▁ | ▁ ActiveRecord : ▁ 6.6ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Processing ▁ by ▁ Api : : V2 : : ReportsController # create ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " report " = > " [ FILTERED ] " , ▁ " apiv " = > " v2 " } STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ ▁ ▁ Rendered ▁ text ▁ template ▁ ( 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ processing ▁ report ▁ for ▁ infrhnpl002 . gac . gulfaero . com STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Imported ▁ report ▁ for ▁ infrhnpl002 . gac . gulfaero . com ▁ in ▁ 0.02 ▁ seconds STRNEWLINE 2015-11-13 ▁ 07:09:22 ▁ [ I ] ▁ Completed ▁ 201 ▁ Created ▁ in ▁ 28ms ▁ ( Views : ▁ 1.2ms ▁ | ▁ ActiveRecord : ▁ 0.0ms ) STRNEWLINE 2015-11-13 ▁ 07:30:17 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Organization . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:18 ▁ [ W ] ▁ Creating ▁ scope ▁ : completer _ scope . ▁ Overwriting ▁ existing ▁ method ▁ Location . completer _ scope . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Client ▁ connected . STRNEWLINE 2015-11-13 ▁ 07:30:25 ▁ [ I ] ▁ Connected ▁ to ▁ server . STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:30 ▁ [ I ] ▁ init ▁ config ▁ for ▁ SecureHeaders : : Configuration STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 07:30:32 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 110ms ▁ ( Views : ▁ 2.7ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 07:30:33 ▁ [ I ] ▁ 2015-11-13 ▁ 07:30:33 ▁ - 0500 : ▁ Expired ▁ 48 ▁ Reports STRNEWLINE 2015-11-13 ▁ 07:30:33 ▁ [ I ] ▁ Client ▁ disconnected . STRNEWLINE 2015-11-13 ▁ 09:41:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 93ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 09:42:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 80ms ▁ ( Views : ▁ 3.6ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE 2015-11-13 ▁ 09:43:58 ▁ [ I ] ▁ Processing ▁ by ▁ Katello : : Api : : Rhsm : : CandlepinProxiesController # consumer _ show ▁ as ▁ JSON STRNEWLINE 2015-11-13 ▁ 09:43:58 ▁ [ I ] ▁ ▁ ▁ Parameters : ▁ { " id " = > " cfd7275b - 8cce - 4323-8d1f - 55ef85eca883 " } STRNEWLINE 2015-11-13 ▁ 09:43:59 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 80ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) STRNEWLINE """ . strip ( ) NEW_LINE SATELLITE_OUT = """ STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ cert ] / require : ▁ requires ▁ Class [ Certs : : Pulp _ client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ cert ] / require : ▁ requires ▁ Exec [ foreman - rake - db : seed ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ key ] / require : ▁ requires ▁ Class [ Certs : : Pulp _ client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config : : Pulp _ client / Foreman _ config _ entry [ pulp _ client _ key ] / require : ▁ requires ▁ Exec [ foreman - rake - db : seed ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / before : ▁ requires ▁ Class [ Foreman : : Database ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / before : ▁ requires ▁ Exec [ foreman - rake - db : migrate ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / notify : ▁ subscribes ▁ to ▁ Service [ foreman - tasks ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / File [ / etc / foreman / plugins / katello . yaml ] / notify : ▁ subscribes ▁ to ▁ Class [ Foreman : : Service ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Katello : : Config / Foreman : : Config : : Passenger : : Fragment [ katello ] / require : ▁ requires ▁ Class [ Foreman : : Config : : Passenger ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / notify : ▁ subscribes ▁ to ▁ Class [ Certs : : Candlepin ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Cert [ kam1opapp999 . connex . bclc . com - qpid - broker ] / notify : ▁ subscribes ▁ to ▁ Pubkey [ / etc / pki / katello / certs / kam1opapp999 . connex . bclc . com - qpid - broker . crt ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Pubkey [ / etc / pki / katello / certs / kam1opapp999 . connex . bclc . com - qpid - broker . crt ] / notify : ▁ subscribes ▁ to ▁ Privkey [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Privkey [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / private / kam1opapp999 . connex . bclc . com - qpid - broker . key ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb ] / notify : ▁ subscribes ▁ to ▁ Exec [ generate - nss - password ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ generate - nss - password ] / before : ▁ requires ▁ File [ / etc / pki / katello / nssdb / nss _ db _ password - file ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / nss _ db _ password - file ] / notify : ▁ subscribes ▁ to ▁ Exec [ create - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ ca ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / before : ▁ requires ▁ Exec [ delete ▁ amqp - client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ create - nss - db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ ca ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / cert8 . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / key3 . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ ca ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / pki / katello / nssdb / secmod . db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / cert8 . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / key3 . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / File [ / etc / pki / katello / nssdb / secmod . db ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ broker ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Certs : : Ssltools : : Certutil [ broker ] / notify : ▁ subscribes ▁ to ▁ Exec [ generate - pfx - for - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ generate - pfx - for - nss - db ] / notify : ▁ subscribes ▁ to ▁ Exec [ add - private - key - to - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Qpid / Exec [ add - private - key - to - nss - db ] / notify : ▁ subscribes ▁ to ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Cert [ java - client ] / notify : ▁ subscribes ▁ to ▁ Pubkey [ / etc / pki / katello / certs / java - client . crt ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / pki / katello / keystore _ password - file ] / notify : ▁ subscribes ▁ to ▁ Exec [ candlepin - generate - ssl - keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ candlepin - generate - ssl - keystore ] / notify : ▁ subscribes ▁ to ▁ File [ / usr / share / tomcat / conf / keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / usr / share / tomcat / conf / keystore ] / notify : ▁ subscribes ▁ to ▁ Service [ tomcat ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Pubkey [ / etc / pki / katello / certs / java - client . crt ] / notify : ▁ subscribes ▁ to ▁ Privkey [ / etc / pki / katello / private / java - client . key ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Privkey [ / etc / pki / katello / private / java - client . key ] / notify : ▁ subscribes ▁ to ▁ Certs : : Ssltools : : Certutil [ amqp - client ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / subscribe : ▁ subscribes ▁ to ▁ Exec [ create - nss - db ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / notify : ▁ subscribes ▁ to ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Certs : : Ssltools : : Certutil [ amqp - client ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / candlepin / certs / amqp ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / candlepin / certs / amqp ] / notify : ▁ subscribes ▁ to ▁ Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] / require : ▁ requires ▁ Service [ qpidd ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ create ▁ candlepin ▁ qpid ▁ exchange ] / notify : ▁ subscribes ▁ to ▁ Exec [ import ▁ CA ▁ into ▁ Candlepin ▁ truststore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ import ▁ CA ▁ into ▁ Candlepin ▁ truststore ] / notify : ▁ subscribes ▁ to ▁ Exec [ import ▁ client ▁ certificate ▁ into ▁ Candlepin ▁ keystore ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / Exec [ import ▁ client ▁ certificate ▁ into ▁ Candlepin ▁ keystore ] / notify : ▁ subscribes ▁ to ▁ File [ / etc / candlepin / certs / amqp / candlepin . jks ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Certs : : Candlepin / File [ / etc / candlepin / certs / amqp / candlepin . jks ] / notify : ▁ subscribes ▁ to ▁ Service [ tomcat ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin / notify : ▁ subscribes ▁ to ▁ Class [ Qpid ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Install / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Config ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Config / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Database ] STRNEWLINE [ DEBUG ▁ 2016-08-11 ▁ 13:09:49 ▁ main ] ▁ ▁ / Stage [ main ] / Candlepin : : Database / notify : ▁ subscribes ▁ to ▁ Class [ Candlepin : : Service ] STRNEWLINE """ . strip ( ) NEW_LINE CANDLEPIN_LOG = """ STRNEWLINE 2016-09-09 ▁ 13:45:52,650 ▁ [ req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b STRNEWLINE 2016-09-09 ▁ 13:45:52,784 ▁ [ req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc , ▁ org = ING _ Luxembourg _ SA ] ▁ INFO ▁ ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 134 STRNEWLINE 2016-09-09 ▁ 13:45:52,947 ▁ [ req = 909ca4c5 - f24e - 4212-8f23 - cc754d06ac57 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b / content _ overrides STRNEWLINE 2016-09-09 ▁ 13:45:52,976 ▁ [ req = 909ca4c5 - f24e - 4212-8f23 - cc754d06ac57 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 29 STRNEWLINE 2016-09-09 ▁ 13:45:53,072 ▁ [ req = 49becd26-5dfe - 4d2f - 8667-470519230d88 , ▁ org = ] ▁ INFO ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Request : ▁ verb = GET , ▁ uri = / candlepin / consumers / f7677b4b - c470-4626-86a4-2fdf2546af4b / release STRNEWLINE 2016-09-09 ▁ 13:45:53,115 ▁ [ req = 49becd26-5dfe - 4d2f - 8667-470519230d88 , ▁ org = ING _ Luxembourg _ SA ] ▁ INFO ▁ ▁ org . candlepin . common . filter . LoggingFilter ▁ - ▁ Response : ▁ status = 200 , ▁ content - type = " application / json " , ▁ time = 43 STRNEWLINE """ . strip ( ) NEW_LINE PROXY_LOG = """ STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:28 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL _ 6_5 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 6.1205 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:38 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL _ 7_6 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 4.4754 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:42:49 ▁ - 0400 ] ▁ " GET ▁ / puppet / environments / KT _ Encore _ Library _ RHEL6_8 / classes ▁ HTTP / 1.1 " ▁ 200 ▁ 76785 ▁ 4.5776 STRNEWLINE 127.0.0.1 ▁ - ▁ - ▁ [ 31 / May / 2016:09:57:34 ▁ - 0400 ] ▁ " GET ▁ / tftp / serverName ▁ HTTP / 1.1 " ▁ 200 ▁ 38 ▁ 0.0014 STRNEWLINE E , ▁ [ 2016-05-31T09:57:34.884636 ▁ # 4494 ] ▁ ERROR ▁ - - ▁ : ▁ Record ▁ 172.16.100.0/172.16.100.17 ▁ not ▁ found ▁ ] STRNEWLINE """ . strip ( ) NEW_LINE def test_production_log ( ) : NEW_LINE INDENT fm_log = ProductionLog ( context_wrap ( PRODUCTION_LOG ) ) NEW_LINE assert 2 == len ( fm_log . get ( " Rendered ▁ text ▁ template " ) ) NEW_LINE assert " Expired ▁ 48 ▁ Reports " in fm_log NEW_LINE assert fm_log . get ( " Completed ▁ 200 ▁ OK ▁ in ▁ 93" ) [ 0 ] == "2015-11-13 ▁ 09:41:58 ▁ [ I ] ▁ Completed ▁ 200 ▁ OK ▁ in ▁ 93ms ▁ ( Views : ▁ 2.9ms ▁ | ▁ ActiveRecord : ▁ 0.3ms ) " NEW_LINE DEDENT def test_proxy_log ( ) : NEW_LINE INDENT px_log = ProxyLog ( context_wrap ( PROXY_LOG ) ) NEW_LINE assert " ERROR ▁ - - ▁ " in px_log NEW_LINE assert len ( px_log . get ( " KT _ Encore _ Library _ RHEL " ) ) == 3 NEW_LINE DEDENT def test_candlepin_log ( ) : NEW_LINE INDENT cp_log = CandlepinLog ( context_wrap ( CANDLEPIN_LOG ) ) NEW_LINE assert " req = 49becd26-5dfe - 4d2f - 8667-470519230d88" in cp_log NEW_LINE assert len ( cp_log . get ( " req = bd5a4284 - d280-4fc5 - a3d5 - fc976b7aa5cc " ) ) == 2 NEW_LINE DEDENT def test_satellite_log ( ) : NEW_LINE INDENT sat_log = SatelliteLog ( context_wrap ( SATELLITE_OUT ) ) NEW_LINE assert " subscribes ▁ to ▁ Class [ Qpid ] " in sat_log NEW_LINE assert len ( sat_log . get ( " notify : ▁ subscribes ▁ to ▁ Class [ " ) ) == 7 NEW_LINE DEDENT
 import sys NEW_LINE import os NEW_LINE import os . path NEW_LINE OCCURRENCE__REQUIRED_ITEM = " r " NEW_LINE OCCURRENCE__REQUIRED_LIST = " rl " NEW_LINE OCCURRENCE__OPTIONAL_ITEM = " o " NEW_LINE OCCURRENCE__OPTIONAL_LIST = " ol " NEW_LINE OCCURRENCE__IGNORED = " i " NEW_LINE valid_occurrences = [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_ITEM , OCCURRENCE__OPTIONAL_LIST , OCCURRENCE__IGNORED ] NEW_LINE autobind_names = set ( ) NEW_LINE separator = " / * ▁ " + ( " * ▁ " * 37 ) + " * \n " NEW_LINE def aligned ( left , right , length = 59 ) : NEW_LINE INDENT while len ( left ) < length : NEW_LINE INDENT left += " ▁ " NEW_LINE DEDENT return left + right NEW_LINE DEDENT class Member : NEW_LINE INDENT def __init__ ( self , type , occurrence ) : NEW_LINE INDENT self . type = type NEW_LINE self . occurrence = occurrence NEW_LINE DEDENT def is_enum ( self ) : NEW_LINE INDENT return self . type in predefined_enums or self . type in enums_by_name NEW_LINE DEDENT def is_object ( self ) : NEW_LINE INDENT return self . type in predefined_objects or self . type in objects_by_name NEW_LINE DEDENT def is_type_generated ( self ) : NEW_LINE INDENT return self . type in enums_by_name or self . type in objects_by_name NEW_LINE DEDENT def get_occurrence_comment ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__REQUIRED_ITEM : NEW_LINE INDENT return " / * ▁ required ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__REQUIRED_LIST : NEW_LINE INDENT return " / * ▁ required , ▁ list ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_ITEM : NEW_LINE INDENT return " / * ▁ optional ▁ * / " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT return " / * ▁ optional , ▁ list ▁ * / " NEW_LINE DEDENT raise ValueError ( " unknown ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT DEDENT class Parameter ( Member ) : NEW_LINE INDENT def __init__ ( self , type , name , occurrence ) : NEW_LINE INDENT Member . __init__ ( self , type , occurrence ) NEW_LINE if ' : ' in name and name . startswith ( " _ this " ) : NEW_LINE INDENT self . name , self . autobind_name = name . split ( " : " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . name = name NEW_LINE self . autobind_name = None NEW_LINE DEDENT DEDENT def generate_parameter ( self , is_last = False , is_header = True , offset = 0 ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT raise ValueError ( " invalid ▁ function ▁ parameter ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT elif self . autobind_name is not None : NEW_LINE INDENT return " " NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ " NEW_LINE string += " ▁ " * offset NEW_LINE string += " % s % s " % ( self . get_type_string ( ) , self . name ) NEW_LINE if is_last : NEW_LINE INDENT if is_header : NEW_LINE INDENT string += " ) ; ▁ " NEW_LINE DEDENT else : NEW_LINE INDENT string += " ) , ▁ " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT string += " , ▁ " NEW_LINE DEDENT return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_return ( self , offset = 0 , end_of_line = " ; " ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT raise ValueError ( " invalid ▁ function ▁ parameter ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ " NEW_LINE string += " ▁ " * offset NEW_LINE string += " % s % s ) % s " \NEW_LINE % ( self . get_type_string ( True ) , self . name , end_of_line ) NEW_LINE return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_require_code ( self ) : NEW_LINE INDENT if self . occurrence in [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ REQUIRE ( % s ) \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " " NEW_LINE DEDENT DEDENT def generate_serialize_code ( self ) : NEW_LINE INDENT if self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE _ LIST ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE _ VALUE ( String , ▁ % s ) \n " \NEW_LINE % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ SERIALIZE ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def get_type_string ( self , as_return_value = False ) : NEW_LINE INDENT string = " " NEW_LINE if self . type == " String " and \NEW_LINE self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT if as_return_value : NEW_LINE INDENT string += " char ▁ * " NEW_LINE DEDENT else : NEW_LINE INDENT string += " const ▁ char ▁ * " NEW_LINE DEDENT DEDENT elif self . is_enum ( ) : NEW_LINE INDENT string += " esxVI _ % s ▁ " % self . type NEW_LINE DEDENT else : NEW_LINE INDENT string += " esxVI _ % s ▁ * " % self . type NEW_LINE DEDENT if as_return_value : NEW_LINE INDENT string += " * " NEW_LINE DEDENT return string NEW_LINE DEDENT def get_occurrence_short_enum ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__REQUIRED_ITEM : NEW_LINE INDENT return " RequiredItem " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__REQUIRED_LIST : NEW_LINE INDENT return " RequiredList " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_ITEM : NEW_LINE INDENT return " OptionalItem " NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT return " OptionalList " NEW_LINE DEDENT raise ValueError ( " unknown ▁ occurrence ▁ value ▁ ' % s ' " % self . occurrence ) NEW_LINE DEDENT DEDENT class Method : NEW_LINE INDENT def __init__ ( self , name , parameters , returns ) : NEW_LINE INDENT self . name = name NEW_LINE self . parameters = [ ] NEW_LINE self . autobind_parameter = None NEW_LINE self . returns = returns NEW_LINE for parameter in parameters : NEW_LINE INDENT if parameter . autobind_name is None : NEW_LINE INDENT self . parameters . append ( parameter ) NEW_LINE DEDENT else : NEW_LINE INDENT self . autobind_parameter = parameter NEW_LINE DEDENT DEDENT DEDENT def generate_header ( self ) : NEW_LINE INDENT header = " int ▁ esxVI _ % s \n " % self . name NEW_LINE header += " ▁ ▁ ▁ ▁ ▁ ▁ ( esxVI _ Context ▁ * ctx " NEW_LINE if len ( self . parameters ) > 0 or self . returns is not None : NEW_LINE INDENT header += " , \n " NEW_LINE for parameter in self . parameters [ : - 1 ] : NEW_LINE INDENT header += parameter . generate_parameter ( ) NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT header += self . parameters [ - 1 ] . generate_parameter ( is_last = True ) NEW_LINE DEDENT else : NEW_LINE INDENT header += self . parameters [ - 1 ] . generate_parameter ( ) NEW_LINE header += self . returns . generate_return ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT header += " ) ; \n " NEW_LINE DEDENT header += " \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = " / * ▁ esxVI _ % s ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ METHOD ( % s , " % self . name NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT autobind_names . add ( self . autobind_parameter . autobind_name ) NEW_LINE source += " ▁ % s , \n " % self . autobind_parameter . autobind_name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ / * ▁ explicit ▁ _ this ▁ * / , \n " NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ( esxVI _ Context ▁ * ctx " NEW_LINE if len ( self . parameters ) > 0 or self . returns is not None : NEW_LINE INDENT source += " , \n " NEW_LINE for parameter in self . parameters [ : - 1 ] : NEW_LINE INDENT source += parameter . generate_parameter ( is_header = False , offset = 9 ) NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT source += self . parameters [ - 1 ] . generate_parameter ( is_last = True , is_header = False , offset = 9 ) NEW_LINE DEDENT else : NEW_LINE INDENT source += self . parameters [ - 1 ] . generate_parameter ( is_header = False , offset = 9 ) NEW_LINE source += self . returns . generate_return ( offset = 9 , end_of_line = " , " ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT source += " ) , \n " NEW_LINE DEDENT if self . returns is None : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ void , ▁ / * ▁ nothing ▁ * / , ▁ None , \n " NEW_LINE DEDENT elif self . returns . type == " String " : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ String , ▁ Value , ▁ % s , \n " \NEW_LINE % self . returns . get_occurrence_short_enum ( ) NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s , ▁ / * ▁ nothing ▁ * / , ▁ % s , \n " \NEW_LINE % ( self . returns . type , self . returns . get_occurrence_short_enum ( ) ) NEW_LINE DEDENT source += " { \n " NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT source += self . autobind_parameter . generate_require_code ( ) NEW_LINE DEDENT for parameter in self . parameters : NEW_LINE INDENT source += parameter . generate_require_code ( ) NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . autobind_parameter is not None : NEW_LINE INDENT source += self . autobind_parameter . generate_serialize_code ( ) NEW_LINE DEDENT for parameter in self . parameters : NEW_LINE INDENT source += parameter . generate_serialize_code ( ) NEW_LINE DEDENT source += " } ) \n \n \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class Property ( Member ) : NEW_LINE INDENT def __init__ ( self , type , name , occurrence ) : NEW_LINE INDENT Member . __init__ ( self , type , occurrence ) NEW_LINE self . name = name NEW_LINE DEDENT def generate_struct_member ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ % s % s ; ▁ " % ( self . get_type_string ( ) , self . name ) NEW_LINE return aligned ( string , self . get_occurrence_comment ( ) + " \n " ) NEW_LINE DEDENT DEDENT def generate_free_code ( self ) : NEW_LINE INDENT if self . type == " String " and \NEW_LINE self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST , OCCURRENCE__IGNORED ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ VIR _ FREE ( item - > % s ) ; \n " % self . name NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " " NEW_LINE DEDENT else : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > % s ) ; \n " % ( self . type , self . name ) NEW_LINE DEDENT DEDENT DEDENT def generate_validate_code ( self , managed = False ) : NEW_LINE INDENT if managed : NEW_LINE INDENT macro = " ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ MANAGED _ REQUIRE " NEW_LINE DEDENT else : NEW_LINE INDENT macro = " ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ REQUIRE " NEW_LINE DEDENT if self . occurrence in [ OCCURRENCE__REQUIRED_ITEM , OCCURRENCE__REQUIRED_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ % s ( % s ) \n " % ( macro , self . name ) NEW_LINE DEDENT elif self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " " NEW_LINE DEDENT DEDENT def generate_deep_copy_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY _ LIST ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY _ VALUE ( String , ▁ % s ) \n " \NEW_LINE % self . name NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ( * dest ) - > % s ▁ = ▁ src - > % s ; \n " % ( self . name , self . name ) NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DEEP _ COPY ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_serialize_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ / * ▁ FIXME : ▁ % s ▁ is ▁ currently ▁ ignored ▁ * / \n " % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE _ LIST ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE _ VALUE ( String , ▁ % s ) \n " \NEW_LINE % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ SERIALIZE ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_deserialize_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ IGNORE ( % s ) ▁ / * ▁ FIXME ▁ * / \n " \NEW_LINE % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ LIST ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE _ VALUE ( String , ▁ % s ) \n " \NEW_LINE % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ DESERIALIZE ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def generate_lookup_code ( self ) : NEW_LINE INDENT if self . occurrence == OCCURRENCE__IGNORED : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ FROM _ ANY _ TYPE _ IGNORE ( % s ) ▁ / * ▁ FIXME ▁ * / \n " \NEW_LINE % self . name NEW_LINE DEDENT elif self . occurrence in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ LIST _ FROM _ ANY _ TYPE ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT elif self . type == " String " : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ VALUE _ FROM _ ANY _ TYPE ( String , ▁ % s ) \n " \NEW_LINE % self . name NEW_LINE DEDENT else : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ PROPERTY _ _ CAST _ FROM _ ANY _ TYPE ( % s , ▁ % s ) \n " \NEW_LINE % ( self . type , self . name ) NEW_LINE DEDENT DEDENT def get_type_string ( self ) : NEW_LINE INDENT if self . type == " String " and \NEW_LINE self . occurrence not in [ OCCURRENCE__REQUIRED_LIST , OCCURRENCE__OPTIONAL_LIST ] : NEW_LINE INDENT return " char ▁ * " NEW_LINE DEDENT elif self . is_enum ( ) : NEW_LINE INDENT return " esxVI _ % s ▁ " % self . type NEW_LINE DEDENT else : NEW_LINE INDENT return " esxVI _ % s ▁ * " % self . type NEW_LINE DEDENT DEDENT DEDENT class Type : NEW_LINE INDENT def __init__ ( self , kind , name ) : NEW_LINE INDENT self . kind = kind NEW_LINE self . name = name NEW_LINE DEDENT def generate_typedef ( self ) : NEW_LINE INDENT return " typedef ▁ % s ▁ _ esxVI _ % s ▁ esxVI _ % s ; \n " \NEW_LINE % ( self . kind , self . name , self . name ) NEW_LINE DEDENT def generate_typeenum ( self ) : NEW_LINE INDENT return " ▁ ▁ ▁ ▁ esxVI _ Type _ % s , \n " % self . name NEW_LINE DEDENT def generate_typetostring ( self ) : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ case ▁ esxVI _ Type _ % s : \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ return ▁ \ " % s\ " ; \n \n " % self . name NEW_LINE return string NEW_LINE DEDENT def generate_typefromstring ( self ) : NEW_LINE INDENT string = " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ else ▁ if ▁ ( STREQ ( type , ▁ \ " % s\ " ) ) ▁ { \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ return ▁ esxVI _ Type _ % s ; \n " % self . name NEW_LINE string += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } \n " NEW_LINE return string NEW_LINE DEDENT DEDENT class Object ( Type ) : NEW_LINE INDENT FEATURE__DYNAMIC_CAST = ( 1 << 1 ) NEW_LINE FEATURE__LIST = ( 1 << 2 ) NEW_LINE FEATURE__DEEP_COPY = ( 1 << 3 ) NEW_LINE FEATURE__ANY_TYPE = ( 1 << 4 ) NEW_LINE FEATURE__SERIALIZE = ( 1 << 5 ) NEW_LINE FEATURE__DESERIALIZE = ( 1 << 6 ) NEW_LINE def __init__ ( self , name , extends , properties , features = 0 , extended_by = None ) : NEW_LINE INDENT Type . __init__ ( self , " struct " , name ) NEW_LINE self . extends = extends NEW_LINE self . features = features NEW_LINE self . properties = properties NEW_LINE self . extended_by = extended_by NEW_LINE self . candidate_for_dynamic_cast = False NEW_LINE if self . extended_by is not None : NEW_LINE INDENT self . extended_by . sort ( ) NEW_LINE DEDENT DEDENT def generate_struct_members ( self , add_banner = False , struct_gap = False ) : NEW_LINE INDENT members = " " NEW_LINE if struct_gap : NEW_LINE INDENT members += " \n " NEW_LINE DEDENT if self . extends is not None : NEW_LINE INDENT members += objects_by_name [ self . extends ] \NEW_LINE . generate_struct_members ( add_banner = True , struct_gap = False ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT for property in self . properties : NEW_LINE INDENT members += property . generate_struct_member ( ) NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT return members NEW_LINE DEDENT def generate_free_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] \NEW_LINE . generate_free_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_free_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ freed ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_validate_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] \NEW_LINE . generate_validate_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_validate_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ required ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_dynamic_cast_code ( self , is_first = True ) : NEW_LINE INDENT source = " " NEW_LINE if self . extended_by is not None : NEW_LINE INDENT if not is_first : NEW_LINE INDENT source += " \n " NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST _ _ ACCEPT ( % s ) \n " \NEW_LINE % extended_by NEW_LINE DEDENT for extended_by in self . extended_by : NEW_LINE INDENT source += objects_by_name [ extended_by ] \NEW_LINE . generate_dynamic_cast_code ( False ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_deep_copy_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] \NEW_LINE . generate_deep_copy_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_deep_copy_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ deep ▁ copied ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_serialize_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] \NEW_LINE . generate_serialize_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT for property in self . properties : NEW_LINE INDENT source += property . generate_serialize_code ( ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_deserialize_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += objects_by_name [ self . extends ] \NEW_LINE . generate_deserialize_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT for property in self . properties : NEW_LINE INDENT source += property . generate_deserialize_code ( ) NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = separator NEW_LINE header += " ▁ * ▁ VI ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT header += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " % extended_by NEW_LINE DEDENT DEDENT DEDENT header += " ▁ * / \n \n " NEW_LINE header += " struct ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ next ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT else : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ unused ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ Type ▁ _ type ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += self . generate_struct_members ( struct_gap = True ) NEW_LINE header += " } ; \n \n " NEW_LINE header += " int ▁ esxVI _ % s _ Alloc ( esxVI _ % s ▁ * * item ) ; \n " \NEW_LINE % ( self . name , self . name ) NEW_LINE header += " void ▁ esxVI _ % s _ Free ( esxVI _ % s ▁ * * item ) ; \n " \NEW_LINE % ( self . name , self . name ) NEW_LINE header += " int ▁ esxVI _ % s _ Validate ( esxVI _ % s ▁ * item ) ; \n " \NEW_LINE % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__DYNAMIC_CAST : NEW_LINE INDENT if self . extended_by is not None or self . extends is not None : NEW_LINE INDENT header += " esxVI _ % s ▁ * esxVI _ % s _ DynamicCast ( void ▁ * item ) ; \n " \NEW_LINE % ( self . name , self . name ) NEW_LINE DEDENT else : NEW_LINE INDENT report_error ( " cannot ▁ add ▁ dynamic ▁ cast ▁ support ▁ for ▁ an ▁ untyped ▁ object " ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ AppendToList ( esxVI _ % s ▁ * * list , ▁ esxVI _ % s ▁ * item ) ; \n " \NEW_LINE % ( self . name , self . name , self . name ) NEW_LINE DEDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ DeepCopy ( esxVI _ % s ▁ * * dst , ▁ esxVI _ % s ▁ * src ) ; \n " \NEW_LINE % ( self . name , self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ DeepCopyList ( esxVI _ % s ▁ * * dstList , ▁ " " esxVI _ % s ▁ * srcList ) ; \n " ) \NEW_LINE % ( self . name , self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * * item ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastListFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * * list ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Serialize ( esxVI _ % s ▁ * item , ▁ " " const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ SerializeList ( esxVI _ % s ▁ * list , ▁ " " const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ Deserialize ( xmlNodePtr ▁ node , ▁ esxVI _ % s ▁ * * item ) ; \n " \NEW_LINE % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ DeserializeList ( xmlNodePtr ▁ node , ▁ " " esxVI _ % s ▁ * * list ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE DEDENT DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = separator NEW_LINE source += " ▁ * ▁ VI ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " % extended_by NEW_LINE DEDENT DEDENT DEDENT source += " ▁ * / \n \n " NEW_LINE source += " / * ▁ esxVI _ % s _ Alloc ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ALLOC ( % s ) \n \n " % self . name NEW_LINE if self . extended_by is None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " \NEW_LINE % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n \n " % self . name NEW_LINE DEDENT DEDENT source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ FREE ( % s ) \n " \NEW_LINE % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " \NEW_LINE % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n \n " % self . name NEW_LINE DEDENT DEDENT source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT source += " / * ▁ esxVI _ % s _ Validate ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ VALIDATE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_validate_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__DYNAMIC_CAST : NEW_LINE INDENT if self . extended_by is not None or self . extends is not None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DynamicCast ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_dynamic_cast_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT report_error ( " cannot ▁ add ▁ dynamic ▁ cast ▁ support ▁ for ▁ an ▁ untyped ▁ object " ) NEW_LINE DEDENT DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ AppendToList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ APPEND ( % s ) \n \n " % self . name NEW_LINE DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopy ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DEEP _ COPY ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_deep_copy_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopyList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DEEP _ COPY ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__DEEP_COPY : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopy ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ DEEP _ COPY ( % s ) \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ DEEP _ COPY ( % s ) \n " \NEW_LINE % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_deep_copy_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeepCopyList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DEEP _ COPY ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT DEDENT DEDENT if self . features & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastFromAnyType ▁ * / \n " % self . name NEW_LINE if self . extended_by is None : NEW_LINE INDENT source += " ESX _ VI _ _ TEMPLATE _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ CAST _ FROM _ ANY _ TYPE ( % s , \n " \NEW_LINE % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n " \NEW_LINE % extended_by NEW_LINE DEDENT source += " } ) \n \n " NEW_LINE DEDENT if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastListFromAnyType ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ SERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_serialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ SerializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ SERIALIZE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ SERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ SERIALIZE ( % s ) \n " \NEW_LINE % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_serialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ SerializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ SERIALIZE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT DEDENT DEDENT if self . extended_by is None : NEW_LINE INDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DESERIALIZE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_deserialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeserializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DESERIALIZE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if self . features & Object . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ DESERIALIZE ( % s , \n " \NEW_LINE % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ DESERIALIZE ( % s ) \n " \NEW_LINE % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_deserialize_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ DeserializeList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ DESERIALIZE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT DEDENT DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class ManagedObject ( Type ) : NEW_LINE INDENT FEATURE__LIST = ( 1 << 2 ) NEW_LINE def __init__ ( self , name , extends , properties , features = 0 , extended_by = None ) : NEW_LINE INDENT Type . __init__ ( self , " struct " , name ) NEW_LINE self . extends = extends NEW_LINE self . features = features NEW_LINE self . properties = properties NEW_LINE self . extended_by = extended_by NEW_LINE if self . extended_by is not None : NEW_LINE INDENT self . extended_by . sort ( ) NEW_LINE DEDENT DEDENT def generate_struct_members ( self , add_banner = False , struct_gap = False ) : NEW_LINE INDENT members = " " NEW_LINE if struct_gap : NEW_LINE INDENT members += " \n " NEW_LINE DEDENT if self . extends is not None : NEW_LINE INDENT members += managed_objects_by_name [ self . extends ] \NEW_LINE . generate_struct_members ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT for property in self . properties : NEW_LINE INDENT members += property . generate_struct_member ( ) NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT members += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT return members NEW_LINE DEDENT def generate_free_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] \NEW_LINE . generate_free_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_free_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ to ▁ be ▁ freed ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_validate_code ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] \NEW_LINE . generate_validate_code ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_validate_code ( managed = True ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ required ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_lookup_code1 ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] \NEW_LINE . generate_lookup_code1 ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += " ▁ ▁ ▁ ▁ \ " % s\\0\ " \n " % property . name NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_lookup_code2 ( self , add_banner = False ) : NEW_LINE INDENT source = " " NEW_LINE if self . extends is not None : NEW_LINE INDENT source += managed_objects_by_name [ self . extends ] \NEW_LINE . generate_lookup_code2 ( add_banner = True ) + " \n " NEW_LINE DEDENT if self . extends is not None or add_banner : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ % s ▁ * / \n " % self . name NEW_LINE DEDENT if len ( self . properties ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT string = " " NEW_LINE for property in self . properties : NEW_LINE INDENT string += property . generate_lookup_code ( ) NEW_LINE DEDENT if len ( string ) < 1 : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ / * ▁ no ▁ properties ▁ * / \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += string NEW_LINE DEDENT DEDENT return source NEW_LINE DEDENT def generate_comment ( self ) : NEW_LINE INDENT comment = separator NEW_LINE comment += " ▁ * ▁ VI ▁ Managed ▁ Object : ▁ % s \n " % self . name NEW_LINE if self . extends is not None : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extends ▁ % s \n " % self . extends NEW_LINE DEDENT first = True NEW_LINE if self . extended_by is not None : NEW_LINE INDENT for extended_by in self . extended_by : NEW_LINE INDENT if first : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ extended ▁ by ▁ % s \n " \NEW_LINE % extended_by NEW_LINE first = False NEW_LINE DEDENT else : NEW_LINE INDENT comment += " ▁ * ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ % s \n " \NEW_LINE % extended_by NEW_LINE DEDENT DEDENT DEDENT comment += " ▁ * / \n \n " NEW_LINE return comment NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = self . generate_comment ( ) NEW_LINE header += " struct ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ next ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT else : NEW_LINE INDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * _ unused ; ▁ " % self . name , " / * ▁ optional ▁ * / \n " ) NEW_LINE DEDENT header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ Type ▁ _ type ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += aligned ( " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference ▁ * _ reference ; ▁ " , " / * ▁ required ▁ * / \n " ) NEW_LINE header += " \n " NEW_LINE header += self . generate_struct_members ( ) NEW_LINE header += " } ; \n \n " NEW_LINE header += " int ▁ esxVI _ % s _ Alloc ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += " void ▁ esxVI _ % s _ Free ( esxVI _ % s ▁ * * item ) ; \n " % ( self . name , self . name ) NEW_LINE header += ( " int ▁ esxVI _ % s _ Validate ( esxVI _ % s ▁ * item , ▁ " " esxVI _ String ▁ * selectedPropertyNameList ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT header += " int ▁ esxVI _ % s _ AppendToList ( esxVI _ % s ▁ * * list , ▁ esxVI _ % s ▁ * item ) ; \n " \NEW_LINE % ( self . name , self . name , self . name ) NEW_LINE DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_helper_header ( self ) : NEW_LINE INDENT header = " " NEW_LINE header += ( " int ▁ esxVI _ Lookup % s ( esxVI _ Context ▁ * ctx , ▁ " " const ▁ char ▁ * name , ▁ " " esxVI _ ManagedObjectReference ▁ * root , ▁ " " esxVI _ String ▁ * selectedPropertyNameList , ▁ " " esxVI _ % s ▁ * * item , ▁ " " esxVI _ Occurrence ▁ occurrence ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE header += " \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = self . generate_comment ( ) NEW_LINE source += " / * ▁ esxVI _ % s _ Alloc ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ALLOC ( % s ) \n \n " % self . name NEW_LINE if self . extended_by is None : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE if self . features & ManagedObject . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " \NEW_LINE % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n " % self . name NEW_LINE DEDENT DEDENT source += " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference _ Free ( & item - > _ reference ) ; \n \n " NEW_LINE source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT else : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Free ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ DYNAMIC _ FREE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE for extended_by in self . extended_by : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ESX _ VI _ _ TEMPLATE _ _ DISPATCH _ _ FREE ( % s ) \n " % extended_by NEW_LINE DEDENT source += " } , \n " NEW_LINE source += " { \n " NEW_LINE if self . features & Object . FEATURE__LIST : NEW_LINE INDENT if self . extends is not None : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s ▁ * next ▁ = ▁ ( esxVI _ % s ▁ * ) item - > _ next ; \n \n " \NEW_LINE % ( self . extends , self . extends ) NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & next ) ; \n " % self . extends NEW_LINE source += " ▁ ▁ ▁ ▁ item - > _ next ▁ = ▁ ( esxVI _ % s ▁ * ) next ; \n \n " % self . name NEW_LINE DEDENT else : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ esxVI _ % s _ Free ( & item - > _ next ) ; \n " % self . name NEW_LINE DEDENT DEDENT source += " ▁ ▁ ▁ ▁ esxVI _ ManagedObjectReference _ Free ( & item - > _ reference ) ; \n \n " NEW_LINE source += self . generate_free_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE DEDENT source += " / * ▁ esxVI _ % s _ Validate ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ MANAGED _ VALIDATE ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_validate_code ( ) NEW_LINE source += " } ) \n \n " NEW_LINE if self . features & ManagedObject . FEATURE__LIST : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ AppendToList ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LIST _ _ APPEND ( % s ) \n \n " % self . name NEW_LINE DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT def generate_helper_source ( self ) : NEW_LINE INDENT source = " " NEW_LINE source += " / * ▁ esxVI _ Lookup % s ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ LOOKUP ( % s , \n " % self . name NEW_LINE source += " { \n " NEW_LINE source += self . generate_lookup_code1 ( ) NEW_LINE source += " } , \n " NEW_LINE source += " { \n " NEW_LINE source += self . generate_lookup_code2 ( ) NEW_LINE source += " } ) \n \n " NEW_LINE source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT class Enum ( Type ) : NEW_LINE INDENT FEATURE__ANY_TYPE = ( 1 << 1 ) NEW_LINE FEATURE__SERIALIZE = ( 1 << 2 ) NEW_LINE FEATURE__DESERIALIZE = ( 1 << 3 ) NEW_LINE def __init__ ( self , name , values , features = 0 ) : NEW_LINE INDENT Type . __init__ ( self , " enum " , name ) NEW_LINE self . values = values NEW_LINE self . features = features NEW_LINE DEDENT def generate_header ( self ) : NEW_LINE INDENT header = separator NEW_LINE header += " ▁ * ▁ VI ▁ Enum : ▁ % s \n " % self . name NEW_LINE header += " ▁ * / \n \n " NEW_LINE header += " enum ▁ _ esxVI _ % s ▁ { \n " % self . name NEW_LINE header += " ▁ ▁ ▁ ▁ esxVI _ % s _ Undefined ▁ = ▁ 0 , \n " % self . name NEW_LINE for value in self . values : NEW_LINE INDENT header += " ▁ ▁ ▁ ▁ esxVI _ % s _ % s , \n " % ( self . name , capitalize_first ( value ) ) NEW_LINE DEDENT header += " } ; \n \n " NEW_LINE if self . features & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ CastFromAnyType ( esxVI _ AnyType ▁ * anyType , ▁ " " esxVI _ % s ▁ * item ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE DEDENT if self . features & Enum . FEATURE__SERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Serialize ( esxVI _ % s ▁ item , ▁ const ▁ char ▁ * element , ▁ " " virBufferPtr ▁ output ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE DEDENT if self . features & Enum . FEATURE__DESERIALIZE : NEW_LINE INDENT header += ( " int ▁ esxVI _ % s _ Deserialize ( xmlNodePtr ▁ node , ▁ " " esxVI _ % s ▁ * item ) ; \n " ) \NEW_LINE % ( self . name , self . name ) NEW_LINE DEDENT header += " \n \n \n " NEW_LINE return header NEW_LINE DEDENT def generate_source ( self ) : NEW_LINE INDENT source = separator NEW_LINE source += " ▁ * ▁ VI ▁ Enum : ▁ % s \n " % self . name NEW_LINE source += " ▁ * / \n \n " NEW_LINE source += " static ▁ const ▁ esxVI _ Enumeration ▁ _ esxVI _ % s _ Enumeration ▁ = ▁ { \n " \NEW_LINE % self . name NEW_LINE source += " ▁ ▁ ▁ ▁ esxVI _ Type _ % s , ▁ { \n " % self . name NEW_LINE for value in self . values : NEW_LINE INDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { ▁ \ " % s\ " , ▁ esxVI _ % s _ % s ▁ } , \n " \NEW_LINE % ( value , self . name , capitalize_first ( value ) ) NEW_LINE DEDENT source += " ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { ▁ NULL , ▁ - 1 ▁ } , \n " NEW_LINE source += " ▁ ▁ ▁ ▁ } , \n " NEW_LINE source += " } ; \n \n " NEW_LINE if self . features & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ CastFromAnyType ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ CAST _ FROM _ ANY _ TYPE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT if self . features & Enum . FEATURE__SERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Serialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ SERIALIZE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT if self . features & Enum . FEATURE__DESERIALIZE : NEW_LINE INDENT source += " / * ▁ esxVI _ % s _ Deserialize ▁ * / \n " % self . name NEW_LINE source += " ESX _ VI _ _ TEMPLATE _ _ ENUMERATION _ _ DESERIALIZE ( % s ) \n \n " \NEW_LINE % self . name NEW_LINE DEDENT source += " \n \n " NEW_LINE return source NEW_LINE DEDENT DEDENT def report_error ( message ) : NEW_LINE INDENT print " error : ▁ " + message NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT def capitalize_first ( string ) : NEW_LINE INDENT return string [ : 1 ] . upper ( ) + string [ 1 : ] NEW_LINE DEDENT def parse_object ( block ) : NEW_LINE INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE managed = False NEW_LINE if header_items [ 0 ] == " managed " : NEW_LINE INDENT managed = True NEW_LINE del header_items [ 0 ] NEW_LINE DEDENT if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " object " NEW_LINE name = header_items [ 1 ] NEW_LINE extends = None NEW_LINE if len ( header_items ) > 2 : NEW_LINE INDENT if header_items [ 2 ] != " extends " : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT extends = header_items [ 3 ] NEW_LINE DEDENT DEDENT properties = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE INDENT items = line [ 1 ] . split ( ) NEW_LINE if len ( items ) != 3 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ property " % line [ 0 ] ) NEW_LINE DEDENT if items [ 2 ] not in valid_occurrences : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ occurrence " % line [ 0 ] ) NEW_LINE DEDENT properties . append ( Property ( type = items [ 0 ] , name = items [ 1 ] , occurrence = items [ 2 ] ) ) NEW_LINE DEDENT if managed : NEW_LINE INDENT return ManagedObject ( name = name , extends = extends , properties = properties ) NEW_LINE DEDENT else : NEW_LINE INDENT return Object ( name = name , extends = extends , properties = properties ) NEW_LINE DEDENT DEDENT def parse_enum ( block ) : NEW_LINE INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " enum " NEW_LINE name = header_items [ 1 ] NEW_LINE values = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE INDENT values . append ( line [ 1 ] ) NEW_LINE DEDENT return Enum ( name = name , values = values ) NEW_LINE DEDENT def parse_method ( block ) : NEW_LINE INDENT header_items = block [ 0 ] [ 1 ] . split ( ) NEW_LINE if len ( header_items ) < 2 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT assert header_items [ 0 ] == " method " NEW_LINE name = header_items [ 1 ] NEW_LINE returns = None NEW_LINE if len ( header_items ) > 2 : NEW_LINE INDENT if header_items [ 2 ] != " returns " : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ block ▁ header " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT returns = Parameter ( type = header_items [ 3 ] , name = " output " , occurrence = header_items [ 4 ] ) NEW_LINE DEDENT DEDENT parameters = [ ] NEW_LINE for line in block [ 1 : ] : NEW_LINE INDENT items = line [ 1 ] . split ( ) NEW_LINE if len ( items ) != 3 : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ property " % line [ 0 ] ) NEW_LINE DEDENT if items [ 2 ] not in valid_occurrences : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ invalid ▁ occurrence " % line [ 0 ] ) NEW_LINE DEDENT parameters . append ( Parameter ( type = items [ 0 ] , name = items [ 1 ] , occurrence = items [ 2 ] ) ) NEW_LINE DEDENT return Method ( name = name , parameters = parameters , returns = returns ) NEW_LINE DEDENT def is_known_type ( type ) : NEW_LINE INDENT return type in predefined_objects or \NEW_LINE type in predefined_enums or \NEW_LINE type in objects_by_name or \NEW_LINE type in managed_objects_by_name or \NEW_LINE type in enums_by_name NEW_LINE DEDENT def open_and_print ( filename ) : NEW_LINE INDENT if filename . startswith ( " . / " ) : NEW_LINE INDENT print " ▁ ▁ GEN ▁ ▁ ▁ ▁ " + filename [ 2 : ] NEW_LINE DEDENT else : NEW_LINE INDENT print " ▁ ▁ GEN ▁ ▁ ▁ ▁ " + filename NEW_LINE DEDENT return open ( filename , " wb " ) NEW_LINE DEDENT predefined_enums = [ " Boolean " ] NEW_LINE predefined_objects = [ " AnyType " , " Int " , " Long " , " String " , " DateTime " , " MethodFault " , " ManagedObjectReference " ] NEW_LINE additional_enum_features = { " ManagedEntityStatus " : Enum . FEATURE__ANY_TYPE , " TaskInfoState " : Enum . FEATURE__ANY_TYPE , " VirtualMachinePowerState " : Enum . FEATURE__ANY_TYPE } NEW_LINE additional_object_features = { " AutoStartDefaults " : Object . FEATURE__ANY_TYPE , " AutoStartPowerInfo " : Object . FEATURE__ANY_TYPE , " DatastoreHostMount " : Object . FEATURE__DEEP_COPY | Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " DatastoreInfo " : Object . FEATURE__ANY_TYPE | Object . FEATURE__DYNAMIC_CAST , " HostConfigManager " : Object . FEATURE__ANY_TYPE , " HostCpuIdInfo " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " HostDatastoreBrowserSearchResults " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " ManagedObjectReference " : Object . FEATURE__ANY_TYPE , " ObjectContent " : Object . FEATURE__DEEP_COPY , " ResourcePoolResourceUsage " : Object . FEATURE__ANY_TYPE , " ServiceContent " : Object . FEATURE__DESERIALIZE , " SharesInfo " : Object . FEATURE__ANY_TYPE , " TaskInfo " : Object . FEATURE__LIST | Object . FEATURE__ANY_TYPE , " UserSession " : Object . FEATURE__ANY_TYPE , " VirtualMachineQuestionInfo " : Object . FEATURE__ANY_TYPE , " VirtualMachineSnapshotTree " : Object . FEATURE__DEEP_COPY | Object . FEATURE__ANY_TYPE , " VmEventArgument " : Object . FEATURE__DESERIALIZE } NEW_LINE removed_object_features = { } NEW_LINE if " srcdir " in os . environ : NEW_LINE INDENT input_filename = os . path . join ( os . environ [ " srcdir " ] , " esx / esx _ vi _ generator . input " ) NEW_LINE output_dirname = os . path . join ( os . environ [ " srcdir " ] , " esx " ) NEW_LINE DEDENT else : NEW_LINE INDENT input_filename = os . path . join ( os . getcwd ( ) , " esx _ vi _ generator . input " ) NEW_LINE output_dirname = os . getcwd ( ) NEW_LINE DEDENT types_typedef = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typedef " ) ) NEW_LINE types_typeenum = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typeenum " ) ) NEW_LINE types_typetostring = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typetostring " ) ) NEW_LINE types_typefromstring = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . typefromstring " ) ) NEW_LINE types_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . h " ) ) NEW_LINE types_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ types . generated . c " ) ) NEW_LINE methods_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . h " ) ) NEW_LINE methods_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . c " ) ) NEW_LINE methods_macro = open_and_print ( os . path . join ( output_dirname , " esx _ vi _ methods . generated . macro " ) ) NEW_LINE helpers_header = open_and_print ( os . path . join ( output_dirname , " esx _ vi . generated . h " ) ) NEW_LINE helpers_source = open_and_print ( os . path . join ( output_dirname , " esx _ vi . generated . c " ) ) NEW_LINE number = 0 NEW_LINE objects_by_name = { } NEW_LINE managed_objects_by_name = { } NEW_LINE enums_by_name = { } NEW_LINE methods_by_name = { } NEW_LINE block = None NEW_LINE for line in file ( input_filename , " rb " ) . readlines ( ) : NEW_LINE INDENT number += 1 NEW_LINE if " # " in line : NEW_LINE INDENT line = line [ : line . index ( " # " ) ] NEW_LINE DEDENT line = line . lstrip ( ) . rstrip ( ) NEW_LINE if len ( line ) < 1 : NEW_LINE INDENT continue NEW_LINE DEDENT if line . startswith ( " object " ) or line . startswith ( " managed ▁ object " ) or \NEW_LINE line . startswith ( " enum " ) or line . startswith ( " method " ) : NEW_LINE INDENT if block is not None : NEW_LINE INDENT report_error ( " line ▁ % d : ▁ nested ▁ block ▁ found " % ( number ) ) NEW_LINE DEDENT else : NEW_LINE INDENT block = [ ] NEW_LINE DEDENT DEDENT if block is not None : NEW_LINE INDENT if line == " end " : NEW_LINE INDENT if block [ 0 ] [ 1 ] . startswith ( " object " ) : NEW_LINE INDENT obj = parse_object ( block ) NEW_LINE objects_by_name [ obj . name ] = obj NEW_LINE DEDENT elif block [ 0 ] [ 1 ] . startswith ( " managed ▁ object " ) : NEW_LINE INDENT obj = parse_object ( block ) NEW_LINE managed_objects_by_name [ obj . name ] = obj NEW_LINE DEDENT elif block [ 0 ] [ 1 ] . startswith ( " enum " ) : NEW_LINE INDENT enum = parse_enum ( block ) NEW_LINE enums_by_name [ enum . name ] = enum NEW_LINE DEDENT else : NEW_LINE INDENT method = parse_method ( block ) NEW_LINE methods_by_name [ method . name ] = method NEW_LINE DEDENT block = None NEW_LINE DEDENT else : NEW_LINE INDENT block . append ( ( number , line ) ) NEW_LINE DEDENT DEDENT DEDENT for method in methods_by_name . values ( ) : NEW_LINE INDENT for parameter in method . parameters : NEW_LINE INDENT if not parameter . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if parameter . is_enum ( ) : NEW_LINE INDENT enums_by_name [ parameter . type ] . features |= Enum . FEATURE__SERIALIZE NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ parameter . type ] . features |= Object . FEATURE__SERIALIZE NEW_LINE objects_by_name [ parameter . type ] . candidate_for_dynamic_cast = True NEW_LINE DEDENT if parameter . occurrence == OCCURRENCE__REQUIRED_LIST or \NEW_LINE parameter . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if parameter . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( parameter . type , method . name ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ parameter . type ] . features |= Object . FEATURE__LIST NEW_LINE DEDENT DEDENT DEDENT if method . returns and method . returns . is_type_generated ( ) : NEW_LINE INDENT if method . returns . is_enum ( ) : NEW_LINE INDENT enums_by_name [ method . returns . type ] . features |= Enum . FEATURE__DESERIALIZE NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ method . returns . type ] . features |= Object . FEATURE__DESERIALIZE NEW_LINE objects_by_name [ method . returns . type ] . candidate_for_dynamic_cast = True NEW_LINE DEDENT if method . returns . occurrence == OCCURRENCE__REQUIRED_LIST or \NEW_LINE method . returns . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if method . returns . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( method . returns . type , method . name ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ method . returns . type ] . features |= Object . FEATURE__LIST NEW_LINE DEDENT DEDENT DEDENT DEDENT for enum in enums_by_name . values ( ) : NEW_LINE INDENT if enum . name in additional_enum_features : NEW_LINE INDENT enum . features |= additional_enum_features [ enum . name ] NEW_LINE if additional_enum_features [ enum . name ] & Enum . FEATURE__ANY_TYPE : NEW_LINE INDENT enum . features |= Enum . FEATURE__DESERIALIZE NEW_LINE DEDENT DEDENT DEDENT for obj in objects_by_name . values ( ) : NEW_LINE INDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence != OCCURRENCE__IGNORED and \NEW_LINE not is_known_type ( property . type ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ contains ▁ unknown ▁ property ▁ type ▁ ' % s ' " % ( obj . name , property . type ) ) NEW_LINE DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT if not is_known_type ( obj . extends ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ extends ▁ unknown ▁ object ▁ ' % s ' " % ( obj . name , obj . extends ) ) NEW_LINE DEDENT DEDENT for property in obj . properties : NEW_LINE INDENT if not property . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if property . is_enum ( ) : NEW_LINE INDENT enums_by_name [ property . type ] . candidate_for_dynamic_cast = True NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ property . type ] . candidate_for_dynamic_cast = True NEW_LINE DEDENT if property . occurrence == OCCURRENCE__REQUIRED_LIST or \NEW_LINE property . occurrence == OCCURRENCE__OPTIONAL_LIST : NEW_LINE INDENT if property . is_enum ( ) : NEW_LINE INDENT report_error ( " unsupported ▁ usage ▁ of ▁ enum ▁ ' % s ' ▁ as ▁ list ▁ in ▁ ' % s ' " % ( property . type , obj . type ) ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_by_name [ property . type ] . features |= Object . FEATURE__LIST NEW_LINE DEDENT DEDENT DEDENT if obj . name in additional_object_features : NEW_LINE INDENT obj . features |= additional_object_features [ obj . name ] NEW_LINE if additional_object_features [ obj . name ] & Object . FEATURE__ANY_TYPE : NEW_LINE INDENT obj . features |= Object . FEATURE__DESERIALIZE NEW_LINE DEDENT DEDENT if obj . name in removed_object_features : NEW_LINE INDENT obj . features &= ~ removed_object_features [ obj . name ] NEW_LINE DEDENT if obj . extends is not None : NEW_LINE INDENT extended_obj = objects_by_name [ obj . extends ] NEW_LINE if extended_obj . extended_by is None : NEW_LINE INDENT extended_obj . extended_by = [ obj . name ] NEW_LINE DEDENT else : NEW_LINE INDENT extended_obj . extended_by . append ( obj . name ) NEW_LINE extended_obj . extended_by . sort ( ) NEW_LINE DEDENT DEDENT DEDENT for obj in objects_by_name . values ( ) : NEW_LINE INDENT if obj . candidate_for_dynamic_cast and obj . extended_by : NEW_LINE INDENT obj . features |= Object . FEATURE__DYNAMIC_CAST NEW_LINE DEDENT DEDENT def propagate_feature ( obj , feature ) : NEW_LINE INDENT global features_have_changed NEW_LINE if not ( obj . features & feature ) : NEW_LINE INDENT return NEW_LINE DEDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence == OCCURRENCE__IGNORED or \NEW_LINE not property . is_type_generated ( ) : NEW_LINE INDENT continue NEW_LINE DEDENT if property . is_enum ( ) : NEW_LINE INDENT if feature == Object . FEATURE__SERIALIZE and \NEW_LINE not ( enums_by_name [ property . type ] . features & Enum . FEATURE__SERIALIZE ) : NEW_LINE INDENT enums_by_name [ property . type ] . features |= Enum . FEATURE__SERIALIZE NEW_LINE features_have_changed = True NEW_LINE DEDENT elif feature == Object . FEATURE__DESERIALIZE and \NEW_LINE not ( enums_by_name [ property . type ] . features & Enum . FEATURE__DESERIALIZE ) : NEW_LINE INDENT enums_by_name [ property . type ] . features |= Enum . FEATURE__DESERIALIZE NEW_LINE features_have_changed = True NEW_LINE DEDENT DEDENT elif property . is_object ( ) : NEW_LINE INDENT if not ( objects_by_name [ property . type ] . features & feature ) : NEW_LINE INDENT objects_by_name [ property . type ] . features |= feature NEW_LINE features_have_changed = True NEW_LINE DEDENT if obj . name != property . type : NEW_LINE INDENT propagate_feature ( objects_by_name [ property . type ] , feature ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def inherit_features ( obj ) : NEW_LINE INDENT global features_have_changed NEW_LINE if obj . extended_by is not None : NEW_LINE INDENT for extended_by in obj . extended_by : NEW_LINE INDENT previous = objects_by_name [ extended_by ] . features NEW_LINE objects_by_name [ extended_by ] . features |= obj . features NEW_LINE if objects_by_name [ extended_by ] . features != previous : NEW_LINE INDENT features_have_changed = True NEW_LINE DEDENT DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT previous = objects_by_name [ obj . extends ] . features NEW_LINE objects_by_name [ obj . extends ] . features |= obj . features NEW_LINE if objects_by_name [ obj . extends ] . features != previous : NEW_LINE INDENT features_have_changed = True NEW_LINE DEDENT DEDENT if obj . extended_by is not None : NEW_LINE INDENT for extended_by in obj . extended_by : NEW_LINE INDENT inherit_features ( objects_by_name [ extended_by ] ) NEW_LINE DEDENT DEDENT DEDENT features_have_changed = True NEW_LINE while features_have_changed : NEW_LINE INDENT features_have_changed = False NEW_LINE for obj in objects_by_name . values ( ) : NEW_LINE INDENT propagate_feature ( obj , Object . FEATURE__DEEP_COPY ) NEW_LINE propagate_feature ( obj , Object . FEATURE__SERIALIZE ) NEW_LINE propagate_feature ( obj , Object . FEATURE__DESERIALIZE ) NEW_LINE DEDENT for obj in objects_by_name . values ( ) : NEW_LINE INDENT inherit_features ( obj ) NEW_LINE DEDENT DEDENT for obj in managed_objects_by_name . values ( ) : NEW_LINE INDENT for property in obj . properties : NEW_LINE INDENT if property . occurrence != OCCURRENCE__IGNORED and \NEW_LINE not is_known_type ( property . type ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ contains ▁ unknown ▁ property ▁ type ▁ ' % s ' " % ( obj . name , property . type ) ) NEW_LINE DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT if not is_known_type ( obj . extends ) : NEW_LINE INDENT report_error ( " object ▁ ' % s ' ▁ extends ▁ unknown ▁ object ▁ ' % s ' " % ( obj . name , obj . extends ) ) NEW_LINE DEDENT DEDENT if obj . extends is not None : NEW_LINE INDENT extended_obj = managed_objects_by_name [ obj . extends ] NEW_LINE if extended_obj . extended_by is None : NEW_LINE INDENT extended_obj . extended_by = [ obj . name ] NEW_LINE DEDENT else : NEW_LINE INDENT extended_obj . extended_by . append ( obj . name ) NEW_LINE extended_obj . extended_by . sort ( ) NEW_LINE DEDENT DEDENT DEDENT notice = " / * ▁ Generated ▁ by ▁ esx _ vi _ generator . py ▁ * / \n \n \n \n " NEW_LINE types_typedef . write ( notice ) NEW_LINE types_typeenum . write ( notice ) NEW_LINE types_typetostring . write ( notice ) NEW_LINE types_typefromstring . write ( notice ) NEW_LINE types_header . write ( notice ) NEW_LINE types_source . write ( notice ) NEW_LINE methods_header . write ( notice ) NEW_LINE methods_source . write ( notice ) NEW_LINE methods_macro . write ( notice ) NEW_LINE helpers_header . write ( notice ) NEW_LINE helpers_source . write ( notice ) NEW_LINE types_typedef . write ( separator + " ▁ * ▁ VI ▁ Enums \n " + " ▁ * / \n \n " ) NEW_LINE names = enums_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( enums_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( enums_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( enums_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( enums_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( enums_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( enums_by_name [ name ] . generate_source ( ) ) NEW_LINE DEDENT types_typedef . write ( " \n \n \n " + separator + " ▁ * ▁ VI ▁ Objects \n " + " ▁ * / \n \n " ) NEW_LINE types_typeenum . write ( " \n " ) NEW_LINE types_typetostring . write ( " \n " ) NEW_LINE types_typefromstring . write ( " \n " ) NEW_LINE names = objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( objects_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( objects_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( objects_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( objects_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( objects_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( objects_by_name [ name ] . generate_source ( ) ) NEW_LINE DEDENT types_typedef . write ( " \n \n \n " + separator + " ▁ * ▁ VI ▁ Managed ▁ Objects \n " + " ▁ * / \n \n " ) NEW_LINE types_typeenum . write ( " \n " ) NEW_LINE types_typetostring . write ( " \n " ) NEW_LINE types_typefromstring . write ( " \n " ) NEW_LINE names = managed_objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT types_typedef . write ( managed_objects_by_name [ name ] . generate_typedef ( ) ) NEW_LINE types_typeenum . write ( managed_objects_by_name [ name ] . generate_typeenum ( ) ) NEW_LINE types_typetostring . write ( managed_objects_by_name [ name ] . generate_typetostring ( ) ) NEW_LINE types_typefromstring . write ( managed_objects_by_name [ name ] . generate_typefromstring ( ) ) NEW_LINE types_header . write ( managed_objects_by_name [ name ] . generate_header ( ) ) NEW_LINE types_source . write ( managed_objects_by_name [ name ] . generate_source ( ) ) NEW_LINE DEDENT names = methods_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT methods_header . write ( methods_by_name [ name ] . generate_header ( ) ) NEW_LINE methods_source . write ( methods_by_name [ name ] . generate_source ( ) ) NEW_LINE DEDENT names = list ( autobind_names ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT string = aligned ( " # define ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ THIS _ _ % s ▁ " % name , " \\ \n " , 78 ) NEW_LINE string += " ▁ ▁ ▁ ▁ ESX _ VI _ _ METHOD _ _ PARAMETER _ _ THIS _ FROM _ SERVICE ( ManagedObjectReference , ▁ ▁ ▁ ▁ ▁ ▁ \\ \n " NEW_LINE string += aligned ( " " , " % s ) \n \n \n \n " % name , 49 ) NEW_LINE methods_macro . write ( string ) NEW_LINE DEDENT names = managed_objects_by_name . keys ( ) NEW_LINE names . sort ( ) NEW_LINE for name in names : NEW_LINE INDENT helpers_header . write ( managed_objects_by_name [ name ] . generate_helper_header ( ) ) NEW_LINE helpers_source . write ( managed_objects_by_name [ name ] . generate_helper_source ( ) ) NEW_LINE DEDENT
 from django . contrib import messages NEW_LINE from django . contrib . admin import helpers NEW_LINE from django . contrib . admin . utils import get_deleted_objects , model_ngettext NEW_LINE from django . core . exceptions import PermissionDenied NEW_LINE from django . db import router NEW_LINE from django . template . response import TemplateResponse NEW_LINE from django . utils . encoding import force_text NEW_LINE from django . utils . translation import ugettext as _ , ugettext_lazy NEW_LINE def delete_selected ( modeladmin , request , queryset ) : NEW_LINE INDENT opts = modeladmin . model . _meta NEW_LINE app_label = opts . app_label NEW_LINE if not modeladmin . has_delete_permission ( request ) : NEW_LINE INDENT raise PermissionDenied NEW_LINE DEDENT using = router . db_for_write ( modeladmin . model ) NEW_LINE deletable_objects , model_count , perms_needed , protected = get_deleted_objects ( queryset , opts , request . user , modeladmin . admin_site , using ) NEW_LINE if request . POST . get ( ' post ' ) : NEW_LINE INDENT if perms_needed : NEW_LINE INDENT raise PermissionDenied NEW_LINE DEDENT n = queryset . count ( ) NEW_LINE if n : NEW_LINE INDENT for obj in queryset : NEW_LINE INDENT obj_display = force_text ( obj ) NEW_LINE modeladmin . log_deletion ( request , obj , obj_display ) NEW_LINE DEDENT queryset . delete ( ) NEW_LINE modeladmin . message_user ( request , _ ( " Successfully ▁ deleted ▁ % ( count ) d ▁ % ( items ) s . " ) % { " count " : n , " items " : model_ngettext ( modeladmin . opts , n ) } , messages . SUCCESS ) NEW_LINE DEDENT return None NEW_LINE DEDENT if len ( queryset ) == 1 : NEW_LINE INDENT objects_name = force_text ( opts . verbose_name ) NEW_LINE DEDENT else : NEW_LINE INDENT objects_name = force_text ( opts . verbose_name_plural ) NEW_LINE DEDENT if perms_needed or protected : NEW_LINE INDENT title = _ ( " Cannot ▁ delete ▁ % ( name ) s " ) % { " name " : objects_name } NEW_LINE DEDENT else : NEW_LINE INDENT title = _ ( " Are ▁ you ▁ sure ? " ) NEW_LINE DEDENT context = dict ( modeladmin . admin_site . each_context ( request ) , title = title , objects_name = objects_name , deletable_objects = [ deletable_objects ] , model_count = dict ( model_count ) . items ( ) , queryset = queryset , perms_lacking = perms_needed , protected = protected , opts = opts , action_checkbox_name = helpers . ACTION_CHECKBOX_NAME , ) NEW_LINE request . current_app = modeladmin . admin_site . name NEW_LINE return TemplateResponse ( request , modeladmin . delete_selected_confirmation_template or [ " admin / % s / % s / delete _ selected _ confirmation . html " % ( app_label , opts . model_name ) , " admin / % s / delete _ selected _ confirmation . html " % app_label , " admin / delete _ selected _ confirmation . html " ] , context ) NEW_LINE DEDENT delete_selected . short_description = ugettext_lazy ( " Delete ▁ selected ▁ % ( verbose _ name _ plural ) s " ) NEW_LINE
 from MySQLdb . constants import FIELD_TYPE NEW_LINE from django . contrib . gis . gdal import OGRGeomType NEW_LINE from django . db . backends . mysql . introspection import DatabaseIntrospection NEW_LINE class MySQLIntrospection ( DatabaseIntrospection ) : NEW_LINE INDENT data_types_reverse = DatabaseIntrospection . data_types_reverse . copy ( ) NEW_LINE data_types_reverse [ FIELD_TYPE . GEOMETRY ] = ' GeometryField ' NEW_LINE def get_geometry_type ( self , table_name , geo_col ) : NEW_LINE INDENT cursor = self . connection . cursor ( ) NEW_LINE try : NEW_LINE INDENT cursor . execute ( ' DESCRIBE ▁ % s ' % self . connection . ops . quote_name ( table_name ) ) NEW_LINE for column , typ , null , key , default , extra in cursor . fetchall ( ) : NEW_LINE INDENT if column == geo_col : NEW_LINE INDENT field_type = OGRGeomType ( typ ) . django NEW_LINE field_params = { } NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT finally : NEW_LINE INDENT cursor . close ( ) NEW_LINE DEDENT return field_type , field_params NEW_LINE DEDENT def supports_spatial_index ( self , cursor , table_name ) : NEW_LINE INDENT storage_engine = self . get_storage_engine ( cursor , table_name ) NEW_LINE return ( ( storage_engine == ' InnoDB ' and self . connection . mysql_version >= ( 5 , 7 , 5 ) ) or storage_engine == ' MyISAM ' ) NEW_LINE DEDENT DEDENT
 from __future__ import ( absolute_import , division , print_function ) NEW_LINE __metaclass__ = type NEW_LINE class FactsArgs ( object ) : NEW_LINE INDENT def __init__ ( self , ** kwargs ) : NEW_LINE INDENT pass NEW_LINE DEDENT argument_spec = { ' gather _ subset ' : dict ( default = [ ' ! config ' ] , type = ' list ' ) , ' gather _ network _ resources ' : dict ( type = ' list ' ) , } NEW_LINE DEDENT
 import subprocess NEW_LINE import re , os NEW_LINE def _eintr_retry_call ( func , * args ) : NEW_LINE INDENT while True : NEW_LINE INDENT try : NEW_LINE INDENT return func ( * args ) NEW_LINE DEDENT except OSError , e : NEW_LINE INDENT if e . errno == errno . EINTR : NEW_LINE INDENT continue NEW_LINE DEDENT raise NEW_LINE DEDENT DEDENT DEDENT def cmdForFile ( f ) : NEW_LINE INDENT suffix_cmd_map = [ ] NEW_LINE custom_map = os . getenv ( ' SEASCOPE _ CTAGS _ SUFFIX _ CMD _ MAP ' ) NEW_LINE if custom_map : NEW_LINE INDENT custom_map = eval ( custom_map ) NEW_LINE suffix_cmd_map += custom_map NEW_LINE DEDENT args = ' ctags ▁ - n ▁ - u ▁ - - fields = + K ▁ - f ▁ - ' NEW_LINE suffix_cmd_map . append ( [ ' ' , args ] ) NEW_LINE for ( suffix , cmd ) in suffix_cmd_map : NEW_LINE INDENT if f . endswith ( suffix ) : NEW_LINE INDENT return cmd NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def ct_query ( filename ) : NEW_LINE INDENT args = cmdForFile ( filename ) NEW_LINE args = args . split ( ) NEW_LINE args . append ( filename ) NEW_LINE try : NEW_LINE INDENT proc = subprocess . Popen ( args , stdout = subprocess . PIPE ) NEW_LINE ( out_data , err_data ) = _eintr_retry_call ( proc . communicate ) NEW_LINE out_data = out_data . split ( ' \n ' ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT out_data = [ ' Failed ▁ to ▁ run ▁ ctags ▁ cmd\tignore\t0 ; \t ▁ ' , ' cmd : ▁ % s\tignore\t0 ; \t ▁ ' % ' ▁ ' . join ( args ) , ' error : ▁ % s\tignore\t0 ; \t ▁ ' % str ( e ) , ' ctags ▁ not ▁ installed ▁ ? \tignore\t0 ; \t ▁ ' , ] NEW_LINE DEDENT res = [ ] NEW_LINE for line in out_data : NEW_LINE INDENT if ( line == ' ' ) : NEW_LINE INDENT break NEW_LINE DEDENT line = line . split ( ' \t ' ) NEW_LINE num = line [ 2 ] . split ( ' ; ' , 1 ) [ 0 ] NEW_LINE line = [ line [ 0 ] , num , line [ 3 ] ] NEW_LINE res . append ( line ) NEW_LINE DEDENT return res NEW_LINE DEDENT is_OrderedDict_available = False NEW_LINE try : NEW_LINE INDENT from collections import OrderedDict NEW_LINE is_OrderedDict_available = True NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT def emptyOrderedDict ( ) : NEW_LINE INDENT if is_OrderedDict_available : NEW_LINE INDENT return OrderedDict ( { } ) NEW_LINE DEDENT return { } NEW_LINE DEDENT class CtagsTreeBuilder : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . symTree = emptyOrderedDict ( ) NEW_LINE DEDENT def cmdForFile ( self , f ) : NEW_LINE INDENT suffix_cmd_map = [ ] NEW_LINE custom_map = os . getenv ( ' SEASCOPE _ CTAGS _ SUFFIX _ CMD _ MAP ' ) NEW_LINE if custom_map : NEW_LINE INDENT custom_map = eval ( custom_map ) NEW_LINE suffix_cmd_map += custom_map NEW_LINE DEDENT args = ' ctags ▁ - n ▁ - u ▁ - - fields = + K - f - t ▁ - f ▁ - ' NEW_LINE suffix_cmd_map . append ( [ ' ' , args ] ) NEW_LINE for ( suffix , cmd ) in suffix_cmd_map : NEW_LINE INDENT if f . endswith ( suffix ) : NEW_LINE INDENT return cmd NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def runCtags ( self , f ) : NEW_LINE INDENT args = self . cmdForFile ( f ) NEW_LINE args = args . split ( ) NEW_LINE args . append ( f ) NEW_LINE proc = subprocess . Popen ( args , stdout = subprocess . PIPE ) NEW_LINE ( out_data , err_data ) = proc . communicate ( ) NEW_LINE return out_data NEW_LINE DEDENT def parseCtagsOutput ( self , data ) : NEW_LINE INDENT data = re . split ( ' \r ? \n ' , data ) NEW_LINE res = [ ] NEW_LINE for line in data : NEW_LINE INDENT if line == ' ' : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE INDENT line = line . split ( ' \t ' , 4 ) NEW_LINE res . append ( line ) NEW_LINE DEDENT except : NEW_LINE INDENT print ' bad ▁ line : ' , line NEW_LINE DEDENT DEDENT return res NEW_LINE DEDENT def addToSymLayout ( self , sc ) : NEW_LINE INDENT t = self . symTree NEW_LINE if sc and sc != ' ' : NEW_LINE INDENT for s in re . split ( ' : : | \ . ' , sc ) : NEW_LINE INDENT if s not in t : NEW_LINE INDENT t [ s ] = emptyOrderedDict ( ) NEW_LINE DEDENT t = t [ s ] NEW_LINE DEDENT DEDENT DEDENT def addToSymTree ( self , sc , line ) : NEW_LINE INDENT t = self . symTree NEW_LINE if sc and sc != ' ' : NEW_LINE INDENT for s in re . split ( ' : : | \ . ' , sc ) : NEW_LINE INDENT assert s in t NEW_LINE t = t [ s ] NEW_LINE DEDENT DEDENT cline = [ line [ 0 ] , line [ 2 ] . split ( ' ; ' ) [ 0 ] , line [ 3 ] ] NEW_LINE if line [ 0 ] in t : NEW_LINE INDENT x = t [ line [ 0 ] ] NEW_LINE if ' + ' not in x : NEW_LINE INDENT x [ ' + ' ] = cline NEW_LINE return NEW_LINE DEDENT DEDENT if ' * ' not in t : NEW_LINE INDENT t [ ' * ' ] = [ ] NEW_LINE DEDENT t [ ' * ' ] . append ( cline ) NEW_LINE NEW_LINE DEDENT def buildTree ( self , data ) : NEW_LINE INDENT type_list = [ ' namespace ' , ' class ' , ' interface ' , ' struct ' , ' union ' , ' enum ' , ' function ' ] NEW_LINE for line in data : NEW_LINE INDENT if len ( line ) == 4 : NEW_LINE INDENT continue NEW_LINE DEDENT try : NEW_LINE INDENT sd = dict ( [ x . split ( ' : ' , 1 ) for x in line [ 4 ] . split ( ' \t ' ) ] ) NEW_LINE DEDENT except : NEW_LINE INDENT print ' bad ▁ line ' , line NEW_LINE continue NEW_LINE DEDENT line [ 4 ] = sd NEW_LINE count = 0 NEW_LINE for t in type_list : NEW_LINE INDENT if t in sd : NEW_LINE INDENT self . addToSymLayout ( sd [ t ] ) NEW_LINE count = count + 1 NEW_LINE DEDENT DEDENT if count != 1 : NEW_LINE INDENT print ' * * * * * * * * ▁ count ▁ = = ▁ 1 ▁ * * * * * * * * * ' NEW_LINE print data NEW_LINE print line NEW_LINE DEDENT NEW_LINE DEDENT if len ( self . symTree ) == 0 : NEW_LINE INDENT return ( data , False ) NEW_LINE DEDENT for line in data : NEW_LINE INDENT if len ( line ) == 4 : NEW_LINE INDENT self . addToSymTree ( None , line ) NEW_LINE continue NEW_LINE DEDENT sd = line [ 4 ] NEW_LINE count = 0 NEW_LINE for t in type_list : NEW_LINE INDENT if t in sd : NEW_LINE INDENT self . addToSymTree ( sd [ t ] , line ) NEW_LINE count = count + 1 NEW_LINE DEDENT DEDENT if count != 1 : NEW_LINE INDENT print ' * * * * * * * * ▁ count ▁ = = ▁ 1 ▁ * * * * * * * * * ' NEW_LINE print data NEW_LINE print line NEW_LINE DEDENT NEW_LINE DEDENT return ( self . symTree , True ) NEW_LINE DEDENT def doQuery ( self , filename ) : NEW_LINE INDENT try : NEW_LINE INDENT output = self . runCtags ( filename ) NEW_LINE output = self . parseCtagsOutput ( output ) NEW_LINE output = self . buildTree ( output ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT print str ( e ) NEW_LINE output = [ None , False ] NEW_LINE DEDENT return output NEW_LINE DEDENT DEDENT def ct_tree_query ( filename ) : NEW_LINE INDENT ct = CtagsTreeBuilder ( ) NEW_LINE output = ct . doQuery ( filename ) NEW_LINE return output NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT import optparse NEW_LINE import sys NEW_LINE depth = 0 NEW_LINE def recursePrint ( t ) : NEW_LINE INDENT global depth NEW_LINE for k , v in t . items ( ) : NEW_LINE INDENT if k == ' * ' : NEW_LINE INDENT for line in v : NEW_LINE INDENT print ' % s % s ' % ( ' ▁ ' * depth , line ) NEW_LINE DEDENT continue NEW_LINE DEDENT if k == ' + ' : NEW_LINE INDENT continue NEW_LINE DEDENT if ' + ' in v : NEW_LINE INDENT k = v [ ' + ' ] NEW_LINE DEDENT print ' % s % s ' % ( ' ▁ ' * depth , k ) NEW_LINE depth = depth + 4 NEW_LINE recursePrint ( v ) NEW_LINE depth = depth - 4 NEW_LINE DEDENT DEDENT op = optparse . OptionParser ( ) NEW_LINE ( options , args ) = op . parse_args ( ) NEW_LINE if len ( args ) != 1 : NEW_LINE INDENT print ' Please ▁ specify ▁ a ▁ file ' NEW_LINE sys . exit ( - 1 ) NEW_LINE DEDENT ( output , isTree ) = ct_tree_query ( args [ 0 ] ) NEW_LINE if isTree : NEW_LINE INDENT recursePrint ( output ) NEW_LINE DEDENT else : NEW_LINE INDENT for line in output : NEW_LINE INDENT print line NEW_LINE DEDENT DEDENT DEDENT
 from __future__ import print_function NEW_LINE import filecmp NEW_LINE import os NEW_LINE import unittest NEW_LINE from shutil import rmtree NEW_LINE from tempfile import mkdtemp NEW_LINE import pytest NEW_LINE from pelican import Pelican NEW_LINE from pelican . settings import read_settings NEW_LINE from . notebook import IPYTHON_VERSION NEW_LINE PLUGIN_DIR = os . path . dirname ( __file__ ) NEW_LINE TEST_DATA_DIR = os . path . join ( PLUGIN_DIR , ' test _ data ' ) NEW_LINE class TestFullRun ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . temp_path = mkdtemp ( prefix = ' pelicantests . ' ) NEW_LINE self . temp_cache = mkdtemp ( prefix = ' pelican _ cache . ' ) NEW_LINE os . chdir ( TEST_DATA_DIR ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT rmtree ( self . temp_path ) NEW_LINE rmtree ( self . temp_cache ) NEW_LINE os . chdir ( PLUGIN_DIR ) NEW_LINE DEDENT @ pytest . mark . skipif ( IPYTHON_VERSION >= 3 , reason = " output ▁ must ▁ be ▁ created ▁ with ▁ ipython ▁ version ▁ 2" ) NEW_LINE def test_generate_with_ipython3 ( self ) : NEW_LINE INDENT base_path = os . path . dirname ( os . path . abspath ( __file__ ) ) NEW_LINE base_path = os . path . join ( base_path , ' test _ data ' ) NEW_LINE content_path = os . path . join ( base_path , ' content ' ) NEW_LINE output_path = os . path . join ( base_path , ' output ' ) NEW_LINE settings_path = os . path . join ( base_path , ' pelicanconf . py ' ) NEW_LINE settings = read_settings ( path = settings_path , override = { ' PATH ' : content_path , ' OUTPUT _ PATH ' : self . temp_path , ' CACHE _ PATH ' : self . temp_cache , } ) NEW_LINE pelican = Pelican ( settings ) NEW_LINE pelican . run ( ) NEW_LINE assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 3 . html ' ) ) NEW_LINE assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 4 . html ' ) ) NEW_LINE NEW_LINE DEDENT @ pytest . mark . skipif ( IPYTHON_VERSION < 3 , reason = " output ▁ must ▁ be ▁ created ▁ with ▁ ipython ▁ version ▁ 3" ) NEW_LINE def test_generate_with_ipython2 ( self ) : NEW_LINE INDENT base_path = os . path . dirname ( os . path . abspath ( __file__ ) ) NEW_LINE base_path = os . path . join ( base_path , ' test _ data ' ) NEW_LINE content_path = os . path . join ( base_path , ' content ' ) NEW_LINE output_path = os . path . join ( base_path , ' output ' ) NEW_LINE settings_path = os . path . join ( base_path , ' pelicanconf . py ' ) NEW_LINE settings = read_settings ( path = settings_path , override = { ' PATH ' : content_path , ' OUTPUT _ PATH ' : self . temp_path , ' CACHE _ PATH ' : self . temp_cache , } ) NEW_LINE pelican = Pelican ( settings ) NEW_LINE pelican . run ( ) NEW_LINE assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 3 . html ' ) ) NEW_LINE assert os . path . exists ( os . path . join ( self . temp_path , ' test - ipython - notebook - nb - format - 4 . html ' ) ) NEW_LINE NEW_LINE DEDENT DEDENT
 def setUp ( ) : NEW_LINE INDENT import socket NEW_LINE socket . setdefaulttimeout ( 5 ) NEW_LINE DEDENT
 import logging NEW_LINE import sys NEW_LINE from modularodm import Q NEW_LINE from framework . auth . core import User NEW_LINE from framework . transactions . context import TokuTransaction NEW_LINE from website . models import Comment NEW_LINE from website . app import init_app NEW_LINE from scripts import utils as script_utils NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE def main ( ) : NEW_LINE INDENT update_comments_viewed_timestamp ( ) NEW_LINE DEDENT def update_comments_viewed_timestamp ( ) : NEW_LINE INDENT users = User . find ( Q ( ' comments _ viewed _ timestamp ' , ' ne ' , None ) & Q ( ' comments _ viewed _ timestamp ' , ' ne ' , { } ) ) NEW_LINE for user in users : NEW_LINE INDENT if user . comments_viewed_timestamp : NEW_LINE INDENT timestamps = { } NEW_LINE for node_id in user . comments_viewed_timestamp : NEW_LINE INDENT node_timestamps = user . comments_viewed_timestamp [ node_id ] NEW_LINE if node_timestamps . get ( ' node ' , None ) : NEW_LINE INDENT timestamps [ node_id ] = node_timestamps [ ' node ' ] NEW_LINE DEDENT file_timestamps = node_timestamps . get ( ' files ' , None ) NEW_LINE if file_timestamps : NEW_LINE INDENT for file_id in file_timestamps : NEW_LINE INDENT timestamps [ file_id ] = file_timestamps [ file_id ] NEW_LINE DEDENT DEDENT DEDENT user . comments_viewed_timestamp = timestamps NEW_LINE user . save ( ) NEW_LINE logger . info ( ' Migrated ▁ timestamp ▁ for ▁ user ▁ { 0 } ' . format ( user . _id ) ) NEW_LINE DEDENT DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT dry = ' - - dry ' in sys . argv NEW_LINE if not dry : NEW_LINE INDENT script_utils . add_file_logger ( logger , __file__ ) NEW_LINE DEDENT init_app ( routes = False , set_backends = True ) NEW_LINE with TokuTransaction ( ) : NEW_LINE INDENT main ( ) NEW_LINE if dry : NEW_LINE INDENT raise Exception ( ' Dry ▁ Run ▁ - - ▁ Aborting ▁ Transaction ' ) NEW_LINE DEDENT DEDENT DEDENT
 import json NEW_LINE import random NEW_LINE from django import template NEW_LINE import logging NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE register = template . Library ( ) NEW_LINE def jsescape ( string ) : NEW_LINE INDENT return string . replace ( ' < script ' , ' $ BEGINSCRIPT ' ) . replace ( ' < / script > ' , ' $ ENDSCRIPT ' ) . replace ( ' \n ' , ' $ NEWLINE ' ) . replace ( ' \r ' , ' ' ) NEW_LINE DEDENT @ register . tag ( name = ' writecapture ' ) NEW_LINE def write_capture ( parser , token ) : NEW_LINE INDENT tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 4 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture ▁ block ▁ takes ▁ at ▁ most ▁ 3 ▁ arguments " ) NEW_LINE DEDENT nodelist = parser . parse ( ( ' endwritecapture ' , ) ) NEW_LINE parser . delete_first_token ( ) NEW_LINE if len ( tokens ) > 1 : NEW_LINE INDENT script_filter = tokens [ 1 ] NEW_LINE if script_filter == ' False ' : NEW_LINE INDENT script_filter = False NEW_LINE DEDENT elif script_filter == ' True ' : NEW_LINE INDENT script_filter = True NEW_LINE DEDENT else : NEW_LINE INDENT script_filter = template . Variable ( script_filter ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT script_filter = False NEW_LINE DEDENT return WriteCaptureNode ( nodelist , script_filter , * tokens [ 2 : ] ) NEW_LINE DEDENT class WriteCaptureNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , nodelist , script_filter = False , prototype = ' writecapture _ widget ' , widget_id = None ) : NEW_LINE INDENT self . nodelist = nodelist NEW_LINE self . script_filter = script_filter NEW_LINE self . prototype = prototype NEW_LINE self . widget_id = widget_id NEW_LINE if not self . widget_id : NEW_LINE INDENT self . widget_id = ' writecapture ' + str ( random . randint ( 0 , 99999999 ) ) NEW_LINE DEDENT DEDENT def render ( self , context ) : NEW_LINE INDENT eviloutput = jsescape ( self . nodelist . render ( context ) ) NEW_LINE if isinstance ( self . script_filter , template . Variable ) : NEW_LINE INDENT self . script_filter = bool ( self . script_filter . resolve ( context ) ) NEW_LINE DEDENT global_compatibility_mode = context . get ( ' wc _ compatibility _ mode ' , None ) NEW_LINE if global_compatibility_mode is None : NEW_LINE INDENT wc_compatibility_mode = self . script_filter NEW_LINE DEDENT else : NEW_LINE INDENT wc_compatibility_mode = global_compatibility_mode NEW_LINE DEDENT widget_dict = dict ( widget_prototype = self . prototype , id = self . widget_id , html = eviloutput , wc_compatibility_mode = wc_compatibility_mode , ) NEW_LINE output = """ < div ▁ id = " { widget _ id } " > < / div > STRNEWLINE < script ▁ type = " text / javascript " > STRNEWLINE ▁ ▁ ▁ ▁ marimo . emit ( ' { widget _ id } _ ready ' ) ; STRNEWLINE ▁ ▁ ▁ ▁ marimo . add _ widget ( { widget _ json } ) ; STRNEWLINE < / script > """ NEW_LINE output = output . format ( widget_id = self . widget_id , widget_json = json . dumps ( widget_dict ) , ) NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT @ register . tag ( name = ' writecapture _ delay ' ) NEW_LINE def write_capture_delay ( parser , token ) : NEW_LINE INDENT tokens = token . split_contents ( ) NEW_LINE if len ( tokens ) > 2 : NEW_LINE INDENT raise template . TemplateSyntaxError ( " writecapture _ delay ▁ takes ▁ at ▁ most ▁ 1 ▁ argument " ) NEW_LINE DEDENT if len ( tokens ) == 2 : NEW_LINE INDENT return WriteCaptureDelayNode ( tokens [ 1 ] ) NEW_LINE DEDENT return WriteCaptureDelayNode ( ) NEW_LINE DEDENT class WriteCaptureDelayNode ( template . Node ) : NEW_LINE INDENT def __init__ ( self , event = None ) : NEW_LINE INDENT self . event = event NEW_LINE DEDENT def render ( self , context ) : NEW_LINE INDENT output = ' ' NEW_LINE if self . event is None : NEW_LINE INDENT self . event = ' write _ ' + str ( random . randint ( 0 , 999999 ) ) NEW_LINE output = """ < script ▁ type = " text / javascript " > marimo . emit ( ' % s ' ) ; < / script > """ % self . event NEW_LINE DEDENT wc_delay = context . get ( ' marimo _ writecapture _ delay ' , None ) NEW_LINE if not wc_delay : NEW_LINE INDENT logger . error ( " The ▁ writecapture _ delay ▁ was ▁ called ▁ but ▁ didn ' t ▁ find ▁ " " marimo _ writecapture _ delay ▁ in ▁ the ▁ context . ▁ The ▁ tag ▁ " " depends ▁ on ▁ the ▁ Marimo ▁ middleware ▁ and ▁ context _ processor . " ) NEW_LINE return output NEW_LINE DEDENT if wc_delay . marimo_event : NEW_LINE INDENT logger . error ( ' Overwriting ▁ the ▁ marimo ▁ event ▁ delay ▁ % s ▁ with ▁ % s ' % ( wc_delay . marimo_event , self . event ) ) NEW_LINE DEDENT wc_delay . marimo_event = self . event NEW_LINE return output NEW_LINE DEDENT DEDENT
 import os NEW_LINE import sys NEW_LINE sys . path . append ( os . environ [ ' PERF _ EXEC _ PATH ' ] + ' / scripts / python / Perf - Trace - Util / lib / Perf / Trace ' ) NEW_LINE from Core import * NEW_LINE from perf_trace_context import * NEW_LINE unhandled = autodict ( ) NEW_LINE def trace_begin ( ) : NEW_LINE INDENT print " trace _ begin " NEW_LINE pass NEW_LINE DEDENT def trace_end ( ) : NEW_LINE INDENT print_unhandled ( ) NEW_LINE DEDENT def irq__softirq_entry ( event_name , context , common_cpu , common_secs , common_nsecs , common_pid , common_comm , vec ) : NEW_LINE INDENT print_header ( event_name , common_cpu , common_secs , common_nsecs , common_pid , common_comm ) NEW_LINE print_uncommon ( context ) NEW_LINE print " vec = % s \n " % \NEW_LINE ( symbol_str ( " irq _ _ softirq _ entry " , " vec " , vec ) ) , NEW_LINE DEDENT def kmem__kmalloc ( event_name , context , common_cpu , common_secs , common_nsecs , common_pid , common_comm , call_site , ptr , bytes_req , bytes_alloc , gfp_flags ) : NEW_LINE INDENT print_header ( event_name , common_cpu , common_secs , common_nsecs , common_pid , common_comm ) NEW_LINE print_uncommon ( context ) NEW_LINE print " call _ site = % u , ▁ ptr = % u , ▁ bytes _ req = % u , ▁ " " bytes _ alloc = % u , ▁ gfp _ flags = % s \n " % \NEW_LINE ( call_site , ptr , bytes_req , bytes_alloc , flag_str ( " kmem _ _ kmalloc " , " gfp _ flags " , gfp_flags ) ) , NEW_LINE DEDENT def trace_unhandled ( event_name , context , event_fields_dict ) : NEW_LINE INDENT try : NEW_LINE INDENT unhandled [ event_name ] += 1 NEW_LINE DEDENT except TypeError : NEW_LINE INDENT unhandled [ event_name ] = 1 NEW_LINE DEDENT DEDENT def print_header ( event_name , cpu , secs , nsecs , pid , comm ) : NEW_LINE INDENT print " % -20s ▁ % 5u ▁ % 05u . %09u ▁ % 8u ▁ % -20s ▁ " % \NEW_LINE ( event_name , cpu , secs , nsecs , pid , comm ) , NEW_LINE DEDENT def print_uncommon ( context ) : NEW_LINE INDENT print " common _ preempt _ count = % d , ▁ common _ flags = % s , ▁ common _ lock _ depth = % d , ▁ " \NEW_LINE % ( common_pc ( context ) , trace_flag_str ( common_flags ( context ) ) , \NEW_LINE common_lock_depth ( context ) ) NEW_LINE DEDENT def print_unhandled ( ) : NEW_LINE INDENT keys = unhandled . keys ( ) NEW_LINE if not keys : NEW_LINE INDENT return NEW_LINE DEDENT print " \n unhandled ▁ events : \n \n " , NEW_LINE print " % -40s ▁ ▁ % 10s \n " % ( " event " , " count " ) , NEW_LINE print " % -40s ▁ ▁ % 10s \n " % ( " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - " , " - - - - - - - - - - - " ) , NEW_LINE for event_name in keys : NEW_LINE INDENT print " % -40s ▁ ▁ % 10d \n " % ( event_name , unhandled [ event_name ] ) NEW_LINE DEDENT DEDENT
 from Listener import Listener NEW_LINE from _version import __version__ NEW_LINE import time NEW_LINE class Console ( object ) : NEW_LINE INDENT def __init__ ( self , args = None ) : NEW_LINE INDENT delay = 3.0 NEW_LINE number = 1 NEW_LINE command = [ ] NEW_LINE interface = ' eth0' NEW_LINE listen = False NEW_LINE host = ' localhost ' NEW_LINE if args : NEW_LINE INDENT delay = float ( args . delay ) if args . delay else delay NEW_LINE number = args . number if ( args . number != None ) else number NEW_LINE command = args . command if args . command else command NEW_LINE interface = args . interface if args . interface else interface NEW_LINE listen = args . listen if args . listen else listen NEW_LINE host = args . host if args . host else host NEW_LINE DEDENT if command != [ ] : NEW_LINE INDENT raise NotImplementedError ( ' Issuing ▁ commands ▁ to ▁ hosts ▁ has ▁ ' + ' not ▁ been ▁ implemented ▁ yet ' ) NEW_LINE DEDENT if listen : NEW_LINE INDENT self . listener = Listener ( interface ) NEW_LINE key = ''' STRNEWLINE remote ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ Dly ▁ St ▁ Dom ▁ Pr1 ▁ ▁ Cl ▁ Acc ▁ ▁ ▁ Var ▁ ▁ Pr2 ▁ ▁ ▁ ▁ ▁ ▁ ▁ Uniq ▁ ▁ ▁ ▁ ▁ ▁ ▁ SyncT ▁ ▁ DlyT ▁ ▁ AnnT STRNEWLINE = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ''' . strip ( ) NEW_LINE while number > 0 : NEW_LINE INDENT fmt = ' % a ▁ % b ▁ % d ▁ % Y ▁ % H : % M : % S ' NEW_LINE t = time . time ( ) NEW_LINE time_str = time . strftime ( fmt , time . localtime ( t ) ) NEW_LINE time_msecs = int ( ( t - int ( t ) ) * 1000 ) NEW_LINE print time_str + ' . %03d ▁ ' % ( time_msecs ) + time . tzname [ 0 ] NEW_LINE print key NEW_LINE neighbor_stats = self . listener . ptp_neighbors NEW_LINE for neighbor in neighbor_stats : NEW_LINE INDENT print self . listener . ptp_neighbors [ neighbor ] NEW_LINE DEDENT print NEW_LINE number -= 1 NEW_LINE if number <= 0 : NEW_LINE INDENT exit ( 0 ) NEW_LINE NEW_LINE DEDENT time . sleep ( delay ) NEW_LINE DEDENT NEW_LINE DEDENT else : NEW_LINE INDENT for supplied_command in command : NEW_LINE INDENT command = supplied_command . lower ( ) NEW_LINE if command == ' rv ' or command == ' readvar ' : NEW_LINE INDENT None NEW_LINE NEW_LINE DEDENT elif command == ' peers ' : NEW_LINE INDENT None NEW_LINE NEW_LINE DEDENT else : NEW_LINE INDENT raise NotImplementedError ( ' Unknown ▁ command , ▁ \ ' ' + command + ' \ ' ' ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT import argparse NEW_LINE def main ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( prog = ' ptpop ' , description = ' Gain ▁ ' + ' insight ▁ into ▁ the ▁ operations ▁ of ▁ IEEE ▁ 1588 ▁ Precision ▁ Time ▁ Protocol ▁ ' + ' domains ▁ on ▁ a ▁ network . ▁ Press ▁ the ▁ \ ' q\ ' ▁ key ▁ to ▁ quit . ' ) NEW_LINE command_choices = [ ' readvar ' , ' rv ' , ' peers ' ] NEW_LINE parser . add_argument ( ' host ' , type = str , nargs = ' ? ' , help = ' each ▁ of ▁ the ▁ ' + ' commands ▁ will ▁ be ▁ sent ▁ to ▁ the ▁ PTP ▁ servers ▁ ' + ' running ▁ on ▁ the ▁ host ▁ provided , ▁ localhost ▁ by ▁ ' + ' default . ' ) NEW_LINE parser . add_argument ( ' - c ' , ' - - command ' , type = str , action = ' append ' , help = ' a ▁ command ▁ to ▁ run ▁ on ▁ the ▁ provided ▁ host , ▁ ' + ' i . e . ▁ ' + str ( command_choices ) + ' , ▁ \ ' readvar\ ' ▁ ' + ' by ▁ default . ▁ Multiple ▁ commands ▁ can ▁ be ▁ issued . ' ) NEW_LINE parser . add_argument ( ' - i ' , ' - - interface ' , type = str , help = ' interface ▁ to ▁ issue ▁ commands ▁ on ▁ or ▁ to ▁ ' + ' observe ▁ on ▁ in ▁ listen ▁ mode . ' ) NEW_LINE parser . add_argument ( ' - l ' , ' - - listen ' , action = ' store _ true ' , help = ' don\ ' t ▁ contact ▁ any ▁ PTP ▁ servers , ▁ but ▁ ' + ' report ▁ on ▁ any ▁ services ▁ currently ▁ observed ▁ ' + ' on ▁ the ▁ network , ▁ instead . ' ) NEW_LINE parser . add_argument ( ' - d ' , ' - - delay ' , metavar = ' SECS . TENTHS ' , type = str , help = ' Specifies ▁ the ▁ delay ▁ between ▁ screen ▁ ' + ' updates ▁ when ▁ interactive . ▁ Can ▁ be ▁ changed ▁ while ▁ ' + ' running ▁ using ▁ the ▁ \ ' d\ ' ▁ key . ▁ Negative ▁ ' + ' numbers ▁ are ▁ not ▁ allowed . ▁ Setting ▁ this ▁ value ▁ ' + ' to ▁ 0 ▁ is ▁ the ▁ same ▁ as ▁ issuing ▁ the ▁ \ ' - n ▁ 1\ ' ▁ ' + ' option . ' ) NEW_LINE parser . add_argument ( ' - n ' , ' - - number ' , metavar = ' COUNT ' , type = int , help = ' Specifies ▁ the ▁ maximum ▁ number ▁ of ▁ iterations ▁ ' + ' in ▁ interactive ▁ mode ▁ before ▁ ending . ' ) NEW_LINE parser . add_argument ( ' - v ' , ' - - version ' , action = ' version ' , version = ' % ( prog ) s ▁ ' + __version__ ) NEW_LINE args = parser . parse_args ( ) NEW_LINE try : NEW_LINE INDENT c = Console ( args ) NEW_LINE DEDENT except Exception as e : NEW_LINE INDENT print type ( e ) . __name__ + " : ▁ " + str ( e . message ) NEW_LINE exit ( - 1 ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT
 __authors__ = [ " kurian . os " ] NEW_LINE __version__ = " $ Revision : ▁ 104961 ▁ $ " . split ( ) [ 1 ] NEW_LINE __revision__ = __version__ NEW_LINE __date__ = " $ Date : ▁ ▁ July ▁ 19 , ▁ 2011 ▁ 12:00:00 ▁ PM $ " . split ( ) [ 1 ] NEW_LINE __copyright__ = "2011" NEW_LINE __license__ = " Copyright ▁ 2011 ▁ Dr ▁ D ▁ Studios ▁ Pty ▁ Limited " NEW_LINE __contact__ = " kurian . os @ drdstudios . com " NEW_LINE __status__ = " Development " NEW_LINE import os NEW_LINE import traceback NEW_LINE import napalm . core as nap_core NEW_LINE import node_curves as node_curves NEW_LINE import kip . kip_reader as kip_reader NEW_LINE reload ( node_curves ) NEW_LINE reload ( kip_reader ) NEW_LINE from rodin import logging NEW_LINE from kip . kip_curve_class import * NEW_LINE from kip . kip_napalm_class import * NEW_LINE from kip . utils . kipError import * NEW_LINE from kip . template import * NEW_LINE rodin_logger = logging . get_logger ( ' kipHoudini ' ) NEW_LINE napalm_func = Napalm ( ) NEW_LINE GLOBAL_FPS = 24 NEW_LINE GLOBAL_TIME = 1 NEW_LINE class HoudiniWriter ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT rodin_logger . info ( " kip ▁ houdini ▁ writing ▁ class ▁ initialized " ) NEW_LINE self . houdini_version = " houdini , % s " % hou . applicationVersionString ( ) NEW_LINE self . kip_houdini_version = " kipHoudini % s " % os . getenv ( " DRD _ KIPHOUDINI _ VERSION " ) NEW_LINE DEDENT def writeOutCurves ( self , nap_file_name = None , houdini_nodes = [ ] , houdini_node_attributes = [ ] , start_frame = None , end_frame = None , write_xml = False , silent = False , left_eyes = [ ] , right_eyes = [ ] , map_file_name = None ) : NEW_LINE INDENT if nap_file_name : NEW_LINE INDENT node_curv = node_curves . NodeCurves ( ) NEW_LINE get_all_curves = node_curv . getCurves ( houdini_node_curves = houdini_nodes , \NEW_LINE houdini_attribute_curves = houdini_node_attributes , \NEW_LINE start_frame = start_frame , end_frame = end_frame , \NEW_LINE silent = silent , left_eye_curves = left_eyes , \NEW_LINE right_eye_curves = right_eyes ) NEW_LINE if write_xml : NEW_LINE INDENT if not nap_file_name . endswith ( " . xml " ) : NEW_LINE INDENT split_base_ext = os . path . splitext ( nap_file_name ) NEW_LINE if split_base_ext [ - 1 ] : NEW_LINE INDENT nap_file_name = " % s / . xml " % ( split_base_ext [ 0 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT nap_file_name = " % s / . xml " % ( nap_file_name ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if not nap_file_name . endswith ( " . nap " ) : NEW_LINE INDENT raise KipBaseError ( " Unknown ▁ file ▁ extension ▁ found ▁ in ▁ % s ▁ ! " % nap_file_name ) NEW_LINE DEDENT DEDENT write_status , map_file , nap_file = napalm_func . write ( nap_file_name , get_all_curves , \NEW_LINE debug = True , map_file_name = map_file_name , \NEW_LINE software = self . houdini_version , \NEW_LINE app_version = self . kip_houdini_version ) NEW_LINE rodin_logger . info ( " % s ▁ % s ▁ % s " % ( write_status , map_file , nap_file ) ) NEW_LINE return ( write_status , map_file , nap_file ) NEW_LINE DEDENT else : NEW_LINE INDENT raise KipBaseError ( " Expected ▁ napalm ▁ file ▁ name ▁ for ▁ write ▁ curve ▁ ! " ) NEW_LINE DEDENT DEDENT DEDENT class HoudiniReader ( object ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT rodin_logger . info ( " kip ▁ houdini ▁ read ▁ class ▁ initialized " ) NEW_LINE self . nuke_tan_types = { " spline " : " spline ( ) " , " linear " : " linear ( ) " , " constant " : " constant ( ) " , " cubic " : " bezier ( ) " } NEW_LINE self . channel_match = { ' translateX ' : ' tx ' , ' translateY ' : ' ty ' , ' translateZ ' : ' tz ' , ' rotateX ' : ' rx ' , ' rotateY ' : ' ry ' , ' rotateZ ' : ' rz ' , ' scaleX ' : ' sx ' , ' scaleY ' : ' sy ' , ' scaleZ ' : ' sz ' } NEW_LINE DEDENT def houSetAttr ( self , nap_file_name = None , houdini_nodes = [ ] , houdini_node_attribute = None , map_file_name = None , offset_value = 0 , start_frame = None , end_frame = None , attribute_map = None ) : NEW_LINE INDENT if nap_file_name : NEW_LINE INDENT if not map_file_name : NEW_LINE INDENT map_file_name = kip_reader . build_map_file_name ( nap_file_name ) NEW_LINE DEDENT header_info = kip_reader . header ( map_file_name ) NEW_LINE array_index = kip_reader . find_software_index ( header_info [ " client _ software " ] ) NEW_LINE houdini_node_list = houdini_nodes NEW_LINE knob_read = kip_reader . ReadCurve ( ) NEW_LINE get_curve_class = knob_read . getCurves ( nap_file_name = nap_file_name , \NEW_LINE map_file_name = map_file_name , offset_value = offset_value ) NEW_LINE DEDENT for each_node in get_curve_class : NEW_LINE INDENT node_key = get_curve_class . index ( each_node ) NEW_LINE current_node_curve = each_node [ 2 ] NEW_LINE curent_source_node = each_node [ 0 ] NEW_LINE for each_curve in current_node_curve : NEW_LINE INDENT curve_attr = each_curve [ 1 ] NEW_LINE current_key_dict = each_curve [ 2 ] NEW_LINE time_keys = current_key_dict [ " time " ] NEW_LINE key_value = current_key_dict [ " key _ value " ] NEW_LINE in_angle = current_key_dict [ " in _ angle " ] NEW_LINE out_angle = current_key_dict [ " out _ angle " ] NEW_LINE in_weight = current_key_dict [ " in _ weight " ] NEW_LINE out_weight = current_key_dict [ " out _ weight " ] NEW_LINE in_tan_type = current_key_dict [ " in _ tan _ type " ] NEW_LINE out_tan_type = current_key_dict [ " out _ tan _ type " ] NEW_LINE in_slope = current_key_dict [ " in _ slope " ] NEW_LINE out_slope = current_key_dict [ " out _ slope " ] NEW_LINE try : NEW_LINE INDENT for time in time_keys : NEW_LINE INDENT if houdini_node_attribute : NEW_LINE INDENT curve_attr = houdini_node_attribute NEW_LINE DEDENT else : NEW_LINE INDENT if attribute_map : NEW_LINE INDENT temp_attr_keys = attribute_map . keys ( ) NEW_LINE for each_template in temp_attr_keys : NEW_LINE INDENT source_details = each_template . split ( " . " ) NEW_LINE current_node_attr = " % s . % s " % ( curent_source_node , \NEW_LINE each_curve [ 1 ] ) NEW_LINE if current_node_attr == each_template : NEW_LINE INDENT destenation_details = attribute_map [ each_template ] \NEW_LINE . split ( " . " ) NEW_LINE curve_attr = destenation_details [ 1 ] NEW_LINE current_houdini_node = destenation_details [ 0 ] NEW_LINE current_houdini_node = hou . node ( current_houdini_node ) NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT current_houdini_node = hou . node ( houdini_node_list [ node_key ] ) NEW_LINE DEDENT DEDENT if start_frame and end_frame : NEW_LINE INDENT if time in range ( start_frame , end_frame + 1 ) : NEW_LINE INDENT key_index = time_keys . index ( time ) NEW_LINE DEDENT else : NEW_LINE INDENT print " % s ▁ not ▁ in ▁ range ▁ not ▁ applying ▁ the ▁ key " % time NEW_LINE continue NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT key_index = time_keys . index ( time ) NEW_LINE DEDENT in_tan_v = in_tan_type [ key_index ] NEW_LINE if self . nuke_tan_types . has_key ( in_tan_v ) : NEW_LINE INDENT in_tan_v = self . nuke_tan_types [ in_tan_v ] NEW_LINE DEDENT else : NEW_LINE INDENT in_tan_v = " bezier ( ) " NEW_LINE DEDENT hkey = hou . Keyframe ( ) NEW_LINE hkey . setTime ( ( time_keys [ key_index ] / GLOBAL_FPS ) ) NEW_LINE hkey . setValue ( key_value [ key_index ] ) NEW_LINE hkey . setExpression ( " bezier ( ) " ) NEW_LINE hkey . setExpression ( " spline ( ) " ) NEW_LINE hkey . setInAccel ( in_weight [ key_index ] ) NEW_LINE hkey . setAccel ( out_weight [ key_index ] ) NEW_LINE hkey . setInSlope ( in_slope [ key_index ] ) NEW_LINE hkey . setSlope ( out_slope [ key_index ] ) NEW_LINE this_node_attr = curve_attr NEW_LINE if self . channel_match . has_key ( curve_attr ) : NEW_LINE INDENT this_node_attr = self . channel_match [ curve_attr ] NEW_LINE DEDENT hou_nod = current_houdini_node . parm ( this_node_attr ) . setKeyframe ( hkey ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT traceback . print_exc ( ) NEW_LINE raise KipBaseError ( " No ▁ objects ▁ found ▁ in ▁ node ▁ list ! " ) NEW_LINE DEDENT DEDENT DEDENT rodin_logger . info ( " Aniamtion ▁ curve ▁ trasfer ▁ is ▁ finished ▁ ! " ) NEW_LINE return True NEW_LINE DEDENT DEDENT def header ( map_file_name ) : NEW_LINE INDENT if os . path . exists ( map_file_name ) : NEW_LINE INDENT nap_header = kip_reader . header ( map_file_name ) NEW_LINE return nap_header NEW_LINE DEDENT return None NEW_LINE DEDENT
 from django . test import TestCase NEW_LINE from . models import Person NEW_LINE class ChoicesTests ( TestCase ) : NEW_LINE INDENT def test_display ( self ) : NEW_LINE INDENT a = Person . objects . create ( name = ' Adrian ' , gender = ' M ' ) NEW_LINE s = Person . objects . create ( name = ' Sara ' , gender = ' F ' ) NEW_LINE self . assertEqual ( a . gender , ' M ' ) NEW_LINE self . assertEqual ( s . gender , ' F ' ) NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' Male ' ) NEW_LINE self . assertEqual ( s . get_gender_display ( ) , ' Female ' ) NEW_LINE a . gender = ' ' NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' ' ) NEW_LINE a . gender = ' U ' NEW_LINE self . assertEqual ( a . get_gender_display ( ) , ' U ' ) NEW_LINE DEDENT DEDENT
 from django . db import models NEW_LINE from django . contrib . contenttypes import generic NEW_LINE from django . conf import settings NEW_LINE from django . utils . translation import ugettext_lazy as _ NEW_LINE from django . utils import timezone NEW_LINE from taiga . projects . notifications . mixins import WatchedModelMixin NEW_LINE from taiga . projects . occ import OCCModelMixin NEW_LINE class WikiPage ( OCCModelMixin , WatchedModelMixin , models . Model ) : NEW_LINE INDENT project = models . ForeignKey ( " projects . Project " , null = False , blank = False , related_name = " wiki _ pages " , verbose_name = _ ( " project " ) ) NEW_LINE slug = models . SlugField ( max_length = 500 , db_index = True , null = False , blank = False , verbose_name = _ ( " slug " ) ) NEW_LINE content = models . TextField ( null = False , blank = True , verbose_name = _ ( " content " ) ) NEW_LINE owner = models . ForeignKey ( settings . AUTH_USER_MODEL , null = True , blank = True , related_name = " owned _ wiki _ pages " , verbose_name = _ ( " owner " ) ) NEW_LINE last_modifier = models . ForeignKey ( settings . AUTH_USER_MODEL , null = True , blank = True , related_name = " last _ modified _ wiki _ pages " , verbose_name = _ ( " last ▁ modifier " ) ) NEW_LINE created_date = models . DateTimeField ( null = False , blank = False , verbose_name = _ ( " created ▁ date " ) , default = timezone . now ) NEW_LINE modified_date = models . DateTimeField ( null = False , blank = False , verbose_name = _ ( " modified ▁ date " ) ) NEW_LINE attachments = generic . GenericRelation ( " attachments . Attachment " ) NEW_LINE _importing = None NEW_LINE class Meta : NEW_LINE INDENT verbose_name = " wiki ▁ page " NEW_LINE verbose_name_plural = " wiki ▁ pages " NEW_LINE ordering = [ " project " , " slug " ] NEW_LINE unique_together = ( " project " , " slug " , ) NEW_LINE permissions = ( ( " view _ wikipage " , " Can ▁ view ▁ wiki ▁ page " ) , ) NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return " project ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . project_id , self . slug ) NEW_LINE DEDENT def save ( self , * args , ** kwargs ) : NEW_LINE INDENT if not self . _importing or not self . modified_date : NEW_LINE INDENT self . modified_date = timezone . now ( ) NEW_LINE DEDENT return super ( ) . save ( * args , ** kwargs ) NEW_LINE DEDENT DEDENT class WikiLink ( models . Model ) : NEW_LINE INDENT project = models . ForeignKey ( " projects . Project " , null = False , blank = False , related_name = " wiki _ links " , verbose_name = _ ( " project " ) ) NEW_LINE title = models . CharField ( max_length = 500 , null = False , blank = False ) NEW_LINE href = models . SlugField ( max_length = 500 , db_index = True , null = False , blank = False , verbose_name = _ ( " href " ) ) NEW_LINE order = models . PositiveSmallIntegerField ( default = 1 , null = False , blank = False , verbose_name = _ ( " order " ) ) NEW_LINE class Meta : NEW_LINE INDENT verbose_name = " wiki ▁ link " NEW_LINE verbose_name_plural = " wiki ▁ links " NEW_LINE ordering = [ " project " , " order " ] NEW_LINE unique_together = ( " project " , " href " ) NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return self . title NEW_LINE DEDENT DEDENT
 import datetime NEW_LINE from south . db import db NEW_LINE from south . v2 import SchemaMigration NEW_LINE from django . db import models NEW_LINE class Migration ( SchemaMigration ) : NEW_LINE INDENT def forwards ( self , orm ) : NEW_LINE INDENT db . create_table ( ' student _ testcenteruser ' , ( ( ' id ' , self . gf ( ' django . db . models . fields . AutoField ' ) ( primary_key = True ) ) , ( ' user ' , self . gf ( ' django . db . models . fields . related . ForeignKey ' ) ( default = None , to = orm [ ' auth . User ' ] , unique = True ) ) , ( ' created _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now_add = True , db_index = True , blank = True ) ) , ( ' updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now = True , db_index = True , blank = True ) ) , ( ' user _ updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( db_index = True ) ) , ( ' candidate _ id ' , self . gf ( ' django . db . models . fields . IntegerField ' ) ( null = True , db_index = True ) ) , ( ' client _ candidate _ id ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' first _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , db_index = True ) ) , ( ' last _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' middle _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , blank = True ) ) , ( ' suffix ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 255 , blank = True ) ) , ( ' salutation ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ( ' address _ 1' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 ) ) , ( ' address _ 2' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' address _ 3' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' city ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 32 , db_index = True ) ) , ( ' state ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 20 , blank = True ) ) , ( ' postal _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 16 , blank = True ) ) , ( ' country ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' phone ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 ) ) , ( ' extension ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 8 , blank = True ) ) , ( ' phone _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' fax ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 , blank = True ) ) , ( ' fax _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , blank = True ) ) , ( ' company _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ) ) NEW_LINE db . send_create_signal ( ' student ' , [ ' TestCenterUser ' ] ) NEW_LINE DEDENT def backwards ( self , orm ) : NEW_LINE INDENT db . delete_table ( ' student _ testcenteruser ' ) NEW_LINE DEDENT models = { ' auth . group ' : { ' Meta ' : { ' object _ name ' : ' Group ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '80' } ) , ' permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) } , ' auth . permission ' : { ' Meta ' : { ' ordering ' : " ( ' content _ type _ _ app _ label ' , ▁ ' content _ type _ _ model ' , ▁ ' codename ' ) " , ' unique _ together ' : " ( ( ' content _ type ' , ▁ ' codename ' ) , ) " , ' object _ name ' : ' Permission ' } , ' codename ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' content _ type ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' contenttypes . ContentType ' ] " } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } , ' auth . user ' : { ' Meta ' : { ' object _ name ' : ' User ' } , ' about ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' avatar _ type ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' n ' " , ' max _ length ' : '1' } ) , ' bronze ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' consecutive _ days _ visit _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' country ' : ( ' django _ countries . fields . CountryField ' , [ ] , { ' max _ length ' : '2' , ' blank ' : ' True ' } ) , ' date _ joined ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' date _ of _ birth ' : ( ' django . db . models . fields . DateField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' display _ tag _ filter _ strategy ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' email ' : ( ' django . db . models . fields . EmailField ' , [ ] , { ' max _ length ' : '75' , ' blank ' : ' True ' } ) , ' email _ isvalid ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' email _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' null ' : ' True ' } ) , ' email _ tag _ filter _ strategy ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '1' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' gold ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' gravatar ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' } ) , ' groups ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' ignored _ tags ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' interesting _ tags ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' is _ active ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' is _ staff ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' is _ superuser ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' last _ login ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' last _ seen ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' location ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' , ' blank ' : ' True ' } ) , ' new _ response _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' password ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '128' } ) , ' questions _ per _ page ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '10' } ) , ' real _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' , ' blank ' : ' True ' } ) , ' reputation ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' default ' : '1' } ) , ' seen _ response _ count ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '0' } ) , ' show _ country ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' silver ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' } ) , ' status ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' w ' " , ' max _ length ' : '2' } ) , ' user _ permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' username ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '30' } ) , ' website ' : ( ' django . db . models . fields . URLField ' , [ ] , { ' max _ length ' : '200' , ' blank ' : ' True ' } ) } , ' contenttypes . contenttype ' : { ' Meta ' : { ' ordering ' : " ( ' name ' , ) " , ' unique _ together ' : " ( ( ' app _ label ' , ▁ ' model ' ) , ) " , ' object _ name ' : ' ContentType ' , ' db _ table ' : " ' django _ content _ type ' " } , ' app _ label ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' model ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) } , ' student . courseenrollment ' : { ' Meta ' : { ' unique _ together ' : " ( ( ' user ' , ▁ ' course _ id ' ) , ) " , ' object _ name ' : ' CourseEnrollment ' } , ' course _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' db _ index ' : ' True ' } ) , ' created ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' null ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " } ) } , ' student . pendingemailchange ' : { ' Meta ' : { ' object _ name ' : ' PendingEmailChange ' } , ' activation _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' new _ email ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . pendingnamechange ' : { ' Meta ' : { ' object _ name ' : ' PendingNameChange ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' new _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' rationale ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '1024' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . registration ' : { ' Meta ' : { ' object _ name ' : ' Registration ' , ' db _ table ' : " ' auth _ registration ' " } , ' activation _ key ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) } , ' student . testcenteruser ' : { ' Meta ' : { ' object _ name ' : ' TestCenterUser ' } , ' address _ 1' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' } ) , ' address _ 2' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' , ' blank ' : ' True ' } ) , ' address _ 3' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '40' , ' blank ' : ' True ' } ) , ' candidate _ id ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' null ' : ' True ' , ' db _ index ' : ' True ' } ) , ' city ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' client _ candidate _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' company _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' blank ' : ' True ' } ) , ' country ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' db _ index ' : ' True ' } ) , ' created _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' extension ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '8' , ' blank ' : ' True ' } ) , ' fax ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '35' , ' blank ' : ' True ' } ) , ' fax _ country _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' blank ' : ' True ' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' middle _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' phone ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '35' } ) , ' phone _ country _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' db _ index ' : ' True ' } ) , ' postal _ code ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '16' , ' blank ' : ' True ' } ) , ' salutation ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' blank ' : ' True ' } ) , ' state ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '20' , ' blank ' : ' True ' } ) , ' suffix ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' updated _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' default ' : ' None ' , ' to ' : " orm [ ' auth . User ' ] " , ' unique ' : ' True ' } ) , ' user _ updated _ at ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' student . userprofile ' : { ' Meta ' : { ' object _ name ' : ' UserProfile ' , ' db _ table ' : " ' auth _ userprofile ' " } , ' courseware ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' default ' : " ' course . xml ' " , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' gender ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '6' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' goals ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' level _ of _ education ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '6' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' location ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' mailing _ address ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '255' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' related _ name ' : " ' profile ' " , ' unique ' : ' True ' , ' to ' : " orm [ ' auth . User ' ] " } ) , ' year _ of _ birth ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' student . usertestgroup ' : { ' Meta ' : { ' object _ name ' : ' UserTestGroup ' } , ' description ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '32' , ' db _ index ' : ' True ' } ) , ' users ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . User ' ] " , ' db _ index ' : ' True ' , ' symmetrical ' : ' False ' } ) } } NEW_LINE complete_apps = [ ' student ' ] NEW_LINE DEDENT
 from __future__ import unicode_literals NEW_LINE from django . test import TestCase NEW_LINE from django . utils import six NEW_LINE from . models import Person NEW_LINE class SaveDeleteHookTests ( TestCase ) : NEW_LINE INDENT def test_basic ( self ) : NEW_LINE INDENT p = Person ( first_name = " John " , last_name = " Smith " ) NEW_LINE self . assertEqual ( p . data , [ ] ) NEW_LINE p . save ( ) NEW_LINE self . assertEqual ( p . data , [ " Before ▁ save " , " After ▁ save " , ] ) NEW_LINE self . assertQuerysetEqual ( Person . objects . all ( ) , [ " John ▁ Smith " , ] , six . text_type ) NEW_LINE p . delete ( ) NEW_LINE self . assertEqual ( p . data , [ " Before ▁ save " , " After ▁ save " , " Before ▁ deletion " , " After ▁ deletion " , ] ) NEW_LINE self . assertQuerysetEqual ( Person . objects . all ( ) , [ ] ) NEW_LINE DEDENT DEDENT
 from cryptomath import * NEW_LINE from RSAKey import * NEW_LINE from Python_RSAKey import Python_RSAKey NEW_LINE if pycryptoLoaded : NEW_LINE INDENT from Crypto . PublicKey import RSA NEW_LINE class PyCrypto_RSAKey ( RSAKey ) : NEW_LINE INDENT def __init__ ( self , n = 0 , e = 0 , d = 0 , p = 0 , q = 0 , dP = 0 , dQ = 0 , qInv = 0 ) : NEW_LINE INDENT if not d : NEW_LINE INDENT self . rsa = RSA . construct ( ( n , e ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . rsa = RSA . construct ( ( n , e , d , p , q ) ) NEW_LINE DEDENT DEDENT def __getattr__ ( self , name ) : NEW_LINE INDENT return getattr ( self . rsa , name ) NEW_LINE DEDENT def hasPrivateKey ( self ) : NEW_LINE INDENT return self . rsa . has_private ( ) NEW_LINE DEDENT def hash ( self ) : NEW_LINE INDENT return Python_RSAKey ( self . n , self . e ) . hash ( ) NEW_LINE DEDENT def _rawPrivateKeyOp ( self , m ) : NEW_LINE INDENT s = numberToString ( m ) NEW_LINE byteLength = numBytes ( self . n ) NEW_LINE if len ( s ) == byteLength : NEW_LINE INDENT pass NEW_LINE DEDENT elif len ( s ) == byteLength - 1 : NEW_LINE INDENT s = ' \0' + s NEW_LINE DEDENT else : NEW_LINE INDENT raise AssertionError ( ) NEW_LINE DEDENT c = stringToNumber ( self . rsa . decrypt ( ( s , ) ) ) NEW_LINE return c NEW_LINE DEDENT def _rawPublicKeyOp ( self , c ) : NEW_LINE INDENT s = numberToString ( c ) NEW_LINE byteLength = numBytes ( self . n ) NEW_LINE if len ( s ) == byteLength : NEW_LINE INDENT pass NEW_LINE DEDENT elif len ( s ) == byteLength - 1 : NEW_LINE INDENT s = ' \0' + s NEW_LINE DEDENT else : NEW_LINE INDENT raise AssertionError ( ) NEW_LINE DEDENT m = stringToNumber ( self . rsa . encrypt ( s , None ) [ 0 ] ) NEW_LINE return m NEW_LINE DEDENT def writeXMLPublicKey ( self , indent = ' ' ) : NEW_LINE INDENT return Python_RSAKey ( self . n , self . e ) . write ( indent ) NEW_LINE DEDENT def generate ( bits ) : NEW_LINE INDENT key = PyCrypto_RSAKey ( ) NEW_LINE def f ( numBytes ) : NEW_LINE INDENT return bytesToString ( getRandomBytes ( numBytes ) ) NEW_LINE DEDENT key . rsa = RSA . generate ( bits , f ) NEW_LINE return key NEW_LINE DEDENT generate = staticmethod ( generate ) NEW_LINE DEDENT DEDENT
 from __future__ import unicode_literals NEW_LINE import frappe NEW_LINE import frappe . model . meta NEW_LINE from frappe . model . dynamic_links import get_dynamic_link_map NEW_LINE import frappe . defaults NEW_LINE from frappe . utils . file_manager import remove_all NEW_LINE from frappe . utils . password import delete_all_passwords_for NEW_LINE from frappe import _ NEW_LINE from frappe . model . naming import revert_series_if_last NEW_LINE def delete_doc ( doctype = None , name = None , force = 0 , ignore_doctypes = None , for_reload = False , ignore_permissions = False , flags = None , ignore_on_trash = False ) : NEW_LINE INDENT if not ignore_doctypes : NEW_LINE INDENT ignore_doctypes = [ ] NEW_LINE DEDENT if not doctype : NEW_LINE INDENT doctype = frappe . form_dict . get ( ' dt ' ) NEW_LINE name = frappe . form_dict . get ( ' dn ' ) NEW_LINE DEDENT names = name NEW_LINE if isinstance ( name , basestring ) : NEW_LINE INDENT names = [ name ] NEW_LINE DEDENT for name in names or [ ] : NEW_LINE INDENT if not frappe . db . exists ( doctype , name ) : NEW_LINE INDENT return NEW_LINE DEDENT remove_all ( doctype , name ) NEW_LINE delete_all_passwords_for ( doctype , name ) NEW_LINE doc = None NEW_LINE if doctype == " DocType " : NEW_LINE INDENT if for_reload : NEW_LINE INDENT try : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE DEDENT except frappe . DoesNotExistError : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT doc . run_method ( " before _ reload " ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE update_flags ( doc , flags , ignore_permissions ) NEW_LINE check_permission_and_not_submitted ( doc ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabCustom ▁ Field ` ▁ where ▁ dt ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabCustom ▁ Script ` ▁ where ▁ dt ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabProperty ▁ Setter ` ▁ where ▁ doc _ type ▁ = ▁ % s " , name ) NEW_LINE frappe . db . sql ( " delete ▁ from ▁ ` tabReport ` ▁ where ▁ ref _ doctype = % s " , name ) NEW_LINE DEDENT delete_from_table ( doctype , name , ignore_doctypes , None ) NEW_LINE DEDENT else : NEW_LINE INDENT doc = frappe . get_doc ( doctype , name ) NEW_LINE if not for_reload : NEW_LINE INDENT update_flags ( doc , flags , ignore_permissions ) NEW_LINE check_permission_and_not_submitted ( doc ) NEW_LINE if not ignore_on_trash : NEW_LINE INDENT doc . run_method ( " on _ trash " ) NEW_LINE doc . run_method ( ' on _ change ' ) NEW_LINE DEDENT dynamic_linked_doctypes = [ df . parent for df in get_dynamic_link_map ( ) . get ( doc . doctype , [ ] ) ] NEW_LINE if " ToDo " in dynamic_linked_doctypes : NEW_LINE INDENT delete_linked_todos ( doc ) NEW_LINE DEDENT if " Communication " in dynamic_linked_doctypes : NEW_LINE INDENT delete_linked_communications ( doc ) NEW_LINE DEDENT if " DocShare " in dynamic_linked_doctypes : NEW_LINE INDENT delete_shared ( doc ) NEW_LINE DEDENT if " Email ▁ Unsubscribe " in dynamic_linked_doctypes : NEW_LINE INDENT delete_email_subscribe ( doc ) NEW_LINE DEDENT if not force : NEW_LINE INDENT check_if_doc_is_linked ( doc ) NEW_LINE check_if_doc_is_dynamically_linked ( doc ) NEW_LINE DEDENT DEDENT update_naming_series ( doc ) NEW_LINE delete_from_table ( doctype , name , ignore_doctypes , doc ) NEW_LINE doc . run_method ( " after _ delete " ) NEW_LINE DEDENT if doc and not frappe . flags . in_patch : NEW_LINE INDENT try : NEW_LINE INDENT doc . notify_update ( ) NEW_LINE insert_feed ( doc ) NEW_LINE DEDENT except ImportError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT frappe . defaults . clear_default ( parenttype = " User ▁ Permission " , key = doctype , value = name ) NEW_LINE DEDENT DEDENT def update_naming_series ( doc ) : NEW_LINE INDENT if doc . meta . autoname : NEW_LINE INDENT if doc . meta . autoname . startswith ( " naming _ series : " ) \NEW_LINE and getattr ( doc , " naming _ series " , None ) : NEW_LINE INDENT revert_series_if_last ( doc . naming_series , doc . name ) NEW_LINE DEDENT elif doc . meta . autoname . split ( " : " ) [ 0 ] not in ( " Prompt " , " field " , " hash " ) : NEW_LINE INDENT revert_series_if_last ( doc . meta . autoname , doc . name ) NEW_LINE DEDENT DEDENT DEDENT def delete_from_table ( doctype , name , ignore_doctypes , doc ) : NEW_LINE INDENT if doctype != " DocType " and doctype == name : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tabSingles ` ▁ where ▁ doctype = % s " , name ) NEW_LINE DEDENT else : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tab % s ` ▁ where ▁ name = % s " % ( frappe . db . escape ( doctype ) , " % s " ) , ( name , ) ) NEW_LINE DEDENT if doc : NEW_LINE INDENT tables = [ d . options for d in doc . meta . get_table_fields ( ) ] NEW_LINE DEDENT else : NEW_LINE INDENT def get_table_fields ( field_doctype ) : NEW_LINE INDENT return frappe . db . sql_list ( """ select ▁ options ▁ from ▁ ` tab { } ` ▁ where ▁ fieldtype = ' Table ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL TABSYMBOL and ▁ parent = % s """ . format ( field_doctype ) , doctype ) NEW_LINE DEDENT tables = get_table_fields ( " DocField " ) NEW_LINE if not frappe . flags . in_install == " frappe " : NEW_LINE INDENT tables += get_table_fields ( " Custom ▁ Field " ) NEW_LINE DEDENT DEDENT for t in list ( set ( tables ) ) : NEW_LINE INDENT if t not in ignore_doctypes : NEW_LINE INDENT frappe . db . sql ( " delete ▁ from ▁ ` tab % s ` ▁ where ▁ parenttype = % s ▁ and ▁ parent ▁ = ▁ % s " % ( t , ' % s ' , ' % s ' ) , ( doctype , name ) ) NEW_LINE DEDENT DEDENT DEDENT def update_flags ( doc , flags = None , ignore_permissions = False ) : NEW_LINE INDENT if ignore_permissions : NEW_LINE INDENT if not flags : NEW_LINE INDENT flags = { } NEW_LINE DEDENT flags [ " ignore _ permissions " ] = ignore_permissions NEW_LINE DEDENT if flags : NEW_LINE INDENT doc . flags . update ( flags ) NEW_LINE DEDENT DEDENT def check_permission_and_not_submitted ( doc ) : NEW_LINE INDENT if not doc . flags . ignore_permissions and frappe . session . user != " Administrator " and ( not doc . has_permission ( " delete " ) or ( doc . doctype == " DocType " and not doc . custom ) ) : NEW_LINE INDENT frappe . msgprint ( _ ( " User ▁ not ▁ allowed ▁ to ▁ delete ▁ { 0 } : ▁ { 1 } " ) . format ( doc . doctype , doc . name ) , raise_exception = True ) NEW_LINE DEDENT if doc . docstatus == 1 : NEW_LINE INDENT frappe . msgprint ( _ ( " { 0 } ▁ { 1 } : ▁ Submitted ▁ Record ▁ cannot ▁ be ▁ deleted . " ) . format ( doc . doctype , doc . name ) , raise_exception = True ) NEW_LINE DEDENT DEDENT def check_if_doc_is_linked ( doc , method = " Delete " ) : NEW_LINE INDENT from frappe . model . rename_doc import get_link_fields NEW_LINE link_fields = get_link_fields ( doc . doctype ) NEW_LINE link_fields = [ [ lf [ ' parent ' ] , lf [ ' fieldname ' ] , lf [ ' issingle ' ] ] for lf in link_fields ] NEW_LINE for link_dt , link_field , issingle in link_fields : NEW_LINE INDENT if not issingle : NEW_LINE INDENT item = frappe . db . get_value ( link_dt , { link_field : doc . name } , [ " name " , " parent " , " parenttype " , " docstatus " ] , as_dict = True ) NEW_LINE if item and ( ( item . parent or item . name ) != doc . name ) \NEW_LINE and ( ( method == " Delete " and item . docstatus < 2 ) or ( method == " Cancel " and item . docstatus == 1 ) ) : NEW_LINE INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) . format ( doc . doctype , doc . name , item . parenttype if item . parent else link_dt , item . parent or item . name ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def check_if_doc_is_dynamically_linked ( doc , method = " Delete " ) : NEW_LINE INDENT for df in get_dynamic_link_map ( ) . get ( doc . doctype , [ ] ) : NEW_LINE INDENT if df . parent in ( " Communication " , " ToDo " , " DocShare " , " Email ▁ Unsubscribe " ) : NEW_LINE INDENT continue NEW_LINE DEDENT meta = frappe . get_meta ( df . parent ) NEW_LINE if meta . issingle : NEW_LINE INDENT refdoc = frappe . db . get_singles_dict ( df . parent ) NEW_LINE if ( refdoc . get ( df . options ) == doc . doctype and refdoc . get ( df . fieldname ) == doc . name and ( ( method == " Delete " and refdoc . docstatus < 2 ) or ( method == " Cancel " and refdoc . docstatus == 1 ) ) ) : NEW_LINE INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) . format ( doc . doctype , doc . name , df . parent , " " ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT for refdoc in frappe . db . sql ( """ select ▁ name , ▁ docstatus ▁ from ▁ ` tab { parent } ` ▁ where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL TABSYMBOL { options } = % s ▁ and ▁ { fieldname } = % s """ . format ( ** df ) , ( doc . doctype , doc . name ) , as_dict = True ) : NEW_LINE INDENT if ( ( method == " Delete " and refdoc . docstatus < 2 ) or ( method == " Cancel " and refdoc . docstatus == 1 ) ) : NEW_LINE INDENT frappe . throw ( _ ( " Cannot ▁ delete ▁ or ▁ cancel ▁ because ▁ { 0 } ▁ { 1 } ▁ is ▁ linked ▁ with ▁ { 2 } ▁ { 3 } " ) \NEW_LINE . format ( doc . doctype , doc . name , df . parent , refdoc . name ) , frappe . LinkExistsError ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def delete_linked_todos ( doc ) : NEW_LINE INDENT delete_doc ( " ToDo " , frappe . db . sql_list ( """ select ▁ name ▁ from ▁ ` tabToDo ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ reference _ type = % s ▁ and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) , ignore_permissions = True ) NEW_LINE DEDENT def delete_email_subscribe ( doc ) : NEW_LINE INDENT frappe . db . sql ( ''' delete ▁ from ▁ ` tabEmail ▁ Unsubscribe ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ reference _ doctype = % s ▁ and ▁ reference _ name = % s ''' , ( doc . doctype , doc . name ) ) NEW_LINE DEDENT def delete_linked_communications ( doc ) : NEW_LINE INDENT frappe . db . sql ( """ delete ▁ from ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL communication _ type ▁ = ▁ ' Comment ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ doctype = % s ▁ and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ reference _ doctype = null , ▁ reference _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL communication _ type ▁ = ▁ ' Communication ' STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ doctype = % s STRNEWLINE TABSYMBOL TABSYMBOL TABSYMBOL and ▁ reference _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ link _ doctype = null , ▁ link _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where ▁ link _ doctype = % s ▁ and ▁ link _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE frappe . db . sql ( """ update ▁ ` tabCommunication ` STRNEWLINE TABSYMBOL TABSYMBOL set ▁ timeline _ doctype = null , ▁ timeline _ name = null STRNEWLINE TABSYMBOL TABSYMBOL where ▁ timeline _ doctype = % s ▁ and ▁ timeline _ name = % s """ , ( doc . doctype , doc . name ) ) NEW_LINE DEDENT def insert_feed ( doc ) : NEW_LINE INDENT from frappe . utils import get_fullname NEW_LINE if frappe . flags . in_install or frappe . flags . in_import or getattr ( doc , " no _ feed _ on _ delete " , False ) : NEW_LINE INDENT return NEW_LINE DEDENT frappe . get_doc ( { " doctype " : " Communication " , " communication _ type " : " Comment " , " comment _ type " : " Deleted " , " reference _ doctype " : doc . doctype , " subject " : " { 0 } ▁ { 1 } " . format ( _ ( doc . doctype ) , doc . name ) , " full _ name " : get_fullname ( doc . owner ) } ) . insert ( ignore_permissions = True ) NEW_LINE DEDENT def delete_shared ( doc ) : NEW_LINE INDENT delete_doc ( " DocShare " , frappe . db . sql_list ( """ select ▁ name ▁ from ▁ ` tabDocShare ` STRNEWLINE TABSYMBOL TABSYMBOL where ▁ share _ doctype = % s ▁ and ▁ share _ name = % s """ , ( doc . doctype , doc . name ) ) , ignore_on_trash = True ) NEW_LINE DEDENT
 import sys NEW_LINE import unittest NEW_LINE from libcloud . utils . py3 import httplib NEW_LINE from libcloud . utils . py3 import urlparse NEW_LINE from libcloud . utils . py3 import parse_qs NEW_LINE from libcloud . compute . base import NodeState , NodeLocation NEW_LINE from libcloud . common . types import LibcloudError , InvalidCredsError NEW_LINE from libcloud . common . gogrid import GoGridIpAddress NEW_LINE from libcloud . compute . drivers . gogrid import GoGridNodeDriver NEW_LINE from libcloud . compute . base import Node , NodeImage , NodeSize NEW_LINE from libcloud . test import MockHttp NEW_LINE from libcloud . test . compute import TestCaseMixin NEW_LINE from libcloud . test . file_fixtures import ComputeFileFixtures NEW_LINE class GoGridTests ( unittest . TestCase , TestCaseMixin ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT GoGridNodeDriver . connectionCls . conn_classes = ( None , GoGridMockHttp ) NEW_LINE GoGridMockHttp . type = None NEW_LINE self . driver = GoGridNodeDriver ( " foo " , " bar " ) NEW_LINE DEDENT def _get_test_512Mb_node_size ( self ) : NEW_LINE INDENT return NodeSize ( id = '512Mb ' , name = None , ram = None , disk = None , bandwidth = None , price = None , driver = self . driver ) NEW_LINE DEDENT def test_create_node ( self ) : NEW_LINE INDENT image = NodeImage ( 1531 , None , self . driver ) NEW_LINE node = self . driver . create_node ( name = ' test1' , image = image , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE self . assertEqual ( node . name , ' test1' ) NEW_LINE self . assertTrue ( node . id is not None ) NEW_LINE self . assertEqual ( node . extra [ ' password ' ] , ' bebebe ' ) NEW_LINE DEDENT def test_list_nodes ( self ) : NEW_LINE INDENT node = self . driver . list_nodes ( ) [ 0 ] NEW_LINE self . assertEqual ( node . id , '90967' ) NEW_LINE self . assertEqual ( node . extra [ ' password ' ] , ' bebebe ' ) NEW_LINE self . assertEqual ( node . extra [ ' description ' ] , ' test ▁ server ' ) NEW_LINE DEDENT def test_reboot_node ( self ) : NEW_LINE INDENT node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE ret = self . driver . reboot_node ( node ) NEW_LINE self . assertTrue ( ret ) NEW_LINE DEDENT def test_reboot_node_not_successful ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE try : NEW_LINE INDENT self . driver . reboot_node ( node ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Exception ▁ was ▁ not ▁ thrown ' ) NEW_LINE DEDENT DEDENT def test_destroy_node ( self ) : NEW_LINE INDENT node = Node ( 90967 , None , None , None , None , self . driver ) NEW_LINE ret = self . driver . destroy_node ( node ) NEW_LINE self . assertTrue ( ret ) NEW_LINE DEDENT def test_list_images ( self ) : NEW_LINE INDENT images = self . driver . list_images ( ) NEW_LINE image = images [ 0 ] NEW_LINE self . assertEqual ( len ( images ) , 4 ) NEW_LINE self . assertEqual ( image . name , ' CentOS ▁ 5.3 ▁ ( 32 - bit ) ▁ w / ▁ None ' ) NEW_LINE self . assertEqual ( image . id , '1531' ) NEW_LINE location = NodeLocation ( id = ' gogrid / GSI - 939ef909-84b8-4a2f - ad56-02ccd7da05ff . img ' , name = ' test ▁ location ' , country = ' Slovenia ' , driver = self . driver ) NEW_LINE images = self . driver . list_images ( location = location ) NEW_LINE image = images [ 0 ] NEW_LINE self . assertEqual ( len ( images ) , 4 ) NEW_LINE self . assertEqual ( image . name , ' CentOS ▁ 5.3 ▁ ( 32 - bit ) ▁ w / ▁ None ' ) NEW_LINE self . assertEqual ( image . id , '1531' ) NEW_LINE DEDENT def test_malformed_reply ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE try : NEW_LINE INDENT self . driver . list_images ( ) NEW_LINE DEDENT except LibcloudError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( isinstance ( e , LibcloudError ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_invalid_creds ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' FAIL ' NEW_LINE try : NEW_LINE INDENT self . driver . list_nodes ( ) NEW_LINE DEDENT except InvalidCredsError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( e . driver is not None ) NEW_LINE self . assertEqual ( e . driver . name , self . driver . name ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_node_creation_without_free_public_ips ( self ) : NEW_LINE INDENT GoGridMockHttp . type = ' NOPUBIPS ' NEW_LINE try : NEW_LINE INDENT image = NodeImage ( 1531 , None , self . driver ) NEW_LINE self . driver . create_node ( name = ' test1' , image = image , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE DEDENT except LibcloudError : NEW_LINE INDENT e = sys . exc_info ( ) [ 1 ] NEW_LINE self . assertTrue ( isinstance ( e , LibcloudError ) ) NEW_LINE self . assertTrue ( e . driver is not None ) NEW_LINE self . assertEqual ( e . driver . name , self . driver . name ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( " test ▁ should ▁ have ▁ thrown " ) NEW_LINE DEDENT DEDENT def test_list_locations ( self ) : NEW_LINE INDENT locations = self . driver . list_locations ( ) NEW_LINE location_names = [ location . name for location in locations ] NEW_LINE self . assertEqual ( len ( locations ) , 2 ) NEW_LINE for i in 0 , 1 : NEW_LINE INDENT self . assertTrue ( isinstance ( locations [ i ] , NodeLocation ) ) NEW_LINE DEDENT self . assertTrue ( " US - West - 1" in location_names ) NEW_LINE self . assertTrue ( " US - East - 1" in location_names ) NEW_LINE DEDENT def test_ex_save_image ( self ) : NEW_LINE INDENT node = self . driver . list_nodes ( ) [ 0 ] NEW_LINE image = self . driver . ex_save_image ( node , " testimage " ) NEW_LINE self . assertEqual ( image . name , " testimage " ) NEW_LINE DEDENT def test_ex_edit_image ( self ) : NEW_LINE INDENT image = self . driver . list_images ( ) [ 0 ] NEW_LINE ret = self . driver . ex_edit_image ( image = image , public = False , ex_description = " test " , name = " testname " ) NEW_LINE self . assertTrue ( isinstance ( ret , NodeImage ) ) NEW_LINE DEDENT def test_ex_edit_node ( self ) : NEW_LINE INDENT node = Node ( id = 90967 , name = None , state = None , public_ips = None , private_ips = None , driver = self . driver ) NEW_LINE ret = self . driver . ex_edit_node ( node = node , size = self . _get_test_512Mb_node_size ( ) ) NEW_LINE self . assertTrue ( isinstance ( ret , Node ) ) NEW_LINE DEDENT def test_ex_list_ips ( self ) : NEW_LINE INDENT ips = self . driver . ex_list_ips ( ) NEW_LINE expected_ips = { "192.168.75.66" : GoGridIpAddress ( id = "5348099" , ip = "192.168.75.66" , public = True , state = " Unassigned " , subnet = "192.168.75.64/255.255.255.240" ) , "192.168.75.67" : GoGridIpAddress ( id = "5348100" , ip = "192.168.75.67" , public = True , state = " Assigned " , subnet = "192.168.75.64/255.255.255.240" ) , "192.168.75.68" : GoGridIpAddress ( id = "5348101" , ip = "192.168.75.68" , public = False , state = " Unassigned " , subnet = "192.168.75.64/255.255.255.240" ) } NEW_LINE self . assertEqual ( len ( expected_ips ) , 3 ) NEW_LINE for ip in ips : NEW_LINE INDENT self . assertTrue ( ip . ip in expected_ips ) NEW_LINE self . assertEqual ( ip . public , expected_ips [ ip . ip ] . public ) NEW_LINE self . assertEqual ( ip . state , expected_ips [ ip . ip ] . state ) NEW_LINE self . assertEqual ( ip . subnet , expected_ips [ ip . ip ] . subnet ) NEW_LINE del expected_ips [ ip . ip ] NEW_LINE DEDENT self . assertEqual ( len ( expected_ips ) , 0 ) NEW_LINE DEDENT def test_get_state_invalid ( self ) : NEW_LINE INDENT state = self . driver . _get_state ( ' invalid ' ) NEW_LINE self . assertEqual ( state , NodeState . UNKNOWN ) NEW_LINE DEDENT DEDENT class GoGridMockHttp ( MockHttp ) : NEW_LINE INDENT fixtures = ComputeFileFixtures ( ' gogrid ' ) NEW_LINE def _api_grid_image_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' image _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_image_list_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT body = " < h3 > some ▁ non ▁ valid ▁ json ▁ here < / h3 > " NEW_LINE return ( httplib . SERVICE_UNAVAILABLE , body , { } , httplib . responses [ httplib . SERVICE_UNAVAILABLE ] ) NEW_LINE DEDENT def _api_grid_server_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_grid_server_list_NOPUBIPS = _api_grid_server_list NEW_LINE def _api_grid_server_list_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT return ( httplib . FORBIDDEN , "123" , { } , httplib . responses [ httplib . FORBIDDEN ] ) NEW_LINE DEDENT def _api_grid_ip_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' ip _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_ip_list_NOPUBIPS ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' ip _ list _ empty . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_power ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ power . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_power_FAIL ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ power _ fail . json ' ) NEW_LINE return ( httplib . NOT_FOUND , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_add ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ add . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_grid_server_add_NOPUBIPS = _api_grid_server_add NEW_LINE def _api_grid_server_delete ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ delete . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_server_edit ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' server _ edit . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_support_password_list ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' password _ list . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT _api_support_password_list_NOPUBIPS = _api_support_password_list NEW_LINE def _api_grid_image_save ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' image _ save . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_grid_image_edit ( self , method , url , body , headers ) : NEW_LINE INDENT body = self . fixtures . load ( ' image _ save . json ' ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT def _api_common_lookup_list ( self , method , url , body , headers ) : NEW_LINE INDENT _valid_lookups = ( " ip . datacenter " , ) NEW_LINE lookup = parse_qs ( urlparse . urlparse ( url ) . query ) [ " lookup " ] [ 0 ] NEW_LINE if lookup in _valid_lookups : NEW_LINE INDENT fixture_path = " lookup _ list _ % s . json " % \NEW_LINE ( lookup . replace ( " . " , " _ " ) ) NEW_LINE DEDENT else : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT body = self . fixtures . load ( fixture_path ) NEW_LINE return ( httplib . OK , body , { } , httplib . responses [ httplib . OK ] ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT sys . exit ( unittest . main ( ) ) NEW_LINE DEDENT
 import datetime NEW_LINE import gettext NEW_LINE import iso8601 NEW_LINE import netaddr NEW_LINE from oslo_utils import timeutils NEW_LINE from oslo_versionedobjects import fields NEW_LINE from magnum . common import context as magnum_context NEW_LINE from magnum . common import exception NEW_LINE from magnum . objects import base NEW_LINE from magnum . objects import utils NEW_LINE from magnum . tests import base as test_base NEW_LINE gettext . install ( ' magnum ' ) NEW_LINE @ base . MagnumObjectRegistry . register NEW_LINE class MyObj ( base . MagnumObject ) : NEW_LINE INDENT VERSION = '1.0' NEW_LINE fields = { ' foo ' : fields . IntegerField ( ) , ' bar ' : fields . StringField ( ) , ' missing ' : fields . StringField ( ) , } NEW_LINE def obj_load_attr ( self , attrname ) : NEW_LINE INDENT setattr ( self , attrname , ' loaded ! ' ) NEW_LINE DEDENT @ base . remotable_classmethod NEW_LINE def query ( cls , context ) : NEW_LINE INDENT obj = cls ( context ) NEW_LINE obj . foo = 1 NEW_LINE obj . bar = ' bar ' NEW_LINE obj . obj_reset_changes ( ) NEW_LINE return obj NEW_LINE DEDENT @ base . remotable NEW_LINE def marco ( self , context ) : NEW_LINE INDENT return ' polo ' NEW_LINE DEDENT @ base . remotable NEW_LINE def update_test ( self , context ) : NEW_LINE INDENT if context . project_id == ' alternate ' : NEW_LINE INDENT self . bar = ' alternate - context ' NEW_LINE DEDENT else : NEW_LINE INDENT self . bar = ' updated ' NEW_LINE DEDENT DEDENT @ base . remotable NEW_LINE def save ( self , context ) : NEW_LINE INDENT self . obj_reset_changes ( ) NEW_LINE DEDENT @ base . remotable NEW_LINE def refresh ( self , context ) : NEW_LINE INDENT self . foo = 321 NEW_LINE self . bar = ' refreshed ' NEW_LINE self . obj_reset_changes ( ) NEW_LINE DEDENT @ base . remotable NEW_LINE def modify_save_modify ( self , context ) : NEW_LINE INDENT self . bar = ' meow ' NEW_LINE self . save ( ) NEW_LINE self . foo = 42 NEW_LINE DEDENT DEDENT class MyObj2 ( object ) : NEW_LINE INDENT @ classmethod NEW_LINE def obj_name ( cls ) : NEW_LINE INDENT return ' MyObj ' NEW_LINE DEDENT @ base . remotable_classmethod NEW_LINE def get ( cls , * args , ** kwargs ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class TestSubclassedObject ( MyObj ) : NEW_LINE INDENT fields = { ' new _ field ' : fields . StringField ( ) } NEW_LINE DEDENT class TestUtils ( test_base . TestCase ) : NEW_LINE INDENT def test_datetime_or_none ( self ) : NEW_LINE INDENT naive_dt = datetime . datetime . now ( ) NEW_LINE dt = timeutils . parse_isotime ( timeutils . isotime ( naive_dt ) ) NEW_LINE self . assertEqual ( utils . datetime_or_none ( dt ) , dt ) NEW_LINE self . assertEqual ( utils . datetime_or_none ( dt ) , naive_dt . replace ( tzinfo = iso8601 . iso8601 . Utc ( ) , microsecond = 0 ) ) NEW_LINE self . assertIsNone ( utils . datetime_or_none ( None ) ) NEW_LINE self . assertRaises ( ValueError , utils . datetime_or_none , ' foo ' ) NEW_LINE DEDENT def test_datetime_or_str_or_none ( self ) : NEW_LINE INDENT dts = timeutils . isotime ( ) NEW_LINE dt = timeutils . parse_isotime ( dts ) NEW_LINE self . assertEqual ( utils . datetime_or_str_or_none ( dt ) , dt ) NEW_LINE self . assertIsNone ( utils . datetime_or_str_or_none ( None ) ) NEW_LINE self . assertEqual ( utils . datetime_or_str_or_none ( dts ) , dt ) NEW_LINE self . assertRaises ( ValueError , utils . datetime_or_str_or_none , ' foo ' ) NEW_LINE DEDENT def test_int_or_none ( self ) : NEW_LINE INDENT self . assertEqual ( utils . int_or_none ( 1 ) , 1 ) NEW_LINE self . assertEqual ( utils . int_or_none ( '1' ) , 1 ) NEW_LINE self . assertIsNone ( utils . int_or_none ( None ) ) NEW_LINE self . assertRaises ( ValueError , utils . int_or_none , ' foo ' ) NEW_LINE DEDENT def test_str_or_none ( self ) : NEW_LINE INDENT class Obj ( object ) : NEW_LINE INDENT pass NEW_LINE DEDENT self . assertEqual ( utils . str_or_none ( ' foo ' ) , ' foo ' ) NEW_LINE self . assertEqual ( utils . str_or_none ( 1 ) , '1' ) NEW_LINE self . assertIsNone ( utils . str_or_none ( None ) ) NEW_LINE DEDENT def test_ip_or_none ( self ) : NEW_LINE INDENT ip4 = netaddr . IPAddress ( '1.2.3.4' , 4 ) NEW_LINE ip6 = netaddr . IPAddress ( '1 : : 2' , 6 ) NEW_LINE self . assertEqual ( utils . ip_or_none ( 4 ) ( '1.2.3.4' ) , ip4 ) NEW_LINE self . assertEqual ( utils . ip_or_none ( 6 ) ( '1 : : 2' ) , ip6 ) NEW_LINE self . assertIsNone ( utils . ip_or_none ( 4 ) ( None ) ) NEW_LINE self . assertIsNone ( utils . ip_or_none ( 6 ) ( None ) ) NEW_LINE self . assertRaises ( netaddr . AddrFormatError , utils . ip_or_none ( 4 ) , ' foo ' ) NEW_LINE self . assertRaises ( netaddr . AddrFormatError , utils . ip_or_none ( 6 ) , ' foo ' ) NEW_LINE DEDENT def test_dt_serializer ( self ) : NEW_LINE INDENT class Obj ( object ) : NEW_LINE INDENT foo = utils . dt_serializer ( ' bar ' ) NEW_LINE DEDENT obj = Obj ( ) NEW_LINE obj . bar = timeutils . parse_isotime ( '1955-11-05T00:00:00Z ' ) NEW_LINE self . assertEqual ( '1955-11-05T00:00:00Z ' , obj . foo ( ) ) NEW_LINE obj . bar = None NEW_LINE self . assertIsNone ( obj . foo ( ) ) NEW_LINE obj . bar = ' foo ' NEW_LINE self . assertRaises ( AttributeError , obj . foo ) NEW_LINE DEDENT def test_dt_deserializer ( self ) : NEW_LINE INDENT dt = timeutils . parse_isotime ( '1955-11-05T00:00:00Z ' ) NEW_LINE self . assertEqual ( utils . dt_deserializer ( None , timeutils . isotime ( dt ) ) , dt ) NEW_LINE self . assertIsNone ( utils . dt_deserializer ( None , None ) ) NEW_LINE self . assertRaises ( ValueError , utils . dt_deserializer , None , ' foo ' ) NEW_LINE DEDENT DEDENT class _TestObject ( object ) : NEW_LINE INDENT def test_hydration_type_error ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : ' a ' } } NEW_LINE self . assertRaises ( ValueError , MyObj . obj_from_primitive , primitive ) NEW_LINE DEDENT def test_hydration ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE obj = MyObj . obj_from_primitive ( primitive ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE DEDENT def test_hydration_bad_ns ( self ) : NEW_LINE INDENT primitive = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' foo ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE self . assertRaises ( exception . UnsupportedObjectError , MyObj . obj_from_primitive , primitive ) NEW_LINE DEDENT def test_dehydration ( self ) : NEW_LINE INDENT expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.5' , ' magnum _ object . data ' : { ' foo ' : 1 } } NEW_LINE obj = MyObj ( self . context ) NEW_LINE obj . foo = 1 NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( expected , obj . obj_to_primitive ( ) ) NEW_LINE DEDENT def test_get_updates ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( { ' foo ' : 123 } , obj . obj_get_changes ( ) ) NEW_LINE obj . bar = ' test ' NEW_LINE self . assertEqual ( { ' foo ' : 123 , ' bar ' : ' test ' } , obj . obj_get_changes ( ) ) NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE DEDENT def test_object_property ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE DEDENT def test_object_property_type_error ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE def fail ( ) : NEW_LINE INDENT obj . foo = ' a ' NEW_LINE DEDENT self . assertRaises ( ValueError , fail ) NEW_LINE DEDENT def test_load ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( ' loaded ! ' , obj . bar ) NEW_LINE DEDENT def test_load_in_base ( self ) : NEW_LINE INDENT class Foo ( base . MagnumObject ) : NEW_LINE INDENT fields = { ' foobar ' : fields . IntegerField ( ) } NEW_LINE DEDENT obj = Foo ( self . context ) NEW_LINE raised = False NEW_LINE try : NEW_LINE INDENT obj . foobar NEW_LINE DEDENT except NotImplementedError as ex : NEW_LINE INDENT raised = True NEW_LINE DEDENT self . assertTrue ( raised ) NEW_LINE self . assertTrue ( ' foobar ' in str ( ex ) ) NEW_LINE DEDENT def test_loaded_in_primitive ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE obj . foo = 1 NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( ' loaded ! ' , obj . bar ) NEW_LINE expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.0' , ' magnum _ object . changes ' : [ ' bar ' ] , ' magnum _ object . data ' : { ' foo ' : 1 , ' bar ' : ' loaded ! ' } } NEW_LINE self . assertEqual ( expected , obj . obj_to_primitive ( ) ) NEW_LINE DEDENT def test_changes_in_primitive ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE primitive = obj . obj_to_primitive ( ) NEW_LINE self . assertTrue ( ' magnum _ object . changes ' in primitive ) NEW_LINE obj2 = MyObj . obj_from_primitive ( primitive ) NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj2 . obj_what_changed ( ) ) NEW_LINE obj2 . obj_reset_changes ( ) NEW_LINE self . assertEqual ( set ( ) , obj2 . obj_what_changed ( ) ) NEW_LINE DEDENT def test_unknown_objtype ( self ) : NEW_LINE INDENT self . assertRaises ( exception . UnsupportedObjectError , base . MagnumObject . obj_class_from_name , ' foo ' , '1.0' ) NEW_LINE DEDENT def test_with_alternate_context ( self ) : NEW_LINE INDENT context1 = magnum_context . RequestContext ( ' foo ' , ' foo ' ) NEW_LINE context2 = magnum_context . RequestContext ( ' bar ' , project_id = ' alternate ' ) NEW_LINE obj = MyObj . query ( context1 ) NEW_LINE obj . update_test ( context2 ) NEW_LINE self . assertEqual ( ' alternate - context ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_orphaned_object ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . _context = None NEW_LINE self . assertRaises ( exception . OrphanedObjectError , obj . update_test ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_1 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . update_test ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' foo ' , ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_2 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . save ( ) NEW_LINE self . assertEqual ( set ( [ ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_3 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . refresh ( ) NEW_LINE self . assertEqual ( set ( [ ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 321 , obj . foo ) NEW_LINE self . assertEqual ( ' refreshed ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_changed_4 ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE obj . bar = ' something ' NEW_LINE self . assertEqual ( set ( [ ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE obj . modify_save_modify ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' foo ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE self . assertEqual ( 42 , obj . foo ) NEW_LINE self . assertEqual ( ' meow ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_static_result ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE self . assertEqual ( ' bar ' , obj . bar ) NEW_LINE result = obj . marco ( ) NEW_LINE self . assertEqual ( ' polo ' , result ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_updates ( self ) : NEW_LINE INDENT obj = MyObj . query ( self . context ) NEW_LINE self . assertEqual ( 1 , obj . foo ) NEW_LINE obj . update_test ( ) NEW_LINE self . assertEqual ( ' updated ' , obj . bar ) NEW_LINE self . assertRemotes ( ) NEW_LINE DEDENT def test_base_attributes ( self ) : NEW_LINE INDENT dt = datetime . datetime ( 1955 , 11 , 5 ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE obj . created_at = dt NEW_LINE obj . updated_at = dt NEW_LINE expected = { ' magnum _ object . name ' : ' MyObj ' , ' magnum _ object . namespace ' : ' magnum ' , ' magnum _ object . version ' : '1.0' , ' magnum _ object . changes ' : [ ' created _ at ' , ' updated _ at ' ] , ' magnum _ object . data ' : { ' created _ at ' : timeutils . isotime ( dt ) , ' updated _ at ' : timeutils . isotime ( dt ) } } NEW_LINE actual = obj . obj_to_primitive ( ) NEW_LINE self . assertEqual ( sorted ( expected [ ' magnum _ object . changes ' ] ) , sorted ( actual [ ' magnum _ object . changes ' ] ) ) NEW_LINE del expected [ ' magnum _ object . changes ' ] , actual [ ' magnum _ object . changes ' ] NEW_LINE self . assertEqual ( expected , actual ) NEW_LINE DEDENT def test_contains ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertFalse ( ' foo ' in obj ) NEW_LINE obj . foo = 1 NEW_LINE self . assertTrue ( ' foo ' in obj ) NEW_LINE self . assertFalse ( ' does _ not _ exist ' in obj ) NEW_LINE DEDENT def test_obj_attr_is_set ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertTrue ( obj . obj_attr_is_set ( ' foo ' ) ) NEW_LINE self . assertFalse ( obj . obj_attr_is_set ( ' bar ' ) ) NEW_LINE self . assertRaises ( AttributeError , obj . obj_attr_is_set , ' bang ' ) NEW_LINE DEDENT def test_get ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 1 ) NEW_LINE self . assertEqual ( obj . get ( ' foo ' , 2 ) , 1 ) NEW_LINE self . assertEqual ( obj . get ( ' foo ' ) , 1 ) NEW_LINE self . assertEqual ( obj . get ( ' bar ' , ' not - loaded ' ) , ' not - loaded ' ) NEW_LINE self . assertEqual ( obj . get ( ' bar ' ) , ' loaded ! ' ) NEW_LINE self . assertEqual ( obj . get ( ' bar ' , ' not - loaded ' ) , ' loaded ! ' ) NEW_LINE self . assertRaises ( AttributeError , obj . get , ' nothing ' ) NEW_LINE self . assertRaises ( AttributeError , obj . get , ' nothing ' , 3 ) NEW_LINE DEDENT def test_object_inheritance ( self ) : NEW_LINE INDENT base_fields = list ( base . MagnumObject . fields . keys ( ) ) NEW_LINE myobj_fields = [ ' foo ' , ' bar ' , ' missing ' ] + base_fields NEW_LINE myobj3_fields = [ ' new _ field ' ] NEW_LINE self . assertTrue ( issubclass ( TestSubclassedObject , MyObj ) ) NEW_LINE self . assertEqual ( len ( myobj_fields ) , len ( MyObj . fields ) ) NEW_LINE self . assertEqual ( set ( myobj_fields ) , set ( MyObj . fields . keys ( ) ) ) NEW_LINE self . assertEqual ( len ( myobj_fields ) + len ( myobj3_fields ) , len ( TestSubclassedObject . fields ) ) NEW_LINE self . assertEqual ( set ( myobj_fields ) | set ( myobj3_fields ) , set ( TestSubclassedObject . fields . keys ( ) ) ) NEW_LINE DEDENT def test_get_changes ( self ) : NEW_LINE INDENT obj = MyObj ( self . context ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE obj . foo = 123 NEW_LINE self . assertEqual ( { ' foo ' : 123 } , obj . obj_get_changes ( ) ) NEW_LINE obj . bar = ' test ' NEW_LINE self . assertEqual ( { ' foo ' : 123 , ' bar ' : ' test ' } , obj . obj_get_changes ( ) ) NEW_LINE obj . obj_reset_changes ( ) NEW_LINE self . assertEqual ( { } , obj . obj_get_changes ( ) ) NEW_LINE DEDENT def test_obj_fields ( self ) : NEW_LINE INDENT class TestObj ( base . MagnumObject ) : NEW_LINE INDENT fields = { ' foo ' : fields . IntegerField ( ) } NEW_LINE obj_extra_fields = [ ' bar ' ] NEW_LINE @ property NEW_LINE def bar ( self ) : NEW_LINE INDENT return ' this ▁ is ▁ bar ' NEW_LINE DEDENT DEDENT obj = TestObj ( self . context ) NEW_LINE self . assertEqual ( set ( [ ' created _ at ' , ' updated _ at ' , ' foo ' , ' bar ' ] ) , set ( obj . obj_fields ) ) NEW_LINE DEDENT def test_obj_constructor ( self ) : NEW_LINE INDENT obj = MyObj ( self . context , foo = 123 , bar = ' abc ' ) NEW_LINE self . assertEqual ( 123 , obj . foo ) NEW_LINE self . assertEqual ( ' abc ' , obj . bar ) NEW_LINE self . assertEqual ( set ( [ ' foo ' , ' bar ' ] ) , obj . obj_what_changed ( ) ) NEW_LINE DEDENT DEDENT class TestObjectSerializer ( test_base . TestCase ) : NEW_LINE INDENT def test_object_serialization ( self ) : NEW_LINE INDENT ser = base . MagnumObjectSerializer ( ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE primitive = ser . serialize_entity ( self . context , obj ) NEW_LINE self . assertTrue ( ' magnum _ object . name ' in primitive ) NEW_LINE obj2 = ser . deserialize_entity ( self . context , primitive ) NEW_LINE self . assertIsInstance ( obj2 , MyObj ) NEW_LINE self . assertEqual ( self . context , obj2 . _context ) NEW_LINE DEDENT def test_object_serialization_iterables ( self ) : NEW_LINE INDENT ser = base . MagnumObjectSerializer ( ) NEW_LINE obj = MyObj ( self . context ) NEW_LINE for iterable in ( list , tuple , set ) : NEW_LINE INDENT thing = iterable ( [ obj ] ) NEW_LINE primitive = ser . serialize_entity ( self . context , thing ) NEW_LINE self . assertEqual ( 1 , len ( primitive ) ) NEW_LINE for item in primitive : NEW_LINE INDENT self . assertFalse ( isinstance ( item , base . MagnumObject ) ) NEW_LINE DEDENT thing2 = ser . deserialize_entity ( self . context , primitive ) NEW_LINE self . assertEqual ( 1 , len ( thing2 ) ) NEW_LINE for item in thing2 : NEW_LINE INDENT self . assertIsInstance ( item , MyObj ) NEW_LINE DEDENT DEDENT DEDENT DEDENT
 import zlib NEW_LINE import posixpath NEW_LINE try : NEW_LINE INDENT from io import BytesIO NEW_LINE DEDENT except ImportError : NEW_LINE INDENT from cStringIO import StringIO as BytesIO NEW_LINE DEDENT from docutils import nodes NEW_LINE from sphinx import addnodes NEW_LINE from sphinx . ext . intersphinx import read_inventory_v1 , read_inventory_v2 , \NEW_LINE load_mappings , missing_reference NEW_LINE from util import with_app , with_tempdir , write_file NEW_LINE inventory_v1 = ''' \ STRNEWLINE # ▁ Sphinx ▁ inventory ▁ version ▁ 1 STRNEWLINE # ▁ Project : ▁ foo STRNEWLINE # ▁ Version : ▁ 1.0 STRNEWLINE module ▁ mod ▁ foo . html STRNEWLINE module . cls ▁ class ▁ foo . html STRNEWLINE ''' . encode ( ' utf - 8' ) NEW_LINE inventory_v2 = ''' \ STRNEWLINE # ▁ Sphinx ▁ inventory ▁ version ▁ 2 STRNEWLINE # ▁ Project : ▁ foo STRNEWLINE # ▁ Version : ▁ 2.0 STRNEWLINE # ▁ The ▁ remainder ▁ of ▁ this ▁ file ▁ is ▁ compressed ▁ with ▁ zlib . STRNEWLINE ''' . encode ( ' utf - 8' ) + zlib . compress ( ''' \ STRNEWLINE module1 ▁ py : module ▁ 0 ▁ foo . html # module - module1 ▁ Long ▁ Module ▁ desc STRNEWLINE module2 ▁ py : module ▁ 0 ▁ foo . html # module - $ ▁ - STRNEWLINE module1 . func ▁ py : function ▁ 1 ▁ sub / foo . html # $ ▁ - STRNEWLINE CFunc ▁ c : function ▁ 2 ▁ cfunc . html # CFunc ▁ - STRNEWLINE a ▁ term ▁ std : term ▁ - 1 ▁ glossary . html # term - a - term ▁ - STRNEWLINE ''' . encode ( ' utf - 8' ) ) NEW_LINE def test_read_inventory_v1 ( ) : NEW_LINE INDENT f = BytesIO ( inventory_v1 ) NEW_LINE f . readline ( ) NEW_LINE invdata = read_inventory_v1 ( f , ' / util ' , posixpath . join ) NEW_LINE assert invdata [ ' py : module ' ] [ ' module ' ] == \NEW_LINE ( ' foo ' , '1.0' , ' / util / foo . html # module - module ' , ' - ' ) NEW_LINE assert invdata [ ' py : class ' ] [ ' module . cls ' ] == \NEW_LINE ( ' foo ' , '1.0' , ' / util / foo . html # module . cls ' , ' - ' ) NEW_LINE DEDENT def test_read_inventory_v2 ( ) : NEW_LINE INDENT f = BytesIO ( inventory_v2 ) NEW_LINE f . readline ( ) NEW_LINE invdata1 = read_inventory_v2 ( f , ' / util ' , posixpath . join ) NEW_LINE f = BytesIO ( inventory_v2 ) NEW_LINE f . readline ( ) NEW_LINE invdata2 = read_inventory_v2 ( f , ' / util ' , posixpath . join , bufsize = 5 ) NEW_LINE assert invdata1 == invdata2 NEW_LINE assert len ( invdata1 [ ' py : module ' ] ) == 2 NEW_LINE assert invdata1 [ ' py : module ' ] [ ' module1' ] == \NEW_LINE ( ' foo ' , '2.0' , ' / util / foo . html # module - module1' , ' Long ▁ Module ▁ desc ' ) NEW_LINE assert invdata1 [ ' py : module ' ] [ ' module2' ] == \NEW_LINE ( ' foo ' , '2.0' , ' / util / foo . html # module - module2' , ' - ' ) NEW_LINE assert invdata1 [ ' py : function ' ] [ ' module1 . func ' ] [ 2 ] == ' / util / sub / foo . html # module1 . func ' NEW_LINE assert invdata1 [ ' c : function ' ] [ ' CFunc ' ] [ 2 ] == ' / util / cfunc . html # CFunc ' NEW_LINE assert invdata1 [ ' std : term ' ] [ ' a ▁ term ' ] [ 2 ] == ' / util / glossary . html # term - a - term ' NEW_LINE DEDENT @ with_app ( confoverrides = { ' extensions ' : ' sphinx . ext . intersphinx ' } ) NEW_LINE @ with_tempdir NEW_LINE def test_missing_reference ( tempdir , app ) : NEW_LINE INDENT inv_file = tempdir / ' inventory ' NEW_LINE write_file ( inv_file , inventory_v2 ) NEW_LINE app . config . intersphinx_mapping = { ' http : / / docs . python . org / ' : inv_file , ' py3k ' : ( ' http : / / docs . python . org / py3k / ' , inv_file ) , } NEW_LINE app . config . intersphinx_cache_limit = 0 NEW_LINE load_mappings ( app ) NEW_LINE inv = app . env . intersphinx_inventory NEW_LINE assert inv [ ' py : module ' ] [ ' module2' ] == \NEW_LINE ( ' foo ' , '2.0' , ' http : / / docs . python . org / foo . html # module - module2' , ' - ' ) NEW_LINE def fake_node ( domain , type , target , content , ** attrs ) : NEW_LINE INDENT contnode = nodes . emphasis ( content , content ) NEW_LINE node = addnodes . pending_xref ( ' ' ) NEW_LINE node [ ' reftarget ' ] = target NEW_LINE node [ ' reftype ' ] = type NEW_LINE node [ ' refdomain ' ] = domain NEW_LINE node . attributes . update ( attrs ) NEW_LINE node += contnode NEW_LINE return node , contnode NEW_LINE DEDENT def reference_check ( * args , ** kwds ) : NEW_LINE INDENT node , contnode = fake_node ( * args , ** kwds ) NEW_LINE return missing_reference ( app , app . env , node , contnode ) NEW_LINE DEDENT rn = reference_check ( ' py ' , ' func ' , ' module1 . func ' , ' foo ' ) NEW_LINE assert isinstance ( rn , nodes . reference ) NEW_LINE assert rn [ ' refuri ' ] == ' http : / / docs . python . org / sub / foo . html # module1 . func ' NEW_LINE assert rn [ ' reftitle ' ] == ' ( in ▁ foo ▁ v2.0 ) ' NEW_LINE assert rn [ 0 ] . astext ( ) == ' foo ' NEW_LINE assert reference_check ( ' py ' , ' foo ' , ' module1 . func ' , ' foo ' ) is None NEW_LINE assert reference_check ( ' py ' , ' func ' , ' foo ' , ' foo ' ) is None NEW_LINE assert reference_check ( ' py ' , ' func ' , ' foo ' , ' foo ' ) is None NEW_LINE rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' py3k : module2' ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' module2' NEW_LINE rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' module2' ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' module2' NEW_LINE rn = reference_check ( ' py ' , ' mod ' , ' py3k : module2' , ' py3k : module2' , refexplicit = True ) NEW_LINE assert rn [ 0 ] . astext ( ) == ' py3k : module2' NEW_LINE node , contnode = fake_node ( ' py ' , ' mod ' , ' py3k : unknown ' , ' py3k : unknown ' , refexplicit = False ) NEW_LINE rn = missing_reference ( app , app . env , node , contnode ) NEW_LINE assert rn is None NEW_LINE assert contnode [ 0 ] . astext ( ) == ' unknown ' NEW_LINE node , contnode = fake_node ( ' py ' , ' mod ' , ' py3k : unknown ' , ' py3k : unknown ' , refexplicit = True ) NEW_LINE rn = missing_reference ( app , app . env , node , contnode ) NEW_LINE assert rn is None NEW_LINE assert contnode [ 0 ] . astext ( ) == ' py3k : unknown ' NEW_LINE DEDENT @ with_app ( confoverrides = { ' extensions ' : ' sphinx . ext . intersphinx ' } ) NEW_LINE @ with_tempdir NEW_LINE def test_load_mappings_warnings ( tempdir , app ) : NEW_LINE INDENT inv_file = tempdir / ' inventory ' NEW_LINE write_file ( inv_file , inventory_v2 ) NEW_LINE app . config . intersphinx_mapping = { ' http : / / docs . python . org / ' : inv_file , ' py3k ' : ( ' http : / / docs . python . org / py3k / ' , inv_file ) , ' repoze . workflow ' : ( ' http : / / docs . repoze . org / workflow / ' , inv_file ) , ' django - taggit ' : ( ' http : / / django - taggit . readthedocs . org / en / latest / ' , inv_file ) } NEW_LINE app . config . intersphinx_cache_limit = 0 NEW_LINE load_mappings ( app ) NEW_LINE assert len ( app . _warning . content ) == 2 NEW_LINE DEDENT
 from __future__ import ( absolute_import , division , print_function ) NEW_LINE __metaclass__ = type NEW_LINE import os NEW_LINE import json NEW_LINE import sys NEW_LINE from nose . plugins . skip import SkipTest NEW_LINE if sys . version_info < ( 2 , 7 ) : NEW_LINE INDENT raise SkipTest ( " F5 ▁ Ansible ▁ modules ▁ require ▁ Python ▁ > = ▁ 2.7" ) NEW_LINE DEDENT from ansible . compat . tests import unittest NEW_LINE from ansible . compat . tests . mock import patch , Mock NEW_LINE from ansible . module_utils import basic NEW_LINE from ansible . module_utils . _text import to_bytes NEW_LINE from ansible . module_utils . f5_utils import AnsibleF5Client NEW_LINE try : NEW_LINE INDENT from library . bigip_iapp_service import Parameters NEW_LINE from library . bigip_iapp_service import ModuleManager NEW_LINE from library . bigip_iapp_service import ArgumentSpec NEW_LINE DEDENT except ImportError : NEW_LINE INDENT try : NEW_LINE INDENT from ansible . modules . network . f5 . bigip_iapp_service import Parameters NEW_LINE from ansible . modules . network . f5 . bigip_iapp_service import ModuleManager NEW_LINE from ansible . modules . network . f5 . bigip_iapp_service import ArgumentSpec NEW_LINE DEDENT except ImportError : NEW_LINE INDENT raise SkipTest ( " F5 ▁ Ansible ▁ modules ▁ require ▁ the ▁ f5 - sdk ▁ Python ▁ library " ) NEW_LINE DEDENT DEDENT fixture_path = os . path . join ( os . path . dirname ( __file__ ) , ' fixtures ' ) NEW_LINE fixture_data = { } NEW_LINE def set_module_args ( args ) : NEW_LINE INDENT args = json . dumps ( { ' ANSIBLE _ MODULE _ ARGS ' : args } ) NEW_LINE basic . _ANSIBLE_ARGS = to_bytes ( args ) NEW_LINE DEDENT def load_fixture ( name ) : NEW_LINE INDENT path = os . path . join ( fixture_path , name ) NEW_LINE if path in fixture_data : NEW_LINE INDENT return fixture_data [ path ] NEW_LINE DEDENT with open ( path ) as f : NEW_LINE INDENT data = f . read ( ) NEW_LINE DEDENT try : NEW_LINE INDENT data = json . loads ( data ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT fixture_data [ path ] = data NEW_LINE return data NEW_LINE DEDENT class TestParameters ( unittest . TestCase ) : NEW_LINE INDENT def test_module_parameters_keys ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . name == ' http _ example ' NEW_LINE assert p . partition == ' Common ' NEW_LINE assert p . template == ' / Common / f5 . http ' NEW_LINE DEDENT def test_module_parameters_lists ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' lists ' in p . _values NEW_LINE assert p . lists [ 0 ] [ ' name ' ] == ' irules _ _ irules ' NEW_LINE assert p . lists [ 0 ] [ ' encrypted ' ] == ' no ' NEW_LINE assert len ( p . lists [ 0 ] [ ' value ' ] ) == 1 NEW_LINE assert p . lists [ 0 ] [ ' value ' ] [ 0 ] == ' / Common / lgyft ' NEW_LINE assert p . lists [ 1 ] [ ' name ' ] == ' net _ _ client _ vlan ' NEW_LINE assert p . lists [ 1 ] [ ' encrypted ' ] == ' no ' NEW_LINE assert len ( p . lists [ 1 ] [ ' value ' ] ) == 1 NEW_LINE assert p . lists [ 1 ] [ ' value ' ] [ 0 ] == ' / Common / net2' NEW_LINE DEDENT def test_module_parameters_tables ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' tables ' in p . _values NEW_LINE assert ' columnNames ' in p . tables [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' columnNames ' ] ) == 1 NEW_LINE assert p . tables [ 0 ] [ ' columnNames ' ] [ 0 ] == ' name ' NEW_LINE assert ' name ' in p . tables [ 0 ] NEW_LINE assert p . tables [ 0 ] [ ' name ' ] == ' pool _ _ hosts ' NEW_LINE assert ' rows ' in p . tables [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] ) == 1 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] ) == 1 NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 0 ] == ' demo . example . com ' NEW_LINE assert len ( p . tables [ 1 ] [ ' rows ' ] ) == 2 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert len ( p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] ) == 2 NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 0 ] == '10.1.1.1' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 0 ] [ ' row ' ] [ 1 ] == '0' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 1 ] [ ' row ' ] [ 0 ] == '10.1.1.2' NEW_LINE assert p . tables [ 1 ] [ ' rows ' ] [ 1 ] [ ' row ' ] [ 1 ] == '0' NEW_LINE DEDENT def test_module_parameters_variables ( self ) : NEW_LINE INDENT args = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert ' variables ' in p . _values NEW_LINE assert len ( p . variables ) == 34 NEW_LINE assert ' name ' in p . variables [ 0 ] NEW_LINE assert ' value ' in p . variables [ 0 ] NEW_LINE assert p . variables [ 0 ] [ ' name ' ] == ' afm _ _ dos _ security _ profile ' NEW_LINE assert p . variables [ 0 ] [ ' value ' ] == ' / # do _ not _ use # ' NEW_LINE assert ' name ' in p . variables [ 1 ] NEW_LINE assert ' value ' in p . variables [ 1 ] NEW_LINE assert p . variables [ 1 ] [ ' name ' ] == ' afm _ _ policy ' NEW_LINE assert p . variables [ 1 ] [ ' value ' ] == ' / # do _ not _ use # ' NEW_LINE DEDENT def test_api_parameters_variables ( self ) : NEW_LINE INDENT args = dict ( variables = [ dict ( name = " client _ _ http _ compression " , encrypted = " no " , value = " / # create _ new # " ) ] ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . variables [ 0 ] [ ' name ' ] == ' client _ _ http _ compression ' NEW_LINE DEDENT def test_api_parameters_tables ( self ) : NEW_LINE INDENT args = dict ( tables = [ { " name " : " pool _ _ members " , " columnNames " : [ " addr " , " port " , " connection _ limit " ] , " rows " : [ { " row " : [ "12.12.12.12" , "80" , "0" ] } , { " row " : [ "13.13.13.13" , "443" , 10 ] } ] } ] ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . tables [ 0 ] [ ' name ' ] == ' pool _ _ members ' NEW_LINE assert p . tables [ 0 ] [ ' columnNames ' ] == [ ' addr ' , ' port ' , ' connection _ limit ' ] NEW_LINE assert len ( p . tables [ 0 ] [ ' rows ' ] ) == 2 NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 0 ] NEW_LINE assert ' row ' in p . tables [ 0 ] [ ' rows ' ] [ 1 ] NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 0 ] [ ' row ' ] == [ '12.12.12.12' , '80' , '0' ] NEW_LINE assert p . tables [ 0 ] [ ' rows ' ] [ 1 ] [ ' row ' ] == [ '13.13.13.13' , '443' , '10' ] NEW_LINE DEDENT def test_module_template_same_partition ( self ) : NEW_LINE INDENT args = dict ( template = ' foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / bar / foo ' NEW_LINE DEDENT def test_module_template_same_partition_full_path ( self ) : NEW_LINE INDENT args = dict ( template = ' / bar / foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / bar / foo ' NEW_LINE DEDENT def test_module_template_different_partition_full_path ( self ) : NEW_LINE INDENT args = dict ( template = ' / Common / foo ' , partition = ' bar ' ) NEW_LINE p = Parameters ( args ) NEW_LINE assert p . template == ' / Common / foo ' NEW_LINE DEDENT DEDENT @ patch ( ' ansible . module _ utils . f5 _ utils . AnsibleF5Client . _ get _ mgmt _ root ' , return_value = True ) NEW_LINE class TestManager ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . spec = ArgumentSpec ( ) NEW_LINE DEDENT def test_create_service ( self , * args ) : NEW_LINE INDENT parameters = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE set_module_args ( dict ( name = ' foo ' , template = ' f5 . http ' , parameters = parameters , state = ' present ' , password = ' passsword ' , server = ' localhost ' , user = ' admin ' ) ) NEW_LINE client = AnsibleF5Client ( argument_spec = self . spec . argument_spec , supports_check_mode = self . spec . supports_check_mode , f5_product_name = self . spec . f5_product_name ) NEW_LINE mm = ModuleManager ( client ) NEW_LINE mm . exists = Mock ( return_value = False ) NEW_LINE mm . create_on_device = Mock ( return_value = True ) NEW_LINE results = mm . exec_module ( ) NEW_LINE assert results [ ' changed ' ] is True NEW_LINE DEDENT def test_update_agent_status_traps ( self , * args ) : NEW_LINE INDENT parameters = load_fixture ( ' update _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE set_module_args ( dict ( name = ' foo ' , template = ' f5 . http ' , parameters = parameters , state = ' present ' , password = ' passsword ' , server = ' localhost ' , user = ' admin ' ) ) NEW_LINE parameters = load_fixture ( ' create _ iapp _ service _ parameters _ f5 _ http . json ' ) NEW_LINE current = Parameters ( parameters ) NEW_LINE client = AnsibleF5Client ( argument_spec = self . spec . argument_spec , supports_check_mode = self . spec . supports_check_mode , f5_product_name = self . spec . f5_product_name ) NEW_LINE mm = ModuleManager ( client ) NEW_LINE mm . exists = Mock ( return_value = True ) NEW_LINE mm . update_on_device = Mock ( return_value = True ) NEW_LINE mm . read_current_from_device = Mock ( return_value = current ) NEW_LINE results = mm . exec_module ( ) NEW_LINE assert results [ ' changed ' ] is True NEW_LINE DEDENT DEDENT
 import os NEW_LINE import sys NEW_LINE from core import config NEW_LINE from core import logger NEW_LINE import threading NEW_LINE controllers = { } NEW_LINE def dialog_ok ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_ok ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_notification ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_notification ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_yesno ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_yesno ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_select ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_select ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_progress ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_progress ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_progress_bg ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_progress_bg ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_input ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_input ( * args , ** kwargs ) NEW_LINE DEDENT def dialog_numeric ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . dialog_numeric ( * args , ** kwargs ) NEW_LINE DEDENT def itemlist_refresh ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . itemlist_refresh ( * args , ** kwargs ) NEW_LINE DEDENT def itemlist_update ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . itemlist_update ( * args , ** kwargs ) NEW_LINE DEDENT def render_items ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . render_items ( * args , ** kwargs ) NEW_LINE DEDENT def is_playing ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . is_playing ( * args , ** kwargs ) NEW_LINE DEDENT def play_video ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . play_video ( * args , ** kwargs ) NEW_LINE DEDENT def open_settings ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . open_settings ( * args , ** kwargs ) NEW_LINE DEDENT def show_channel_settings ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_channel_settings ( * args , ** kwargs ) NEW_LINE DEDENT def show_video_info ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_video_info ( * args , ** kwargs ) NEW_LINE DEDENT def show_recaptcha ( * args , ** kwargs ) : NEW_LINE INDENT id = threading . current_thread ( ) . name NEW_LINE return controllers [ id ] . show_recaptcha ( * args , ** kwargs ) NEW_LINE DEDENT
 import os NEW_LINE import sys NEW_LINE import scipy as sp NEW_LINE from sklearn . feature_extraction . text import CountVectorizer NEW_LINE DIR = r" . . / data / toy " NEW_LINE posts = [ open ( os . path . join ( DIR , f ) ) . read ( ) for f in os . listdir ( DIR ) ] NEW_LINE new_post = " imaging ▁ databases " NEW_LINE import nltk . stem NEW_LINE english_stemmer = nltk . stem . SnowballStemmer ( ' english ' ) NEW_LINE class StemmedCountVectorizer ( CountVectorizer ) : NEW_LINE INDENT def build_analyzer ( self ) : NEW_LINE INDENT analyzer = super ( StemmedCountVectorizer , self ) . build_analyzer ( ) NEW_LINE return lambda doc : ( english_stemmer . stem ( w ) for w in analyzer ( doc ) ) NEW_LINE DEDENT DEDENT vectorizer = StemmedCountVectorizer ( min_df = 1 , stop_words = ' english ' ) NEW_LINE from sklearn . feature_extraction . text import TfidfVectorizer NEW_LINE class StemmedTfidfVectorizer ( TfidfVectorizer ) : NEW_LINE INDENT def build_analyzer ( self ) : NEW_LINE INDENT analyzer = super ( StemmedTfidfVectorizer , self ) . build_analyzer ( ) NEW_LINE return lambda doc : ( english_stemmer . stem ( w ) for w in analyzer ( doc ) ) NEW_LINE DEDENT DEDENT vectorizer = StemmedTfidfVectorizer ( min_df = 1 , stop_words = ' english ' , charset_error = ' ignore ' ) NEW_LINE print ( vectorizer ) NEW_LINE X_train = vectorizer . fit_transform ( posts ) NEW_LINE num_samples , num_features = X_train . shape NEW_LINE print ( " # samples : ▁ % d , ▁ # features : ▁ % d " % ( num_samples , num_features ) ) NEW_LINE new_post_vec = vectorizer . transform ( [ new_post ] ) NEW_LINE print ( new_post_vec , type ( new_post_vec ) ) NEW_LINE print ( new_post_vec . toarray ( ) ) NEW_LINE print ( vectorizer . get_feature_names ( ) ) NEW_LINE def dist_raw ( v1 , v2 ) : NEW_LINE INDENT delta = v1 - v2 NEW_LINE return sp . linalg . norm ( delta . toarray ( ) ) NEW_LINE DEDENT def dist_norm ( v1 , v2 ) : NEW_LINE INDENT v1_normalized = v1 / sp . linalg . norm ( v1 . toarray ( ) ) NEW_LINE v2_normalized = v2 / sp . linalg . norm ( v2 . toarray ( ) ) NEW_LINE delta = v1_normalized - v2_normalized NEW_LINE return sp . linalg . norm ( delta . toarray ( ) ) NEW_LINE DEDENT dist = dist_norm NEW_LINE best_dist = sys . maxsize NEW_LINE best_i = None NEW_LINE for i in range ( 0 , num_samples ) : NEW_LINE INDENT post = posts [ i ] NEW_LINE if post == new_post : NEW_LINE INDENT continue NEW_LINE DEDENT post_vec = X_train . getrow ( i ) NEW_LINE d = dist ( post_vec , new_post_vec ) NEW_LINE print ( " = = = ▁ Post ▁ % i ▁ with ▁ dist = % .2f : ▁ % s " % ( i , d , post ) ) NEW_LINE if d < best_dist : NEW_LINE INDENT best_dist = d NEW_LINE best_i = i NEW_LINE DEDENT DEDENT print ( " Best ▁ post ▁ is ▁ % i ▁ with ▁ dist = % .2f " % ( best_i , best_dist ) ) NEW_LINE
 from __future__ import ( absolute_import , division , print_function ) NEW_LINE __metaclass__ = type NEW_LINE import io NEW_LINE import yaml NEW_LINE try : NEW_LINE INDENT from _yaml import ParserError NEW_LINE DEDENT except ImportError : NEW_LINE INDENT from yaml . parser import ParserError NEW_LINE DEDENT from ansible . parsing . yaml import dumper NEW_LINE from ansible . parsing . yaml . loader import AnsibleLoader NEW_LINE from ansible . compat . tests import unittest NEW_LINE from ansible . parsing . yaml import objects NEW_LINE from ansible . parsing import vault NEW_LINE from units . mock . yaml_helper import YamlTestUtils NEW_LINE class TestAnsibleDumper ( unittest . TestCase , YamlTestUtils ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . vault_password = " hunter42" NEW_LINE self . good_vault = vault . VaultLib ( self . vault_password ) NEW_LINE self . vault = self . good_vault NEW_LINE self . stream = self . _build_stream ( ) NEW_LINE self . dumper = dumper . AnsibleDumper NEW_LINE DEDENT def _build_stream ( self , yaml_text = None ) : NEW_LINE INDENT text = yaml_text or u' ' NEW_LINE stream = io . StringIO ( text ) NEW_LINE return stream NEW_LINE DEDENT def _loader ( self , stream ) : NEW_LINE INDENT return AnsibleLoader ( stream , vault_password = self . vault_password ) NEW_LINE DEDENT def test ( self ) : NEW_LINE INDENT plaintext = ' This ▁ is ▁ a ▁ string ▁ we ▁ are ▁ going ▁ to ▁ encrypt . ' NEW_LINE avu = objects . AnsibleVaultEncryptedUnicode . from_plaintext ( plaintext , vault = self . vault ) NEW_LINE yaml_out = self . _dump_string ( avu , dumper = self . dumper ) NEW_LINE stream = self . _build_stream ( yaml_out ) NEW_LINE loader = self . _loader ( stream ) NEW_LINE data_from_yaml = loader . get_single_data ( ) NEW_LINE self . assertEquals ( plaintext , data_from_yaml . data ) NEW_LINE DEDENT DEDENT
 import pytest NEW_LINE import os NEW_LINE from betfair import betfair NEW_LINE from tests . utils import response_fixture_factory NEW_LINE @ pytest . fixture NEW_LINE def client ( ) : NEW_LINE INDENT return betfair . Betfair ( app_key = ' test ' , cert_file = ' path / to / cert ' ) NEW_LINE DEDENT @ pytest . fixture NEW_LINE def logged_in_client ( client ) : NEW_LINE INDENT client = betfair . Betfair ( app_key = ' test ' , cert_file = ' path / to / cert ' ) NEW_LINE client . session_token = ' secret ' NEW_LINE return client NEW_LINE DEDENT login_success = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' certlogin ' ) , { ' loginStatus ' : ' SUCCESS ' , ' sessionToken ' : ' secret ' , } , ) NEW_LINE login_failure = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' certlogin ' ) , { ' loginStatus ' : ' INVALID _ USERNAME _ OR _ PASSWORD ' } , ) NEW_LINE login_bad_code = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' certlogin ' ) , status = 422 , ) NEW_LINE keepalive_success = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' keepAlive ' ) , { ' status ' : ' SUCCESS ' } , ) NEW_LINE keepalive_failure = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' keepAlive ' ) , { ' status ' : ' FAIL ' , ' error ' : ' NO _ SESSION ' , } , ) NEW_LINE logout_success = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' logout ' ) , { ' status ' : ' SUCCESS ' } , ) NEW_LINE logout_failure = response_fixture_factory ( os . path . join ( betfair . IDENTITY_URLS [ None ] , ' logout ' ) , { ' status ' : ' FAIL ' , ' error ' : ' NO _ SESSION ' , } , ) NEW_LINE login_required_methods = [ ' keep _ alive ' , ' logout ' , ' list _ event _ types ' , ' list _ competitions ' , ' list _ time _ ranges ' , ' list _ events ' , ' list _ market _ types ' , ' list _ countries ' , ' list _ venues ' , ' list _ market _ catalogue ' , ' list _ market _ book ' , ' list _ market _ profit _ and _ loss ' , ' list _ current _ orders ' , ' list _ cleared _ orders ' , ' place _ orders ' , ' cancel _ orders ' , ' replace _ orders ' , ' update _ orders ' , ] NEW_LINE
 import sys NEW_LINE import time NEW_LINE from django . conf import settings NEW_LINE from django . utils . datastructures import DictWrapper NEW_LINE TEST_DATABASE_PREFIX = ' test _ ' NEW_LINE class BaseDatabaseCreation ( object ) : NEW_LINE INDENT data_types = { } NEW_LINE def __init__ ( self , connection ) : NEW_LINE INDENT self . connection = connection NEW_LINE DEDENT def _digest ( self , * args ) : NEW_LINE INDENT return ' % x ' % ( abs ( hash ( args ) ) % 4294967296L ) NEW_LINE DEDENT def db_type ( self , field ) : NEW_LINE INDENT return self . _db_type ( field , field . get_internal_type ( ) ) NEW_LINE DEDENT def related_db_type ( self , field ) : NEW_LINE INDENT return self . _db_type ( field , field . get_related_internal_type ( ) ) NEW_LINE DEDENT def _db_type ( self , field , internal_type ) : NEW_LINE INDENT data = DictWrapper ( field . __dict__ , self . connection . ops . quote_name , " qn _ " ) NEW_LINE try : NEW_LINE INDENT return self . connection . creation . data_types [ internal_type ] % data NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT def sql_create_model ( self , model , style , known_models = set ( ) ) : NEW_LINE INDENT opts = model . _meta NEW_LINE if not opts . managed or opts . proxy : NEW_LINE INDENT return [ ] , { } NEW_LINE DEDENT final_output = [ ] NEW_LINE table_output = [ ] NEW_LINE pending_references = { } NEW_LINE qn = self . connection . ops . quote_name NEW_LINE for f in opts . local_fields : NEW_LINE INDENT col_type = f . db_type ( connection = self . connection ) NEW_LINE tablespace = f . db_tablespace or opts . db_tablespace NEW_LINE if col_type is None : NEW_LINE INDENT continue NEW_LINE DEDENT field_output = [ style . SQL_FIELD ( qn ( f . column ) ) , style . SQL_COLTYPE ( col_type ) ] NEW_LINE if not f . null : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' NOT ▁ NULL ' ) ) NEW_LINE DEDENT if f . primary_key : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' PRIMARY ▁ KEY ' ) ) NEW_LINE DEDENT elif f . unique : NEW_LINE INDENT field_output . append ( style . SQL_KEYWORD ( ' UNIQUE ' ) ) NEW_LINE DEDENT if tablespace and f . unique : NEW_LINE INDENT field_output . append ( self . connection . ops . tablespace_sql ( tablespace , inline = True ) ) NEW_LINE DEDENT if f . rel : NEW_LINE INDENT ref_output , pending = self . sql_for_inline_foreign_key_references ( f , known_models , style ) NEW_LINE if pending : NEW_LINE INDENT pr = pending_references . setdefault ( f . rel . to , [ ] ) . append ( ( model , f ) ) NEW_LINE DEDENT else : NEW_LINE INDENT field_output . extend ( ref_output ) NEW_LINE DEDENT DEDENT table_output . append ( ' ▁ ' . join ( field_output ) ) NEW_LINE DEDENT for field_constraints in opts . unique_together : NEW_LINE INDENT table_output . append ( style . SQL_KEYWORD ( ' UNIQUE ' ) + ' ▁ ( % s ) ' % " , ▁ " . join ( [ style . SQL_FIELD ( qn ( opts . get_field ( f ) . column ) ) for f in field_constraints ] ) ) NEW_LINE DEDENT full_statement = [ style . SQL_KEYWORD ( ' CREATE ▁ TABLE ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( opts . db_table ) ) + ' ▁ ( ' ] NEW_LINE for i , line in enumerate ( table_output ) : NEW_LINE INDENT full_statement . append ( ' ▁ ▁ ▁ ▁ % s % s ' % ( line , i < len ( table_output ) - 1 and ' , ' or ' ' ) ) NEW_LINE DEDENT full_statement . append ( ' ) ' ) NEW_LINE if opts . db_tablespace : NEW_LINE INDENT full_statement . append ( self . connection . ops . tablespace_sql ( opts . db_tablespace ) ) NEW_LINE DEDENT full_statement . append ( ' ; ' ) NEW_LINE final_output . append ( ' \n ' . join ( full_statement ) ) NEW_LINE if opts . has_auto_field : NEW_LINE INDENT auto_column = opts . auto_field . db_column or opts . auto_field . name NEW_LINE autoinc_sql = self . connection . ops . autoinc_sql ( opts . db_table , auto_column ) NEW_LINE if autoinc_sql : NEW_LINE INDENT for stmt in autoinc_sql : NEW_LINE INDENT final_output . append ( stmt ) NEW_LINE DEDENT DEDENT DEDENT return final_output , pending_references NEW_LINE DEDENT def sql_for_inline_foreign_key_references ( self , field , known_models , style ) : NEW_LINE INDENT qn = self . connection . ops . quote_name NEW_LINE if field . rel . to in known_models : NEW_LINE INDENT output = [ style . SQL_KEYWORD ( ' REFERENCES ' ) + ' ▁ ' + \NEW_LINE style . SQL_TABLE ( qn ( field . rel . to . _meta . db_table ) ) + ' ▁ ( ' + \NEW_LINE style . SQL_FIELD ( qn ( field . rel . to . _meta . get_field ( field . rel . field_name ) . column ) ) + ' ) ' + self . connection . ops . deferrable_sql ( ) ] NEW_LINE pending = False NEW_LINE DEDENT else : NEW_LINE INDENT output = [ ] NEW_LINE pending = True NEW_LINE DEDENT return output , pending NEW_LINE DEDENT def sql_for_pending_references ( self , model , style , pending_references ) : NEW_LINE INDENT from django . db . backends . util import truncate_name NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT qn = self . connection . ops . quote_name NEW_LINE final_output = [ ] NEW_LINE opts = model . _meta NEW_LINE if model in pending_references : NEW_LINE INDENT for rel_class , f in pending_references [ model ] : NEW_LINE INDENT rel_opts = rel_class . _meta NEW_LINE r_table = rel_opts . db_table NEW_LINE r_col = f . column NEW_LINE table = opts . db_table NEW_LINE col = opts . get_field ( f . rel . field_name ) . column NEW_LINE r_name = ' % s _ refs _ % s _ % s ' % ( r_col , col , self . _digest ( r_table , table ) ) NEW_LINE final_output . append ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) + ' ▁ % s ▁ ADD ▁ CONSTRAINT ▁ % s ▁ FOREIGN ▁ KEY ▁ ( % s ) ▁ REFERENCES ▁ % s ▁ ( % s ) % s ; ' % \NEW_LINE ( qn ( r_table ) , qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) , qn ( r_col ) , qn ( table ) , qn ( col ) , self . connection . ops . deferrable_sql ( ) ) ) NEW_LINE DEDENT del pending_references [ model ] NEW_LINE DEDENT return final_output NEW_LINE DEDENT def sql_for_many_to_many ( self , model , style ) : NEW_LINE INDENT import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE output = [ ] NEW_LINE for f in model . _meta . local_many_to_many : NEW_LINE INDENT if model . _meta . managed or f . rel . to . _meta . managed : NEW_LINE INDENT output . extend ( self . sql_for_many_to_many_field ( model , f , style ) ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def sql_for_many_to_many_field ( self , model , f , style ) : NEW_LINE INDENT import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE from django . db import models NEW_LINE from django . db . backends . util import truncate_name NEW_LINE output = [ ] NEW_LINE if f . auto_created : NEW_LINE INDENT opts = model . _meta NEW_LINE qn = self . connection . ops . quote_name NEW_LINE tablespace = f . db_tablespace or opts . db_tablespace NEW_LINE if tablespace : NEW_LINE INDENT sql = self . connection . ops . tablespace_sql ( tablespace , inline = True ) NEW_LINE if sql : NEW_LINE INDENT tablespace_sql = ' ▁ ' + sql NEW_LINE DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT table_output = [ style . SQL_KEYWORD ( ' CREATE ▁ TABLE ' ) + ' ▁ ' + \NEW_LINE style . SQL_TABLE ( qn ( f . m2m_db_table ( ) ) ) + ' ▁ ( ' ] NEW_LINE table_output . append ( ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s % s , ' % ( style . SQL_FIELD ( qn ( ' id ' ) ) , style . SQL_COLTYPE ( models . AutoField ( primary_key = True ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ PRIMARY ▁ KEY ' ) , tablespace_sql ) ) NEW_LINE deferred = [ ] NEW_LINE inline_output , deferred = self . sql_for_inline_many_to_many_references ( model , f , style ) NEW_LINE table_output . extend ( inline_output ) NEW_LINE table_output . append ( ' ▁ ▁ ▁ ▁ % s ▁ ( % s , ▁ % s ) % s ' % ( style . SQL_KEYWORD ( ' UNIQUE ' ) , style . SQL_FIELD ( qn ( f . m2m_column_name ( ) ) ) , style . SQL_FIELD ( qn ( f . m2m_reverse_name ( ) ) ) , tablespace_sql ) ) NEW_LINE table_output . append ( ' ) ' ) NEW_LINE if opts . db_tablespace : NEW_LINE INDENT table_output . append ( self . connection . ops . tablespace_sql ( opts . db_tablespace ) ) NEW_LINE DEDENT table_output . append ( ' ; ' ) NEW_LINE output . append ( ' \n ' . join ( table_output ) ) NEW_LINE for r_table , r_col , table , col in deferred : NEW_LINE INDENT r_name = ' % s _ refs _ % s _ % s ' % ( r_col , col , self . _digest ( r_table , table ) ) NEW_LINE output . append ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) + ' ▁ % s ▁ ADD ▁ CONSTRAINT ▁ % s ▁ FOREIGN ▁ KEY ▁ ( % s ) ▁ REFERENCES ▁ % s ▁ ( % s ) % s ; ' % ( qn ( r_table ) , qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) , qn ( r_col ) , qn ( table ) , qn ( col ) , self . connection . ops . deferrable_sql ( ) ) ) NEW_LINE DEDENT autoinc_sql = self . connection . ops . autoinc_sql ( f . m2m_db_table ( ) , ' id ' ) NEW_LINE if autoinc_sql : NEW_LINE INDENT for stmt in autoinc_sql : NEW_LINE INDENT output . append ( stmt ) NEW_LINE DEDENT DEDENT DEDENT return output NEW_LINE DEDENT def sql_for_inline_many_to_many_references ( self , model , field , style ) : NEW_LINE INDENT import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE from django . db import models NEW_LINE opts = model . _meta NEW_LINE qn = self . connection . ops . quote_name NEW_LINE table_output = [ ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s ▁ % s ▁ ( % s ) % s , ' % ( style . SQL_FIELD ( qn ( field . m2m_column_name ( ) ) ) , style . SQL_COLTYPE ( models . ForeignKey ( model ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ REFERENCES ' ) , style . SQL_TABLE ( qn ( opts . db_table ) ) , style . SQL_FIELD ( qn ( opts . pk . column ) ) , self . connection . ops . deferrable_sql ( ) ) , ' ▁ ▁ ▁ ▁ % s ▁ % s ▁ % s ▁ % s ▁ ( % s ) % s , ' % ( style . SQL_FIELD ( qn ( field . m2m_reverse_name ( ) ) ) , style . SQL_COLTYPE ( models . ForeignKey ( field . rel . to ) . db_type ( connection = self . connection ) ) , style . SQL_KEYWORD ( ' NOT ▁ NULL ▁ REFERENCES ' ) , style . SQL_TABLE ( qn ( field . rel . to . _meta . db_table ) ) , style . SQL_FIELD ( qn ( field . rel . to . _meta . pk . column ) ) , self . connection . ops . deferrable_sql ( ) ) ] NEW_LINE deferred = [ ] NEW_LINE return table_output , deferred NEW_LINE DEDENT def sql_indexes_for_model ( self , model , style ) : NEW_LINE INDENT if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT output = [ ] NEW_LINE for f in model . _meta . local_fields : NEW_LINE INDENT output . extend ( self . sql_indexes_for_field ( model , f , style ) ) NEW_LINE DEDENT return output NEW_LINE DEDENT def sql_indexes_for_field ( self , model , f , style ) : NEW_LINE INDENT from django . db . backends . util import truncate_name NEW_LINE if f . db_index and not f . unique : NEW_LINE INDENT qn = self . connection . ops . quote_name NEW_LINE tablespace = f . db_tablespace or model . _meta . db_tablespace NEW_LINE if tablespace : NEW_LINE INDENT sql = self . connection . ops . tablespace_sql ( tablespace ) NEW_LINE if sql : NEW_LINE INDENT tablespace_sql = ' ▁ ' + sql NEW_LINE DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT tablespace_sql = ' ' NEW_LINE DEDENT i_name = ' % s _ % s ' % ( model . _meta . db_table , self . _digest ( f . column ) ) NEW_LINE output = [ style . SQL_KEYWORD ( ' CREATE ▁ INDEX ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( truncate_name ( i_name , self . connection . ops . max_name_length ( ) ) ) ) + ' ▁ ' + style . SQL_KEYWORD ( ' ON ' ) + ' ▁ ' + style . SQL_TABLE ( qn ( model . _meta . db_table ) ) + ' ▁ ' + " ( % s ) " % style . SQL_FIELD ( qn ( f . column ) ) + " % s ; " % tablespace_sql ] NEW_LINE DEDENT else : NEW_LINE INDENT output = [ ] NEW_LINE DEDENT return output NEW_LINE DEDENT def sql_destroy_model ( self , model , references_to_delete , style ) : NEW_LINE INDENT if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT qn = self . connection . ops . quote_name NEW_LINE output = [ ' % s ▁ % s ; ' % ( style . SQL_KEYWORD ( ' DROP ▁ TABLE ' ) , style . SQL_TABLE ( qn ( model . _meta . db_table ) ) ) ] NEW_LINE if model in references_to_delete : NEW_LINE INDENT output . extend ( self . sql_remove_table_constraints ( model , references_to_delete , style ) ) NEW_LINE DEDENT if model . _meta . has_auto_field : NEW_LINE INDENT ds = self . connection . ops . drop_sequence_sql ( model . _meta . db_table ) NEW_LINE if ds : NEW_LINE INDENT output . append ( ds ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def sql_remove_table_constraints ( self , model , references_to_delete , style ) : NEW_LINE INDENT from django . db . backends . util import truncate_name NEW_LINE if not model . _meta . managed or model . _meta . proxy : NEW_LINE INDENT return [ ] NEW_LINE DEDENT output = [ ] NEW_LINE qn = self . connection . ops . quote_name NEW_LINE for rel_class , f in references_to_delete [ model ] : NEW_LINE INDENT table = rel_class . _meta . db_table NEW_LINE col = f . column NEW_LINE r_table = model . _meta . db_table NEW_LINE r_col = model . _meta . get_field ( f . rel . field_name ) . column NEW_LINE r_name = ' % s _ refs _ % s _ % s ' % ( col , r_col , self . _digest ( table , r_table ) ) NEW_LINE output . append ( ' % s ▁ % s ▁ % s ▁ % s ; ' % \NEW_LINE ( style . SQL_KEYWORD ( ' ALTER ▁ TABLE ' ) , style . SQL_TABLE ( qn ( table ) ) , style . SQL_KEYWORD ( self . connection . ops . drop_foreignkey_sql ( ) ) , style . SQL_FIELD ( qn ( truncate_name ( r_name , self . connection . ops . max_name_length ( ) ) ) ) ) ) NEW_LINE DEDENT del references_to_delete [ model ] NEW_LINE return output NEW_LINE DEDENT def sql_destroy_many_to_many ( self , model , f , style ) : NEW_LINE INDENT import warnings NEW_LINE warnings . warn ( ' Database ▁ creation ▁ API ▁ for ▁ m2m ▁ tables ▁ has ▁ been ▁ deprecated . ▁ M2M ▁ models ▁ are ▁ now ▁ automatically ▁ generated ' , DeprecationWarning ) NEW_LINE qn = self . connection . ops . quote_name NEW_LINE output = [ ] NEW_LINE if f . auto_created : NEW_LINE INDENT output . append ( " % s ▁ % s ; " % ( style . SQL_KEYWORD ( ' DROP ▁ TABLE ' ) , style . SQL_TABLE ( qn ( f . m2m_db_table ( ) ) ) ) ) NEW_LINE ds = self . connection . ops . drop_sequence_sql ( " % s _ % s " % ( model . _meta . db_table , f . column ) ) NEW_LINE if ds : NEW_LINE INDENT output . append ( ds ) NEW_LINE DEDENT DEDENT return output NEW_LINE DEDENT def create_test_db ( self , verbosity = 1 , autoclobber = False ) : NEW_LINE INDENT from django . core . management import call_command NEW_LINE test_database_name = self . _get_test_db_name ( ) NEW_LINE if verbosity >= 1 : NEW_LINE INDENT test_db_repr = ' ' NEW_LINE if verbosity >= 2 : NEW_LINE INDENT test_db_repr = " ▁ ( ' % s ' ) " % test_database_name NEW_LINE DEDENT print " Creating ▁ test ▁ database ▁ for ▁ alias ▁ ' % s ' % s . . . " % ( self . connection . alias , test_db_repr ) NEW_LINE DEDENT self . _create_test_db ( verbosity , autoclobber ) NEW_LINE self . connection . close ( ) NEW_LINE self . connection . settings_dict [ " NAME " ] = test_database_name NEW_LINE self . connection . features . confirm ( ) NEW_LINE call_command ( ' syncdb ' , verbosity = max ( verbosity - 1 , 0 ) , interactive = False , database = self . connection . alias , load_initial_data = False ) NEW_LINE call_command ( ' flush ' , verbosity = max ( verbosity - 1 , 0 ) , interactive = False , database = self . connection . alias ) NEW_LINE from django . core . cache import get_cache NEW_LINE from django . core . cache . backends . db import BaseDatabaseCache NEW_LINE for cache_alias in settings . CACHES : NEW_LINE INDENT cache = get_cache ( cache_alias ) NEW_LINE if isinstance ( cache , BaseDatabaseCache ) : NEW_LINE INDENT from django . db import router NEW_LINE if router . allow_syncdb ( self . connection . alias , cache . cache_model_class ) : NEW_LINE INDENT call_command ( ' createcachetable ' , cache . _table , database = self . connection . alias ) NEW_LINE DEDENT DEDENT DEDENT cursor = self . connection . cursor ( ) NEW_LINE return test_database_name NEW_LINE DEDENT def _get_test_db_name ( self ) : NEW_LINE INDENT if self . connection . settings_dict [ ' TEST _ NAME ' ] : NEW_LINE INDENT return self . connection . settings_dict [ ' TEST _ NAME ' ] NEW_LINE DEDENT return TEST_DATABASE_PREFIX + self . connection . settings_dict [ ' NAME ' ] NEW_LINE DEDENT def _create_test_db ( self , verbosity , autoclobber ) : NEW_LINE INDENT suffix = self . sql_table_creation_suffix ( ) NEW_LINE test_database_name = self . _get_test_db_name ( ) NEW_LINE qn = self . connection . ops . quote_name NEW_LINE cursor = self . connection . cursor ( ) NEW_LINE self . set_autocommit ( ) NEW_LINE try : NEW_LINE INDENT cursor . execute ( " CREATE ▁ DATABASE ▁ % s ▁ % s " % ( qn ( test_database_name ) , suffix ) ) NEW_LINE DEDENT except Exception , e : NEW_LINE INDENT sys . stderr . write ( " Got ▁ an ▁ error ▁ creating ▁ the ▁ test ▁ database : ▁ % s \n " % e ) NEW_LINE if not autoclobber : NEW_LINE INDENT confirm = raw_input ( " Type ▁ ' yes ' ▁ if ▁ you ▁ would ▁ like ▁ to ▁ try ▁ deleting ▁ the ▁ test ▁ database ▁ ' % s ' , ▁ or ▁ ' no ' ▁ to ▁ cancel : ▁ " % test_database_name ) NEW_LINE DEDENT if autoclobber or confirm == ' yes ' : NEW_LINE INDENT try : NEW_LINE INDENT if verbosity >= 1 : NEW_LINE INDENT print " Destroying ▁ old ▁ test ▁ database ▁ ' % s ' . . . " % self . connection . alias NEW_LINE DEDENT cursor . execute ( " DROP ▁ DATABASE ▁ % s " % qn ( test_database_name ) ) NEW_LINE cursor . execute ( " CREATE ▁ DATABASE ▁ % s ▁ % s " % ( qn ( test_database_name ) , suffix ) ) NEW_LINE DEDENT except Exception , e : NEW_LINE INDENT sys . stderr . write ( " Got ▁ an ▁ error ▁ recreating ▁ the ▁ test ▁ database : ▁ % s \n " % e ) NEW_LINE sys . exit ( 2 ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " Tests ▁ cancelled . " NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT DEDENT return test_database_name NEW_LINE DEDENT def destroy_test_db ( self , old_database_name , verbosity = 1 ) : NEW_LINE INDENT self . connection . close ( ) NEW_LINE test_database_name = self . connection . settings_dict [ ' NAME ' ] NEW_LINE if verbosity >= 1 : NEW_LINE INDENT test_db_repr = ' ' NEW_LINE if verbosity >= 2 : NEW_LINE INDENT test_db_repr = " ▁ ( ' % s ' ) " % test_database_name NEW_LINE DEDENT print " Destroying ▁ test ▁ database ▁ for ▁ alias ▁ ' % s ' % s . . . " % ( self . connection . alias , test_db_repr ) NEW_LINE DEDENT self . connection . settings_dict [ ' NAME ' ] = old_database_name NEW_LINE self . _destroy_test_db ( test_database_name , verbosity ) NEW_LINE DEDENT def _destroy_test_db ( self , test_database_name , verbosity ) : NEW_LINE INDENT cursor = self . connection . cursor ( ) NEW_LINE self . set_autocommit ( ) NEW_LINE time . sleep ( 1 ) NEW_LINE cursor . execute ( " DROP ▁ DATABASE ▁ % s " % self . connection . ops . quote_name ( test_database_name ) ) NEW_LINE self . connection . close ( ) NEW_LINE DEDENT def set_autocommit ( self ) : NEW_LINE INDENT if hasattr ( self . connection . connection , " autocommit " ) : NEW_LINE INDENT if callable ( self . connection . connection . autocommit ) : NEW_LINE INDENT self . connection . connection . autocommit ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . connection . connection . autocommit = True NEW_LINE DEDENT DEDENT elif hasattr ( self . connection . connection , " set _ isolation _ level " ) : NEW_LINE INDENT self . connection . connection . set_isolation_level ( 0 ) NEW_LINE DEDENT DEDENT def sql_table_creation_suffix ( self ) : NEW_LINE INDENT return ' ' NEW_LINE DEDENT def test_db_signature ( self ) : NEW_LINE INDENT settings_dict = self . connection . settings_dict NEW_LINE return ( settings_dict [ ' HOST ' ] , settings_dict [ ' PORT ' ] , settings_dict [ ' ENGINE ' ] , settings_dict [ ' NAME ' ] ) NEW_LINE DEDENT DEDENT
 from . . excel_comparsion_test import ExcelComparisonTest NEW_LINE from . . . workbook import Workbook NEW_LINE class TestCompareXLSXFiles ( ExcelComparisonTest ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . maxDiff = None NEW_LINE filename = ' chart _ column04 . xlsx ' NEW_LINE test_dir = ' xlsxwriter / test / comparison / ' NEW_LINE self . got_filename = test_dir + ' _ test _ ' + filename NEW_LINE self . exp_filename = test_dir + ' xlsx _ files / ' + filename NEW_LINE self . ignore_files = [ ] NEW_LINE self . ignore_elements = { ' xl / workbook . xml ' : [ ' < fileVersion ' , ' < calcPr ' ] } NEW_LINE DEDENT def test_create_file ( self ) : NEW_LINE INDENT workbook = Workbook ( self . got_filename ) NEW_LINE worksheet = workbook . add_worksheet ( ) NEW_LINE chart = workbook . add_chart ( { ' type ' : ' column ' } ) NEW_LINE chart . axis_ids = [ 63591936 , 63593856 ] NEW_LINE chart . axis2_ids = [ 63613568 , 63612032 ] NEW_LINE data = [ [ 1 , 2 , 3 , 4 , 5 ] , [ 6 , 8 , 6 , 4 , 2 ] ] NEW_LINE worksheet . write_column ( ' A1' , data [ 0 ] ) NEW_LINE worksheet . write_column ( ' B1' , data [ 1 ] ) NEW_LINE chart . add_series ( { ' values ' : ' = Sheet1 ! $ A $ 1 : $ A $ 5' } ) NEW_LINE chart . add_series ( { ' values ' : ' = Sheet1 ! $ B $ 1 : $ B $ 5' , ' y2 _ axis ' : 1 } ) NEW_LINE worksheet . insert_chart ( ' E9' , chart ) NEW_LINE workbook . close ( ) NEW_LINE self . assertExcelEqual ( ) NEW_LINE DEDENT DEDENT
 from openerp . osv import orm , fields NEW_LINE from openerp import SUPERUSER_ID NEW_LINE from openerp . addons import decimal_precision NEW_LINE class delivery_carrier ( orm . Model ) : NEW_LINE INDENT _name = ' delivery . carrier ' NEW_LINE _inherit = [ ' delivery . carrier ' , ' website . published . mixin ' ] NEW_LINE _columns = { ' website _ description ' : fields . text ( ' Description ▁ for ▁ the ▁ website ' ) , } NEW_LINE _defaults = { ' website _ published ' : True } NEW_LINE DEDENT class SaleOrder ( orm . Model ) : NEW_LINE INDENT _inherit = ' sale . order ' NEW_LINE def _amount_all_wrapper ( self , cr , uid , ids , field_name , arg , context = None ) : NEW_LINE INDENT return self . _amount_all ( cr , uid , ids , field_name , arg , context = context ) NEW_LINE DEDENT def _amount_all ( self , cr , uid , ids , field_name , arg , context = None ) : NEW_LINE INDENT res = super ( SaleOrder , self ) . _amount_all ( cr , uid , ids , field_name , arg , context = context ) NEW_LINE currency_pool = self . pool . get ( ' res . currency ' ) NEW_LINE for order in self . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT line_amount = sum ( [ line . price_subtotal for line in order . order_line if line . is_delivery ] ) NEW_LINE currency = order . pricelist_id . currency_id NEW_LINE res [ order . id ] [ ' amount _ delivery ' ] = currency_pool . round ( cr , uid , currency , line_amount ) NEW_LINE DEDENT return res NEW_LINE DEDENT def _get_order ( self , cr , uid , ids , context = None ) : NEW_LINE INDENT result = { } NEW_LINE for line in self . pool . get ( ' sale . order . line ' ) . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT result [ line . order_id . id ] = True NEW_LINE DEDENT return result . keys ( ) NEW_LINE DEDENT _columns = { ' amount _ delivery ' : fields . function ( _amount_all_wrapper , type = ' float ' , digits_compute = decimal_precision . get_precision ( ' Account ' ) , string = ' Delivery ▁ Amount ' , store = { ' sale . order ' : ( lambda self , cr , uid , ids , c = { } : ids , [ ' order _ line ' ] , 10 ) , ' sale . order . line ' : ( _get_order , [ ' price _ unit ' , ' tax _ id ' , ' discount ' , ' product _ uom _ qty ' ] , 10 ) , } , multi = ' sums ' , help = " The ▁ amount ▁ without ▁ tax . " , track_visibility = ' always ' ) , ' website _ order _ line ' : fields . one2many ( ' sale . order . line ' , ' order _ id ' , string = ' Order ▁ Lines ▁ displayed ▁ on ▁ Website ' , readonly = True , domain = [ ( ' is _ delivery ' , ' = ' , False ) ] , help = ' Order ▁ Lines ▁ to ▁ be ▁ displayed ▁ on ▁ the ▁ website . ▁ They ▁ should ▁ not ▁ be ▁ used ▁ for ▁ computation ▁ purpose . ' , ) , } NEW_LINE def _check_carrier_quotation ( self , cr , uid , order , force_carrier_id = None , context = None ) : NEW_LINE INDENT carrier_obj = self . pool . get ( ' delivery . carrier ' ) NEW_LINE if not order : NEW_LINE INDENT return False NEW_LINE DEDENT if all ( line . product_id . type == " service " for line in order . website_order_line ) : NEW_LINE INDENT order . write ( { ' carrier _ id ' : None } ) NEW_LINE self . pool [ ' sale . order ' ] . _delivery_unset ( cr , SUPERUSER_ID , [ order . id ] , context = context ) NEW_LINE return True NEW_LINE DEDENT else : NEW_LINE INDENT carrier_id = force_carrier_id or order . carrier_id . id NEW_LINE carrier_ids = self . _get_delivery_methods ( cr , uid , order , context = context ) NEW_LINE if carrier_id : NEW_LINE INDENT if carrier_id not in carrier_ids : NEW_LINE INDENT carrier_id = False NEW_LINE DEDENT else : NEW_LINE INDENT carrier_ids . remove ( carrier_id ) NEW_LINE carrier_ids . insert ( 0 , carrier_id ) NEW_LINE DEDENT DEDENT if force_carrier_id or not carrier_id or not carrier_id in carrier_ids : NEW_LINE INDENT for delivery_id in carrier_ids : NEW_LINE INDENT grid_id = carrier_obj . grid_get ( cr , SUPERUSER_ID , [ delivery_id ] , order . partner_shipping_id . id ) NEW_LINE if grid_id : NEW_LINE INDENT carrier_id = delivery_id NEW_LINE break NEW_LINE DEDENT DEDENT order . write ( { ' carrier _ id ' : carrier_id } ) NEW_LINE DEDENT if carrier_id : NEW_LINE INDENT order . delivery_set ( ) NEW_LINE DEDENT else : NEW_LINE INDENT order . _delivery_unset ( ) NEW_LINE DEDENT DEDENT return bool ( carrier_id ) NEW_LINE DEDENT def _get_delivery_methods ( self , cr , uid , order , context = None ) : NEW_LINE INDENT carrier_obj = self . pool . get ( ' delivery . carrier ' ) NEW_LINE delivery_ids = carrier_obj . search ( cr , uid , [ ( ' website _ published ' , ' = ' , True ) ] , context = context ) NEW_LINE for delivery_id in carrier_obj . browse ( cr , SUPERUSER_ID , delivery_ids , context = dict ( context , order_id = order . id ) ) : NEW_LINE INDENT if not delivery_id . available : NEW_LINE INDENT delivery_ids . remove ( delivery_id . id ) NEW_LINE DEDENT DEDENT return delivery_ids NEW_LINE DEDENT def _get_errors ( self , cr , uid , order , context = None ) : NEW_LINE INDENT errors = super ( SaleOrder , self ) . _get_errors ( cr , uid , order , context = context ) NEW_LINE if not self . _get_delivery_methods ( cr , uid , order , context = context ) : NEW_LINE INDENT errors . append ( ( ' No ▁ delivery ▁ method ▁ available ' , ' There ▁ is ▁ no ▁ available ▁ delivery ▁ method ▁ for ▁ your ▁ order ' ) ) NEW_LINE DEDENT return errors NEW_LINE DEDENT def _get_website_data ( self , cr , uid , order , context = None ) : NEW_LINE INDENT values = super ( SaleOrder , self ) . _get_website_data ( cr , uid , order , context = context ) NEW_LINE has_stockable_products = False NEW_LINE for line in order . order_line : NEW_LINE INDENT if line . product_id . type in ( ' consu ' , ' product ' ) : NEW_LINE INDENT has_stockable_products = True NEW_LINE DEDENT DEDENT if not has_stockable_products : NEW_LINE INDENT return values NEW_LINE DEDENT delivery_ctx = dict ( context , order_id = order . id ) NEW_LINE DeliveryCarrier = self . pool . get ( ' delivery . carrier ' ) NEW_LINE delivery_ids = self . _get_delivery_methods ( cr , uid , order , context = context ) NEW_LINE values [ ' deliveries ' ] = DeliveryCarrier . browse ( cr , SUPERUSER_ID , delivery_ids , context = delivery_ctx ) NEW_LINE return values NEW_LINE DEDENT DEDENT
 import datetime NEW_LINE from south . db import db NEW_LINE from south . v2 import SchemaMigration NEW_LINE from django . db import models NEW_LINE try : NEW_LINE INDENT from django . contrib . auth import get_user_model NEW_LINE DEDENT except ImportError : NEW_LINE INDENT from django . contrib . auth . models import User NEW_LINE DEDENT else : NEW_LINE INDENT User = get_user_model ( ) NEW_LINE DEDENT user_orm_label = ' % s . % s ' % ( User . _meta . app_label , User . _meta . object_name ) NEW_LINE user_model_label = ' % s . % s ' % ( User . _meta . app_label , User . _meta . model_name ) NEW_LINE user_ptr_name = ' % s _ ptr ' % User . _meta . object_name . lower ( ) NEW_LINE class Migration ( SchemaMigration ) : NEW_LINE INDENT def forwards ( self , orm ) : NEW_LINE INDENT pass NEW_LINE DEDENT def backwards ( self , orm ) : NEW_LINE INDENT pass NEW_LINE DEDENT models = { ' auth . group ' : { ' Meta ' : { ' object _ name ' : ' Group ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '80' } ) , ' permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) } , ' auth . permission ' : { ' Meta ' : { ' ordering ' : " ( ' content _ type _ _ app _ label ' , ▁ ' content _ type _ _ model ' , ▁ ' codename ' ) " , ' unique _ together ' : " ( ( ' content _ type ' , ▁ ' codename ' ) , ) " , ' object _ name ' : ' Permission ' } , ' codename ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' content _ type ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' contenttypes . ContentType ' ] " } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } , user_model_label : { ' Meta ' : { ' object _ name ' : User . __name__ , ' db _ table ' : " ' % s ' " % User . _meta . db_table } , ' date _ joined ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' email ' : ( ' django . db . models . fields . EmailField ' , [ ] , { ' max _ length ' : '75' , ' blank ' : ' True ' } ) , ' first _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' groups ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' is _ active ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' is _ staff ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' is _ superuser ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' last _ login ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' last _ name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '30' , ' blank ' : ' True ' } ) , ' password ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '128' } ) , ' user _ permissions ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' auth . Permission ' ] " , ' symmetrical ' : ' False ' , ' blank ' : ' True ' } ) , ' username ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' unique ' : ' True ' , ' max _ length ' : '30' } ) } , ' cms . cmsplugin ' : { ' Meta ' : { ' object _ name ' : ' CMSPlugin ' } , ' changed _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' blank ' : ' True ' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '15' , ' db _ index ' : ' True ' } ) , ' level ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' lft ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' parent ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . CMSPlugin ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' placeholder ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Placeholder ' ] " , ' null ' : ' True ' } ) , ' plugin _ type ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) , ' position ' : ( ' django . db . models . fields . PositiveSmallIntegerField ' , [ ] , { ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' rght ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' tree _ id ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' cms . globalpagepermission ' : { ' Meta ' : { ' object _ name ' : ' GlobalPagePermission ' } , ' can _ add ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change _ advanced _ settings ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ change _ permissions ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ delete ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ moderate ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ move _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ publish ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ recover _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ view ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' group ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' sites ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' symmetrical ' : ' False ' , ' to ' : " orm [ ' sites . Site ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' cms . page ' : { ' Meta ' : { ' ordering ' : " ( ' site ' , ▁ ' tree _ id ' , ▁ ' lft ' ) " , ' object _ name ' : ' Page ' } , ' changed _ by ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '70' } ) , ' changed _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now ' : ' True ' , ' blank ' : ' True ' } ) , ' created _ by ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '70' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' in _ navigation ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' , ' db _ index ' : ' True ' } ) , ' level ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' lft ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' limit _ visibility _ in _ menu ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : ' None ' , ' null ' : ' True ' , ' db _ index ' : ' True ' , ' blank ' : ' True ' } ) , ' login _ required ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderator _ state ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '1' , ' blank ' : ' True ' } ) , ' navigation _ extenders ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '80' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' parent ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' blank ' : ' True ' , ' related _ name ' : " ' children ' " , ' null ' : ' True ' , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' placeholders ' : ( ' django . db . models . fields . related . ManyToManyField ' , [ ] , { ' to ' : " orm [ ' cms . Placeholder ' ] " , ' symmetrical ' : ' False ' } ) , ' publication _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' publication _ end _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' db _ index ' : ' True ' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' published ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' publisher _ is _ draft ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' , ' db _ index ' : ' True ' } ) , ' publisher _ public ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' related _ name ' : " ' publisher _ draft ' " , ' unique ' : ' True ' , ' null ' : ' True ' , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' publisher _ state ' : ( ' django . db . models . fields . SmallIntegerField ' , [ ] , { ' default ' : '0' , ' db _ index ' : ' True ' } ) , ' reverse _ id ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '40' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' rght ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) , ' site ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' sites . Site ' ] " } ) , ' soft _ root ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' , ' db _ index ' : ' True ' } ) , ' template ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' tree _ id ' : ( ' django . db . models . fields . PositiveIntegerField ' , [ ] , { ' db _ index ' : ' True ' } ) } , ' cms . pagemoderator ' : { ' Meta ' : { ' object _ name ' : ' PageModerator ' } , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' moderate _ children ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderate _ descendants ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' moderate _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) } , ' cms . pagemoderatorstate ' : { ' Meta ' : { ' ordering ' : " ( ' page ' , ▁ ' action ' , ▁ ' - created ' ) " , ' object _ name ' : ' PageModeratorState ' } , ' action ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '3' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' created ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' auto _ now _ add ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' message ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' default ' : " ' ' " , ' max _ length ' : '1000' , ' blank ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' } ) } , ' cms . pagepermission ' : { ' Meta ' : { ' object _ name ' : ' PagePermission ' } , ' can _ add ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ change _ advanced _ settings ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ change _ permissions ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' can _ delete ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ moderate ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ move _ page ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ publish ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' True ' } ) , ' can _ view ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' } ) , ' grant _ on ' : ( ' django . db . models . fields . IntegerField ' , [ ] , { ' default ' : '5' } ) , ' group ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' cms . Page ' ] " , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' user ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' null ' : ' True ' , ' blank ' : ' True ' } ) } , ' cms . pageuser ' : { ' Meta ' : { ' object _ name ' : ' PageUser ' , ' _ ormbases ' : [ user_orm_label ] } , ' created _ by ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' created _ users ' " , ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) , ' user _ ptr ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' % s ' ] " % user_orm_label , ' unique ' : ' True ' , ' primary _ key ' : ' True ' } ) } , ' cms . pageusergroup ' : { ' Meta ' : { ' object _ name ' : ' PageUserGroup ' , ' _ ormbases ' : [ ' auth . Group ' ] } , ' created _ by ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' created _ usergroups ' " , ' to ' : " orm [ ' % s ' ] " % user_orm_label } ) , ' group _ ptr ' : ( ' django . db . models . fields . related . OneToOneField ' , [ ] , { ' to ' : " orm [ ' auth . Group ' ] " , ' unique ' : ' True ' , ' primary _ key ' : ' True ' } ) } , ' cms . placeholder ' : { ' Meta ' : { ' object _ name ' : ' Placeholder ' } , ' default _ width ' : ( ' django . db . models . fields . PositiveSmallIntegerField ' , [ ] , { ' null ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' slot ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' , ' db _ index ' : ' True ' } ) } , ' cms . title ' : { ' Meta ' : { ' unique _ together ' : " ( ( ' language ' , ▁ ' page ' ) , ) " , ' object _ name ' : ' Title ' } , ' application _ urls ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' db _ index ' : ' True ' , ' max _ length ' : '200' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' creation _ date ' : ( ' django . db . models . fields . DateTimeField ' , [ ] , { ' default ' : ' datetime . datetime . now ' } ) , ' has _ url _ overwrite ' : ( ' django . db . models . fields . BooleanField ' , [ ] , { ' default ' : ' False ' , ' db _ index ' : ' True ' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' language ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '15' , ' db _ index ' : ' True ' } ) , ' menu _ title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta _ description ' : ( ' django . db . models . fields . TextField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' meta _ keywords ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' page ' : ( ' django . db . models . fields . related . ForeignKey ' , [ ] , { ' related _ name ' : " ' title _ set ' " , ' to ' : " orm [ ' cms . Page ' ] " } ) , ' page _ title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' path ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' db _ index ' : ' True ' } ) , ' redirect ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' , ' null ' : ' True ' , ' blank ' : ' True ' } ) , ' slug ' : ( ' django . db . models . fields . SlugField ' , [ ] , { ' max _ length ' : '255' } ) , ' title ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '255' } ) } , ' contenttypes . contenttype ' : { ' Meta ' : { ' ordering ' : " ( ' name ' , ) " , ' unique _ together ' : " ( ( ' app _ label ' , ▁ ' model ' ) , ) " , ' object _ name ' : ' ContentType ' , ' db _ table ' : " ' django _ content _ type ' " } , ' app _ label ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' model ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) } , ' sites . site ' : { ' Meta ' : { ' ordering ' : " ( ' domain ' , ) " , ' object _ name ' : ' Site ' , ' db _ table ' : " ' django _ site ' " } , ' domain ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '100' } ) , ' id ' : ( ' django . db . models . fields . AutoField ' , [ ] , { ' primary _ key ' : ' True ' } ) , ' name ' : ( ' django . db . models . fields . CharField ' , [ ] , { ' max _ length ' : '50' } ) } } NEW_LINE complete_apps = [ ' cms ' ] NEW_LINE DEDENT
 import traceback NEW_LINE from bs4 import BeautifulSoup NEW_LINE from couchpotato . core . helpers . encoding import toUnicode NEW_LINE from couchpotato . core . helpers . variable import tryInt NEW_LINE from couchpotato . core . logger import CPLog NEW_LINE from couchpotato . core . media . _base . providers . torrent . base import TorrentProvider NEW_LINE log = CPLog ( __name__ ) NEW_LINE class Base ( TorrentProvider ) : NEW_LINE INDENT urls = { ' test ' : ' https : / / www . sceneaccess . eu / ' , ' login ' : ' https : / / www . sceneaccess . eu / login ' , ' login _ check ' : ' https : / / www . sceneaccess . eu / inbox ' , ' detail ' : ' https : / / www . sceneaccess . eu / details ? id = % s ' , ' search ' : ' https : / / www . sceneaccess . eu / browse ? c % d = % d ' , ' archive ' : ' https : / / www . sceneaccess . eu / archive ? & c % d = % d ' , ' download ' : ' https : / / www . sceneaccess . eu / % s ' , } NEW_LINE http_time_between_calls = 1 NEW_LINE def _searchOnTitle ( self , title , media , quality , results ) : NEW_LINE INDENT url = self . buildUrl ( title , media , quality ) NEW_LINE data = self . getHTMLData ( url ) NEW_LINE if data : NEW_LINE INDENT html = BeautifulSoup ( data ) NEW_LINE try : NEW_LINE INDENT resultsTable = html . find ( ' table ' , attrs = { ' id ' : ' torrents - table ' } ) NEW_LINE if resultsTable is None : NEW_LINE INDENT return NEW_LINE DEDENT entries = resultsTable . find_all ( ' tr ' , attrs = { ' class ' : ' tt _ row ' } ) NEW_LINE for result in entries : NEW_LINE INDENT link = result . find ( ' td ' , attrs = { ' class ' : ' ttr _ name ' } ) . find ( ' a ' ) NEW_LINE url = result . find ( ' td ' , attrs = { ' class ' : ' td _ dl ' } ) . find ( ' a ' ) NEW_LINE leechers = result . find ( ' td ' , attrs = { ' class ' : ' ttr _ leechers ' } ) . find ( ' a ' ) NEW_LINE torrent_id = link [ ' href ' ] . replace ( ' details ? id = ' , ' ' ) NEW_LINE results . append ( { ' id ' : torrent_id , ' name ' : link [ ' title ' ] , ' url ' : self . urls [ ' download ' ] % url [ ' href ' ] , ' detail _ url ' : self . urls [ ' detail ' ] % torrent_id , ' size ' : self . parseSize ( result . find ( ' td ' , attrs = { ' class ' : ' ttr _ size ' } ) . contents [ 0 ] ) , ' seeders ' : tryInt ( result . find ( ' td ' , attrs = { ' class ' : ' ttr _ seeders ' } ) . find ( ' a ' ) . string ) , ' leechers ' : tryInt ( leechers . string ) if leechers else 0 , ' get _ more _ info ' : self . getMoreInfo , } ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT log . error ( ' Failed ▁ getting ▁ results ▁ from ▁ % s : ▁ % s ' , ( self . getName ( ) , traceback . format_exc ( ) ) ) NEW_LINE DEDENT DEDENT DEDENT def getMoreInfo ( self , item ) : NEW_LINE INDENT full_description = self . getCache ( ' sceneaccess . % s ' % item [ ' id ' ] , item [ ' detail _ url ' ] , cache_timeout = 25920000 ) NEW_LINE html = BeautifulSoup ( full_description ) NEW_LINE nfo_pre = html . find ( ' div ' , attrs = { ' id ' : ' details _ table ' } ) NEW_LINE description = toUnicode ( nfo_pre . text ) if nfo_pre else ' ' NEW_LINE item [ ' description ' ] = description NEW_LINE return item NEW_LINE DEDENT def getLoginParams ( self ) : NEW_LINE INDENT return { ' username ' : self . conf ( ' username ' ) , ' password ' : self . conf ( ' password ' ) , ' submit ' : ' come ▁ on ▁ in ' , } NEW_LINE DEDENT def loginSuccess ( self , output ) : NEW_LINE INDENT return ' / inbox ' in output . lower ( ) NEW_LINE DEDENT loginCheckSuccess = loginSuccess NEW_LINE DEDENT config = [ { ' name ' : ' sceneaccess ' , ' groups ' : [ { ' tab ' : ' searcher ' , ' list ' : ' torrent _ providers ' , ' name ' : ' SceneAccess ' , ' description ' : ' < a ▁ href = " https : / / sceneaccess . eu / " > SceneAccess < / a > ' , ' wizard ' : True , ' icon ' : ' iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAAABnRSTlMAAAAAAABupgeRAAACT0lEQVR4AYVQS0sbURidO3OTmajJ5FElTTOkPmZ01GhHrIq0aoWAj1Vc + A / cuRMXbl24V9SlCGqrLhVFCrooEhCp2BAx0mobTY2kaR7qmOm87EXL1EWxh29xL + c7nPMdgGHYO5bF / gdbefnr6WlbWRnxluMwAB4Z0uEgXa7nwaDL7 + / RNPzxbYvb / XJ0FBYVfd / ayh0fQ4qCGEHcm0KLRZUk7Pb2YRJPRwcsKMidnKD3t9VVT3s7BDh + z5FOZ3Vfn3h + Hltfx00mRRSRWFcUmmVNhYVqPn8dj3va2oh + txvcQRVF9ebm1fi4k + dRFbosY5rm4Hk7xxULQnJnx93S4g0EIEEQRoDLo6PrWEw8Pc0eHLwYGopMTDirqlJ7eyhYYGHhfgfHCcKYksZGVB / NcXI2mw6HhZERqrjYTNPHi4tFPh8aJIYIhgPlcCRDoZLW1s75 + Z / 7 + 59nZ / OJhLWigqAoKZX6Mjf3dXkZ3pydGYLc4aEoCCkInzQ1fRobS2xuvllaonkedfArnY5OTdGVldBkOADgqq2Nr6z8CIWaJietDHOhKB + HhwFKC6Gnq4ukKJvP9zcSbjYDXbeVlkKzuZBhnnV3e3t6UOmaJO0ODibW1hB1GYkg8R / gup7Z3TVZLJ5AILW9LcZiVpYtYBhw16O3t7cauckyeF9Tgz0ATpL2 + nopmWycmbnY2LiKRjFk6 / d7 + / vRJfl4HGzV1T0UIM43MGBvaIBWK / YvwM5w + IMgGH8tkyEgvIpE7M3Nt6qqZrNyOq1kMmouh455Ggz + BhKY4GEc2CfwAAAAAElFTkSuQmCC ' , ' options ' : [ { ' name ' : ' enabled ' , ' type ' : ' enabler ' , ' default ' : False , } , { ' name ' : ' username ' , ' default ' : ' ' , } , { ' name ' : ' password ' , ' default ' : ' ' , ' type ' : ' password ' , } , { ' name ' : ' seed _ ratio ' , ' label ' : ' Seed ▁ ratio ' , ' type ' : ' float ' , ' default ' : 1 , ' description ' : ' Will ▁ not ▁ be ▁ ( re ) moved ▁ until ▁ this ▁ seed ▁ ratio ▁ is ▁ met . ' , } , { ' name ' : ' seed _ time ' , ' label ' : ' Seed ▁ time ' , ' type ' : ' int ' , ' default ' : 40 , ' description ' : ' Will ▁ not ▁ be ▁ ( re ) moved ▁ until ▁ this ▁ seed ▁ time ▁ ( in ▁ hours ) ▁ is ▁ met . ' , } , { ' name ' : ' extra _ score ' , ' advanced ' : True , ' label ' : ' Extra ▁ Score ' , ' type ' : ' int ' , ' default ' : 20 , ' description ' : ' Starting ▁ score ▁ for ▁ each ▁ release ▁ found ▁ via ▁ this ▁ provider . ' , } ] , } , ] , } ] NEW_LINE
 import base64 NEW_LINE import binascii NEW_LINE import functools NEW_LINE import hashlib NEW_LINE import importlib NEW_LINE import warnings NEW_LINE from collections import OrderedDict NEW_LINE from django . conf import settings NEW_LINE from django . core . exceptions import ImproperlyConfigured NEW_LINE from django . core . signals import setting_changed NEW_LINE from django . dispatch import receiver NEW_LINE from django . utils . crypto import ( constant_time_compare , get_random_string , pbkdf2 , ) NEW_LINE from django . utils . encoding import force_bytes , force_text NEW_LINE from django . utils . module_loading import import_string NEW_LINE from django . utils . translation import gettext_noop as _ NEW_LINE UNUSABLE_PASSWORD_PREFIX = ' ! ' NEW_LINE UNUSABLE_PASSWORD_SUFFIX_LENGTH = 40 NEW_LINE def is_password_usable ( encoded ) : NEW_LINE INDENT if encoded is None or encoded . startswith ( UNUSABLE_PASSWORD_PREFIX ) : NEW_LINE INDENT return False NEW_LINE DEDENT try : NEW_LINE INDENT identify_hasher ( encoded ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE DEDENT def check_password ( password , encoded , setter = None , preferred = ' default ' ) : NEW_LINE INDENT if password is None or not is_password_usable ( encoded ) : NEW_LINE INDENT return False NEW_LINE DEDENT preferred = get_hasher ( preferred ) NEW_LINE hasher = identify_hasher ( encoded ) NEW_LINE hasher_changed = hasher . algorithm != preferred . algorithm NEW_LINE must_update = hasher_changed or preferred . must_update ( encoded ) NEW_LINE is_correct = hasher . verify ( password , encoded ) NEW_LINE if not is_correct and not hasher_changed and must_update : NEW_LINE INDENT hasher . harden_runtime ( password , encoded ) NEW_LINE DEDENT if setter and is_correct and must_update : NEW_LINE INDENT setter ( password ) NEW_LINE DEDENT return is_correct NEW_LINE DEDENT def make_password ( password , salt = None , hasher = ' default ' ) : NEW_LINE INDENT if password is None : NEW_LINE INDENT return UNUSABLE_PASSWORD_PREFIX + get_random_string ( UNUSABLE_PASSWORD_SUFFIX_LENGTH ) NEW_LINE DEDENT hasher = get_hasher ( hasher ) NEW_LINE if not salt : NEW_LINE INDENT salt = hasher . salt ( ) NEW_LINE DEDENT return hasher . encode ( password , salt ) NEW_LINE DEDENT @ functools . lru_cache ( ) NEW_LINE def get_hashers ( ) : NEW_LINE INDENT hashers = [ ] NEW_LINE for hasher_path in settings . PASSWORD_HASHERS : NEW_LINE INDENT hasher_cls = import_string ( hasher_path ) NEW_LINE hasher = hasher_cls ( ) NEW_LINE if not getattr ( hasher , ' algorithm ' ) : NEW_LINE INDENT raise ImproperlyConfigured ( " hasher ▁ doesn ' t ▁ specify ▁ an ▁ " " algorithm ▁ name : ▁ % s " % hasher_path ) NEW_LINE DEDENT hashers . append ( hasher ) NEW_LINE DEDENT return hashers NEW_LINE DEDENT @ functools . lru_cache ( ) NEW_LINE def get_hashers_by_algorithm ( ) : NEW_LINE INDENT return { hasher . algorithm : hasher for hasher in get_hashers ( ) } NEW_LINE DEDENT @ receiver ( setting_changed ) NEW_LINE def reset_hashers ( ** kwargs ) : NEW_LINE INDENT if kwargs [ ' setting ' ] == ' PASSWORD _ HASHERS ' : NEW_LINE INDENT get_hashers . cache_clear ( ) NEW_LINE get_hashers_by_algorithm . cache_clear ( ) NEW_LINE DEDENT DEDENT def get_hasher ( algorithm = ' default ' ) : NEW_LINE INDENT if hasattr ( algorithm , ' algorithm ' ) : NEW_LINE INDENT return algorithm NEW_LINE DEDENT elif algorithm == ' default ' : NEW_LINE INDENT return get_hashers ( ) [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT hashers = get_hashers_by_algorithm ( ) NEW_LINE try : NEW_LINE INDENT return hashers [ algorithm ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise ValueError ( " Unknown ▁ password ▁ hashing ▁ algorithm ▁ ' % s ' . ▁ " " Did ▁ you ▁ specify ▁ it ▁ in ▁ the ▁ PASSWORD _ HASHERS ▁ " " setting ? " % algorithm ) NEW_LINE DEDENT DEDENT DEDENT def identify_hasher ( encoded ) : NEW_LINE INDENT if ( ( len ( encoded ) == 32 and ' $ ' not in encoded ) or ( len ( encoded ) == 37 and encoded . startswith ( ' md5 $ $ ' ) ) ) : NEW_LINE INDENT algorithm = ' unsalted _ md5' NEW_LINE DEDENT elif len ( encoded ) == 46 and encoded . startswith ( ' sha1 $ $ ' ) : NEW_LINE INDENT algorithm = ' unsalted _ sha1' NEW_LINE DEDENT else : NEW_LINE INDENT algorithm = encoded . split ( ' $ ' , 1 ) [ 0 ] NEW_LINE DEDENT return get_hasher ( algorithm ) NEW_LINE DEDENT def mask_hash ( hash , show = 6 , char = " * " ) : NEW_LINE INDENT masked = hash [ : show ] NEW_LINE masked += char * len ( hash [ show : ] ) NEW_LINE return masked NEW_LINE DEDENT class BasePasswordHasher : NEW_LINE INDENT algorithm = None NEW_LINE library = None NEW_LINE def _load_library ( self ) : NEW_LINE INDENT if self . library is not None : NEW_LINE INDENT if isinstance ( self . library , ( tuple , list ) ) : NEW_LINE INDENT name , mod_path = self . library NEW_LINE DEDENT else : NEW_LINE INDENT mod_path = self . library NEW_LINE DEDENT try : NEW_LINE INDENT module = importlib . import_module ( mod_path ) NEW_LINE DEDENT except ImportError as e : NEW_LINE INDENT raise ValueError ( " Couldn ' t ▁ load ▁ % r ▁ algorithm ▁ library : ▁ % s " % ( self . __class__ . __name__ , e ) ) NEW_LINE DEDENT return module NEW_LINE DEDENT raise ValueError ( " Hasher ▁ % r ▁ doesn ' t ▁ specify ▁ a ▁ library ▁ attribute " % self . __class__ . __name__ ) NEW_LINE DEDENT def salt ( self ) : NEW_LINE INDENT return get_random_string ( ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ a ▁ verify ( ) ▁ method ' ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ an ▁ encode ( ) ▁ method ' ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT raise NotImplementedError ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ must ▁ provide ▁ a ▁ safe _ summary ( ) ▁ method ' ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT return False NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT warnings . warn ( ' subclasses ▁ of ▁ BasePasswordHasher ▁ should ▁ provide ▁ a ▁ harden _ runtime ( ) ▁ method ' ) NEW_LINE DEDENT DEDENT class PBKDF2PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT algorithm = " pbkdf2 _ sha256" NEW_LINE iterations = 100000 NEW_LINE digest = hashlib . sha256 NEW_LINE def encode ( self , password , salt , iterations = None ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE if not iterations : NEW_LINE INDENT iterations = self . iterations NEW_LINE DEDENT hash = pbkdf2 ( password , salt , iterations , digest = self . digest ) NEW_LINE hash = base64 . b64encode ( hash ) . decode ( ' ascii ' ) . strip ( ) NEW_LINE return " % s $ % d $ % s $ % s " % ( self . algorithm , iterations , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt , int ( iterations ) ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' iterations ' ) , iterations ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE return int ( iterations ) != self . iterations NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT algorithm , iterations , salt , hash = encoded . split ( ' $ ' , 3 ) NEW_LINE extra_iterations = self . iterations - int ( iterations ) NEW_LINE if extra_iterations > 0 : NEW_LINE INDENT self . encode ( password , salt , extra_iterations ) NEW_LINE DEDENT DEDENT DEDENT class PBKDF2SHA1PasswordHasher ( PBKDF2PasswordHasher ) : NEW_LINE INDENT algorithm = " pbkdf2 _ sha1" NEW_LINE digest = hashlib . sha1 NEW_LINE DEDENT class Argon2PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT algorithm = ' argon2' NEW_LINE library = ' argon2' NEW_LINE time_cost = 2 NEW_LINE memory_cost = 512 NEW_LINE parallelism = 2 NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT argon2 = self . _load_library ( ) NEW_LINE data = argon2 . low_level . hash_secret ( force_bytes ( password ) , force_bytes ( salt ) , time_cost = self . time_cost , memory_cost = self . memory_cost , parallelism = self . parallelism , hash_len = argon2 . DEFAULT_HASH_LENGTH , type = argon2 . low_level . Type . I , ) NEW_LINE return self . algorithm + data . decode ( ' ascii ' ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT argon2 = self . _load_library ( ) NEW_LINE algorithm , rest = encoded . split ( ' $ ' , 1 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE try : NEW_LINE INDENT return argon2 . low_level . verify_secret ( force_bytes ( ' $ ' + rest ) , force_bytes ( password ) , type = argon2 . low_level . Type . I , ) NEW_LINE DEDENT except argon2 . exceptions . VerificationError : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data ) = self . _decode ( encoded ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' variety ' ) , variety ) , ( _ ( ' version ' ) , version ) , ( _ ( ' memory ▁ cost ' ) , memory_cost ) , ( _ ( ' time ▁ cost ' ) , time_cost ) , ( _ ( ' parallelism ' ) , parallelism ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' hash ' ) , mask_hash ( data ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data ) = self . _decode ( encoded ) NEW_LINE assert algorithm == self . algorithm NEW_LINE argon2 = self . _load_library ( ) NEW_LINE return ( argon2 . low_level . ARGON2_VERSION != version or self . time_cost != time_cost or self . memory_cost != memory_cost or self . parallelism != parallelism ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT def _decode ( self , encoded ) : NEW_LINE INDENT bits = encoded . split ( ' $ ' ) NEW_LINE if len ( bits ) == 5 : NEW_LINE INDENT algorithm , variety , raw_params , salt , data = bits NEW_LINE version = 0x10 NEW_LINE DEDENT else : NEW_LINE INDENT assert len ( bits ) == 6 NEW_LINE algorithm , variety , raw_version , raw_params , salt , data = bits NEW_LINE assert raw_version . startswith ( ' v = ' ) NEW_LINE version = int ( raw_version [ len ( ' v = ' ) : ] ) NEW_LINE DEDENT params = dict ( bit . split ( ' = ' , 1 ) for bit in raw_params . split ( ' , ' ) ) NEW_LINE assert len ( params ) == 3 and all ( x in params for x in ( ' t ' , ' m ' , ' p ' ) ) NEW_LINE time_cost = int ( params [ ' t ' ] ) NEW_LINE memory_cost = int ( params [ ' m ' ] ) NEW_LINE parallelism = int ( params [ ' p ' ] ) NEW_LINE return ( algorithm , variety , version , time_cost , memory_cost , parallelism , salt , data , ) NEW_LINE DEDENT DEDENT class BCryptSHA256PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT algorithm = " bcrypt _ sha256" NEW_LINE digest = hashlib . sha256 NEW_LINE library = ( " bcrypt " , " bcrypt " ) NEW_LINE rounds = 12 NEW_LINE def salt ( self ) : NEW_LINE INDENT bcrypt = self . _load_library ( ) NEW_LINE return bcrypt . gensalt ( self . rounds ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT bcrypt = self . _load_library ( ) NEW_LINE if self . digest is not None : NEW_LINE INDENT password = binascii . hexlify ( self . digest ( force_bytes ( password ) ) . digest ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT password = force_bytes ( password ) NEW_LINE DEDENT data = bcrypt . hashpw ( password , salt ) NEW_LINE return " % s $ % s " % ( self . algorithm , force_text ( data ) ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , data = encoded . split ( ' $ ' , 1 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , force_bytes ( data ) ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , empty , algostr , work_factor , data = encoded . split ( ' $ ' , 4 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE salt , checksum = data [ : 22 ] , data [ 22 : ] NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' work ▁ factor ' ) , work_factor ) , ( _ ( ' salt ' ) , mask_hash ( salt ) ) , ( _ ( ' checksum ' ) , mask_hash ( checksum ) ) , ] ) NEW_LINE DEDENT def must_update ( self , encoded ) : NEW_LINE INDENT algorithm , empty , algostr , rounds , data = encoded . split ( ' $ ' , 4 ) NEW_LINE return int ( rounds ) != self . rounds NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT _ , data = encoded . split ( ' $ ' , 1 ) NEW_LINE salt = data [ : 29 ] NEW_LINE rounds = data . split ( ' $ ' ) [ 2 ] NEW_LINE diff = 2 ** ( self . rounds - int ( rounds ) ) - 1 NEW_LINE while diff > 0 : NEW_LINE INDENT self . encode ( password , force_bytes ( salt ) ) NEW_LINE diff -= 1 NEW_LINE DEDENT DEDENT DEDENT class BCryptPasswordHasher ( BCryptSHA256PasswordHasher ) : NEW_LINE INDENT algorithm = " bcrypt " NEW_LINE digest = None NEW_LINE DEDENT class SHA1PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT algorithm = " sha1" NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE hash = hashlib . sha1 ( force_bytes ( salt + password ) ) . hexdigest ( ) NEW_LINE return " % s $ % s $ % s " % ( self . algorithm , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , mask_hash ( salt , show = 2 ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class MD5PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT algorithm = " md5" NEW_LINE def encode ( self , password , salt ) : NEW_LINE INDENT assert password is not None NEW_LINE assert salt and ' $ ' not in salt NEW_LINE hash = hashlib . md5 ( force_bytes ( salt + password ) ) . hexdigest ( ) NEW_LINE return " % s $ % s $ % s " % ( self . algorithm , salt , hash ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE encoded_2 = self . encode ( password , salt ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , hash = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , mask_hash ( salt , show = 2 ) ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class UnsaltedSHA1PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT algorithm = " unsalted _ sha1" NEW_LINE def salt ( self ) : NEW_LINE INDENT return ' ' NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT assert salt == ' ' NEW_LINE hash = hashlib . sha1 ( force_bytes ( password ) ) . hexdigest ( ) NEW_LINE return ' sha1 $ $ % s ' % hash NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT encoded_2 = self . encode ( password , ' ' ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT assert encoded . startswith ( ' sha1 $ $ ' ) NEW_LINE hash = encoded [ 6 : ] NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , self . algorithm ) , ( _ ( ' hash ' ) , mask_hash ( hash ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class UnsaltedMD5PasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT algorithm = " unsalted _ md5" NEW_LINE def salt ( self ) : NEW_LINE INDENT return ' ' NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT assert salt == ' ' NEW_LINE return hashlib . md5 ( force_bytes ( password ) ) . hexdigest ( ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT if len ( encoded ) == 37 and encoded . startswith ( ' md5 $ $ ' ) : NEW_LINE INDENT encoded = encoded [ 5 : ] NEW_LINE DEDENT encoded_2 = self . encode ( password , ' ' ) NEW_LINE return constant_time_compare ( encoded , encoded_2 ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT return OrderedDict ( [ ( _ ( ' algorithm ' ) , self . algorithm ) , ( _ ( ' hash ' ) , mask_hash ( encoded , show = 3 ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class CryptPasswordHasher ( BasePasswordHasher ) : NEW_LINE INDENT algorithm = " crypt " NEW_LINE library = " crypt " NEW_LINE def salt ( self ) : NEW_LINE INDENT return get_random_string ( 2 ) NEW_LINE DEDENT def encode ( self , password , salt ) : NEW_LINE INDENT crypt = self . _load_library ( ) NEW_LINE assert len ( salt ) == 2 NEW_LINE data = crypt . crypt ( password , salt ) NEW_LINE assert data is not None NEW_LINE return " % s $ % s $ % s " % ( self . algorithm , ' ' , data ) NEW_LINE DEDENT def verify ( self , password , encoded ) : NEW_LINE INDENT crypt = self . _load_library ( ) NEW_LINE algorithm , salt , data = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return constant_time_compare ( data , crypt . crypt ( password , data ) ) NEW_LINE DEDENT def safe_summary ( self , encoded ) : NEW_LINE INDENT algorithm , salt , data = encoded . split ( ' $ ' , 2 ) NEW_LINE assert algorithm == self . algorithm NEW_LINE return OrderedDict ( [ ( _ ( ' algorithm ' ) , algorithm ) , ( _ ( ' salt ' ) , salt ) , ( _ ( ' hash ' ) , mask_hash ( data , show = 3 ) ) , ] ) NEW_LINE DEDENT def harden_runtime ( self , password , encoded ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT
 from pyexiv2 . metadata import ImageMetadata NEW_LINE import unittest NEW_LINE import testutils NEW_LINE import os NEW_LINE import tempfile NEW_LINE from testutils import EMPTY_JPG_DATA NEW_LINE class TestUserCommentReadWrite ( unittest . TestCase ) : NEW_LINE INDENT checksums = { ' usercomment - ascii . jpg ' : ' ad29ac65fb6f63c8361aaed6cb02f8c7' , ' usercomment - unicode - ii . jpg ' : '13b7cc09129a8677f2cf18634f5abd3c ' , ' usercomment - unicode - mm . jpg ' : '7addfed7823c556ba489cd4ab2037200' , } NEW_LINE def _read_image ( self , filename ) : NEW_LINE INDENT filepath = testutils . get_absolute_file_path ( os . path . join ( ' data ' , filename ) ) NEW_LINE self . assert_ ( testutils . CheckFileSum ( filepath , self . checksums [ filename ] ) ) NEW_LINE m = ImageMetadata ( filepath ) NEW_LINE m . read ( ) NEW_LINE return m NEW_LINE DEDENT def _expected_raw_value ( self , endianness , value ) : NEW_LINE INDENT from pyexiv2 import __exiv2_version__ NEW_LINE if __exiv2_version__ >= '0.20' : NEW_LINE INDENT return value NEW_LINE DEDENT else : NEW_LINE INDENT encodings = { ' ii ' : ' utf - 16le ' , ' mm ' : ' utf - 16be ' } NEW_LINE return value . decode ( ' utf - 8' ) . encode ( encodings [ endianness ] ) NEW_LINE DEDENT DEDENT def test_read_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Ascii " ▁ deja ▁ vu ' ) NEW_LINE self . assertEqual ( tag . value , u' deja ▁ vu' ) NEW_LINE DEDENT def test_read_unicode_little_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - ii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' ii ' , ' déjà ▁ vu ' ) ) NEW_LINE self . assertEqual ( tag . value , u' déjà ▁ vu' ) NEW_LINE DEDENT def test_read_unicode_big_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - mm . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' mm ' , ' déjà ▁ vu ' ) ) NEW_LINE self . assertEqual ( tag . value , u' déjà ▁ vu' ) NEW_LINE DEDENT def test_write_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = ' foo ▁ bar ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Ascii " ▁ foo ▁ bar ' ) NEW_LINE self . assertEqual ( tag . value , u' foo ▁ bar ' ) NEW_LINE DEDENT def test_write_unicode_over_ascii ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - ascii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u' déjà ▁ vu' NEW_LINE self . assertEqual ( tag . raw_value , ' déjà ▁ vu ' ) NEW_LINE self . assertEqual ( tag . value , u' déjà ▁ vu' ) NEW_LINE DEDENT def test_write_unicode_little_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - ii . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u' DÉJÀ ▁ VU ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' ii ' , ' DÉJÀ ▁ VU ' ) ) NEW_LINE self . assertEqual ( tag . value , u' DÉJÀ ▁ VU ' ) NEW_LINE DEDENT def test_write_unicode_big_endian ( self ) : NEW_LINE INDENT m = self . _read_image ( ' usercomment - unicode - mm . jpg ' ) NEW_LINE tag = m [ ' Exif . Photo . UserComment ' ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE tag . value = u' DÉJÀ ▁ VU ' NEW_LINE self . assertEqual ( tag . raw_value , ' charset = " Unicode " ▁ % s ' % self . _expected_raw_value ( ' mm ' , ' DÉJÀ ▁ VU ' ) ) NEW_LINE self . assertEqual ( tag . value , u' DÉJÀ ▁ VU ' ) NEW_LINE DEDENT DEDENT class TestUserCommentAdd ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT fd , self . pathname = tempfile . mkstemp ( suffix = ' . jpg ' ) NEW_LINE os . write ( fd , EMPTY_JPG_DATA ) NEW_LINE os . close ( fd ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT os . remove ( self . pathname ) NEW_LINE DEDENT def _test_add_comment ( self , value ) : NEW_LINE INDENT metadata = ImageMetadata ( self . pathname ) NEW_LINE metadata . read ( ) NEW_LINE key = ' Exif . Photo . UserComment ' NEW_LINE metadata [ key ] = value NEW_LINE metadata . write ( ) NEW_LINE metadata = ImageMetadata ( self . pathname ) NEW_LINE metadata . read ( ) NEW_LINE self . assert_ ( key in metadata . exif_keys ) NEW_LINE tag = metadata [ key ] NEW_LINE self . assertEqual ( tag . type , ' Comment ' ) NEW_LINE self . assertEqual ( tag . value , value ) NEW_LINE DEDENT def test_add_comment_ascii ( self ) : NEW_LINE INDENT self . _test_add_comment ( ' deja ▁ vu ' ) NEW_LINE DEDENT def test_add_comment_unicode ( self ) : NEW_LINE INDENT self . _test_add_comment ( u' déjà ▁ vu' ) NEW_LINE DEDENT DEDENT
 from __future__ import division , print_function , absolute_import NEW_LINE import warnings NEW_LINE import numpy as np NEW_LINE from numpy . testing import ( assert_equal , assert_almost_equal , assert_array_equal , assert_array_almost_equal , assert_allclose , assert_raises , TestCase , run_module_suite ) NEW_LINE from numpy import array , diff , linspace , meshgrid , ones , pi , shape NEW_LINE from scipy . interpolate . fitpack import bisplrep , bisplev NEW_LINE from scipy . interpolate . fitpack2 import ( UnivariateSpline , LSQUnivariateSpline , InterpolatedUnivariateSpline , LSQBivariateSpline , SmoothBivariateSpline , RectBivariateSpline , LSQSphereBivariateSpline , SmoothSphereBivariateSpline , RectSphereBivariateSpline ) NEW_LINE class TestUnivariateSpline ( TestCase ) : NEW_LINE INDENT def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 3 , 3 , 3 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , [ 1 , 3 ] ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 3 , 3 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] ) , [ 3 , 3 , 3 ] ) NEW_LINE DEDENT def test_preserve_shape ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 0 , 2 , 4 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE arg = 2 NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg ) ) ) NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg , nu = 1 ) ) ) NEW_LINE arg = [ 1.5 , 2 , 2.5 ] NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg ) ) ) NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg , nu = 1 ) ) ) NEW_LINE DEDENT def test_linear_1d ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 0 , 2 , 4 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , [ 1 , 3 ] ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 0 , 4 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] ) , [ 0 , 1 , 2 ] ) NEW_LINE DEDENT def test_subclassing ( self ) : NEW_LINE INDENT class ZeroSpline ( UnivariateSpline ) : NEW_LINE INDENT def __call__ ( self , x ) : NEW_LINE INDENT return 0 * array ( x ) NEW_LINE DEDENT DEDENT sp = ZeroSpline ( [ 1 , 2 , 3 , 4 , 5 ] , [ 3 , 2 , 3 , 2 , 3 ] , k = 2 ) NEW_LINE assert_array_equal ( sp ( [ 1.5 , 2.5 ] ) , [ 0. , 0. ] ) NEW_LINE DEDENT def test_empty_input ( self ) : NEW_LINE INDENT x = [ 1 , 3 , 5 , 7 , 9 ] NEW_LINE y = [ 0 , 4 , 9 , 12 , 21 ] NEW_LINE spl = UnivariateSpline ( x , y , k = 3 ) NEW_LINE assert_array_equal ( spl ( [ ] ) , array ( [ ] ) ) NEW_LINE DEDENT def test_resize_regression ( self ) : NEW_LINE INDENT x = [ - 1. , - 0.65016502 , - 0.58856235 , - 0.26903553 , - 0.17370892 , - 0.10011001 , 0. , 0.10011001 , 0.17370892 , 0.26903553 , 0.58856235 , 0.65016502 , 1. ] NEW_LINE y = [ 1. , 0.62928599 , 0.5797223 , 0.39965815 , 0.36322694 , 0.3508061 , 0.35214793 , 0.3508061 , 0.36322694 , 0.39965815 , 0.5797223 , 0.62928599 , 1. ] NEW_LINE w = [ 1.00000000e+12 , 6.88875973e+02 , 4.89314737e+02 , 4.26864807e+02 , 6.07746770e+02 , 4.51341444e+02 , 3.17480210e+02 , 4.51341444e+02 , 6.07746770e+02 , 4.26864807e+02 , 4.89314737e+02 , 6.88875973e+02 , 1.00000000e+12 ] NEW_LINE spl = UnivariateSpline ( x = x , y = y , w = w , s = None ) NEW_LINE desired = array ( [ 0.35100374 , 0.51715855 , 0.87789547 , 0.98719344 ] ) NEW_LINE assert_allclose ( spl ( [ 0.1 , 0.5 , 0.9 , 0.99 ] ) , desired , atol = 5e-4 ) NEW_LINE DEDENT def test_out_of_range_regression ( self ) : NEW_LINE INDENT x = np . arange ( 5 , dtype = float ) NEW_LINE y = x ** 3 NEW_LINE xp = linspace ( - 8 , 13 , 100 ) NEW_LINE xp_zeros = xp . copy ( ) NEW_LINE xp_zeros [ np . logical_or ( xp_zeros < 0. , xp_zeros > 4. ) ] = 0 NEW_LINE xp_clip = xp . copy ( ) NEW_LINE xp_clip [ xp_clip < x [ 0 ] ] = x [ 0 ] NEW_LINE xp_clip [ xp_clip > x [ - 1 ] ] = x [ - 1 ] NEW_LINE for cls in [ UnivariateSpline , InterpolatedUnivariateSpline ] : NEW_LINE INDENT spl = cls ( x = x , y = y ) NEW_LINE for ext in [ 0 , ' extrapolate ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp ** 3 , atol = 1e-16 ) NEW_LINE DEDENT for ext in [ 1 , ' zeros ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE DEDENT for ext in [ 2 , ' raise ' ] : NEW_LINE INDENT assert_raises ( ValueError , spl , xp , ** dict ( ext = ext ) ) NEW_LINE DEDENT for ext in [ 3 , ' const ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE DEDENT DEDENT t = spl . get_knots ( ) [ 3 : 4 ] NEW_LINE spl = LSQUnivariateSpline ( x , y , t ) NEW_LINE assert_allclose ( spl ( xp , ext = 0 ) , xp ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( spl ( xp , ext = 1 ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE assert_raises ( ValueError , spl , xp , ** dict ( ext = 2 ) ) NEW_LINE assert_allclose ( spl ( xp , ext = 3 ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE for ext in [ - 1 , ' unknown ' ] : NEW_LINE INDENT spl = UnivariateSpline ( x , y ) NEW_LINE assert_raises ( ValueError , spl , xp , ** dict ( ext = ext ) ) NEW_LINE assert_raises ( ValueError , UnivariateSpline , ** dict ( x = x , y = y , ext = ext ) ) NEW_LINE DEDENT DEDENT def test_lsq_fpchec ( self ) : NEW_LINE INDENT xs = np . arange ( 100 ) * 1. NEW_LINE ys = np . arange ( 100 ) * 1. NEW_LINE knots = np . linspace ( 0 , 99 , 10 ) NEW_LINE bbox = ( - 1 , 101 ) NEW_LINE assert_raises ( ValueError , LSQUnivariateSpline , xs , ys , knots , bbox = bbox ) NEW_LINE DEDENT def test_derivative_and_antiderivative ( self ) : NEW_LINE INDENT x = np . linspace ( 0 , 1 , 70 ) ** 3 NEW_LINE y = np . cos ( x ) NEW_LINE spl = UnivariateSpline ( x , y , s = 0 ) NEW_LINE spl2 = spl . antiderivative ( 2 ) . derivative ( 2 ) NEW_LINE assert_allclose ( spl ( 0.3 ) , spl2 ( 0.3 ) ) NEW_LINE spl2 = spl . antiderivative ( 1 ) NEW_LINE assert_allclose ( spl2 ( 0.6 ) - spl2 ( 0.2 ) , spl . integral ( 0.2 , 0.6 ) ) NEW_LINE DEDENT def test_nan ( self ) : NEW_LINE INDENT x = np . arange ( 10 , dtype = float ) NEW_LINE y = x ** 3 NEW_LINE for z in [ np . nan , np . inf , - np . inf ] : NEW_LINE INDENT y [ - 1 ] = z NEW_LINE assert_raises ( ValueError , UnivariateSpline , ** dict ( x = x , y = y , check_finite = True ) ) NEW_LINE DEDENT DEDENT DEDENT class TestLSQBivariateSpline ( TestCase ) : NEW_LINE INDENT def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT assert_almost_equal ( lut ( 2 , 2 ) , 3. ) NEW_LINE DEDENT def test_bilinearity ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( ) : NEW_LINE INDENT warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT tx , ty = lut . get_knots ( ) NEW_LINE for xa , xb in zip ( tx [ : - 1 ] , tx [ 1 : ] ) : NEW_LINE INDENT for ya , yb in zip ( ty [ : - 1 ] , ty [ 1 : ] ) : NEW_LINE INDENT for t in [ 0.1 , 0.5 , 0.9 ] : NEW_LINE INDENT for s in [ 0.3 , 0.4 , 0.7 ] : NEW_LINE INDENT xp = xa * ( 1 - t ) + xb * t NEW_LINE yp = ya * ( 1 - s ) + yb * s NEW_LINE zp = ( + lut ( xa , ya ) * ( 1 - t ) * ( 1 - s ) + lut ( xb , ya ) * t * ( 1 - s ) + lut ( xa , yb ) * ( 1 - t ) * s + lut ( xb , yb ) * t * s ) NEW_LINE assert_almost_equal ( lut ( xp , yp ) , zp ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def test_integral ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 8 , 8 , 8 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = array ( [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] ) NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT tx , ty = lut . get_knots ( ) NEW_LINE tz = lut ( tx , ty ) NEW_LINE trpz = .25 * ( diff ( tx ) [ : , None ] * diff ( ty ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz ) NEW_LINE DEDENT def test_empty_input ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT assert_array_equal ( lut ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_equal ( lut ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT DEDENT class TestSmoothBivariateSpline ( TestCase ) : NEW_LINE INDENT def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , ( [ 1 , 1 , 3 , 3 ] , [ 1 , 1 , 3 , 3 ] ) ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 3 , 3 , 3 , 3 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 3 , 3 ] , [ 3 , 3 ] , [ 3 , 3 ] ] ) NEW_LINE DEDENT def test_linear_1d ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 0 , 0 , 0 , 2 , 2 , 2 , 4 , 4 , 4 ] NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , ( [ 1 , 1 , 3 , 3 ] , [ 1 , 1 , 3 , 3 ] ) ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 0 , 0 , 4 , 4 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 0 , 0 ] , [ 1 , 1 ] , [ 2 , 2 ] ] ) NEW_LINE DEDENT def test_integral ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 4 , 4 , 4 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = array ( [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] ) NEW_LINE with warnings . catch_warnings ( ) : NEW_LINE INDENT warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 , s = 0 ) NEW_LINE DEDENT tx = [ 1 , 2 , 4 ] NEW_LINE ty = [ 1 , 2 , 3 ] NEW_LINE tz = lut ( tx , ty ) NEW_LINE trpz = .25 * ( diff ( tx ) [ : , None ] * diff ( ty ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz ) NEW_LINE lut2 = SmoothBivariateSpline ( x , y , z , kx = 2 , ky = 2 , s = 0 ) NEW_LINE assert_almost_equal ( lut2 . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz , decimal = 0 ) NEW_LINE tz = lut ( tx [ : - 1 ] , ty [ : - 1 ] ) NEW_LINE trpz = .25 * ( diff ( tx [ : - 1 ] ) [ : , None ] * diff ( ty [ : - 1 ] ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 2 ] , ty [ 0 ] , ty [ - 2 ] ) , trpz ) NEW_LINE DEDENT def test_rerun_lwrk2_too_small ( self ) : NEW_LINE INDENT x = np . linspace ( - 2 , 2 , 80 ) NEW_LINE y = np . linspace ( - 2 , 2 , 80 ) NEW_LINE z = x + y NEW_LINE xi = np . linspace ( - 1 , 1 , 100 ) NEW_LINE yi = np . linspace ( - 2 , 2 , 100 ) NEW_LINE tck = bisplrep ( x , y , z ) NEW_LINE res1 = bisplev ( xi , yi , tck ) NEW_LINE interp_ = SmoothBivariateSpline ( x , y , z ) NEW_LINE res2 = interp_ ( xi , yi ) NEW_LINE assert_almost_equal ( res1 , res2 ) NEW_LINE DEDENT DEDENT class TestLSQSphereBivariateSpline ( TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT ntheta , nphi = 70 , 90 NEW_LINE theta = linspace ( 0.5 / ( ntheta - 1 ) , 1 - 0.5 / ( ntheta - 1 ) , ntheta ) * pi NEW_LINE phi = linspace ( 0.5 / ( nphi - 1 ) , 1 - 0.5 / ( nphi - 1 ) , nphi ) * 2. * pi NEW_LINE data = ones ( ( theta . shape [ 0 ] , phi . shape [ 0 ] ) ) NEW_LINE knotst = theta [ : : 5 ] NEW_LINE knotsp = phi [ : : 5 ] NEW_LINE knotdata = data [ : : 5 , : : 5 ] NEW_LINE lats , lons = meshgrid ( theta , phi ) NEW_LINE lut_lsq = LSQSphereBivariateSpline ( lats . ravel ( ) , lons . ravel ( ) , data . T . ravel ( ) , knotst , knotsp ) NEW_LINE self . lut_lsq = lut_lsq NEW_LINE self . data = knotdata NEW_LINE self . new_lons , self . new_lats = knotsp , knotst NEW_LINE DEDENT def test_linear_constant ( self ) : NEW_LINE INDENT assert_almost_equal ( self . lut_lsq . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( self . lut_lsq ( self . new_lats , self . new_lons ) , self . data ) NEW_LINE DEDENT def test_empty_input ( self ) : NEW_LINE INDENT assert_array_almost_equal ( self . lut_lsq ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_almost_equal ( self . lut_lsq ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT DEDENT class TestSmoothSphereBivariateSpline ( TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT theta = array ( [ .25 * pi , .25 * pi , .25 * pi , .5 * pi , .5 * pi , .5 * pi , .75 * pi , .75 * pi , .75 * pi ] ) NEW_LINE phi = array ( [ .5 * pi , pi , 1.5 * pi , .5 * pi , pi , 1.5 * pi , .5 * pi , pi , 1.5 * pi ] ) NEW_LINE r = array ( [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] ) NEW_LINE self . lut = SmoothSphereBivariateSpline ( theta , phi , r , s = 1E10 ) NEW_LINE DEDENT def test_linear_constant ( self ) : NEW_LINE INDENT assert_almost_equal ( self . lut . get_residual ( ) , 0. ) NEW_LINE assert_array_almost_equal ( self . lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 3 , 3 ] , [ 3 , 3 ] , [ 3 , 3 ] ] ) NEW_LINE DEDENT def test_empty_input ( self ) : NEW_LINE INDENT assert_array_almost_equal ( self . lut ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_almost_equal ( self . lut ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT DEDENT class TestRectBivariateSpline ( TestCase ) : NEW_LINE INDENT def test_defaults ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y ) , z ) NEW_LINE DEDENT def test_evaluate ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE xi = [ 1 , 2.3 , 5.3 , 0.5 , 3.3 , 1.2 , 3 ] NEW_LINE yi = [ 1 , 3.3 , 1.2 , 4.0 , 5.0 , 1.0 , 3 ] NEW_LINE zi = lut . ev ( xi , yi ) NEW_LINE zi2 = array ( [ lut ( xp , yp ) [ 0 , 0 ] for xp , yp in zip ( xi , yi ) ] ) NEW_LINE assert_almost_equal ( zi , zi2 ) NEW_LINE DEDENT def test_derivatives_grid ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE dx = array ( [ [ 0 , 0 , - 20 , 0 , 0 ] , [ 0 , 0 , 13 , 0 , 0 ] , [ 0 , 0 , 4 , 0 , 0 ] , [ 0 , 0 , - 11 , 0 , 0 ] , [ 0 , 0 , 4 , 0 , 0 ] ] ) / 6. NEW_LINE dy = array ( [ [ 4 , - 1 , 0 , 1 , - 4 ] , [ 4 , - 1 , 0 , 1 , - 4 ] , [ 0 , 1.5 , 0 , - 1.5 , 0 ] , [ 2 , .25 , 0 , - .25 , - 2 ] , [ 4 , - 1 , 0 , 1 , - 4 ] ] ) NEW_LINE dxdy = array ( [ [ 40 , - 25 , 0 , 25 , - 40 ] , [ - 26 , 16.25 , 0 , - 16.25 , 26 ] , [ - 8 , 5 , 0 , - 5 , 8 ] , [ 22 , - 13.75 , 0 , 13.75 , - 22 ] , [ - 8 , 5 , 0 , - 5 , 8 ] ] ) / 6. NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 ) , dx ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dy = 1 ) , dy ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , dy = 1 ) , dxdy ) NEW_LINE DEDENT def test_derivatives ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE dx = array ( [ 0 , 0 , 2. / 3 , 0 , 0 ] ) NEW_LINE dy = array ( [ 4 , - 1 , 0 , - .25 , - 4 ] ) NEW_LINE dxdy = array ( [ 160 , 65 , 0 , 55 , 32 ] ) / 24. NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , grid = False ) , dx ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dy = 1 , grid = False ) , dy ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , dy = 1 , grid = False ) , dxdy ) NEW_LINE DEDENT def test_broadcast ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_allclose ( lut ( x , y ) , lut ( x [ : , None ] , y [ None , : ] , grid = False ) ) NEW_LINE DEDENT DEDENT class TestRectSphereBivariateSpline ( TestCase ) : NEW_LINE INDENT def test_defaults ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y ) , z ) NEW_LINE DEDENT def test_evaluate ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE yi = [ 0.2 , 1 , 2.3 , 2.35 , 3.0 , 3.99 , 5.25 ] NEW_LINE xi = [ 1.5 , 0.4 , 1.1 , 0.45 , 0.2345 , 1. , 0.0001 ] NEW_LINE zi = lut . ev ( xi , yi ) NEW_LINE zi2 = array ( [ lut ( xp , yp ) [ 0 , 0 ] for xp , yp in zip ( xi , yi ) ] ) NEW_LINE assert_almost_equal ( zi , zi2 ) NEW_LINE DEDENT def test_derivatives_grid ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE y = linspace ( 0.02 , 2 * pi - 0.02 , 7 ) NEW_LINE x = linspace ( 0.02 , pi - 0.02 , 7 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 ) , _numdiff_2d ( lut , x , y , dx = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dphi = 1 ) , _numdiff_2d ( lut , x , y , dy = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , dphi = 1 ) , _numdiff_2d ( lut , x , y , dx = 1 , dy = 1 , eps = 1e-6 ) , rtol = 1e-3 , atol = 1e-3 ) NEW_LINE DEDENT def test_derivatives ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE y = linspace ( 0.02 , 2 * pi - 0.02 , 7 ) NEW_LINE x = linspace ( 0.02 , pi - 0.02 , 7 ) NEW_LINE assert_equal ( lut ( x , y , dtheta = 1 , grid = False ) . shape , x . shape ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dx = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dphi = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dy = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , dphi = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dx = 1 , dy = 1 , eps = 1e-6 ) , rtol = 1e-3 , atol = 1e-3 ) NEW_LINE DEDENT DEDENT def _numdiff_2d ( func , x , y , dx = 0 , dy = 0 , eps = 1e-8 ) : NEW_LINE INDENT if dx == 0 and dy == 0 : NEW_LINE INDENT return func ( x , y ) NEW_LINE DEDENT elif dx == 1 and dy == 0 : NEW_LINE INDENT return ( func ( x + eps , y ) - func ( x - eps , y ) ) / ( 2 * eps ) NEW_LINE DEDENT elif dx == 0 and dy == 1 : NEW_LINE INDENT return ( func ( x , y + eps ) - func ( x , y - eps ) ) / ( 2 * eps ) NEW_LINE DEDENT elif dx == 1 and dy == 1 : NEW_LINE INDENT return ( func ( x + eps , y + eps ) - func ( x - eps , y + eps ) - func ( x + eps , y - eps ) + func ( x - eps , y - eps ) ) / ( 2 * eps ) ** 2 NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( " invalid ▁ derivative ▁ order " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT run_module_suite ( ) NEW_LINE DEDENT
 import os NEW_LINE import re NEW_LINE import glob NEW_LINE import struct NEW_LINE import socket NEW_LINE import logging NEW_LINE import netifaces NEW_LINE from contrail_vrouter_provisioning import local NEW_LINE log = logging . getLogger ( ' contrail _ vrouter _ provisioning . network ' ) NEW_LINE class ComputeNetworkSetup ( object ) : NEW_LINE INDENT def find_gateway ( self , dev ) : NEW_LINE INDENT gateway = ' ' NEW_LINE cmd = " sudo ▁ netstat ▁ - rn ▁ | ▁ sudo ▁ grep ▁ ^ \ " 0.0.0.0\ " ▁ | ▁ " NEW_LINE cmd += " sudo ▁ head ▁ - n ▁ 1 ▁ | ▁ sudo ▁ grep ▁ % s ▁ | ▁ sudo ▁ awk ▁ ' { ▁ print ▁ $ 2 ▁ } ' " % dev NEW_LINE gateway = local ( cmd , capture = True ) . strip ( ) NEW_LINE return gateway NEW_LINE DEDENT def get_dns_servers ( self , dev ) : NEW_LINE INDENT cmd = " sudo ▁ grep ▁ \ " ^ nameserver\\ > \ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ▁ ' { print ▁ $ 2 } ' " NEW_LINE dns_list = local ( cmd , capture = True ) NEW_LINE return dns_list . split ( ) NEW_LINE DEDENT def get_domain_search_list ( self ) : NEW_LINE INDENT domain_list = ' ' NEW_LINE cmd = " sudo ▁ grep ▁ ^ \ " search\ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ' { $ 1 = \ " \ " ; print ▁ $ 0 } ' " NEW_LINE domain_list = local ( cmd , capture = True ) . strip ( ) NEW_LINE if not domain_list : NEW_LINE INDENT cmd = " sudo ▁ grep ▁ ^ \ " domain\ " ▁ / etc / resolv . conf ▁ | ▁ " NEW_LINE cmd += " sudo ▁ awk ▁ ' { $ 1 = \ " \ " ; ▁ print ▁ $ 0 } ' " NEW_LINE domain_list = local ( cmd , capture = True ) . strip ( ) NEW_LINE DEDENT return domain_list NEW_LINE DEDENT def get_if_mtu ( self , dev ) : NEW_LINE INDENT cmd = " sudo ▁ ifconfig ▁ % s ▁ | ▁ sudo ▁ grep ▁ mtu ▁ | ▁ sudo ▁ awk ▁ ' { ▁ print ▁ $ NF ▁ } ' " % \NEW_LINE dev NEW_LINE mtu = local ( cmd , capture = True ) . strip ( ) NEW_LINE if not mtu : NEW_LINE INDENT cmd = r" sudo ▁ ifconfig ▁ % s ▁ | ▁ sudo ▁ grep ▁ MTU ▁ | ▁ " % dev NEW_LINE cmd += r" sudo ▁ sed ▁ ' s / . * MTU . \ ( [0-9 ] \ + \ ) . * / \1 / g ' " NEW_LINE mtu = local ( cmd , capture = True ) . strip ( ) NEW_LINE DEDENT if ( mtu and mtu != '1500' ) : NEW_LINE INDENT return mtu NEW_LINE DEDENT return ' ' NEW_LINE DEDENT def get_device_by_ip ( self , ip ) : NEW_LINE INDENT for i in netifaces . interfaces ( ) : NEW_LINE INDENT try : NEW_LINE INDENT if i == ' pkt1' : NEW_LINE INDENT continue NEW_LINE DEDENT if netifaces . AF_INET in netifaces . ifaddresses ( i ) : NEW_LINE INDENT interfaces = netifaces . ifaddresses ( i ) [ netifaces . AF_INET ] NEW_LINE for interface in interfaces : NEW_LINE INDENT if ip == interface [ ' addr ' ] : NEW_LINE INDENT if i == ' vhost0' : NEW_LINE INDENT log . info ( " vhost0 ▁ is ▁ already ▁ present ! " ) NEW_LINE DEDENT return i NEW_LINE DEDENT DEDENT DEDENT DEDENT except ValueError : NEW_LINE INDENT log . info ( " Skipping ▁ interface ▁ % s " , i ) NEW_LINE DEDENT DEDENT raise RuntimeError ( ' % s ▁ not ▁ configured , ▁ rerun ▁ w / ▁ - - physical _ interface ' % ip ) NEW_LINE DEDENT def get_device_info ( self , ip ) : NEW_LINE INDENT reprov = False NEW_LINE cfg_file = " / etc / contrail / contrail - vrouter - agent . conf " NEW_LINE try : NEW_LINE INDENT dev = self . get_device_by_ip ( ip ) NEW_LINE if dev == " vhost0" : NEW_LINE INDENT dev = self . get_config ( cfg_file , " VIRTUAL - HOST - INTERFACE " , " physical _ interface " ) NEW_LINE log . info ( " Re - provision . ▁ vhost0 ▁ present " ) NEW_LINE reprov = True NEW_LINE DEDENT else : NEW_LINE INDENT log . info ( " Fresh ▁ Install . ▁ vhost0 ▁ not ▁ present " ) NEW_LINE DEDENT DEDENT except RuntimeError : NEW_LINE INDENT dev = self . get_config ( cfg_file , " VIRTUAL - HOST - INTERFACE " , " physical _ interface " ) NEW_LINE if not dev . succeeded : NEW_LINE INDENT raise NEW_LINE DEDENT log . info ( " vhost0 ▁ not ▁ present , ▁ vrouter ▁ not ▁ running " ) NEW_LINE reprov = True NEW_LINE DEDENT return ( dev . strip ( ) , reprov ) NEW_LINE DEDENT def get_secondary_device ( self , primary ) : NEW_LINE INDENT for i in netifaces . interfaces ( ) : NEW_LINE INDENT try : NEW_LINE INDENT if i == ' pkt1' : NEW_LINE INDENT continue NEW_LINE DEDENT if i == primary : NEW_LINE INDENT continue NEW_LINE DEDENT if i == ' vhost0' : NEW_LINE INDENT continue NEW_LINE DEDENT if netifaces . AF_INET not in netifaces . ifaddresses ( i ) : NEW_LINE INDENT return i NEW_LINE DEDENT DEDENT except ValueError : NEW_LINE INDENT log . info ( " Skipping ▁ interface ▁ % s " % i ) NEW_LINE DEDENT DEDENT raise RuntimeError ( ' Secondary ▁ interace ▁ ▁ not ▁ configured , ' , ' rerun ▁ w / ▁ - - physical _ interface ' ) NEW_LINE DEDENT def get_if_mac ( self , dev ) : NEW_LINE INDENT iface_addr = netifaces . ifaddresses ( dev ) NEW_LINE link_info = iface_addr [ netifaces . AF_LINK ] NEW_LINE mac_addr = link_info [ 0 ] [ ' addr ' ] NEW_LINE return mac_addr NEW_LINE DEDENT @ staticmethod NEW_LINE def is_interface_vlan ( interface ) : NEW_LINE INDENT iface = local ( " sudo ▁ ip ▁ link ▁ show ▁ % s ▁ | ▁ head ▁ - 1" % interface + " | ▁ cut ▁ - f2 ▁ - d ' : ' ▁ | ▁ grep ▁ ' @ ' " , capture = True , warn_only = True ) NEW_LINE if iface . succeeded : NEW_LINE INDENT return True NEW_LINE DEDENT else : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT @ staticmethod NEW_LINE def get_physical_interface_of_vlan ( interface ) : NEW_LINE INDENT iface = local ( " sudo ▁ ip ▁ link ▁ show ▁ % s ▁ | ▁ head ▁ - 1 ▁ | ▁ cut ▁ - f2 ▁ - d ' : ' " % interface + " | ▁ cut ▁ - f2 ▁ - d ' @ ' " , capture = True ) NEW_LINE return iface NEW_LINE DEDENT def _rewrite_ifcfg_file ( self , filename , dev , prsv_cfg ) : NEW_LINE INDENT bond = False NEW_LINE mac = ' ' NEW_LINE temp_dir_name = self . _temp_dir_name NEW_LINE vlan = False NEW_LINE if os . path . isfile ( ' / proc / net / vlan / % s ' % dev ) : NEW_LINE INDENT vlan_info = open ( ' / proc / net / vlan / config ' ) . readlines ( ) NEW_LINE match = re . search ( ' ^ % s . * \ | \s + ( \S + ) $ ' % dev , " \n " . join ( vlan_info ) , flags = re . M | re . I ) NEW_LINE if not match : NEW_LINE INDENT raise RuntimeError ( " Configured ▁ vlan ▁ % s ▁ is ▁ not ▁ found ▁ in " , " / proc / net / vlan / config " % dev ) NEW_LINE DEDENT vlan = True NEW_LINE DEDENT if os . path . isdir ( ' / sys / class / net / % s / bonding ' % dev ) : NEW_LINE INDENT bond = True NEW_LINE DEDENT mac = netifaces . ifaddresses ( dev ) [ netifaces . AF_LINK ] [ 0 ] [ ' addr ' ] NEW_LINE ifcfg_file = ' / etc / sysconfig / network - scripts / ifcfg - % s ' % dev NEW_LINE if not os . path . isfile ( ifcfg_file ) : NEW_LINE INDENT ifcfg_file = temp_dir_name + ' ifcfg - ' + dev NEW_LINE with open ( ifcfg_file , ' w ' ) as f : NEW_LINE INDENT f . write ( ''' # Contrail ▁ % s STRNEWLINE TYPE = Ethernet STRNEWLINE ONBOOT = yes STRNEWLINE DEVICE = " % s " STRNEWLINE USERCTL = yes STRNEWLINE NM _ CONTROLLED = no STRNEWLINE HWADDR = % s STRNEWLINE ''' % ( dev , dev , mac ) ) NEW_LINE for dcfg in prsv_cfg : NEW_LINE INDENT f . write ( dcfg + ' \n ' ) NEW_LINE DEDENT if vlan : NEW_LINE INDENT f . write ( ' VLAN = yes \n ' ) NEW_LINE DEDENT DEDENT DEDENT fd = open ( ifcfg_file ) NEW_LINE f_lines = fd . readlines ( ) NEW_LINE fd . close ( ) NEW_LINE local ( " sudo ▁ rm ▁ - f ▁ % s " % ifcfg_file ) NEW_LINE new_f_lines = [ ] NEW_LINE remove_items = [ ' IPADDR ' , ' NETMASK ' , ' PREFIX ' , ' GATEWAY ' , ' HWADDR ' , ' DNS1' , ' DNS2' , ' BOOTPROTO ' , ' NM _ CONTROLLED ' , ' # Contrail ' ] NEW_LINE remove_items . append ( ' DEVICE ' ) NEW_LINE new_f_lines . append ( ' # Contrail ▁ % s \n ' % dev ) NEW_LINE new_f_lines . append ( ' DEVICE = % s \n ' % dev ) NEW_LINE for line in f_lines : NEW_LINE INDENT found = False NEW_LINE for text in remove_items : NEW_LINE INDENT if text in line : NEW_LINE INDENT found = True NEW_LINE DEDENT DEDENT if not found : NEW_LINE INDENT new_f_lines . append ( line ) NEW_LINE DEDENT DEDENT new_f_lines . append ( ' NM _ CONTROLLED = no \n ' ) NEW_LINE if bond : NEW_LINE INDENT new_f_lines . append ( ' SUBCHANNELS = 1,2,3 \n ' ) NEW_LINE DEDENT elif not vlan : NEW_LINE INDENT new_f_lines . append ( ' HWADDR = % s \n ' % mac ) NEW_LINE DEDENT fdw = open ( filename , ' w ' ) NEW_LINE fdw . writelines ( new_f_lines ) NEW_LINE fdw . close ( ) NEW_LINE DEDENT def migrate_routes ( self , device ) : NEW_LINE INDENT temp_dir_name = self . _temp_dir_name NEW_LINE cfg_file = ' / etc / sysconfig / network - scripts / route - vhost0' NEW_LINE tmp_file = ' % s / route - vhost0' % temp_dir_name NEW_LINE with open ( tmp_file , ' w ' ) as route_cfg_file : NEW_LINE INDENT for route in open ( ' / proc / net / route ' , ' r ' ) . readlines ( ) : NEW_LINE INDENT if route . startswith ( device ) : NEW_LINE INDENT route_fields = route . split ( ) NEW_LINE destination = int ( route_fields [ 1 ] , 16 ) NEW_LINE gateway = int ( route_fields [ 2 ] , 16 ) NEW_LINE flags = int ( route_fields [ 3 ] , 16 ) NEW_LINE mask = int ( route_fields [ 7 ] , 16 ) NEW_LINE if flags & 0x2 : NEW_LINE INDENT if destination != 0 : NEW_LINE INDENT route_cfg_file . write ( socket . inet_ntoa ( struct . pack ( ' I ' , destination ) ) ) NEW_LINE route_cfg_file . write ( ' / ' + str ( bin ( mask ) . count ( '1' ) ) + ' ▁ ' ) NEW_LINE route_cfg_file . write ( ' via ▁ ' ) NEW_LINE route_cfg_file . write ( socket . inet_ntoa ( struct . pack ( ' I ' , gateway ) ) + ' ▁ ' ) NEW_LINE route_cfg_file . write ( ' dev ▁ vhost0' ) NEW_LINE DEDENT NEW_LINE DEDENT NEW_LINE DEDENT NEW_LINE DEDENT NEW_LINE DEDENT local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( tmp_file , cfg_file ) ) NEW_LINE if os . path . isfile ( ' / etc / sysconfig / network - scripts / route - % s ' % device ) : NEW_LINE INDENT os . unlink ( ' / etc / sysconfig / network - scripts / route - % s ' % device ) NEW_LINE DEDENT DEDENT def get_cfgfile_for_dev ( self , iface , cfg_files ) : NEW_LINE INDENT if not cfg_files : NEW_LINE INDENT return None NEW_LINE DEDENT mapped_intf_cfgfile = None NEW_LINE for file in cfg_files : NEW_LINE INDENT with open ( file , ' r ' ) as fd : NEW_LINE INDENT contents = fd . read ( ) NEW_LINE regex = ' ( ? : ^ | \n ) \s * iface\s + % s\s + ' % iface NEW_LINE if re . search ( regex , contents ) : NEW_LINE INDENT mapped_intf_cfgfile = file NEW_LINE DEDENT DEDENT DEDENT return mapped_intf_cfgfile NEW_LINE DEDENT def get_sourced_files ( self ) : NEW_LINE INDENT files = self . get_valid_files ( self . get_source_entries ( ) ) NEW_LINE files += self . get_source_directory_files ( ) NEW_LINE return list ( set ( files ) ) NEW_LINE DEDENT def get_source_directory_files ( self ) : NEW_LINE INDENT regex = ' ( ? : ^ | \n ) \s * source - directory\s + ( \S + ) ' NEW_LINE files = list ( ) NEW_LINE with open ( self . default_cfg_file , ' r ' ) as fd : NEW_LINE INDENT entries = re . findall ( regex , fd . read ( ) ) NEW_LINE DEDENT dirs = [ d for d in self . get_valid_files ( entries ) if os . path . isdir ( d ) ] NEW_LINE for dir in dirs : NEW_LINE INDENT files . extend ( [ os . path . join ( dir , f ) for f in os . listdir ( dir ) if os . path . isfile ( os . path . join ( dir , f ) ) and re . match ( ' ^ [ a - zA - Z0-9 _ - ] + $ ' , f ) ] ) NEW_LINE DEDENT return files NEW_LINE DEDENT def get_source_entries ( self ) : NEW_LINE INDENT regex = ' ( ? : ^ | \n ) \s * source\s + ( \S + ) ' NEW_LINE with open ( self . default_cfg_file , ' r ' ) as fd : NEW_LINE INDENT return re . findall ( regex , fd . read ( ) ) NEW_LINE DEDENT DEDENT def get_valid_files ( self , entries ) : NEW_LINE INDENT files = list ( ) NEW_LINE prepend = os . path . join ( os . path . sep , ' etc ' , ' network ' ) + os . path . sep NEW_LINE for entry in entries : NEW_LINE INDENT entry = entry . lstrip ( ' . / ' ) if entry . startswith ( ' . / ' ) else entry NEW_LINE if entry . startswith ( os . path . sep ) : NEW_LINE INDENT entry = entry NEW_LINE DEDENT else : NEW_LINE INDENT entry = prepend + entry NEW_LINE DEDENT files . extend ( glob . glob ( entry ) ) NEW_LINE DEDENT return files NEW_LINE DEDENT def _rewrite_net_interfaces_file ( self , dev , mac , vhost_ip , netmask , gateway_ip , esxi_vm , vmpg_mtu , datapg_mtu ) : NEW_LINE INDENT self . default_cfg_file = ' / etc / network / interfaces ' NEW_LINE cfg_files = self . get_sourced_files ( ) NEW_LINE cfg_files . append ( self . default_cfg_file ) NEW_LINE intf_cfgfile = self . get_cfgfile_for_dev ( ' vhost0' , cfg_files ) NEW_LINE if intf_cfgfile : NEW_LINE INDENT log . info ( " Interface ▁ vhost0 ▁ is ▁ already ▁ present ▁ in " + " / etc / network / interfaces " ) NEW_LINE log . info ( " Skipping ▁ rewrite ▁ of ▁ this ▁ file " ) NEW_LINE return NEW_LINE DEDENT vlan = False NEW_LINE if os . path . isfile ( ' / proc / net / vlan / % s ' % dev ) : NEW_LINE INDENT vlan_info = open ( ' / proc / net / vlan / config ' ) . readlines ( ) NEW_LINE match = re . search ( ' ^ % s . * \ | \s + ( \S + ) $ ' % dev , " \n " . join ( vlan_info ) , flags = re . M | re . I ) NEW_LINE if not match : NEW_LINE INDENT raise RuntimeError ( ' Configured ▁ vlan ▁ % s ▁ is ▁ not ▁ found ▁ in ' , ' / proc / net / vlan / config ' % dev ) NEW_LINE DEDENT phydev = match . group ( 1 ) NEW_LINE vlan = True NEW_LINE DEDENT ifup_parts_file = os . path . join ( os . path . sep , ' etc ' , ' network ' , ' if - up . d ' , ' routes ' ) NEW_LINE ifdown_parts_file = os . path . join ( os . path . sep , ' etc ' , ' network ' , ' if - down . d ' , ' routes ' ) NEW_LINE if ( os . path . isfile ( ifup_parts_file ) and os . path . isfile ( ifdown_parts_file ) ) : NEW_LINE INDENT local ( " sudo ▁ sed ▁ - i ▁ ' s / % s / vhost0 / g ' ▁ % s " % ( dev , ifup_parts_file ) , warn_only = True ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' s / % s / vhost0 / g ' ▁ % s " % ( dev , ifdown_parts_file ) , warn_only = True ) NEW_LINE DEDENT dev_cfgfile = self . get_cfgfile_for_dev ( dev , cfg_files ) NEW_LINE temp_intf_file = ' % s / interfaces ' % self . _temp_dir_name NEW_LINE local ( " sudo ▁ cp ▁ % s ▁ % s " % ( dev_cfgfile , temp_intf_file ) ) NEW_LINE with open ( dev_cfgfile , ' r ' ) as fd : NEW_LINE INDENT cfg_file = fd . read ( ) NEW_LINE DEDENT if not self . _args . non_mgmt_ip : NEW_LINE INDENT local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / , / auto / { / auto / ! d } ' ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / d ' ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' auto ▁ % s ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ % s ▁ inet ▁ manual ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE if vlan : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - up ▁ ifconfig ▁ % s ▁ up ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE DEDENT else : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE DEDENT if esxi_vm : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( dev , datapg_mtu , temp_intf_file ) ) NEW_LINE cmd = " sudo ▁ ethtool ▁ - i ▁ % s ▁ | ▁ grep ▁ driver ▁ | ▁ cut ▁ - f ▁ 2 ▁ - d ▁ ' ▁ ' " \NEW_LINE % dev NEW_LINE device_driver = local ( cmd , capture = True ) NEW_LINE if ( device_driver == " vmxnet3" ) : NEW_LINE INDENT cmd = " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ " NEW_LINE rx_cmd = ( cmd + " % s ▁ rx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE tx_cmd = ( cmd + " % s ▁ tx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) ) NEW_LINE local ( rx_cmd ) NEW_LINE local ( tx_cmd ) NEW_LINE DEDENT DEDENT if vlan : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ vlan - raw - device ▁ % s ' ▁ > > ▁ % s " % ( phydev , temp_intf_file ) ) NEW_LINE DEDENT if ' bond ' in dev . lower ( ) : NEW_LINE INDENT iters = re . finditer ( ' ^ \s * auto\s ' , cfg_file , re . M ) NEW_LINE indices = [ pat_match . start ( ) for pat_match in iters ] NEW_LINE matches = map ( cfg_file . __getslice__ , indices , indices [ 1 : ] + [ len ( cfg_file ) ] ) NEW_LINE for each in matches : NEW_LINE INDENT each = each . strip ( ) NEW_LINE if re . match ( ' ^ auto\s + % s ' % dev , each ) : NEW_LINE INDENT string = ' ' NEW_LINE for lines in each . splitlines ( ) : NEW_LINE INDENT if ' bond - ' in lines : NEW_LINE INDENT string += lines + os . linesep NEW_LINE DEDENT DEDENT local ( " sudo ▁ echo ▁ ' % s ' ▁ > > ▁ % s " % ( string , temp_intf_file ) ) NEW_LINE DEDENT else : NEW_LINE INDENT continue NEW_LINE DEDENT DEDENT DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE DEDENT else : NEW_LINE INDENT local ( " sudo ▁ sed ▁ - i ▁ ' / iface ▁ % s ▁ inet ▁ static / , ▁ + 2d ' ▁ % s " % ( dev , temp_intf_file ) , warn_only = True ) NEW_LINE if esxi_vm : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( dev , datapg_mtu , temp_intf_file ) , warn_only = True ) NEW_LINE cmd = " sudo ▁ ethtool ▁ - i ▁ % s ▁ | ▁ " % dev NEW_LINE cmd += " sudo ▁ grep ▁ driver ▁ | ▁ sudo ▁ cut ▁ - f ▁ 2 ▁ - d ▁ ' ▁ ' " NEW_LINE device_driver = local ( cmd , capture = True , warn_only = True ) NEW_LINE if ( device_driver == " vmxnet3" ) : NEW_LINE INDENT cmd = " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ " NEW_LINE rx_cmd = cmd + " % s ▁ rx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) NEW_LINE tx_cmd = cmd + " % s ▁ tx ▁ off ' ▁ > > ▁ % s " % ( dev , temp_intf_file ) NEW_LINE local ( rx_cmd , warn_only = True ) NEW_LINE local ( tx_cmd , warn_only = True ) NEW_LINE DEDENT DEDENT if vlan : NEW_LINE INDENT cmd = " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / ▁ a\iface ▁ % s ▁ inet ▁ manual\ \n ▁ ▁ ▁ ▁ " % \NEW_LINE ( dev , dev ) NEW_LINE cmd += " post - up ▁ ifconfig ▁ % s ▁ up\ \n ▁ ▁ ▁ ▁ " % dev NEW_LINE cmd += " pre - down ▁ ifconfig ▁ % s ▁ down\ ' ▁ % s " % ( dev , temp_intf_file ) NEW_LINE local ( cmd ) NEW_LINE DEDENT else : NEW_LINE INDENT cmd = " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / ▁ a\iface ▁ % s ▁ inet ▁ manual\ \n ▁ ▁ ▁ ▁ " % \NEW_LINE ( dev , dev ) NEW_LINE cmd += " pre - up ▁ ifconfig ▁ % s ▁ up\ \n ▁ ▁ ▁ ▁ " % dev NEW_LINE cmd += " post - down ▁ ifconfig ▁ % s ▁ down\ ' ▁ % s " % \NEW_LINE ( dev , temp_intf_file ) NEW_LINE local ( cmd ) NEW_LINE DEDENT DEDENT if esxi_vm and vmpg_mtu : NEW_LINE INDENT intf = self . get_secondary_device ( self . dev ) NEW_LINE mac_addr = self . get_if_mac ( intf ) NEW_LINE udev_net_file = ' / etc / udev / rules . d / 70 - persistent - net . rules ' NEW_LINE temp_udev_net_file = ' % s / 70 - persistent - net . rules ' % \NEW_LINE ( self . _temp_dir_name ) NEW_LINE local ( " sudo ▁ touch ▁ % s " % temp_udev_net_file ) NEW_LINE local ( " sudo ▁ cp ▁ % s ▁ % s " % ( udev_net_file , temp_udev_net_file ) ) NEW_LINE cmd = " sudo ▁ echo ▁ ' SUBSYSTEM = = \ " net\ " , ▁ ACTION = = \ " add\ " , " NEW_LINE cmd += " ▁ DRIVERS = = \ " ? * \ " , " NEW_LINE cmd += " ▁ ATTR { address } = = \ " % s\ " , ▁ ATTR { dev _ id } = = \ " 0x0\ " , ▁ " % mac_addr NEW_LINE cmd += " ATTR { type } = = \ " 1\ " , ▁ KERNEL = = \ " eth * \ " , ▁ NAME = \ " % s\ " ' ▁ > > ▁ % s " % \NEW_LINE ( intf , temp_udev_net_file ) NEW_LINE local ( cmd ) NEW_LINE local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( temp_udev_net_file , udev_net_file ) ) NEW_LINE local ( " sudo ▁ sed ▁ - i ▁ ' / auto ▁ % s / , / down / d ' ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' \n auto ▁ % s ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ % s ▁ inet ▁ manual ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ifconfig ▁ % s ▁ up ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( intf , vmpg_mtu , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - down ▁ ifconfig ▁ % s ▁ down ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ ethtool ▁ - - offload ▁ % s ▁ lro ▁ off ' ▁ > > ▁ % s " % ( intf , temp_intf_file ) ) NEW_LINE DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' auto ▁ vhost0 ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' iface ▁ vhost0 ▁ inet ▁ static ' ▁ > > ▁ % s " % ( temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ pre - up ▁ % s / if - vhost0 ' ▁ > > ▁ % s " % ( self . contrail_bin_dir , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ netmask ▁ % s ' ▁ > > ▁ % s " % ( netmask , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ network _ name ▁ application ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE if esxi_vm and datapg_mtu : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ mtu ▁ % s ' ▁ > > ▁ % s " % ( datapg_mtu , temp_intf_file ) ) NEW_LINE DEDENT if vhost_ip : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ address ▁ % s ' ▁ > > ▁ % s " % ( vhost_ip , temp_intf_file ) ) NEW_LINE DEDENT if ( not self . _args . non_mgmt_ip ) and gateway_ip : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ gateway ▁ % s ' ▁ > > ▁ % s " % ( gateway_ip , temp_intf_file ) ) NEW_LINE DEDENT domain = self . get_domain_search_list ( ) NEW_LINE if domain : NEW_LINE INDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ dns - search ▁ % s ' ▁ > > ▁ % s " % ( domain , temp_intf_file ) ) NEW_LINE DEDENT dns_list = self . get_dns_servers ( dev ) NEW_LINE if dns_list : NEW_LINE INDENT local ( " sudo ▁ echo ▁ - n ▁ ' ▁ ▁ ▁ ▁ dns - nameservers ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE for dns in dns_list : NEW_LINE INDENT local ( " sudo ▁ echo ▁ - n ▁ ' ▁ % s ' ▁ > > ▁ % s " % ( dns , temp_intf_file ) ) NEW_LINE DEDENT local ( " sudo ▁ echo ▁ ' ' ▁ > > ▁ % s " % temp_intf_file ) NEW_LINE DEDENT local ( " sudo ▁ echo ▁ ' ▁ ▁ ▁ ▁ post - up ▁ ip ▁ link ▁ set ▁ vhost0 ▁ address ▁ % s ' ▁ > > ▁ % s " % ( mac , temp_intf_file ) ) NEW_LINE local ( " sudo ▁ mv ▁ - f ▁ % s ▁ % s " % ( temp_intf_file , dev_cfgfile ) ) NEW_LINE DEDENT DEDENT
 from oslo_log import log as logging NEW_LINE from oslo_service import periodic_task NEW_LINE from trove . common import cfg NEW_LINE from trove . common import exception NEW_LINE from trove . common . i18n import _ NEW_LINE from trove . common import instance as rd_instance NEW_LINE from trove . common import utils NEW_LINE from trove . guestagent import backup NEW_LINE from trove . guestagent . common import operating_system NEW_LINE from trove . guestagent . datastore . experimental . redis import service NEW_LINE from trove . guestagent import dbaas NEW_LINE from trove . guestagent . strategies . replication import get_replication_strategy NEW_LINE from trove . guestagent import volume NEW_LINE LOG = logging . getLogger ( __name__ ) NEW_LINE CONF = cfg . CONF NEW_LINE MANAGER = CONF . datastore_manager or ' redis ' NEW_LINE REPLICATION_STRATEGY = CONF . get ( MANAGER ) . replication_strategy NEW_LINE REPLICATION_NAMESPACE = CONF . get ( MANAGER ) . replication_namespace NEW_LINE REPLICATION_STRATEGY_CLASS = get_replication_strategy ( REPLICATION_STRATEGY , REPLICATION_NAMESPACE ) NEW_LINE class Manager ( periodic_task . PeriodicTasks ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT super ( Manager , self ) . __init__ ( CONF ) NEW_LINE self . _app = service . RedisApp ( ) NEW_LINE DEDENT @ periodic_task . periodic_task NEW_LINE def update_status ( self , context ) : NEW_LINE INDENT LOG . debug ( " Update ▁ status ▁ called . " ) NEW_LINE self . _app . status . update ( ) NEW_LINE DEDENT def rpc_ping ( self , context ) : NEW_LINE INDENT LOG . debug ( " Responding ▁ to ▁ RPC ▁ ping . " ) NEW_LINE return True NEW_LINE DEDENT def change_passwords ( self , context , users ) : NEW_LINE INDENT LOG . debug ( " Change ▁ passwords ▁ called . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' change _ passwords ' , datastore = MANAGER ) NEW_LINE DEDENT def reset_configuration ( self , context , configuration ) : NEW_LINE INDENT LOG . debug ( " Reset ▁ configuration ▁ called . " ) NEW_LINE self . _app . reset_configuration ( configuration ) NEW_LINE DEDENT def _perform_restore ( self , backup_info , context , restore_location , app ) : NEW_LINE INDENT LOG . info ( _ ( " Restoring ▁ database ▁ from ▁ backup ▁ % s . " ) % backup_info [ ' id ' ] ) NEW_LINE try : NEW_LINE INDENT backup . restore ( context , backup_info , restore_location ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( _ ( " Error ▁ performing ▁ restore ▁ from ▁ backup ▁ % s . " ) % backup_info [ ' id ' ] ) NEW_LINE app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT LOG . info ( _ ( " Restored ▁ database ▁ successfully . " ) ) NEW_LINE DEDENT def prepare ( self , context , packages , databases , memory_mb , users , device_path = None , mount_point = None , backup_info = None , config_contents = None , root_password = None , overrides = None , cluster_config = None , snapshot = None ) : NEW_LINE INDENT try : NEW_LINE INDENT self . _app . status . begin_install ( ) NEW_LINE if device_path : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . unmount_device ( device_path ) NEW_LINE device . format ( ) NEW_LINE device . mount ( mount_point ) NEW_LINE operating_system . chown ( mount_point , ' redis ' , ' redis ' , as_root = True ) NEW_LINE LOG . debug ( ' Mounted ▁ the ▁ volume . ' ) NEW_LINE DEDENT self . _app . install_if_needed ( packages ) NEW_LINE LOG . info ( _ ( ' Writing ▁ redis ▁ configuration . ' ) ) NEW_LINE if cluster_config : NEW_LINE INDENT config_contents = ( config_contents + " \n " + " cluster - enabled ▁ yes \n " + " cluster - config - file ▁ cluster . conf \n " ) NEW_LINE DEDENT self . _app . configuration_manager . save_configuration ( config_contents ) NEW_LINE self . _app . apply_initial_guestagent_configuration ( ) NEW_LINE if backup_info : NEW_LINE INDENT persistence_dir = self . _app . get_working_dir ( ) NEW_LINE self . _perform_restore ( backup_info , context , persistence_dir , self . _app ) NEW_LINE DEDENT if snapshot : NEW_LINE INDENT self . attach_replica ( context , snapshot , snapshot [ ' config ' ] ) NEW_LINE DEDENT self . _app . restart ( ) NEW_LINE if cluster_config : NEW_LINE INDENT self . _app . status . set_status ( rd_instance . ServiceStatuses . BUILD_PENDING ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _app . complete_install_or_restart ( ) NEW_LINE DEDENT LOG . info ( _ ( ' Redis ▁ instance ▁ has ▁ been ▁ setup ▁ and ▁ configured . ' ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( _ ( " Error ▁ setting ▁ up ▁ Redis ▁ instance . " ) ) NEW_LINE self . _app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT DEDENT def restart ( self , context ) : NEW_LINE INDENT LOG . debug ( " Restart ▁ called . " ) NEW_LINE self . _app . restart ( ) NEW_LINE DEDENT def start_db_with_conf_changes ( self , context , config_contents ) : NEW_LINE INDENT LOG . debug ( " Start ▁ DB ▁ with ▁ conf ▁ changes ▁ called . " ) NEW_LINE self . _app . start_db_with_conf_changes ( config_contents ) NEW_LINE DEDENT def stop_db ( self , context , do_not_start_on_reboot = False ) : NEW_LINE INDENT LOG . debug ( " Stop ▁ DB ▁ called . " ) NEW_LINE self . _app . stop_db ( do_not_start_on_reboot = do_not_start_on_reboot ) NEW_LINE DEDENT def get_filesystem_stats ( self , context , fs_path ) : NEW_LINE INDENT LOG . debug ( " Get ▁ Filesystem ▁ Stats . " ) NEW_LINE mount_point = CONF . get ( ' mysql ' if not MANAGER else MANAGER ) . mount_point NEW_LINE return dbaas . get_filesystem_volume_stats ( mount_point ) NEW_LINE DEDENT def create_backup ( self , context , backup_info ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ backup . " ) NEW_LINE backup . backup ( context , backup_info ) NEW_LINE DEDENT def mount_volume ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . mount ( mount_point , write_to_fstab = False ) NEW_LINE LOG . debug ( " Mounted ▁ the ▁ device ▁ % s ▁ at ▁ the ▁ mount ▁ point ▁ % s . " % ( device_path , mount_point ) ) NEW_LINE DEDENT def unmount_volume ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . unmount ( mount_point ) NEW_LINE LOG . debug ( " Unmounted ▁ the ▁ device ▁ % s ▁ from ▁ the ▁ mount ▁ point ▁ % s . " % ( device_path , mount_point ) ) NEW_LINE DEDENT def resize_fs ( self , context , device_path = None , mount_point = None ) : NEW_LINE INDENT device = volume . VolumeDevice ( device_path ) NEW_LINE device . resize_fs ( mount_point ) NEW_LINE LOG . debug ( " Resized ▁ the ▁ filesystem ▁ at ▁ % s . " % mount_point ) NEW_LINE DEDENT def update_overrides ( self , context , overrides , remove = False ) : NEW_LINE INDENT LOG . debug ( " Updating ▁ overrides . " ) NEW_LINE if remove : NEW_LINE INDENT self . _app . remove_overrides ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _app . update_overrides ( context , overrides , remove ) NEW_LINE DEDENT DEDENT def apply_overrides ( self , context , overrides ) : NEW_LINE INDENT LOG . debug ( " Applying ▁ overrides . " ) NEW_LINE self . _app . apply_overrides ( self . _app . admin , overrides ) NEW_LINE DEDENT def update_attributes ( self , context , username , hostname , user_attrs ) : NEW_LINE INDENT LOG . debug ( " Updating ▁ attributes . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' update _ attributes ' , datastore = MANAGER ) NEW_LINE DEDENT def create_database ( self , context , databases ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ database . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' create _ database ' , datastore = MANAGER ) NEW_LINE DEDENT def create_user ( self , context , users ) : NEW_LINE INDENT LOG . debug ( " Creating ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' create _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def delete_database ( self , context , database ) : NEW_LINE INDENT LOG . debug ( " Deleting ▁ database . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' delete _ database ' , datastore = MANAGER ) NEW_LINE DEDENT def delete_user ( self , context , user ) : NEW_LINE INDENT LOG . debug ( " Deleting ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' delete _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def get_user ( self , context , username , hostname ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ user . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' get _ user ' , datastore = MANAGER ) NEW_LINE DEDENT def grant_access ( self , context , username , hostname , databases ) : NEW_LINE INDENT LOG . debug ( " Granting ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' grant _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def revoke_access ( self , context , username , hostname , database ) : NEW_LINE INDENT LOG . debug ( " Revoking ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' revoke _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def list_access ( self , context , username , hostname ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ access . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ access ' , datastore = MANAGER ) NEW_LINE DEDENT def list_databases ( self , context , limit = None , marker = None , include_marker = False ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ databases . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ databases ' , datastore = MANAGER ) NEW_LINE DEDENT def list_users ( self , context , limit = None , marker = None , include_marker = False ) : NEW_LINE INDENT LOG . debug ( " Listing ▁ users . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' list _ users ' , datastore = MANAGER ) NEW_LINE DEDENT def enable_root ( self , context ) : NEW_LINE INDENT LOG . debug ( " Enabling ▁ root . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' enable _ root ' , datastore = MANAGER ) NEW_LINE DEDENT def enable_root_with_password ( self , context , root_password = None ) : NEW_LINE INDENT LOG . debug ( " Enabling ▁ root ▁ with ▁ password . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' enable _ root _ with _ password ' , datastore = MANAGER ) NEW_LINE DEDENT def is_root_enabled ( self , context ) : NEW_LINE INDENT LOG . debug ( " Checking ▁ if ▁ root ▁ is ▁ enabled . " ) NEW_LINE raise exception . DatastoreOperationNotSupported ( operation = ' is _ root _ enabled ' , datastore = MANAGER ) NEW_LINE DEDENT def backup_required_for_replication ( self , context ) : NEW_LINE INDENT replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE return replication . backup_required_for_replication ( ) NEW_LINE DEDENT def get_replication_snapshot ( self , context , snapshot_info , replica_source_config = None ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ replication ▁ snapshot . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_master ( self . _app , replica_source_config ) NEW_LINE snapshot_id , log_position = ( replication . snapshot_for_replication ( context , self . _app , None , snapshot_info ) ) NEW_LINE mount_point = CONF . get ( MANAGER ) . mount_point NEW_LINE volume_stats = dbaas . get_filesystem_volume_stats ( mount_point ) NEW_LINE replication_snapshot = { ' dataset ' : { ' datastore _ manager ' : MANAGER , ' dataset _ size ' : volume_stats . get ( ' used ' , 0.0 ) , ' volume _ size ' : volume_stats . get ( ' total ' , 0.0 ) , ' snapshot _ id ' : snapshot_id } , ' replication _ strategy ' : REPLICATION_STRATEGY , ' master ' : replication . get_master_ref ( self . _app , snapshot_info ) , ' log _ position ' : log_position } NEW_LINE return replication_snapshot NEW_LINE DEDENT def enable_as_master ( self , context , replica_source_config ) : NEW_LINE INDENT LOG . debug ( " Calling ▁ enable _ as _ master . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_master ( self . _app , replica_source_config ) NEW_LINE DEDENT def detach_replica ( self , context , for_failover = False ) : NEW_LINE INDENT LOG . debug ( " Detaching ▁ replica . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replica_info = replication . detach_slave ( self . _app , for_failover ) NEW_LINE return replica_info NEW_LINE DEDENT def get_replica_context ( self , context ) : NEW_LINE INDENT LOG . debug ( " Getting ▁ replica ▁ context . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replica_info = replication . get_replica_context ( self . _app ) NEW_LINE return replica_info NEW_LINE DEDENT def _validate_slave_for_replication ( self , context , replica_info ) : NEW_LINE INDENT if ( replica_info [ ' replication _ strategy ' ] != REPLICATION_STRATEGY ) : NEW_LINE INDENT raise exception . IncompatibleReplicationStrategy ( replica_info . update ( { ' guest _ strategy ' : REPLICATION_STRATEGY } ) ) NEW_LINE DEDENT DEDENT def attach_replica ( self , context , replica_info , slave_config ) : NEW_LINE INDENT LOG . debug ( " Attaching ▁ replica . " ) NEW_LINE try : NEW_LINE INDENT if ' replication _ strategy ' in replica_info : NEW_LINE INDENT self . _validate_slave_for_replication ( context , replica_info ) NEW_LINE DEDENT replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . enable_as_slave ( self . _app , replica_info , slave_config ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT LOG . exception ( " Error ▁ enabling ▁ replication . " ) NEW_LINE self . _app . status . set_status ( rd_instance . ServiceStatuses . FAILED ) NEW_LINE raise NEW_LINE DEDENT DEDENT def make_read_only ( self , context , read_only ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ make _ read _ only ( % s ) " % read_only ) NEW_LINE self . _app . make_read_only ( read_only ) NEW_LINE DEDENT def _get_repl_info ( self ) : NEW_LINE INDENT return self . _app . admin . get_info ( ' replication ' ) NEW_LINE DEDENT def _get_master_host ( self ) : NEW_LINE INDENT slave_info = self . _get_repl_info ( ) NEW_LINE return slave_info and slave_info [ ' master _ host ' ] or None NEW_LINE DEDENT def _get_repl_offset ( self ) : NEW_LINE INDENT repl_info = self . _get_repl_info ( ) NEW_LINE LOG . debug ( " Got ▁ repl ▁ info : ▁ % s " % repl_info ) NEW_LINE offset_key = ' % s _ repl _ offset ' % repl_info [ ' role ' ] NEW_LINE offset = repl_info [ offset_key ] NEW_LINE LOG . debug ( " Found ▁ offset ▁ % s ▁ for ▁ key ▁ % s . " % ( offset , offset_key ) ) NEW_LINE return int ( offset ) NEW_LINE DEDENT def get_last_txn ( self , context ) : NEW_LINE INDENT master_host = self . _get_master_host ( ) NEW_LINE repl_offset = self . _get_repl_offset ( ) NEW_LINE return master_host , repl_offset NEW_LINE DEDENT def get_latest_txn_id ( self , context ) : NEW_LINE INDENT LOG . info ( _ ( " Retrieving ▁ latest ▁ repl ▁ offset . " ) ) NEW_LINE return self . _get_repl_offset ( ) NEW_LINE DEDENT def wait_for_txn ( self , context , txn ) : NEW_LINE INDENT LOG . info ( _ ( " Waiting ▁ on ▁ repl ▁ offset ▁ ' % s ' . " ) % txn ) NEW_LINE def _wait_for_txn ( ) : NEW_LINE INDENT current_offset = self . _get_repl_offset ( ) NEW_LINE LOG . debug ( " Current ▁ offset : ▁ % s . " % current_offset ) NEW_LINE return current_offset >= txn NEW_LINE DEDENT try : NEW_LINE INDENT utils . poll_until ( _wait_for_txn , time_out = 120 ) NEW_LINE DEDENT except exception . PollTimeOut : NEW_LINE INDENT raise RuntimeError ( _ ( " Timeout ▁ occurred ▁ waiting ▁ for ▁ Redis ▁ repl ▁ " " offset ▁ to ▁ change ▁ to ▁ ' % s ' . " ) % txn ) NEW_LINE DEDENT DEDENT def cleanup_source_on_replica_detach ( self , context , replica_info ) : NEW_LINE INDENT LOG . debug ( " Cleaning ▁ up ▁ the ▁ source ▁ on ▁ the ▁ detach ▁ of ▁ a ▁ replica . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . cleanup_source_on_replica_detach ( self . _app , replica_info ) NEW_LINE DEDENT def demote_replication_master ( self , context ) : NEW_LINE INDENT LOG . debug ( " Demoting ▁ replica ▁ source . " ) NEW_LINE replication = REPLICATION_STRATEGY_CLASS ( context ) NEW_LINE replication . demote_master ( self . _app ) NEW_LINE DEDENT def cluster_meet ( self , context , ip , port ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ cluster _ meet ▁ to ▁ join ▁ node ▁ to ▁ cluster . " ) NEW_LINE self . _app . cluster_meet ( ip , port ) NEW_LINE DEDENT def get_node_ip ( self , context ) : NEW_LINE INDENT LOG . debug ( " Retrieving ▁ cluster ▁ node ▁ ip ▁ address . " ) NEW_LINE return self . _app . get_node_ip ( ) NEW_LINE DEDENT def get_node_id_for_removal ( self , context ) : NEW_LINE INDENT LOG . debug ( " Validating ▁ removal ▁ of ▁ node ▁ from ▁ cluster . " ) NEW_LINE return self . _app . get_node_id_for_removal ( ) NEW_LINE DEDENT def remove_nodes ( self , context , node_ids ) : NEW_LINE INDENT LOG . debug ( " Removing ▁ nodes ▁ from ▁ cluster . " ) NEW_LINE self . _app . remove_nodes ( node_ids ) NEW_LINE DEDENT def cluster_addslots ( self , context , first_slot , last_slot ) : NEW_LINE INDENT LOG . debug ( " Executing ▁ cluster _ addslots ▁ to ▁ assign ▁ hash ▁ slots ▁ % s - % s . " , first_slot , last_slot ) NEW_LINE self . _app . cluster_addslots ( first_slot , last_slot ) NEW_LINE DEDENT def cluster_complete ( self , context ) : NEW_LINE INDENT LOG . debug ( " Cluster ▁ creation ▁ complete , ▁ starting ▁ status ▁ checks . " ) NEW_LINE self . _app . complete_install_or_restart ( ) NEW_LINE DEDENT DEDENT
 import warnings NEW_LINE from django . utils . deprecation import RemovedInDjango110Warning NEW_LINE class TokenBase ( object ) : NEW_LINE INDENT id = None NEW_LINE value = None NEW_LINE first = second = None NEW_LINE def nud ( self , parser ) : NEW_LINE INDENT raise parser . error_class ( " Not ▁ expecting ▁ ' % s ' ▁ in ▁ this ▁ position ▁ in ▁ if ▁ tag . " % self . id ) NEW_LINE DEDENT def led ( self , left , parser ) : NEW_LINE INDENT raise parser . error_class ( " Not ▁ expecting ▁ ' % s ' ▁ as ▁ infix ▁ operator ▁ in ▁ if ▁ tag . " % self . id ) NEW_LINE DEDENT def display ( self ) : NEW_LINE INDENT return self . id NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT out = [ str ( x ) for x in [ self . id , self . first , self . second ] if x is not None ] NEW_LINE return " ( " + " ▁ " . join ( out ) + " ) " NEW_LINE DEDENT DEDENT def infix ( bp , func ) : NEW_LINE INDENT class Operator ( TokenBase ) : NEW_LINE INDENT lbp = bp NEW_LINE def led ( self , left , parser ) : NEW_LINE INDENT self . first = left NEW_LINE self . second = parser . expression ( bp ) NEW_LINE return self NEW_LINE DEDENT def eval ( self , context ) : NEW_LINE INDENT try : NEW_LINE INDENT return func ( context , self . first , self . second ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT DEDENT return Operator NEW_LINE DEDENT def prefix ( bp , func ) : NEW_LINE INDENT class Operator ( TokenBase ) : NEW_LINE INDENT lbp = bp NEW_LINE def nud ( self , parser ) : NEW_LINE INDENT self . first = parser . expression ( bp ) NEW_LINE self . second = None NEW_LINE return self NEW_LINE DEDENT def eval ( self , context ) : NEW_LINE INDENT try : NEW_LINE INDENT return func ( context , self . first ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT DEDENT return Operator NEW_LINE DEDENT OPERATORS = { ' or ' : infix ( 6 , lambda context , x , y : x . eval ( context ) or y . eval ( context ) ) , ' and ' : infix ( 7 , lambda context , x , y : x . eval ( context ) and y . eval ( context ) ) , ' not ' : prefix ( 8 , lambda context , x : not x . eval ( context ) ) , ' in ' : infix ( 9 , lambda context , x , y : x . eval ( context ) in y . eval ( context ) ) , ' not ▁ in ' : infix ( 9 , lambda context , x , y : x . eval ( context ) not in y . eval ( context ) ) , ' = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) == y . eval ( context ) ) , ' = = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) == y . eval ( context ) ) , ' ! = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) != y . eval ( context ) ) , ' > ' : infix ( 10 , lambda context , x , y : x . eval ( context ) > y . eval ( context ) ) , ' > = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) >= y . eval ( context ) ) , ' < ' : infix ( 10 , lambda context , x , y : x . eval ( context ) < y . eval ( context ) ) , ' < = ' : infix ( 10 , lambda context , x , y : x . eval ( context ) <= y . eval ( context ) ) , } NEW_LINE for key , op in OPERATORS . items ( ) : NEW_LINE INDENT op . id = key NEW_LINE DEDENT class Literal ( TokenBase ) : NEW_LINE INDENT id = " literal " NEW_LINE lbp = 0 NEW_LINE def __init__ ( self , value ) : NEW_LINE INDENT self . value = value NEW_LINE DEDENT def display ( self ) : NEW_LINE INDENT return repr ( self . value ) NEW_LINE DEDENT def nud ( self , parser ) : NEW_LINE INDENT return self NEW_LINE DEDENT def eval ( self , context ) : NEW_LINE INDENT return self . value NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT return " ( % s ▁ % r ) " % ( self . id , self . value ) NEW_LINE DEDENT DEDENT class EndToken ( TokenBase ) : NEW_LINE INDENT lbp = 0 NEW_LINE def nud ( self , parser ) : NEW_LINE INDENT raise parser . error_class ( " Unexpected ▁ end ▁ of ▁ expression ▁ in ▁ if ▁ tag . " ) NEW_LINE DEDENT DEDENT EndToken = EndToken ( ) NEW_LINE class IfParser ( object ) : NEW_LINE INDENT error_class = ValueError NEW_LINE def __init__ ( self , tokens ) : NEW_LINE INDENT l = len ( tokens ) NEW_LINE mapped_tokens = [ ] NEW_LINE i = 0 NEW_LINE while i < l : NEW_LINE INDENT token = tokens [ i ] NEW_LINE if token == " not " and i + 1 < l and tokens [ i + 1 ] == " in " : NEW_LINE INDENT token = " not ▁ in " NEW_LINE i += 1 NEW_LINE DEDENT mapped_tokens . append ( self . translate_token ( token ) ) NEW_LINE i += 1 NEW_LINE DEDENT self . tokens = mapped_tokens NEW_LINE self . pos = 0 NEW_LINE self . current_token = self . next_token ( ) NEW_LINE DEDENT def translate_token ( self , token ) : NEW_LINE INDENT try : NEW_LINE INDENT op = OPERATORS [ token ] NEW_LINE DEDENT except ( KeyError , TypeError ) : NEW_LINE INDENT return self . create_var ( token ) NEW_LINE DEDENT else : NEW_LINE INDENT if token == ' = ' : NEW_LINE INDENT warnings . warn ( " Operator ▁ ' = ' ▁ is ▁ deprecated ▁ and ▁ will ▁ be ▁ removed ▁ in ▁ Django ▁ 1.10 . ▁ Use ▁ ' = = ' ▁ instead . " , RemovedInDjango110Warning , stacklevel = 2 ) NEW_LINE DEDENT return op ( ) NEW_LINE DEDENT DEDENT def next_token ( self ) : NEW_LINE INDENT if self . pos >= len ( self . tokens ) : NEW_LINE INDENT return EndToken NEW_LINE DEDENT else : NEW_LINE INDENT retval = self . tokens [ self . pos ] NEW_LINE self . pos += 1 NEW_LINE return retval NEW_LINE DEDENT DEDENT def parse ( self ) : NEW_LINE INDENT retval = self . expression ( ) NEW_LINE if self . current_token is not EndToken : NEW_LINE INDENT raise self . error_class ( " Unused ▁ ' % s ' ▁ at ▁ end ▁ of ▁ if ▁ expression . " % self . current_token . display ( ) ) NEW_LINE DEDENT return retval NEW_LINE DEDENT def expression ( self , rbp = 0 ) : NEW_LINE INDENT t = self . current_token NEW_LINE self . current_token = self . next_token ( ) NEW_LINE left = t . nud ( self ) NEW_LINE while rbp < self . current_token . lbp : NEW_LINE INDENT t = self . current_token NEW_LINE self . current_token = self . next_token ( ) NEW_LINE left = t . led ( left , self ) NEW_LINE DEDENT return left NEW_LINE DEDENT def create_var ( self , value ) : NEW_LINE INDENT return Literal ( value ) NEW_LINE DEDENT DEDENT
 import os NEW_LINE import json NEW_LINE import mm . util as util NEW_LINE import mm . config as config NEW_LINE from mm . exceptions import * NEW_LINE from mm . basecommand import Command NEW_LINE from mm . sfdc_client import MavensMateClient NEW_LINE class GetActiveSessionCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT if ' username ' not in self . params or self . params [ ' username ' ] == None or self . params [ ' username ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ enter ▁ a ▁ Salesforce . com ▁ username ' ) NEW_LINE DEDENT if ' password ' not in self . params or self . params [ ' password ' ] == None or self . params [ ' password ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ enter ▁ a ▁ Salesforce . com ▁ password ' ) NEW_LINE DEDENT if ' org _ type ' not in self . params or self . params [ ' org _ type ' ] == None or self . params [ ' org _ type ' ] == ' ' : NEW_LINE INDENT raise MMException ( ' Please ▁ select ▁ an ▁ org ▁ type ' ) NEW_LINE DEDENT if ' org _ type ' in self . params and self . params [ ' org _ type ' ] == " custom " and " org _ url " not in self . params : NEW_LINE INDENT raise MMException ( ' To ▁ use ▁ a ▁ custom ▁ org ▁ type , ▁ please ▁ include ▁ a ▁ org _ url ▁ parameter ' ) NEW_LINE DEDENT if ' org _ type ' in self . params and self . params [ ' org _ type ' ] == " custom " and " org _ url " in self . params and self . params [ " org _ url " ] == " " : NEW_LINE INDENT raise MMException ( ' Please ▁ specify ▁ the ▁ org ▁ url ' ) NEW_LINE DEDENT config . logger . debug ( ' = = = = = = = = = = = = = = = = = > ' ) NEW_LINE config . logger . debug ( self . params ) NEW_LINE client = MavensMateClient ( credentials = { " username " : self . params [ ' username ' ] , " password " : self . params [ ' password ' ] , " org _ type " : self . params [ ' org _ type ' ] , " org _ url " : self . params . get ( ' org _ url ' , None ) } ) NEW_LINE response = { " sid " : client . sid , " user _ id " : client . user_id , " metadata _ server _ url " : client . metadata_server_url , " server _ url " : client . server_url , " metadata " : client . get_org_metadata ( subscription = self . params . get ( ' subscription ' , None ) ) , " org _ metadata _ types " : util . metadata_types ( ) , " success " : True } NEW_LINE return util . generate_response ( response ) NEW_LINE DEDENT DEDENT class IndexApexSymbolsCommand ( Command ) : NEW_LINE INDENT aliases = [ " index _ apex " , " index _ apex _ file _ properties " ] NEW_LINE def execute ( self ) : NEW_LINE INDENT return config . project . index_apex_symbols ( self . params . get ( " files " , None ) ) NEW_LINE DEDENT DEDENT class ResetMetadataContainerCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT return config . project . reset_metadata_container ( accept = " json " ) NEW_LINE DEDENT DEDENT class OpenFileInClientCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT file_name = self . params [ " file _ name " ] NEW_LINE extension = util . get_file_extension_no_period ( file_name ) NEW_LINE mtype = util . get_meta_type_by_suffix ( extension ) NEW_LINE full_file_path = os . path . join ( config . project . location , " src " , mtype [ " directoryName " ] , file_name ) NEW_LINE params = { " project _ name " : config . project . project_name , " file _ name " : full_file_path , " line _ number " : self . params . get ( " line _ number " , 0 ) } NEW_LINE config . connection . run_subl_command ( " open _ file _ in _ project " , json . dumps ( params ) ) NEW_LINE return util . generate_success_response ( " ok " ) NEW_LINE DEDENT DEDENT class ExecuteApexCommand ( Command ) : NEW_LINE INDENT aliases = [ " run _ apex _ script " ] NEW_LINE def execute ( self ) : NEW_LINE INDENT if ' script _ name ' in self . params : NEW_LINE INDENT self . params [ " body " ] = util . get_file_as_string ( os . path . join ( config . project . location , " apex - scripts " , self . params [ " script _ name " ] ) ) NEW_LINE DEDENT if ' debug _ categories ' not in self . params and not os . path . isfile ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) : NEW_LINE INDENT self . params [ " debug _ categories " ] = [ { " category " : " Apex _ code " , " level " : " DEBUG " } ] NEW_LINE DEDENT elif os . path . isfile ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) : NEW_LINE INDENT log_settings = util . parse_json_from_file ( os . path . join ( config . project . location , " config " , " . apex _ script " ) ) NEW_LINE categories = [ ] NEW_LINE levels = log_settings [ " levels " ] NEW_LINE for category in levels . keys ( ) : NEW_LINE INDENT categories . append ( { " category " : category , " level " : levels [ category ] } ) NEW_LINE DEDENT self . params [ " debug _ categories " ] = categories NEW_LINE DEDENT elif ' debug _ categories ' not in self . params : NEW_LINE INDENT self . params [ " debug _ categories " ] = [ { " category " : " Apex _ code " , " level " : " DEBUG " } ] NEW_LINE DEDENT return_log = self . params . get ( " return _ log " , True ) NEW_LINE execute_result = config . sfdc_client . execute_apex ( self . params ) NEW_LINE result = { ' column ' : execute_result [ ' column ' ] , ' compileProblem ' : execute_result [ ' compileProblem ' ] , ' compiled ' : execute_result [ ' compiled ' ] , ' exceptionMessage ' : execute_result [ ' exceptionMessage ' ] , ' exceptionStackTrace ' : execute_result [ ' exceptionStackTrace ' ] , ' line ' : execute_result [ ' line ' ] , ' success ' : execute_result [ ' success ' ] , } NEW_LINE if ' log ' in execute_result and return_log : NEW_LINE INDENT result [ ' log ' ] = execute_result [ ' log ' ] NEW_LINE DEDENT if result [ ' success ' ] : NEW_LINE INDENT log_apex = config . connection . get_plugin_client_setting ( ' mm _ log _ anonymous _ apex ' , False ) NEW_LINE if log_apex : NEW_LINE INDENT location = config . project . log_anonymous_apex ( self . params [ ' body ' ] , execute_result [ ' log ' ] , self . params . get ( " script _ name " , None ) ) NEW_LINE result [ " log _ location " ] = location NEW_LINE DEDENT DEDENT return util . generate_response ( result ) NEW_LINE DEDENT DEDENT class SignInWithGithubCommand ( Command ) : NEW_LINE INDENT def execute ( self ) : NEW_LINE INDENT return config . connection . sign_in_with_github ( self . params ) NEW_LINE DEDENT DEDENT
 import re NEW_LINE from os . path import splitext NEW_LINE from streamlink . compat import urlparse , unquote NEW_LINE from streamlink . plugin import Plugin NEW_LINE from streamlink . plugin . api import http , validate NEW_LINE from streamlink . stream import HTTPStream , RTMPStream NEW_LINE _url_re = re . compile ( """ STRNEWLINE ▁ ▁ ▁ ▁ http ( s ) ? : / / ( \w + \ . ) ? aliez . tv STRNEWLINE ▁ ▁ ▁ ▁ ( ? : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ / live / [ ^ / ] + STRNEWLINE ▁ ▁ ▁ ▁ ) ? STRNEWLINE ▁ ▁ ▁ ▁ ( ? : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ / video / \d + / [ ^ / ] + STRNEWLINE ▁ ▁ ▁ ▁ ) ? STRNEWLINE """ , re . VERBOSE ) NEW_LINE _file_re = re . compile ( " \ " ? file\ " ? : \s + [ ' \ " ] ( [ ^ ' \ " ] + ) [ ' \ " ] " ) NEW_LINE _swf_url_re = re . compile ( " swfobject . embedSWF\ ( \ " ( [ ^ \ " ] + ) \ " , " ) NEW_LINE _schema = validate . Schema ( validate . union ( { " urls " : validate . all ( validate . transform ( _file_re . findall ) , validate . map ( unquote ) , [ validate . url ( ) ] ) , " swf " : validate . all ( validate . transform ( _swf_url_re . search ) , validate . any ( None , validate . all ( validate . get ( 1 ) , validate . url ( scheme = " http " , path = validate . endswith ( " swf " ) ) ) ) ) } ) ) NEW_LINE class Aliez ( Plugin ) : NEW_LINE INDENT @ classmethod NEW_LINE def can_handle_url ( self , url ) : NEW_LINE INDENT return _url_re . match ( url ) NEW_LINE DEDENT def _get_streams ( self ) : NEW_LINE INDENT res = http . get ( self . url , schema = _schema ) NEW_LINE streams = { } NEW_LINE for url in res [ " urls " ] : NEW_LINE INDENT parsed = urlparse ( url ) NEW_LINE if parsed . scheme . startswith ( " rtmp " ) : NEW_LINE INDENT params = { " rtmp " : url , " pageUrl " : self . url , " live " : True } NEW_LINE if res [ " swf " ] : NEW_LINE INDENT params [ " swfVfy " ] = res [ " swf " ] NEW_LINE DEDENT stream = RTMPStream ( self . session , params ) NEW_LINE streams [ " live " ] = stream NEW_LINE DEDENT elif parsed . scheme . startswith ( " http " ) : NEW_LINE INDENT name = splitext ( parsed . path ) [ 1 ] [ 1 : ] NEW_LINE stream = HTTPStream ( self . session , url ) NEW_LINE streams [ name ] = stream NEW_LINE DEDENT DEDENT return streams NEW_LINE DEDENT DEDENT __plugin__ = Aliez NEW_LINE
 from xmodule . modulestore . xml_importer import import_course_from_xml NEW_LINE from xmodule . modulestore . tests . django_utils import ModuleStoreTestCase NEW_LINE from xmodule . modulestore . django import modulestore NEW_LINE from django . conf import settings NEW_LINE TEST_DATA_DIR = settings . COMMON_TEST_DATA_ROOT NEW_LINE class DraftReorderTestCase ( ModuleStoreTestCase ) : NEW_LINE INDENT def test_order ( self ) : NEW_LINE INDENT store = modulestore ( ) NEW_LINE course_items = import_course_from_xml ( store , self . user . id , TEST_DATA_DIR , [ ' import _ draft _ order ' ] , create_if_not_present = True ) NEW_LINE course_key = course_items [ 0 ] . id NEW_LINE sequential = store . get_item ( course_key . make_usage_key ( ' sequential ' , '0f4f7649b10141b0bdc9922dcf94515a ' ) ) NEW_LINE verticals = sequential . children NEW_LINE self . assertEqual ( 7 , len ( verticals ) ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' z ' ) , verticals [ 0 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , '5a05be9d59fc4bb79282c94c9e6b88c7' ) , verticals [ 1 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' a ' ) , verticals [ 2 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' second ' ) , verticals [ 3 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' b ' ) , verticals [ 4 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' d ' ) , verticals [ 5 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' c ' ) , verticals [ 6 ] ) NEW_LINE sequential = store . get_item ( course_key . make_usage_key ( ' sequential ' , ' secondseq ' ) ) NEW_LINE verticals = sequential . children NEW_LINE self . assertEqual ( 3 , len ( verticals ) ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' asecond ' ) , verticals [ 0 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' secondsubsection ' ) , verticals [ 1 ] ) NEW_LINE self . assertEqual ( course_key . make_usage_key ( ' vertical ' , ' zsecond ' ) , verticals [ 2 ] ) NEW_LINE DEDENT DEDENT
 from __future__ import ( absolute_import , division , print_function , unicode_literals ) NEW_LINE import six NEW_LINE from collections import namedtuple , deque NEW_LINE import logging NEW_LINE import pandas as pd NEW_LINE import tzlocal NEW_LINE import numpy as np NEW_LINE from scipy . interpolate import interp1d NEW_LINE import pandas . core . groupby NEW_LINE logger = logging . getLogger ( __name__ ) NEW_LINE __all__ = [ ' DataMuxer ' , ' dataframe _ to _ dict ' ] NEW_LINE TZ = str ( tzlocal . get_localzone ( ) ) NEW_LINE class BinningError ( Exception ) : NEW_LINE INDENT pass NEW_LINE DEDENT class BadDownsamplerError ( Exception ) : NEW_LINE INDENT pass NEW_LINE DEDENT class ColSpec ( namedtuple ( ' ColSpec ' , [ ' name ' , ' ndim ' , ' shape ' , ' upsample ' , ' downsample ' ] ) ) : NEW_LINE INDENT upsampling_methods = { ' None ' , ' linear ' , ' nearest ' , ' zero ' , ' slinear ' , ' quadratic ' , ' cubic ' , ' ffill ' , ' bfill ' } NEW_LINE downsampling_methods = { ' None ' , ' last ' , ' first ' , ' median ' , ' mean ' , ' sum ' , ' min ' , ' max ' } NEW_LINE _downsample_mapping = { ' last ' : lambda x : x [ - 1 ] , ' first ' : lambda x : x [ 0 ] , ' median ' : lambda x : np . median ( x , 0 ) , ' mean ' : lambda x : np . mean ( x , 0 ) , ' sum ' : lambda x : np . sum ( x , 0 ) , ' min ' : lambda x : np . min ( x , 0 ) , ' max ' : lambda x : np . max ( x , 0 ) } NEW_LINE __slots__ = ( ) NEW_LINE def __new__ ( cls , name , ndim , shape , upsample , downsample ) : NEW_LINE INDENT upsample = _validate_upsample ( upsample ) NEW_LINE downsample = _validate_downsample ( downsample ) NEW_LINE if int ( ndim ) < 0 : NEW_LINE INDENT raise ValueError ( " ndim ▁ must ▁ be ▁ positive ▁ not ▁ { } " . format ( ndim ) ) NEW_LINE DEDENT if shape is not None : NEW_LINE INDENT shape = tuple ( shape ) NEW_LINE DEDENT return super ( ColSpec , cls ) . __new__ ( cls , name , int ( ndim ) , shape , upsample , downsample ) NEW_LINE DEDENT DEDENT def _validate_upsample ( input ) : NEW_LINE INDENT if input is None or input == ' None ' : NEW_LINE INDENT return ' None ' NEW_LINE DEDENT if not ( input in ColSpec . upsampling_methods ) : NEW_LINE INDENT raise ValueError ( " { } ▁ is ▁ not ▁ a ▁ valid ▁ upsampling ▁ method . ▁ It ▁ " " must ▁ be ▁ one ▁ of ▁ { } " . format ( input , ColSpec . upsampling_methods ) ) NEW_LINE DEDENT return input . lower ( ) NEW_LINE DEDENT def _validate_downsample ( input ) : NEW_LINE INDENT if ( input is not None ) and ( not ( callable ( input ) or input in ColSpec . downsampling_methods ) ) : NEW_LINE INDENT raise ValueError ( " The ▁ downsampling ▁ method ▁ must ▁ be ▁ a ▁ callable , ▁ None , ▁ " " or ▁ one ▁ of ▁ { } . " . format ( ColSpec . downsampling_methods ) ) NEW_LINE DEDENT if input is None : NEW_LINE INDENT return ' None ' NEW_LINE DEDENT return input NEW_LINE DEDENT class DataMuxer ( object ) : NEW_LINE INDENT class Planner ( object ) : NEW_LINE INDENT def __init__ ( self , dm ) : NEW_LINE INDENT self . dm = dm NEW_LINE DEDENT def determine_upsample ( self , interpolation = None , use_cols = None ) : NEW_LINE INDENT if interpolation is None : NEW_LINE INDENT interpolation = dict ( ) NEW_LINE DEDENT if use_cols is None : NEW_LINE INDENT use_cols = self . dm . columns NEW_LINE DEDENT rules = dict ( ) NEW_LINE for name in use_cols : NEW_LINE INDENT col_info = self . dm . col_info [ name ] NEW_LINE rule = _validate_upsample ( interpolation . get ( name , col_info . upsample ) ) NEW_LINE rule = _normalize_string_none ( rule ) NEW_LINE if ( rule is not None ) and ( col_info . ndim > 0 ) : NEW_LINE INDENT raise NotImplementedError ( " Only ▁ scalar ▁ data ▁ can ▁ be ▁ upsampled . ▁ " " The ▁ { 0 } - dimensional ▁ source ▁ { 1 } ▁ was ▁ given ▁ the ▁ " " upsampling ▁ rule ▁ { 2 } . " . format ( col_info . ndim , name , rule ) ) NEW_LINE DEDENT rules [ name ] = rule NEW_LINE DEDENT return rules NEW_LINE DEDENT def determine_downsample ( self , agg = None , use_cols = None ) : NEW_LINE INDENT if agg is None : NEW_LINE INDENT agg = dict ( ) NEW_LINE DEDENT if use_cols is None : NEW_LINE INDENT use_cols = self . dm . columns NEW_LINE DEDENT rules = dict ( ) NEW_LINE for name in use_cols : NEW_LINE INDENT col_info = self . dm . col_info [ name ] NEW_LINE rule = _validate_downsample ( agg . get ( name , col_info . downsample ) ) NEW_LINE rule = _normalize_string_none ( rule ) NEW_LINE rules [ name ] = rule NEW_LINE DEDENT return rules NEW_LINE DEDENT def bin_by_edges ( self , bin_edges , bin_anchors , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT bin_anchors , binning = self . dm . _bin_by_edges ( bin_anchors , bin_edges ) NEW_LINE grouped = self . dm . _dataframe . groupby ( binning ) NEW_LINE counts = grouped . count ( ) NEW_LINE df = pd . DataFrame . from_dict ( _is_resampling_applicable ( counts ) ) NEW_LINE df [ ' upsample ' ] = self . determine_upsample ( interpolation , use_cols ) NEW_LINE df [ ' downsample ' ] = self . determine_downsample ( agg , use_cols ) NEW_LINE return df NEW_LINE DEDENT def bin_on ( self , source_name , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT centers , bin_edges = self . dm . _bin_on ( source_name ) NEW_LINE bin_anchors , binning = self . dm . _bin_by_edges ( centers , bin_edges ) NEW_LINE grouped = self . dm . _dataframe . groupby ( binning ) NEW_LINE counts = grouped . count ( ) NEW_LINE df = pd . DataFrame . from_dict ( _is_resampling_applicable ( counts ) ) NEW_LINE df [ ' upsample ' ] = self . determine_upsample ( interpolation , use_cols ) NEW_LINE df [ ' downsample ' ] = self . determine_downsample ( agg , use_cols ) NEW_LINE return df NEW_LINE DEDENT DEDENT default_upsample = None NEW_LINE default_downsample = None NEW_LINE def __init__ ( self ) : NEW_LINE INDENT self . sources = { } NEW_LINE self . col_info = { } NEW_LINE self . col_info [ ' time ' ] = ColSpec ( ' time ' , 0 , [ ] , ' linear ' , ' mean ' ) NEW_LINE self . _data = deque ( ) NEW_LINE self . _time = deque ( ) NEW_LINE self . _timestamps = deque ( ) NEW_LINE self . _timestamps_as_data = set ( ) NEW_LINE self . _known_events = set ( ) NEW_LINE self . _known_descriptors = set ( ) NEW_LINE self . _stale = True NEW_LINE self . plan = self . Planner ( self ) NEW_LINE self . convert_times = True NEW_LINE self . _reference_time = None NEW_LINE DEDENT @ property NEW_LINE def reference_time ( self ) : NEW_LINE INDENT return self . _reference_time NEW_LINE DEDENT @ reference_time . setter NEW_LINE def reference_time ( self , val ) : NEW_LINE INDENT self . _reference_time = pd . Timestamp ( val , unit = ' s ' ) NEW_LINE DEDENT @ property NEW_LINE def columns ( self ) : NEW_LINE INDENT return set ( self . sources ) | self . _time_columns NEW_LINE DEDENT @ property NEW_LINE def _time_columns ( self ) : NEW_LINE INDENT ts_names = [ name + ' _ timestamp ' for name in self . _timestamps_as_data ] NEW_LINE return { ' time ' } | set ( ts_names ) NEW_LINE DEDENT @ classmethod NEW_LINE def from_events ( cls , events , verbose = False ) : NEW_LINE INDENT instance = cls ( ) NEW_LINE instance . append_events ( events , verbose ) NEW_LINE return instance NEW_LINE DEDENT def append_events ( self , events , verbose = False ) : NEW_LINE INDENT for idx , event in enumerate ( events ) : NEW_LINE INDENT if verbose and idx % 25 == 0 : NEW_LINE INDENT print ( ' loading ▁ event ▁ % s ' % idx ) , NEW_LINE DEDENT self . append_event ( event ) NEW_LINE DEDENT DEDENT def append_event ( self , event ) : NEW_LINE INDENT if event . uid in self . _known_events : NEW_LINE INDENT return False NEW_LINE DEDENT self . _known_events . add ( event . uid ) NEW_LINE self . _stale = True NEW_LINE if event . descriptor . uid not in self . _known_descriptors : NEW_LINE INDENT self . _process_new_descriptor ( event . descriptor ) NEW_LINE DEDENT self . _data . append ( { name : data for name , data in six . iteritems ( event . data ) } ) NEW_LINE self . _timestamps . append ( { name : ts for name , ts in six . iteritems ( event . timestamps ) } ) NEW_LINE self . _time . append ( event . time ) NEW_LINE return True NEW_LINE DEDENT def _process_new_descriptor ( self , descriptor ) : NEW_LINE INDENT for name , description in six . iteritems ( descriptor . data_keys ) : NEW_LINE INDENT if name in self . sources : NEW_LINE INDENT if self . sources [ name ] != description [ ' source ' ] : NEW_LINE INDENT raise ValueError ( " In ▁ a ▁ previously ▁ loaded ▁ descriptor , ▁ " " ' {0 } ' ▁ refers ▁ to ▁ { 1 } ▁ but ▁ in ▁ Event ▁ " " Descriptor ▁ { 2 } ▁ it ▁ refers ▁ to ▁ { 3 } . " . format ( name , self . sources [ name ] , descriptor . uid , description [ ' source ' ] ) ) NEW_LINE DEDENT if name == ' time ' : NEW_LINE INDENT raise ValueError ( " The ▁ name ▁ ' time ' ▁ is ▁ reserved ▁ and ▁ cannot ▁ " " be ▁ used ▁ as ▁ an ▁ alias . " ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . sources [ name ] = description [ ' source ' ] NEW_LINE if ' external ' in description and ' shape ' in description : NEW_LINE INDENT shape = description [ ' shape ' ] NEW_LINE ndim = len ( shape ) NEW_LINE DEDENT else : NEW_LINE INDENT shape = None NEW_LINE ndim = 0 NEW_LINE DEDENT upsample = self . default_upsample NEW_LINE if ndim > 0 : NEW_LINE INDENT upsample = None NEW_LINE DEDENT col_info = ColSpec ( name , ndim , shape , upsample , self . default_downsample ) NEW_LINE self . col_info [ name ] = col_info NEW_LINE DEDENT DEDENT self . _known_descriptors . add ( descriptor . uid ) NEW_LINE DEDENT @ property NEW_LINE def _dataframe ( self ) : NEW_LINE INDENT if self . _stale : NEW_LINE INDENT df = pd . DataFrame ( list ( self . _data ) ) NEW_LINE df [ ' time ' ] = list ( self . _time ) NEW_LINE if self . _timestamps_as_data : NEW_LINE INDENT timestamps = pd . DataFrame ( list ( self . _timestamps ) ) NEW_LINE DEDENT for source_name in self . _timestamps_as_data : NEW_LINE INDENT col_name = _timestamp_col_name ( source_name ) NEW_LINE df [ col_name ] = timestamps [ source_name ] NEW_LINE logger . debug ( " Including ▁ % s ▁ timestamps ▁ as ▁ data " , source_name ) NEW_LINE DEDENT self . _df = df . sort ( ' time ' ) . reset_index ( drop = True ) NEW_LINE self . _stale = False NEW_LINE DEDENT return self . _df NEW_LINE DEDENT def to_sparse_dataframe ( self , include_all_timestamps = False ) : NEW_LINE INDENT if include_all_timestamps : NEW_LINE INDENT raise NotImplementedError ( " TODO " ) NEW_LINE DEDENT result = self . _dataframe . copy ( ) NEW_LINE for col_name in self . _time_columns : NEW_LINE INDENT result [ col_name ] = self . _maybe_convert_times ( result [ col_name ] ) NEW_LINE DEDENT return result NEW_LINE DEDENT def _maybe_convert_times ( self , data ) : NEW_LINE INDENT if self . convert_times : NEW_LINE INDENT t = pd . to_datetime ( data , unit = ' s ' , utc = True ) . dt . tz_localize ( TZ ) NEW_LINE if self . reference_time is None : NEW_LINE INDENT return t NEW_LINE DEDENT else : NEW_LINE INDENT return t - self . reference_time NEW_LINE DEDENT DEDENT return data NEW_LINE DEDENT def include_timestamp_data ( self , source_name ) : NEW_LINE INDENT self . _timestamps_as_data . add ( source_name ) NEW_LINE name = _timestamp_col_name ( source_name ) NEW_LINE self . col_info [ name ] = ColSpec ( name , 0 , None , None , np . mean ) NEW_LINE self . _stale = True NEW_LINE DEDENT def remove_timestamp_data ( self , source_name ) : NEW_LINE INDENT self . _timestamps_as_data . remove ( source_name ) NEW_LINE del self . _df [ _timestamp_col_name ( source_name ) ] NEW_LINE DEDENT def bin_on ( self , source_name , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT centers , bin_edges = self . _bin_on ( source_name ) NEW_LINE return self . bin_by_edges ( bin_edges , bin_anchors = centers , interpolation = interpolation , agg = agg , use_cols = use_cols ) NEW_LINE DEDENT def _bin_on ( self , source_name ) : NEW_LINE INDENT col = self . _dataframe [ source_name ] NEW_LINE centers = self . _dataframe [ ' time ' ] . reindex_like ( col . dropna ( ) ) . values NEW_LINE bin_edges = np . mean ( [ centers [ 1 : ] , centers [ : - 1 ] ] , 0 ) NEW_LINE bin_edges = [ - np . inf ] + list ( np . repeat ( bin_edges , 2 ) ) + [ np . inf ] NEW_LINE bin_edges = np . reshape ( bin_edges , ( - 1 , 2 ) ) NEW_LINE return centers , bin_edges NEW_LINE DEDENT def bin_by_edges ( self , bin_edges , bin_anchors , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT bin_anchors , binning = self . _bin_by_edges ( bin_anchors , bin_edges ) NEW_LINE return self . resample ( bin_anchors , binning , interpolation , agg , use_cols = use_cols ) NEW_LINE DEDENT def _bin_by_edges ( self , bin_anchors , bin_edges ) : NEW_LINE INDENT time = self . _dataframe [ ' time ' ] . values NEW_LINE edges_as_pairs = np . reshape ( bin_edges , ( - 1 , 2 ) ) NEW_LINE all_edges = np . ravel ( edges_as_pairs ) NEW_LINE if not np . all ( np . diff ( all_edges ) >= 0 ) : NEW_LINE INDENT raise ValueError ( " Illegal ▁ binning : ▁ the ▁ left ▁ edge ▁ must ▁ be ▁ less ▁ " " than ▁ the ▁ right ▁ edge . " ) NEW_LINE DEDENT binning = np . searchsorted ( all_edges , time ) . astype ( float ) NEW_LINE binning [ binning % 2 == 0 ] = np . nan NEW_LINE binning //= 2 NEW_LINE if bin_anchors is None : NEW_LINE INDENT bin_anchors = np . mean ( edges_as_pairs , axis = 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT if len ( bin_anchors ) != len ( bin_edges ) : NEW_LINE INDENT raise ValueError ( " There ▁ are ▁ { 0 } ▁ bin _ anchors ▁ but ▁ { 1 } ▁ pairs ▁ of ▁ " " bin _ edges . ▁ These ▁ must ▁ match . " . format ( len ( bin_anchors ) , len ( bin_edges ) ) ) NEW_LINE DEDENT DEDENT return bin_anchors , binning NEW_LINE DEDENT def resample ( self , bin_anchors , binning , interpolation = None , agg = None , verify_integrity = True , use_cols = None ) : NEW_LINE INDENT if use_cols is None : NEW_LINE INDENT use_cols = self . columns NEW_LINE DEDENT plan = self . Planner ( self ) NEW_LINE upsampling_rules = plan . determine_upsample ( interpolation , use_cols ) NEW_LINE downsampling_rules = plan . determine_downsample ( agg , use_cols ) NEW_LINE grouped = self . _dataframe . groupby ( binning ) NEW_LINE first_point = grouped . first ( ) NEW_LINE counts = grouped . count ( ) NEW_LINE resampling_requirements = _is_resampling_applicable ( counts ) NEW_LINE index = np . arange ( len ( bin_anchors ) ) NEW_LINE result = { } NEW_LINE for name in use_cols : NEW_LINE INDENT upsample = upsampling_rules [ name ] NEW_LINE downsample = downsampling_rules [ name ] NEW_LINE upsampling_possible = resampling_requirements [ ' upsampling _ possible ' ] [ name ] NEW_LINE downsampling_needed = resampling_requirements [ ' downsampling _ needed ' ] [ name ] NEW_LINE result [ name ] = pd . DataFrame ( index = index ) NEW_LINE result [ name ] [ ' val ' ] = pd . Series ( data = first_point [ name ] ) NEW_LINE if not ( upsampling_possible or downsampling_needed ) : NEW_LINE INDENT logger . debug ( " % s ▁ has ▁ exactly ▁ one ▁ data ▁ point ▁ per ▁ bin " , name ) NEW_LINE continue NEW_LINE DEDENT result [ name ] [ ' count ' ] = counts [ name ] NEW_LINE if upsampling_possible and ( upsample is not None ) : NEW_LINE INDENT if upsample in ( ' ffill ' , ' bfill ' ) : NEW_LINE INDENT result [ name ] [ ' val ' ] . fillna ( method = upsample , inplace = True ) NEW_LINE DEDENT else : NEW_LINE INDENT dense_col = self . _dataframe [ name ] . dropna ( ) NEW_LINE y = dense_col . values NEW_LINE x = self . _dataframe [ ' time ' ] . reindex_like ( dense_col ) . values NEW_LINE interpolator = interp1d ( x , y , kind = upsample ) NEW_LINE is_safe = ( ( bin_anchors > np . min ( x ) ) & ( bin_anchors < np . max ( x ) ) ) NEW_LINE safe_times = bin_anchors [ is_safe ] NEW_LINE safe_bins = index [ is_safe ] NEW_LINE interp_points = pd . Series ( interpolator ( safe_times ) , index = safe_bins ) NEW_LINE logger . debug ( " Interpolating ▁ to ▁ fill ▁ % d ▁ of ▁ % d ▁ " " empty ▁ bins ▁ in ▁ % s " , len ( safe_bins ) , ( counts [ name ] == 0 ) . sum ( ) , name ) NEW_LINE result [ name ] [ ' val ' ] . fillna ( interp_points , inplace = True ) NEW_LINE DEDENT DEDENT if not downsampling_needed : NEW_LINE INDENT logger . debug ( " % s ▁ has ▁ at ▁ most ▁ one ▁ data ▁ point ▁ per ▁ bin " , name ) NEW_LINE continue NEW_LINE DEDENT if ( downsample is None ) : NEW_LINE INDENT raise BinningError ( " The ▁ specified ▁ binning ▁ puts ▁ multiple ▁ " " ' {0 } ' ▁ measurements ▁ in ▁ at ▁ least ▁ one ▁ bin , ▁ " " and ▁ there ▁ is ▁ no ▁ rule ▁ for ▁ downsampling ▁ " " ( i . e . , ▁ reducing ) ▁ it . " . format ( name ) ) NEW_LINE DEDENT if verify_integrity and callable ( downsample ) : NEW_LINE INDENT downsample = _build_verified_downsample ( downsample , self . col_info [ name ] . shape ) NEW_LINE DEDENT g = grouped [ name ] NEW_LINE if self . col_info [ name ] . ndim == 0 : NEW_LINE INDENT logger . debug ( " The ▁ scalar ▁ column ▁ % s ▁ must ▁ be ▁ downsampled . " , name ) NEW_LINE downsampled = g . agg ( downsample ) NEW_LINE std_series = g . std ( ) NEW_LINE max_series = g . max ( ) NEW_LINE min_series = g . min ( ) NEW_LINE DEDENT else : NEW_LINE INDENT logger . debug ( " The ▁ nonscalar ▁ column ▁ % s ▁ must ▁ be ▁ downsampled . " , name ) NEW_LINE if not callable ( downsample ) : NEW_LINE INDENT downsample = ColSpec . _downsample_mapping [ downsample ] NEW_LINE DEDENT downsampled = g . apply ( lambda x : downsample ( np . asarray ( x . dropna ( ) ) ) ) NEW_LINE std_series = g . apply ( lambda x : np . std ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE max_series = g . apply ( lambda x : np . max ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE min_series = g . apply ( lambda x : np . min ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE DEDENT result [ name ] [ ' val ' ] . where ( ~ ( counts [ name ] > 1 ) , downsampled , inplace = True ) NEW_LINE result [ name ] [ ' std ' ] = std_series NEW_LINE result [ name ] [ ' max ' ] = max_series NEW_LINE result [ name ] [ ' min ' ] = min_series NEW_LINE DEDENT result = pd . concat ( result , axis = 1 ) NEW_LINE result . index . name = ' bin ' NEW_LINE for col_name in self . _time_columns : NEW_LINE INDENT if isinstance ( result [ col_name ] , pd . DataFrame ) : NEW_LINE INDENT subcols = result [ col_name ] . columns NEW_LINE for subcol in subcols & { ' max ' , ' min ' , ' val ' } : NEW_LINE INDENT result [ ( col_name , subcol ) ] = self . _maybe_convert_times ( result [ ( col_name , subcol ) ] ) NEW_LINE DEDENT for subcol in subcols & { ' std ' } : NEW_LINE INDENT result [ ( col_name , subcol ) ] = pd . to_timedelta ( result [ ( col_name , subcol ) ] , unit = ' s ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT result [ col_name ] = self . _maybe_convert_times ( result [ col_name ] ) NEW_LINE DEDENT DEDENT return result NEW_LINE DEDENT def __getitem__ ( self , source_name ) : NEW_LINE INDENT if source_name not in list ( self . col_info . keys ( ) ) + [ ' time ' ] : NEW_LINE INDENT raise KeyError ( " No ▁ data ▁ from ▁ a ▁ source ▁ called ▁ ' {0 } ' ▁ has ▁ been ▁ " " added . " . format ( source_name ) ) NEW_LINE DEDENT result = self . _dataframe [ source_name ] . dropna ( ) NEW_LINE result . index = self . _dataframe [ ' time ' ] . reindex_like ( result ) NEW_LINE return result NEW_LINE DEDENT def __getattr__ ( self , attr ) : NEW_LINE INDENT if attr in self . col_info . keys ( ) : NEW_LINE INDENT return self [ attr ] NEW_LINE DEDENT else : NEW_LINE INDENT raise AttributeError ( " DataMuxer ▁ has ▁ no ▁ attribute ▁ { 0 } ▁ and ▁ no ▁ " " data ▁ source ▁ named ▁ ' {0 } ' " . format ( attr ) ) NEW_LINE DEDENT DEDENT @ property NEW_LINE def ncols ( self ) : NEW_LINE INDENT return len ( self . col_info ) NEW_LINE DEDENT @ property NEW_LINE def col_info_by_ndim ( self ) : NEW_LINE INDENT result = { } NEW_LINE for name , col_spec in six . iteritems ( self . col_info ) : NEW_LINE INDENT try : NEW_LINE INDENT result [ col_spec . ndim ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT result [ col_spec . ndim ] = [ ] NEW_LINE DEDENT result [ col_spec . ndim ] . append ( col_spec ) NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT def dataframe_to_dict ( df ) : NEW_LINE INDENT dict_of_lists = { col : df [ col ] . to_list ( ) for col in df . columns } NEW_LINE return df . index . values , dict_of_lists NEW_LINE DEDENT def _build_verified_downsample ( downsample , expected_shape ) : NEW_LINE INDENT def _downsample ( data ) : NEW_LINE INDENT if len ( data ) == 1 : NEW_LINE INDENT return data NEW_LINE DEDENT downsampled = downsample ( data ) NEW_LINE if ( expected_shape is None or expected_shape == 0 ) : NEW_LINE INDENT if not np . isscalar ( downsampled ) : NEW_LINE INDENT raise BadDownsamplerError ( " The ▁ ' agg ' ▁ ( downsampling ) ▁ function ▁ " " for ▁ { 0 } ▁ is ▁ expected ▁ to ▁ produce ▁ " " a ▁ scalar ▁ from ▁ the ▁ data ▁ in ▁ each ▁ " " bin . " . format ( downsampled ) ) NEW_LINE DEDENT DEDENT elif downsampled . shape != expected_shape : NEW_LINE INDENT raise BadDownsamplerError ( " An ▁ ' agg ' ▁ ( downsampling ) ▁ function ▁ " " returns ▁ data ▁ shaped ▁ { 0 } ▁ but ▁ the ▁ " " shape ▁ { 1 } ▁ is ▁ expected . " . format ( downsampled . shape , expected_shape ) ) NEW_LINE DEDENT return downsampled NEW_LINE DEDENT return _downsample NEW_LINE DEDENT def _timestamp_col_name ( source_name ) : NEW_LINE INDENT return ' { 0 } _ timestamp ' . format ( source_name ) NEW_LINE DEDENT def _normalize_string_none ( val ) : NEW_LINE INDENT try : NEW_LINE INDENT lowercase_val = val . lower ( ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT return val NEW_LINE DEDENT if lowercase_val == ' none ' : NEW_LINE INDENT return None NEW_LINE DEDENT else : NEW_LINE INDENT return val NEW_LINE DEDENT DEDENT def _is_resampling_applicable ( counts ) : NEW_LINE INDENT has_no_points = counts == 0 NEW_LINE has_multiple_points = counts > 1 NEW_LINE upsampling_possible = has_no_points . any ( ) NEW_LINE downsampling_needed = has_multiple_points . any ( ) NEW_LINE result = { } NEW_LINE result [ ' upsampling _ possible ' ] = upsampling_possible . to_dict ( ) NEW_LINE result [ ' downsampling _ needed ' ] = downsampling_needed . to_dict ( ) NEW_LINE return result NEW_LINE DEDENT
 from subprocess import Popen , PIPE NEW_LINE import glob NEW_LINE import operator NEW_LINE import os NEW_LINE import sys NEW_LINE OUT_CPP = " qt / bitcoinstrings . cpp " NEW_LINE EMPTY = [ ' " " ' ] NEW_LINE def parse_po ( text ) : NEW_LINE INDENT messages = [ ] NEW_LINE msgid = [ ] NEW_LINE msgstr = [ ] NEW_LINE in_msgid = False NEW_LINE in_msgstr = False NEW_LINE for line in text . split ( ' \n ' ) : NEW_LINE INDENT line = line . rstrip ( ' \r ' ) NEW_LINE if line . startswith ( ' msgid ▁ ' ) : NEW_LINE INDENT if in_msgstr : NEW_LINE INDENT messages . append ( ( msgid , msgstr ) ) NEW_LINE in_msgstr = False NEW_LINE DEDENT in_msgid = True NEW_LINE msgid = [ line [ 6 : ] ] NEW_LINE DEDENT elif line . startswith ( ' msgstr ▁ ' ) : NEW_LINE INDENT in_msgid = False NEW_LINE in_msgstr = True NEW_LINE msgstr = [ line [ 7 : ] ] NEW_LINE DEDENT elif line . startswith ( ' " ' ) : NEW_LINE INDENT if in_msgid : NEW_LINE INDENT msgid . append ( line ) NEW_LINE DEDENT if in_msgstr : NEW_LINE INDENT msgstr . append ( line ) NEW_LINE DEDENT DEDENT DEDENT if in_msgstr : NEW_LINE INDENT messages . append ( ( msgid , msgstr ) ) NEW_LINE DEDENT return messages NEW_LINE DEDENT files = sys . argv [ 1 : ] NEW_LINE XGETTEXT = os . getenv ( ' XGETTEXT ' , ' xgettext ' ) NEW_LINE child = Popen ( [ XGETTEXT , ' - - output = - ' , ' - n ' , ' - - keyword = _ ' ] + files , stdout = PIPE ) NEW_LINE ( out , err ) = child . communicate ( ) NEW_LINE messages = parse_po ( out ) NEW_LINE f = open ( OUT_CPP , ' w ' ) NEW_LINE f . write ( """ STRNEWLINE STRNEWLINE # include ▁ < QtGlobal > STRNEWLINE STRNEWLINE / / ▁ Automatically ▁ generated ▁ by ▁ extract _ strings . py STRNEWLINE # ifdef ▁ _ _ GNUC _ _ STRNEWLINE # define ▁ UNUSED ▁ _ _ attribute _ _ ( ( unused ) ) STRNEWLINE # else STRNEWLINE # define ▁ UNUSED STRNEWLINE # endif STRNEWLINE """ ) NEW_LINE f . write ( ' static ▁ const ▁ char ▁ UNUSED ▁ * bitcoin _ strings [ ] ▁ = ▁ { \n ' ) NEW_LINE messages . sort ( key = operator . itemgetter ( 0 ) ) NEW_LINE for ( msgid , msgstr ) in messages : NEW_LINE INDENT if msgid != EMPTY : NEW_LINE INDENT f . write ( ' QT _ TRANSLATE _ NOOP ( " bitcoin - core " , ▁ % s ) , \n ' % ( ' \n ' . join ( msgid ) ) ) NEW_LINE DEDENT DEDENT f . write ( ' } ; \n ' ) NEW_LINE f . close ( ) NEW_LINE
 from Tools . Profile import profile NEW_LINE from Screen import Screen NEW_LINE import Screens . InfoBar NEW_LINE import Components . ParentalControl NEW_LINE from Components . Button import Button NEW_LINE from Components . ServiceList import ServiceList , refreshServiceList NEW_LINE from Components . ActionMap import NumberActionMap , ActionMap , HelpableActionMap NEW_LINE from Components . MenuList import MenuList NEW_LINE from Components . ServiceEventTracker import ServiceEventTracker , InfoBarBase NEW_LINE profile ( " ChannelSelection . py ▁ 1" ) NEW_LINE from EpgSelection import EPGSelection NEW_LINE from enigma import eServiceReference , eEPGCache , eServiceCenter , eRCInput , eTimer , eDVBDB , iPlayableService , iServiceInformation , getPrevAsciiCode , eEnv NEW_LINE from Components . config import config , configfile , ConfigSubsection , ConfigText , ConfigYesNo NEW_LINE from Tools . NumericalTextInput import NumericalTextInput NEW_LINE profile ( " ChannelSelection . py ▁ 2" ) NEW_LINE from Components . NimManager import nimmanager NEW_LINE profile ( " ChannelSelection . py ▁ 2.1" ) NEW_LINE from Components . Sources . RdsDecoder import RdsDecoder NEW_LINE profile ( " ChannelSelection . py ▁ 2.2" ) NEW_LINE from Components . Sources . ServiceEvent import ServiceEvent NEW_LINE from Components . Sources . Event import Event NEW_LINE profile ( " ChannelSelection . py ▁ 2.3" ) NEW_LINE from Components . Input import Input NEW_LINE profile ( " ChannelSelection . py ▁ 3" ) NEW_LINE from Components . ChoiceList import ChoiceList , ChoiceEntryComponent NEW_LINE from Components . SystemInfo import SystemInfo NEW_LINE from Screens . InputBox import PinInput NEW_LINE from Screens . VirtualKeyBoard import VirtualKeyBoard NEW_LINE from Screens . MessageBox import MessageBox NEW_LINE from Screens . ServiceInfo import ServiceInfo NEW_LINE from Screens . Hotkey import InfoBarHotkey , hotkeyActionMap , getHotkeyFunctions NEW_LINE profile ( " ChannelSelection . py ▁ 4" ) NEW_LINE from Screens . PictureInPicture import PictureInPicture NEW_LINE from Screens . RdsDisplay import RassInteractive NEW_LINE from ServiceReference import ServiceReference NEW_LINE from Tools . BoundFunction import boundFunction NEW_LINE from Tools import Notifications NEW_LINE from Tools . Alternatives import CompareWithAlternatives , GetWithAlternative NEW_LINE from Tools . Directories import fileExists NEW_LINE from Plugins . Plugin import PluginDescriptor NEW_LINE from Components . PluginComponent import plugins NEW_LINE from Screens . ChoiceBox import ChoiceBox NEW_LINE from Screens . EventView import EventViewEPGSelect NEW_LINE import os , unicodedata NEW_LINE profile ( " ChannelSelection . py ▁ after ▁ imports " ) NEW_LINE FLAG_SERVICE_NEW_FOUND = 64 NEW_LINE FLAG_IS_DEDICATED_3D = 128 NEW_LINE FLAG_HIDE_VBI = 512 NEW_LINE class BouquetSelector ( Screen ) : NEW_LINE INDENT def __init__ ( self , session , bouquets , selectedFunc , enableWrapAround = True ) : NEW_LINE INDENT Screen . __init__ ( self , session ) NEW_LINE self . setTitle ( _ ( " Choose ▁ bouquet " ) ) NEW_LINE self . selectedFunc = selectedFunc NEW_LINE self [ " actions " ] = ActionMap ( [ " OkCancelActions " ] , { " ok " : self . okbuttonClick , " cancel " : self . cancelClick } ) NEW_LINE entrys = [ ( x [ 0 ] , x [ 1 ] ) for x in bouquets ] NEW_LINE self [ " menu " ] = MenuList ( entrys , enableWrapAround ) NEW_LINE DEDENT def getCurrent ( self ) : NEW_LINE INDENT cur = self [ " menu " ] . getCurrent ( ) NEW_LINE return cur and cur [ 1 ] NEW_LINE DEDENT def okbuttonClick ( self ) : NEW_LINE INDENT self . selectedFunc ( self . getCurrent ( ) ) NEW_LINE DEDENT def up ( self ) : NEW_LINE INDENT self [ " menu " ] . up ( ) NEW_LINE DEDENT def down ( self ) : NEW_LINE INDENT self [ " menu " ] . down ( ) NEW_LINE DEDENT def cancelClick ( self ) : NEW_LINE INDENT self . close ( False ) NEW_LINE DEDENT DEDENT class SilentBouquetSelector : NEW_LINE INDENT def __init__ ( self , bouquets , enableWrapAround = False , current = 0 ) : NEW_LINE INDENT self . bouquets = [ b [ 1 ] for b in bouquets ] NEW_LINE self . pos = current NEW_LINE self . count = len ( bouquets ) NEW_LINE self . enableWrapAround = enableWrapAround NEW_LINE DEDENT def up ( self ) : NEW_LINE INDENT if self . pos > 0 or self . enableWrapAround : NEW_LINE INDENT self . pos = ( self . pos - 1 ) % self . count NEW_LINE DEDENT DEDENT def down ( self ) : NEW_LINE INDENT if self . pos < ( self . count - 1 ) or self . enableWrapAround : NEW_LINE INDENT self . pos = ( self . pos + 1 ) % self . count NEW_LINE DEDENT DEDENT def getCurrent ( self ) : NEW_LINE INDENT return self . bouquets [ self . pos ] NEW_LINE DEDENT DEDENT OFF = 0 NEW_LINE EDIT_BOUQUET = 1 NEW_LINE EDIT_ALTERNATIVES = 2 NEW_LINE def append_when_current_valid ( current , menu , args , level = 0 , key = " " ) : NEW_LINE INDENT if current and current . valid ( ) and level <= config . usage . setup_level . index : NEW_LINE INDENT menu . append ( ChoiceEntryComponent ( key , args ) ) NEW_LINE DEDENT DEDENT def removed_userbouquets_available ( ) : NEW_LINE INDENT for file in os . listdir ( " / etc / enigma2 / " ) : NEW_LINE INDENT if file . startswith ( " userbouquet " ) and file . endswith ( " . del " ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT class ChannelContextMenu ( Screen ) : NEW_LINE INDENT def __init__ ( self , session , csel ) : NEW_LINE INDENT Screen . __init__ ( self , session ) NEW_LINE self . csel = csel NEW_LINE self . bsel = None NEW_LINE if self . isProtected ( ) : NEW_LINE INDENT self . onFirstExecBegin . append ( boundFunction ( self . session . openWithCallback , self . protectResult , PinInput , pinList = [ x . value for x in config . ParentalControl . servicepin ] , triesEntry = config . ParentalControl . retries . servicepin , title = _ ( " Please ▁ enter ▁ the ▁ correct ▁ pin ▁ code " ) , windowTitle = _ ( " Enter ▁ pin ▁ code " ) ) ) NEW_LINE DEDENT self [ " actions " ] = ActionMap ( [ " OkCancelActions " , " ColorActions " , " NumberActions " , " MenuActions " ] , { " ok " : self . okbuttonClick , " cancel " : self . cancelClick , " blue " : self . showServiceInPiP , " red " : self . playMain , " menu " : self . openSetup , "2" : self . renameEntry , "3" : self . findCurrentlyPlayed , "5" : self . addServiceToBouquetOrAlternative , "6" : self . toggleMoveModeSelect , "8" : self . removeEntry } ) NEW_LINE menu = [ ] NEW_LINE self . removeFunction = False NEW_LINE self . addFunction = False NEW_LINE current = csel . getCurrentSelection ( ) NEW_LINE current_root = csel . getRoot ( ) NEW_LINE current_sel_path = current . getPath ( ) NEW_LINE current_sel_flags = current . flags NEW_LINE inBouquetRootList = current_root and ' FROM ▁ BOUQUET ▁ " bouquets . ' in current_root . getPath ( ) NEW_LINE inAlternativeList = current_root and ' FROM ▁ BOUQUET ▁ " alternatives ' in current_root . getPath ( ) NEW_LINE self . inBouquet = csel . getMutableList ( ) is not None NEW_LINE haveBouquets = config . usage . multibouquet . value NEW_LINE from Components . ParentalControl import parentalControl NEW_LINE self . parentalControl = parentalControl NEW_LINE self . parentalControlEnabled = config . ParentalControl . servicepin [ 0 ] . value and config . ParentalControl . servicepinactive . value NEW_LINE if not ( current_sel_path or current_sel_flags & ( eServiceReference . isDirectory | eServiceReference . isMarker ) ) or current_sel_flags & eServiceReference . isGroup : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " show ▁ transponder ▁ info " ) , self . showServiceInformations ) , level = 2 ) NEW_LINE DEDENT if csel . bouquet_mark_edit == OFF and not csel . entry_marked : NEW_LINE INDENT if not inBouquetRootList : NEW_LINE INDENT isPlayable = not ( current_sel_flags & ( eServiceReference . isMarker | eServiceReference . isDirectory ) ) NEW_LINE if isPlayable : NEW_LINE INDENT for p in plugins . getPlugins ( PluginDescriptor . WHERE_CHANNEL_CONTEXT_MENU ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( p . name , boundFunction ( self . runPlugin , p ) ) , key = " bullet " ) NEW_LINE DEDENT if config . servicelist . startupservice . value == current . toString ( ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " stop ▁ using ▁ as ▁ startup ▁ service " ) , self . unsetStartupService ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " set ▁ as ▁ startup ▁ service " ) , self . setStartupService ) , level = 0 ) NEW_LINE DEDENT if self . parentalControlEnabled : NEW_LINE INDENT if self . parentalControl . getProtectionLevel ( current . toCompareString ( ) ) == - 1 : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ to ▁ parental ▁ protection " ) , boundFunction ( self . addParentalProtection , current ) ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT if self . parentalControl . isServiceProtectionBouquet ( current . toCompareString ( ) ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " service ▁ is ▁ in ▁ bouquet ▁ parental ▁ protection " ) , self . cancelClick ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ from ▁ parental ▁ protection " ) , boundFunction ( self . removeParentalProtection , current ) ) , level = 0 ) NEW_LINE DEDENT DEDENT if config . ParentalControl . hideBlacklist . value and not parentalControl . sessionPinCached and config . ParentalControl . storeservicepin . value != " never " : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Unhide ▁ parental ▁ control ▁ services " ) , self . unhideParentalServices ) , level = 0 , key = "1" ) NEW_LINE DEDENT DEDENT if SystemInfo [ "3DMode " ] and fileExists ( " / usr / lib / enigma2 / python / Plugins / SystemPlugins / OSD3DSetup / plugin . py " ) : NEW_LINE INDENT if eDVBDB . getInstance ( ) . getFlag ( eServiceReference ( current . toString ( ) ) ) & FLAG_IS_DEDICATED_3D : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Unmark ▁ service ▁ as ▁ dedicated ▁ 3D ▁ service " ) , self . removeDedicated3DFlag ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Mark ▁ service ▁ as ▁ dedicated ▁ 3D ▁ service " ) , self . addDedicated3DFlag ) , level = 0 ) NEW_LINE DEDENT DEDENT if not ( current_sel_path ) : NEW_LINE INDENT if eDVBDB . getInstance ( ) . getFlag ( eServiceReference ( current . toString ( ) ) ) & FLAG_HIDE_VBI : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Uncover ▁ dashed ▁ flickering ▁ line ▁ for ▁ this ▁ service " ) , self . removeHideVBIFlag ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " Cover ▁ dashed ▁ flickering ▁ line ▁ for ▁ this ▁ service " ) , self . addHideVBIFlag ) , level = 0 ) NEW_LINE DEDENT DEDENT if haveBouquets : NEW_LINE INDENT bouquets = self . csel . getBouquetList ( ) NEW_LINE if bouquets is None : NEW_LINE INDENT bouquetCnt = 0 NEW_LINE DEDENT else : NEW_LINE INDENT bouquetCnt = len ( bouquets ) NEW_LINE DEDENT if not self . inBouquet or bouquetCnt > 1 : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ service ▁ to ▁ bouquet " ) , self . addServiceToBouquetSelected ) , level = 0 , key = "5" ) NEW_LINE self . addFunction = self . addServiceToBouquetSelected NEW_LINE DEDENT if not self . inBouquet : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ entry " ) , self . removeEntry ) , level = 0 , key = "8" ) NEW_LINE self . removeFunction = self . removeSatelliteService NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if not self . inBouquet : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ service ▁ to ▁ favourites " ) , self . addServiceToBouquetSelected ) , level = 0 , key = "5" ) NEW_LINE self . addFunction = self . addServiceToBouquetSelected NEW_LINE DEDENT DEDENT if SystemInfo [ " PIPAvailable " ] : NEW_LINE INDENT if not self . parentalControlEnabled or self . parentalControl . getProtectionLevel ( current . toCompareString ( ) ) == - 1 : NEW_LINE INDENT if self . csel . dopipzap : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " play ▁ in ▁ mainwindow " ) , self . playMain ) , level = 0 , key = " red " ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " play ▁ as ▁ picture ▁ in ▁ picture " ) , self . showServiceInPiP ) , level = 0 , key = " blue " ) NEW_LINE DEDENT DEDENT DEDENT append_when_current_valid ( current , menu , ( _ ( " find ▁ currently ▁ played ▁ service " ) , self . findCurrentlyPlayed ) , level = 0 , key = "3" ) NEW_LINE DEDENT else : NEW_LINE INDENT if ' FROM ▁ SATELLITES ' in current_root . getPath ( ) and current and _ ( " Services " ) in eServiceCenter . getInstance ( ) . info ( current ) . getName ( current ) : NEW_LINE INDENT unsigned_orbpos = current . getUnsignedData ( 4 ) >> 16 NEW_LINE if unsigned_orbpos == 0xFFFF : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ cable ▁ services " ) , self . removeSatelliteServices ) , level = 0 ) NEW_LINE DEDENT elif unsigned_orbpos == 0xEEEE : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ terrestrial ▁ services " ) , self . removeSatelliteServices ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ selected ▁ satellite " ) , self . removeSatelliteServices ) , level = 0 ) NEW_LINE DEDENT DEDENT if haveBouquets : NEW_LINE INDENT if not self . inBouquet and not " PROVIDERS " in current_sel_path : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " copy ▁ to ▁ bouquets " ) , self . copyCurrentToBouquetList ) , level = 0 ) NEW_LINE DEDENT DEDENT if ( " flags ▁ = = ▁ % d " % ( FLAG_SERVICE_NEW_FOUND ) ) in current_sel_path : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ all ▁ new ▁ found ▁ flags " ) , self . removeAllNewFoundFlags ) , level = 0 ) NEW_LINE DEDENT DEDENT if self . inBouquet : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " rename ▁ entry " ) , self . renameEntry ) , level = 0 , key = "2" ) NEW_LINE if not inAlternativeList : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ entry " ) , self . removeEntry ) , level = 0 , key = "8" ) NEW_LINE self . removeFunction = self . removeCurrentService NEW_LINE DEDENT DEDENT if current_root and ( " flags ▁ = = ▁ % d " % ( FLAG_SERVICE_NEW_FOUND ) ) in current_root . getPath ( ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ new ▁ found ▁ flag " ) , self . removeNewFoundFlag ) , level = 0 ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if self . parentalControlEnabled : NEW_LINE INDENT if self . parentalControl . getProtectionLevel ( current . toCompareString ( ) ) == - 1 : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ bouquet ▁ to ▁ parental ▁ protection " ) , boundFunction ( self . addParentalProtection , current ) ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " remove ▁ bouquet ▁ from ▁ parental ▁ protection " ) , boundFunction ( self . removeParentalProtection , current ) ) , level = 0 ) NEW_LINE DEDENT DEDENT menu . append ( ChoiceEntryComponent ( text = ( _ ( " add ▁ bouquet " ) , self . showBouquetInputBox ) ) ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " rename ▁ entry " ) , self . renameEntry ) , level = 0 , key = "2" ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " remove ▁ entry " ) , self . removeEntry ) , level = 0 , key = "8" ) NEW_LINE self . removeFunction = self . removeBouquet NEW_LINE if removed_userbouquets_available ( ) : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " purge ▁ deleted ▁ userbouquets " ) , self . purgeDeletedBouquets ) , level = 0 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " restore ▁ deleted ▁ userbouquets " ) , self . restoreDeletedBouquets ) , level = 0 ) NEW_LINE DEDENT DEDENT DEDENT if self . inBouquet : NEW_LINE INDENT if csel . bouquet_mark_edit == OFF : NEW_LINE INDENT if csel . movemode : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " disable ▁ move ▁ mode " ) , self . toggleMoveMode ) , level = 0 , key = "6" ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " enable ▁ move ▁ mode " ) , self . toggleMoveMode ) , level = 1 , key = "6" ) NEW_LINE DEDENT if not csel . entry_marked and not inBouquetRootList and current_root and not ( current_root . flags & eServiceReference . isGroup ) : NEW_LINE INDENT if current . type != - 1 : NEW_LINE INDENT menu . append ( ChoiceEntryComponent ( text = ( _ ( " add ▁ marker " ) , self . showMarkerInputBox ) ) ) NEW_LINE DEDENT if not csel . movemode : NEW_LINE INDENT if haveBouquets : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " enable ▁ bouquet ▁ edit " ) , self . bouquetMarkStart ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " enable ▁ favourite ▁ edit " ) , self . bouquetMarkStart ) , level = 0 ) NEW_LINE DEDENT DEDENT if current_sel_flags & eServiceReference . isGroup : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " edit ▁ alternatives " ) , self . editAlternativeServices ) , level = 2 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " show ▁ alternatives " ) , self . showAlternativeServices ) , level = 2 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " remove ▁ all ▁ alternatives " ) , self . removeAlternativeServices ) , level = 2 ) NEW_LINE DEDENT elif not current_sel_flags & eServiceReference . isMarker : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " add ▁ alternatives " ) , self . addAlternativeServices ) , level = 2 ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if csel . bouquet_mark_edit == EDIT_BOUQUET : NEW_LINE INDENT if haveBouquets : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " end ▁ bouquet ▁ edit " ) , self . bouquetMarkEnd ) , level = 0 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " abort ▁ bouquet ▁ edit " ) , self . bouquetMarkAbort ) , level = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " end ▁ favourites ▁ edit " ) , self . bouquetMarkEnd ) , level = 0 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " abort ▁ favourites ▁ edit " ) , self . bouquetMarkAbort ) , level = 0 ) NEW_LINE DEDENT if current_sel_flags & eServiceReference . isMarker : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " rename ▁ entry " ) , self . renameEntry ) , level = 0 , key = "2" ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " remove ▁ entry " ) , self . removeEntry ) , level = 0 , key = "8" ) NEW_LINE self . removeFunction = self . removeCurrentService NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT append_when_current_valid ( current , menu , ( _ ( " end ▁ alternatives ▁ edit " ) , self . bouquetMarkEnd ) , level = 0 ) NEW_LINE append_when_current_valid ( current , menu , ( _ ( " abort ▁ alternatives ▁ edit " ) , self . bouquetMarkAbort ) , level = 0 ) NEW_LINE DEDENT DEDENT DEDENT menu . append ( ChoiceEntryComponent ( " menu " , ( _ ( " Configuration . . . " ) , self . openSetup ) ) ) NEW_LINE self [ " menu " ] = ChoiceList ( menu ) NEW_LINE DEDENT def set3DMode ( self , value ) : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceReference ( ) NEW_LINE if config . plugins . OSD3DSetup . mode . value == " auto " and ( playingref and playingref == self . csel . getCurrentSelection ( ) ) : NEW_LINE INDENT from Plugins . SystemPlugins . OSD3DSetup . plugin import applySettings NEW_LINE applySettings ( value and " sidebyside " or config . plugins . OSD3DSetup . mode . value ) NEW_LINE DEDENT DEDENT def addDedicated3DFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . addFlag ( eServiceReference ( self . csel . getCurrentSelection ( ) . toString ( ) ) , FLAG_IS_DEDICATED_3D ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE self . set3DMode ( True ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeDedicated3DFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeFlag ( eServiceReference ( self . csel . getCurrentSelection ( ) . toString ( ) ) , FLAG_IS_DEDICATED_3D ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE self . set3DMode ( False ) NEW_LINE self . close ( ) NEW_LINE DEDENT def addHideVBIFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . addFlag ( eServiceReference ( self . csel . getCurrentSelection ( ) . toString ( ) ) , FLAG_HIDE_VBI ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE Screens . InfoBar . InfoBar . instance . showHideVBI ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeHideVBIFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeFlag ( eServiceReference ( self . csel . getCurrentSelection ( ) . toString ( ) ) , FLAG_HIDE_VBI ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE Screens . InfoBar . InfoBar . instance . showHideVBI ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def isProtected ( self ) : NEW_LINE INDENT return self . csel . protectContextMenu and config . ParentalControl . setuppinactive . value and config . ParentalControl . config_sections . context_menus . value NEW_LINE DEDENT def protectResult ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT self . csel . protectContextMenu = False NEW_LINE DEDENT elif answer is not None : NEW_LINE INDENT self . session . openWithCallback ( self . close , MessageBox , _ ( " The ▁ pin ▁ code ▁ you ▁ entered ▁ is ▁ wrong . " ) , MessageBox . TYPE_ERROR ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT def addServiceToBouquetOrAlternative ( self ) : NEW_LINE INDENT if self . addFunction : NEW_LINE INDENT self . addFunction ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def getCurrentSelectionName ( self ) : NEW_LINE INDENT cur = self . csel . getCurrentSelection ( ) NEW_LINE if cur and cur . valid ( ) : NEW_LINE INDENT name = eServiceCenter . getInstance ( ) . info ( cur ) . getName ( cur ) or ServiceReference ( cur ) . getServiceName ( ) or " " NEW_LINE name = name . replace ( ' \xc2\x86' , ' ' ) . replace ( ' \xc2\x87' , ' ' ) NEW_LINE return name NEW_LINE DEDENT return " " NEW_LINE DEDENT def removeEntry ( self ) : NEW_LINE INDENT if self . removeFunction and self . csel . servicelist . getCurrent ( ) and self . csel . servicelist . getCurrent ( ) . valid ( ) : NEW_LINE INDENT if self . csel . confirmRemove : NEW_LINE INDENT list = [ ( _ ( " yes " ) , True ) , ( _ ( " no " ) , False ) , ( _ ( " yes " ) + " ▁ " + _ ( " and ▁ never ▁ ask ▁ again ▁ this ▁ session ▁ again " ) , " never " ) ] NEW_LINE self . session . openWithCallback ( self . removeFunction , MessageBox , _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ this ▁ entry ? " ) + " \n % s " % self . getCurrentSelectionName ( ) , list = list ) NEW_LINE DEDENT else : NEW_LINE INDENT self . removeFunction ( True ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def removeCurrentService ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT if answer == " never " : NEW_LINE INDENT self . csel . confirmRemove = False NEW_LINE DEDENT self . csel . removeCurrentService ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT def removeSatelliteService ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT if answer == " never " : NEW_LINE INDENT self . csel . confirmRemove = False NEW_LINE DEDENT self . csel . removeSatelliteService ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT def removeBouquet ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT self . csel . removeBouquet ( ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT def purgeDeletedBouquets ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . purgeDeletedBouquetsCallback , MessageBox , _ ( " Are ▁ you ▁ sure ▁ to ▁ purge ▁ all ▁ deleted ▁ userbouquets ? " ) ) NEW_LINE DEDENT def purgeDeletedBouquetsCallback ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT for file in os . listdir ( " / etc / enigma2 / " ) : NEW_LINE INDENT if file . startswith ( " userbouquet " ) and file . endswith ( " . del " ) : NEW_LINE INDENT file = " / etc / enigma2 / " + file NEW_LINE print " permantly ▁ remove ▁ file ▁ " , file NEW_LINE os . remove ( file ) NEW_LINE DEDENT DEDENT self . close ( ) NEW_LINE DEDENT DEDENT def restoreDeletedBouquets ( self ) : NEW_LINE INDENT for file in os . listdir ( " / etc / enigma2 / " ) : NEW_LINE INDENT if file . startswith ( " userbouquet " ) and file . endswith ( " . del " ) : NEW_LINE INDENT file = " / etc / enigma2 / " + file NEW_LINE print " restore ▁ file ▁ " , file [ : - 4 ] NEW_LINE os . rename ( file , file [ : - 4 ] ) NEW_LINE DEDENT DEDENT eDVBDBInstance = eDVBDB . getInstance ( ) NEW_LINE eDVBDBInstance . setLoadUnlinkedUserbouquets ( True ) NEW_LINE eDVBDBInstance . reloadBouquets ( ) NEW_LINE eDVBDBInstance . setLoadUnlinkedUserbouquets ( config . misc . load_unlinked_userbouquets . value ) NEW_LINE refreshServiceList ( ) NEW_LINE self . csel . showFavourites ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def playMain ( self ) : NEW_LINE INDENT sel = self . csel . getCurrentSelection ( ) NEW_LINE if sel and sel . valid ( ) and self . csel . dopipzap and ( not self . parentalControlEnabled or self . parentalControl . getProtectionLevel ( self . csel . getCurrentSelection ( ) . toCompareString ( ) ) == - 1 ) : NEW_LINE INDENT self . csel . zap ( ) NEW_LINE self . csel . setCurrentSelection ( sel ) NEW_LINE self . close ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def okbuttonClick ( self ) : NEW_LINE INDENT self [ " menu " ] . getCurrent ( ) [ 0 ] [ 1 ] ( ) NEW_LINE DEDENT def openSetup ( self ) : NEW_LINE INDENT from Screens . Setup import Setup NEW_LINE self . session . openWithCallback ( self . cancelClick , Setup , " userinterface " ) NEW_LINE DEDENT def cancelClick ( self , dummy = False ) : NEW_LINE INDENT self . close ( False ) NEW_LINE DEDENT def showServiceInformations ( self ) : NEW_LINE INDENT current = self . csel . getCurrentSelection ( ) NEW_LINE if current . flags & eServiceReference . isGroup : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if playingref and playingref == current : NEW_LINE INDENT current = self . session . nav . getCurrentlyPlayingServiceReference ( ) NEW_LINE DEDENT else : NEW_LINE INDENT current = eServiceReference ( GetWithAlternative ( current . toString ( ) ) ) NEW_LINE DEDENT DEDENT self . session . open ( ServiceInfo , current ) NEW_LINE self . close ( ) NEW_LINE DEDENT def setStartupService ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . setStartupServiceCallback , MessageBox , _ ( " Set ▁ startup ▁ service " ) , list = [ ( _ ( " Only ▁ on ▁ startup " ) , " startup " ) , ( _ ( " Also ▁ on ▁ standby " ) , " standby " ) ] ) NEW_LINE DEDENT def setStartupServiceCallback ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT config . servicelist . startupservice . value = self . csel . getCurrentSelection ( ) . toString ( ) NEW_LINE path = ' ; ' . join ( [ i . toString ( ) for i in self . csel . servicePath ] ) NEW_LINE config . servicelist . startuproot . value = path NEW_LINE config . servicelist . startupmode . value = config . servicelist . lastmode . value NEW_LINE config . servicelist . startupservice_onstandby . value = answer == " standby " NEW_LINE config . servicelist . save ( ) NEW_LINE configfile . save ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT def unsetStartupService ( self ) : NEW_LINE INDENT config . servicelist . startupservice . value = ' ' NEW_LINE config . servicelist . startupservice_onstandby . value = False NEW_LINE config . servicelist . save ( ) NEW_LINE configfile . save ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def showBouquetInputBox ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . bouquetInputCallback , VirtualKeyBoard , title = _ ( " Please ▁ enter ▁ a ▁ name ▁ for ▁ the ▁ new ▁ bouquet " ) , text = " bouquetname " , maxSize = False , visible_width = 56 , type = Input . TEXT ) NEW_LINE DEDENT def bouquetInputCallback ( self , bouquet ) : NEW_LINE INDENT if bouquet is not None : NEW_LINE INDENT self . csel . addBouquet ( bouquet , None ) NEW_LINE DEDENT self . close ( ) NEW_LINE DEDENT def addParentalProtection ( self , service ) : NEW_LINE INDENT self . parentalControl . protectService ( service . toCompareString ( ) ) NEW_LINE if config . ParentalControl . hideBlacklist . value and not self . parentalControl . sessionPinCached : NEW_LINE INDENT self . csel . servicelist . resetRoot ( ) NEW_LINE DEDENT self . close ( ) NEW_LINE DEDENT def removeParentalProtection ( self , service ) : NEW_LINE INDENT self . session . openWithCallback ( boundFunction ( self . pinEntered , service . toCompareString ( ) ) , PinInput , pinList = [ config . ParentalControl . servicepin [ 0 ] . value ] , triesEntry = config . ParentalControl . retries . servicepin , title = _ ( " Enter ▁ the ▁ service ▁ pin " ) , windowTitle = _ ( " Enter ▁ pin ▁ code " ) ) NEW_LINE DEDENT def pinEntered ( self , service , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT self . parentalControl . unProtectService ( service ) NEW_LINE self . close ( ) NEW_LINE DEDENT elif answer is not None : NEW_LINE INDENT self . session . openWithCallback ( self . close , MessageBox , _ ( " The ▁ pin ▁ code ▁ you ▁ entered ▁ is ▁ wrong . " ) , MessageBox . TYPE_ERROR ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT def unhideParentalServices ( self ) : NEW_LINE INDENT if self . csel . protectContextMenu : NEW_LINE INDENT self . session . openWithCallback ( self . unhideParentalServicesCallback , PinInput , pinList = [ config . ParentalControl . servicepin [ 0 ] . value ] , triesEntry = config . ParentalControl . retries . servicepin , title = _ ( " Enter ▁ the ▁ service ▁ pin " ) , windowTitle = _ ( " Enter ▁ pin ▁ code " ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . unhideParentalServicesCallback ( True ) NEW_LINE DEDENT DEDENT def unhideParentalServicesCallback ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT service = self . csel . servicelist . getCurrent ( ) NEW_LINE self . parentalControl . setSessionPinCached ( ) NEW_LINE self . parentalControl . hideBlacklist ( ) NEW_LINE self . csel . servicelist . resetRoot ( ) NEW_LINE self . csel . servicelist . setCurrent ( service ) NEW_LINE self . close ( ) NEW_LINE DEDENT elif answer is not None : NEW_LINE INDENT self . session . openWithCallback ( self . close , MessageBox , _ ( " The ▁ pin ▁ code ▁ you ▁ entered ▁ is ▁ wrong . " ) , MessageBox . TYPE_ERROR ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT def showServiceInPiP ( self ) : NEW_LINE INDENT if self . csel . dopipzap or ( self . parentalControlEnabled and not self . parentalControl . getProtectionLevel ( self . csel . getCurrentSelection ( ) . toCompareString ( ) ) == - 1 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if self . session . pipshown : NEW_LINE INDENT del self . session . pip NEW_LINE DEDENT self . session . pip = self . session . instantiateDialog ( PictureInPicture ) NEW_LINE self . session . pip . show ( ) NEW_LINE newservice = self . csel . servicelist . getCurrent ( ) NEW_LINE currentBouquet = self . csel . servicelist and self . csel . servicelist . getRoot ( ) NEW_LINE if newservice and newservice . valid ( ) : NEW_LINE INDENT if self . session . pip . playService ( newservice ) : NEW_LINE INDENT self . session . pipshown = True NEW_LINE self . session . pip . servicePath = self . csel . getCurrentServicePath ( ) NEW_LINE self . session . pip . servicePath [ 1 ] = currentBouquet NEW_LINE self . close ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . session . pipshown = False NEW_LINE del self . session . pip NEW_LINE self . session . openWithCallback ( self . close , MessageBox , _ ( " Could ▁ not ▁ open ▁ Picture ▁ in ▁ Picture " ) , MessageBox . TYPE_ERROR ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def addServiceToBouquetSelected ( self ) : NEW_LINE INDENT bouquets = self . csel . getBouquetList ( ) NEW_LINE if bouquets is None : NEW_LINE INDENT cnt = 0 NEW_LINE DEDENT else : NEW_LINE INDENT cnt = len ( bouquets ) NEW_LINE DEDENT if cnt > 1 : NEW_LINE INDENT self . bsel = self . session . openWithCallback ( self . bouquetSelClosed , BouquetSelector , bouquets , self . addCurrentServiceToBouquet ) NEW_LINE DEDENT elif cnt == 1 : NEW_LINE INDENT self . addCurrentServiceToBouquet ( bouquets [ 0 ] [ 1 ] , closeBouquetSelection = False ) NEW_LINE DEDENT DEDENT def bouquetSelClosed ( self , recursive ) : NEW_LINE INDENT self . bsel = None NEW_LINE if recursive : NEW_LINE INDENT self . close ( False ) NEW_LINE DEDENT DEDENT def removeSatelliteServices ( self ) : NEW_LINE INDENT self . csel . removeSatelliteServices ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def copyCurrentToBouquetList ( self ) : NEW_LINE INDENT self . csel . copyCurrentToBouquetList ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def showMarkerInputBox ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . markerInputCallback , VirtualKeyBoard , title = _ ( " Please ▁ enter ▁ a ▁ name ▁ for ▁ the ▁ new ▁ marker " ) , text = " markername " , maxSize = False , visible_width = 56 , type = Input . TEXT ) NEW_LINE DEDENT def markerInputCallback ( self , marker ) : NEW_LINE INDENT if marker is not None : NEW_LINE INDENT self . csel . addMarker ( marker ) NEW_LINE DEDENT self . close ( ) NEW_LINE DEDENT def addCurrentServiceToBouquet ( self , dest , closeBouquetSelection = True ) : NEW_LINE INDENT self . csel . addServiceToBouquet ( dest ) NEW_LINE if self . bsel is not None : NEW_LINE INDENT self . bsel . close ( True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( closeBouquetSelection ) NEW_LINE DEDENT DEDENT def renameEntry ( self ) : NEW_LINE INDENT if self . inBouquet and self . csel . servicelist . getCurrent ( ) and self . csel . servicelist . getCurrent ( ) . valid ( ) and not self . csel . entry_marked : NEW_LINE INDENT self . csel . renameEntry ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def toggleMoveMode ( self ) : NEW_LINE INDENT if self . inBouquet and self . csel . servicelist . getCurrent ( ) and self . csel . servicelist . getCurrent ( ) . valid ( ) : NEW_LINE INDENT self . csel . toggleMoveMode ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def toggleMoveModeSelect ( self ) : NEW_LINE INDENT if self . inBouquet and self . csel . servicelist . getCurrent ( ) and self . csel . servicelist . getCurrent ( ) . valid ( ) : NEW_LINE INDENT self . csel . toggleMoveMode ( True ) NEW_LINE self . close ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def bouquetMarkStart ( self ) : NEW_LINE INDENT self . csel . startMarkedEdit ( EDIT_BOUQUET ) NEW_LINE self . close ( ) NEW_LINE DEDENT def bouquetMarkEnd ( self ) : NEW_LINE INDENT self . csel . endMarkedEdit ( abort = False ) NEW_LINE self . close ( ) NEW_LINE DEDENT def bouquetMarkAbort ( self ) : NEW_LINE INDENT self . csel . endMarkedEdit ( abort = True ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeNewFoundFlag ( self ) : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeFlag ( self . csel . getCurrentSelection ( ) , FLAG_SERVICE_NEW_FOUND ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeAllNewFoundFlags ( self ) : NEW_LINE INDENT curpath = self . csel . getCurrentSelection ( ) . getPath ( ) NEW_LINE idx = curpath . find ( " satellitePosition ▁ = = ▁ " ) NEW_LINE if idx != - 1 : NEW_LINE INDENT tmp = curpath [ idx + 21 : ] NEW_LINE idx = tmp . find ( ' ) ' ) NEW_LINE if idx != - 1 : NEW_LINE INDENT satpos = int ( tmp [ : idx ] ) NEW_LINE eDVBDB . getInstance ( ) . removeFlags ( FLAG_SERVICE_NEW_FOUND , - 1 , - 1 , - 1 , satpos ) NEW_LINE DEDENT DEDENT self . close ( ) NEW_LINE DEDENT def editAlternativeServices ( self ) : NEW_LINE INDENT self . csel . startMarkedEdit ( EDIT_ALTERNATIVES ) NEW_LINE self . close ( ) NEW_LINE DEDENT def showAlternativeServices ( self ) : NEW_LINE INDENT self . csel [ " Service " ] . editmode = True NEW_LINE self . csel . enterPath ( self . csel . getCurrentSelection ( ) ) NEW_LINE self . close ( ) NEW_LINE DEDENT def removeAlternativeServices ( self ) : NEW_LINE INDENT self . csel . removeAlternativeServices ( ) NEW_LINE self . close ( ) NEW_LINE DEDENT def addAlternativeServices ( self ) : NEW_LINE INDENT self . csel . addAlternativeServices ( ) NEW_LINE self . csel . startMarkedEdit ( EDIT_ALTERNATIVES ) NEW_LINE self . close ( ) NEW_LINE DEDENT def findCurrentlyPlayed ( self ) : NEW_LINE INDENT sel = self . csel . getCurrentSelection ( ) NEW_LINE if sel and sel . valid ( ) and not self . csel . entry_marked : NEW_LINE INDENT currentPlayingService = ( hasattr ( self . csel , " dopipzap " ) and self . csel . dopipzap ) and self . session . pip . getCurrentService ( ) or self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE self . csel . servicelist . setCurrent ( currentPlayingService , adjust = False ) NEW_LINE if self . csel . getCurrentSelection ( ) != currentPlayingService : NEW_LINE INDENT self . csel . setCurrentSelection ( sel ) NEW_LINE DEDENT self . close ( ) NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def runPlugin ( self , plugin ) : NEW_LINE INDENT plugin ( session = self . session , service = self . csel . getCurrentSelection ( ) ) NEW_LINE self . close ( ) NEW_LINE DEDENT DEDENT class SelectionEventInfo : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self [ " Service " ] = self [ " ServiceEvent " ] = ServiceEvent ( ) NEW_LINE self [ " Event " ] = Event ( ) NEW_LINE self . servicelist . connectSelChanged ( self . __selectionChanged ) NEW_LINE self . timer = eTimer ( ) NEW_LINE self . timer . callback . append ( self . updateEventInfo ) NEW_LINE self . onShown . append ( self . __selectionChanged ) NEW_LINE DEDENT def __selectionChanged ( self ) : NEW_LINE INDENT if self . execing : NEW_LINE INDENT self . timer . start ( 100 , True ) NEW_LINE DEDENT DEDENT def updateEventInfo ( self ) : NEW_LINE INDENT cur = self . getCurrentSelection ( ) NEW_LINE service = self [ " Service " ] NEW_LINE service . newService ( cur ) NEW_LINE self [ " Event " ] . newEvent ( service . event ) NEW_LINE DEDENT DEDENT class ChannelSelectionEPG ( InfoBarHotkey ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . hotkeys = [ ( " Info ▁ ( EPG ) " , " info " , " Infobar / openEventView " ) , ( " Info ▁ ( EPG ) " + " ▁ " + _ ( " long " ) , " info _ long " , " Infobar / showEventInfoPlugins " ) , ( " Epg / Guide " , " epg " , " Plugins / Extensions / GraphMultiEPG / 1" ) , ( " Epg / Guide " + " ▁ " + _ ( " long " ) , " epg _ long " , " Infobar / showEventInfoPlugins " ) ] NEW_LINE self [ " ChannelSelectEPGActions " ] = hotkeyActionMap ( [ " ChannelSelectEPGActions " ] , dict ( ( x [ 1 ] , self . hotkeyGlobal ) for x in self . hotkeys ) ) NEW_LINE self . eventViewEPG = self . start_bouquet = self . epg_bouquet = None NEW_LINE self . currentSavedPath = [ ] NEW_LINE DEDENT def getKeyFunctions ( self , key ) : NEW_LINE INDENT selection = eval ( " config . misc . hotkey . " + key + " . value . split ( ' , ' ) " ) NEW_LINE selected = [ ] NEW_LINE for x in selection : NEW_LINE INDENT function = list ( function for function in getHotkeyFunctions ( ) if function [ 1 ] == x and function [ 2 ] == " EPG " ) NEW_LINE if function : NEW_LINE INDENT selected . append ( function [ 0 ] ) NEW_LINE DEDENT DEDENT return selected NEW_LINE DEDENT def runPlugin ( self , plugin ) : NEW_LINE INDENT Screens . InfoBar . InfoBar . instance . runPlugin ( plugin ) NEW_LINE DEDENT def getEPGPluginList ( self , getAll = False ) : NEW_LINE INDENT pluginlist = [ ( p . name , boundFunction ( self . runPlugin , p ) , p . path ) for p in plugins . getPlugins ( where = PluginDescriptor . WHERE_EVENTINFO ) \NEW_LINE if ' selectedevent ' not in p . __call__ . func_code . co_varnames ] or [ ] NEW_LINE from Components . ServiceEventTracker import InfoBarCount NEW_LINE if getAll or InfoBarCount == 1 : NEW_LINE INDENT pluginlist . append ( ( _ ( " Show ▁ EPG ▁ for ▁ current ▁ channel . . . " ) , self . openSingleServiceEPG , " current _ channel " ) ) NEW_LINE DEDENT pluginlist . append ( ( _ ( " Multi ▁ EPG " ) , self . openMultiServiceEPG , " multi _ epg " ) ) NEW_LINE pluginlist . append ( ( _ ( " Current ▁ event ▁ EPG " ) , self . openEventView , " event _ epg " ) ) NEW_LINE return pluginlist NEW_LINE DEDENT def showEventInfoPlugins ( self ) : NEW_LINE INDENT pluginlist = self . getEPGPluginList ( ) NEW_LINE if pluginlist : NEW_LINE INDENT self . session . openWithCallback ( self . EventInfoPluginChosen , ChoiceBox , title = _ ( " Please ▁ choose ▁ an ▁ extension . . . " ) , list = pluginlist , skin_name = " EPGExtensionsList " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . openSingleServiceEPG ( ) NEW_LINE DEDENT DEDENT def EventInfoPluginChosen ( self , answer ) : NEW_LINE INDENT if answer is not None : NEW_LINE INDENT answer [ 1 ] ( ) NEW_LINE DEDENT DEDENT def openEventView ( self ) : NEW_LINE INDENT epglist = [ ] NEW_LINE self . epglist = epglist NEW_LINE ref = self . getCurrentSelection ( ) NEW_LINE epg = eEPGCache . getInstance ( ) NEW_LINE now_event = epg . lookupEventTime ( ref , - 1 , 0 ) NEW_LINE if now_event : NEW_LINE INDENT epglist . append ( now_event ) NEW_LINE next_event = epg . lookupEventTime ( ref , - 1 , 1 ) NEW_LINE if next_event : NEW_LINE INDENT epglist . append ( next_event ) NEW_LINE DEDENT DEDENT if epglist : NEW_LINE INDENT self . eventViewEPG = self . session . openWithCallback ( self . eventViewEPGClosed , EventViewEPGSelect , epglist [ 0 ] , ServiceReference ( ref ) , self . eventViewEPGCallback , self . openSingleServiceEPG , self . openMultiServiceEPG , self . openSimilarList ) NEW_LINE DEDENT DEDENT def eventViewEPGCallback ( self , setEvent , setService , val ) : NEW_LINE INDENT epglist = self . epglist NEW_LINE if len ( epglist ) > 1 : NEW_LINE INDENT tmp = epglist [ 0 ] NEW_LINE epglist [ 0 ] = epglist [ 1 ] NEW_LINE epglist [ 1 ] = tmp NEW_LINE setEvent ( epglist [ 0 ] ) NEW_LINE DEDENT DEDENT def eventViewEPGClosed ( self , ret = False ) : NEW_LINE INDENT self . eventViewEPG = None NEW_LINE if ret : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT def openMultiServiceEPG ( self ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if ref : NEW_LINE INDENT self . start_bouquet = self . epg_bouquet = self . servicelist . getRoot ( ) NEW_LINE self . savedService = ref NEW_LINE self . currentSavedPath = self . servicePath [ : ] NEW_LINE services = self . getServicesList ( self . servicelist . getRoot ( ) ) NEW_LINE self . session . openWithCallback ( self . SingleMultiEPGClosed , EPGSelection , services , self . zapToService , None , bouquetChangeCB = self . changeBouquetForMultiEPG ) NEW_LINE DEDENT DEDENT def openSingleServiceEPG ( self ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if ref : NEW_LINE INDENT self . start_bouquet = self . epg_bouquet = self . servicelist . getRoot ( ) NEW_LINE self . savedService = ref NEW_LINE self . currentSavedPath = self . servicePath [ : ] NEW_LINE self . session . openWithCallback ( self . SingleMultiEPGClosed , EPGSelection , ref , self . zapToService , serviceChangeCB = self . changeServiceCB , bouquetChangeCB = self . changeBouquetForSingleEPG ) NEW_LINE DEDENT DEDENT def openSimilarList ( self , eventid , refstr ) : NEW_LINE INDENT self . session . open ( EPGSelection , refstr , None , eventid ) NEW_LINE DEDENT def getServicesList ( self , root ) : NEW_LINE INDENT services = [ ] NEW_LINE servicelist = root and eServiceCenter . getInstance ( ) . list ( root ) NEW_LINE if not servicelist is None : NEW_LINE INDENT while True : NEW_LINE INDENT service = servicelist . getNext ( ) NEW_LINE if not service . valid ( ) : NEW_LINE INDENT break NEW_LINE DEDENT if service . flags & ( eServiceReference . isDirectory | eServiceReference . isMarker ) : NEW_LINE INDENT continue NEW_LINE DEDENT services . append ( ServiceReference ( service ) ) NEW_LINE DEDENT DEDENT return services NEW_LINE DEDENT def SingleMultiEPGClosed ( self , ret = False ) : NEW_LINE INDENT if ret : NEW_LINE INDENT service = self . getCurrentSelection ( ) NEW_LINE if self . eventViewEPG : NEW_LINE INDENT self . eventViewEPG . close ( service ) NEW_LINE DEDENT elif service is not None : NEW_LINE INDENT self . close ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if self . start_bouquet != self . epg_bouquet and len ( self . currentSavedPath ) > 0 : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . enterPath ( self . bouquet_root ) NEW_LINE self . epg_bouquet = self . start_bouquet NEW_LINE self . enterPath ( self . epg_bouquet ) NEW_LINE DEDENT self . setCurrentSelection ( self . savedService ) NEW_LINE DEDENT DEDENT def changeBouquetForSingleEPG ( self , direction , epg ) : NEW_LINE INDENT if config . usage . multibouquet . value : NEW_LINE INDENT inBouquet = self . getMutableList ( ) is not None NEW_LINE if inBouquet and len ( self . servicePath ) > 1 : NEW_LINE INDENT self . pathUp ( ) NEW_LINE if direction < 0 : NEW_LINE INDENT self . moveUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . moveDown ( ) NEW_LINE DEDENT cur = self . getCurrentSelection ( ) NEW_LINE self . enterPath ( cur ) NEW_LINE self . epg_bouquet = self . servicelist . getRoot ( ) NEW_LINE epg . setService ( ServiceReference ( self . getCurrentSelection ( ) ) ) NEW_LINE DEDENT DEDENT DEDENT def changeBouquetForMultiEPG ( self , direction , epg ) : NEW_LINE INDENT if config . usage . multibouquet . value : NEW_LINE INDENT inBouquet = self . getMutableList ( ) is not None NEW_LINE if inBouquet and len ( self . servicePath ) > 1 : NEW_LINE INDENT self . pathUp ( ) NEW_LINE if direction < 0 : NEW_LINE INDENT self . moveUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . moveDown ( ) NEW_LINE DEDENT cur = self . getCurrentSelection ( ) NEW_LINE self . enterPath ( cur ) NEW_LINE self . epg_bouquet = self . servicelist . getRoot ( ) NEW_LINE services = self . getServicesList ( self . epg_bouquet ) NEW_LINE epg . setServices ( services ) NEW_LINE DEDENT DEDENT DEDENT def changeServiceCB ( self , direction , epg ) : NEW_LINE INDENT beg = self . getCurrentSelection ( ) NEW_LINE while True : NEW_LINE INDENT if direction > 0 : NEW_LINE INDENT self . moveDown ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . moveUp ( ) NEW_LINE DEDENT cur = self . getCurrentSelection ( ) NEW_LINE if cur == beg or not ( cur . flags & eServiceReference . isMarker ) : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT epg . setService ( ServiceReference ( self . getCurrentSelection ( ) ) ) NEW_LINE DEDENT def zapToService ( self , service , preview = False , zapback = False ) : NEW_LINE INDENT if self . startServiceRef is None : NEW_LINE INDENT self . startServiceRef = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE DEDENT if service is not None : NEW_LINE INDENT if self . servicelist . getRoot ( ) != self . epg_bouquet : NEW_LINE INDENT self . servicelist . clearPath ( ) NEW_LINE if self . servicelist . bouquet_root != self . epg_bouquet : NEW_LINE INDENT self . servicelist . enterPath ( self . servicelist . bouquet_root ) NEW_LINE DEDENT self . servicelist . enterPath ( self . epg_bouquet ) NEW_LINE DEDENT self . servicelist . setCurrent ( service ) NEW_LINE DEDENT if not zapback or preview : NEW_LINE INDENT self . zap ( enable_pipzap = True ) NEW_LINE DEDENT if ( self . dopipzap or zapback ) and not preview : NEW_LINE INDENT self . zapBack ( ) NEW_LINE DEDENT if not preview : NEW_LINE INDENT self . startServiceRef = None NEW_LINE self . startRoot = None NEW_LINE self . revertMode = None NEW_LINE DEDENT DEDENT DEDENT class ChannelSelectionEdit : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . entry_marked = False NEW_LINE self . bouquet_mark_edit = OFF NEW_LINE self . mutableList = None NEW_LINE self . __marked = [ ] NEW_LINE self . saved_title = None NEW_LINE self . saved_root = None NEW_LINE self . current_ref = None NEW_LINE self . editMode = False NEW_LINE self . confirmRemove = True NEW_LINE class ChannelSelectionEditActionMap ( ActionMap ) : NEW_LINE INDENT def __init__ ( self , csel , contexts = [ ] , actions = { } , prio = 0 ) : NEW_LINE INDENT ActionMap . __init__ ( self , contexts , actions , prio ) NEW_LINE self . csel = csel NEW_LINE DEDENT def action ( self , contexts , action ) : NEW_LINE INDENT if action == " cancel " : NEW_LINE INDENT self . csel . handleEditCancel ( ) NEW_LINE return 0 NEW_LINE DEDENT elif action == " ok " : NEW_LINE INDENT return 0 NEW_LINE DEDENT else : NEW_LINE INDENT return ActionMap . action ( self , contexts , action ) NEW_LINE DEDENT DEDENT DEDENT self [ " ChannelSelectEditActions " ] = ChannelSelectionEditActionMap ( self , [ " ChannelSelectEditActions " , " OkCancelActions " ] , { " contextMenu " : self . doContext , } ) NEW_LINE DEDENT def getMutableList ( self , root = eServiceReference ( ) ) : NEW_LINE INDENT if not self . mutableList is None : NEW_LINE INDENT return self . mutableList NEW_LINE DEDENT serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE if not root . valid ( ) : NEW_LINE INDENT root = self . getRoot ( ) NEW_LINE DEDENT list = root and serviceHandler . list ( root ) NEW_LINE if list is not None : NEW_LINE INDENT return list . startEdit ( ) NEW_LINE DEDENT return None NEW_LINE DEDENT def buildBouquetID ( self , name ) : NEW_LINE INDENT name = unicodedata . normalize ( ' NFKD ' , unicode ( name , ' utf _ 8' , errors = ' ignore ' ) ) . encode ( ' ASCII ' , ' ignore ' ) . translate ( None , ' < > : " / \ | ? * ( ) ▁ ' ) NEW_LINE while os . path . isfile ( ( self . mode == MODE_TV and " / etc / enigma2 / userbouquet . % s . tv " or " / etc / enigma2 / userbouquet . % s . radio " ) % name ) : NEW_LINE INDENT name = name . rsplit ( " _ " , 1 ) NEW_LINE name = " _ " . join ( ( name [ 0 ] , len ( name ) == 2 and name [ 1 ] . isdigit ( ) and str ( int ( name [ 1 ] ) + 1 ) or "1" ) ) NEW_LINE DEDENT return name NEW_LINE DEDENT def renameEntry ( self ) : NEW_LINE INDENT self . editMode = True NEW_LINE cur = self . getCurrentSelection ( ) NEW_LINE if cur and cur . valid ( ) : NEW_LINE INDENT name = eServiceCenter . getInstance ( ) . info ( cur ) . getName ( cur ) or ServiceReference ( cur ) . getServiceName ( ) or " " NEW_LINE name = name . replace ( ' \xc2\x86' , ' ' ) . replace ( ' \xc2\x87' , ' ' ) NEW_LINE if name : NEW_LINE INDENT self . session . openWithCallback ( self . renameEntryCallback , VirtualKeyBoard , title = _ ( " Please ▁ enter ▁ new ▁ name : " ) , text = name ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT def renameEntryCallback ( self , name ) : NEW_LINE INDENT if name : NEW_LINE INDENT mutableList = self . getMutableList ( ) NEW_LINE if mutableList : NEW_LINE INDENT current = self . servicelist . getCurrent ( ) NEW_LINE current . setName ( name ) NEW_LINE index = self . servicelist . getCurrentIndex ( ) NEW_LINE mutableList . removeService ( current , False ) NEW_LINE mutableList . addService ( current ) NEW_LINE mutableList . moveService ( current , index ) NEW_LINE mutableList . flushChanges ( ) NEW_LINE self . servicelist . addService ( current , True ) NEW_LINE self . servicelist . removeCurrent ( ) NEW_LINE if not self . servicelist . atEnd ( ) : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def addMarker ( self , name ) : NEW_LINE INDENT current = self . servicelist . getCurrent ( ) NEW_LINE mutableList = self . getMutableList ( ) NEW_LINE cnt = 0 NEW_LINE while mutableList : NEW_LINE INDENT str = '1:64 : % d : 0:0:0:0:0:0:0 : : % s ' % ( cnt , name ) NEW_LINE ref = eServiceReference ( str ) NEW_LINE if current and current . valid ( ) : NEW_LINE INDENT if not mutableList . addService ( ref , current ) : NEW_LINE INDENT self . servicelist . addService ( ref , True ) NEW_LINE mutableList . flushChanges ( ) NEW_LINE break NEW_LINE DEDENT DEDENT elif not mutableList . addService ( ref ) : NEW_LINE INDENT self . servicelist . addService ( ref , True ) NEW_LINE mutableList . flushChanges ( ) NEW_LINE break NEW_LINE DEDENT cnt += 1 NEW_LINE DEDENT DEDENT def addAlternativeServices ( self ) : NEW_LINE INDENT cur_service = ServiceReference ( self . getCurrentSelection ( ) ) NEW_LINE end = self . atEnd ( ) NEW_LINE root = self . getRoot ( ) NEW_LINE cur_root = root and ServiceReference ( root ) NEW_LINE mutableBouquet = cur_root . list ( ) . startEdit ( ) NEW_LINE if mutableBouquet : NEW_LINE INDENT name = cur_service . getServiceName ( ) NEW_LINE refstr = ' _ ' . join ( cur_service . ref . toString ( ) . split ( ' : ' ) ) NEW_LINE if self . mode == MODE_TV : NEW_LINE INDENT str = '1:134:1:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ \ " alternatives . % s . tv\ " ▁ ORDER ▁ BY ▁ bouquet ' % ( refstr ) NEW_LINE DEDENT else : NEW_LINE INDENT str = '1:134:2:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ \ " alternatives . % s . radio\ " ▁ ORDER ▁ BY ▁ bouquet ' % ( refstr ) NEW_LINE DEDENT new_ref = ServiceReference ( str ) NEW_LINE if not mutableBouquet . addService ( new_ref . ref , cur_service . ref ) : NEW_LINE INDENT mutableBouquet . removeService ( cur_service . ref ) NEW_LINE mutableBouquet . flushChanges ( ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE mutableAlternatives = new_ref . list ( ) . startEdit ( ) NEW_LINE if mutableAlternatives : NEW_LINE INDENT mutableAlternatives . setListName ( name ) NEW_LINE if mutableAlternatives . addService ( cur_service . ref ) : NEW_LINE INDENT print " add " , cur_service . ref . toString ( ) , " to ▁ new ▁ alternatives ▁ failed " NEW_LINE DEDENT mutableAlternatives . flushChanges ( ) NEW_LINE self . servicelist . addService ( new_ref . ref , True ) NEW_LINE self . servicelist . removeCurrent ( ) NEW_LINE if not end : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT if cur_service . ref . toString ( ) == self . lastservice . value : NEW_LINE INDENT self . saveChannel ( new_ref . ref ) NEW_LINE DEDENT if self . startServiceRef and cur_service . ref == self . startServiceRef : NEW_LINE INDENT self . startServiceRef = new_ref . ref NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " get ▁ mutable ▁ list ▁ for ▁ new ▁ created ▁ alternatives ▁ failed " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " add " , str , " to " , cur_root . getServiceName ( ) , " failed " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " bouquetlist ▁ is ▁ not ▁ editable " NEW_LINE DEDENT DEDENT def addBouquet ( self , bName , services ) : NEW_LINE INDENT serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE mutableBouquetList = serviceHandler . list ( self . bouquet_root ) . startEdit ( ) NEW_LINE if mutableBouquetList : NEW_LINE INDENT bName = self . buildBouquetID ( bName ) NEW_LINE new_bouquet_ref = eServiceReference ( ( self . mode == MODE_TV and '1:7:1:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ " userbouquet . % s . tv " ▁ ORDER ▁ BY ▁ bouquet ' or '1:7:2:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ " userbouquet . % s . radio " ▁ ORDER ▁ BY ▁ bouquet ' ) % bName ) NEW_LINE if not mutableBouquetList . addService ( new_bouquet_ref ) : NEW_LINE INDENT mutableBouquetList . flushChanges ( ) NEW_LINE eDVBDB . getInstance ( ) . reloadBouquets ( ) NEW_LINE mutableBouquet = serviceHandler . list ( new_bouquet_ref ) . startEdit ( ) NEW_LINE if mutableBouquet : NEW_LINE INDENT mutableBouquet . setListName ( bName ) NEW_LINE if services is not None : NEW_LINE INDENT for service in services : NEW_LINE INDENT if mutableBouquet . addService ( service ) : NEW_LINE INDENT print " add " , service . toString ( ) , " to ▁ new ▁ bouquet ▁ failed " NEW_LINE DEDENT DEDENT DEDENT mutableBouquet . flushChanges ( ) NEW_LINE DEDENT else : NEW_LINE INDENT print " get ▁ mutable ▁ list ▁ for ▁ new ▁ created ▁ bouquet ▁ failed " NEW_LINE DEDENT cur_root = self . getRoot ( ) NEW_LINE ; str1 = cur_root and cur_root . toString ( ) NEW_LINE pos1 = str1 and str1 . find ( " FROM ▁ BOUQUET " ) or - 1 NEW_LINE pos2 = self . bouquet_rootstr . find ( " FROM ▁ BOUQUET " ) NEW_LINE if pos1 != - 1 and pos2 != - 1 and str1 [ pos1 : ] == self . bouquet_rootstr [ pos2 : ] : NEW_LINE INDENT self . servicelist . addService ( new_bouquet_ref ) NEW_LINE self . servicelist . resetRoot ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " add " , str , " to ▁ bouquets ▁ failed " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " bouquetlist ▁ is ▁ not ▁ editable " NEW_LINE DEDENT DEDENT def copyCurrentToBouquetList ( self ) : NEW_LINE INDENT provider = ServiceReference ( self . getCurrentSelection ( ) ) NEW_LINE providerName = provider . getServiceName ( ) NEW_LINE serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE services = serviceHandler . list ( provider . ref ) NEW_LINE self . addBouquet ( providerName , services and services . getContent ( ' R ' , True ) ) NEW_LINE DEDENT def removeAlternativeServices ( self ) : NEW_LINE INDENT cur_service = ServiceReference ( self . getCurrentSelection ( ) ) NEW_LINE end = self . atEnd ( ) NEW_LINE root = self . getRoot ( ) NEW_LINE cur_root = root and ServiceReference ( root ) NEW_LINE list = cur_service . list ( ) NEW_LINE first_in_alternative = list and list . getNext ( ) NEW_LINE if first_in_alternative : NEW_LINE INDENT edit_root = cur_root and cur_root . list ( ) . startEdit ( ) NEW_LINE if edit_root : NEW_LINE INDENT if not edit_root . addService ( first_in_alternative , cur_service . ref ) : NEW_LINE INDENT self . servicelist . addService ( first_in_alternative , True ) NEW_LINE if cur_service . ref . toString ( ) == self . lastservice . value : NEW_LINE INDENT self . saveChannel ( first_in_alternative ) NEW_LINE DEDENT if self . startServiceRef and cur_service . ref == self . startServiceRef : NEW_LINE INDENT self . startServiceRef = first_in_alternative NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " couldn ' t ▁ add ▁ first ▁ alternative ▁ service ▁ to ▁ current ▁ root " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " couldn ' t ▁ edit ▁ current ▁ root ! ! " NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print " remove ▁ empty ▁ alternative ▁ list ▁ ! ! " NEW_LINE DEDENT self . removeBouquet ( ) NEW_LINE if not end : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT DEDENT def removeBouquet ( self ) : NEW_LINE INDENT refstr = self . getCurrentSelection ( ) . toString ( ) NEW_LINE print " removeBouquet " , refstr NEW_LINE pos = refstr . find ( ' FROM ▁ BOUQUET ▁ " ' ) NEW_LINE filename = None NEW_LINE self . removeCurrentService ( bouquet = True ) NEW_LINE DEDENT def removeSatelliteService ( self ) : NEW_LINE INDENT current = self . getCurrentSelection ( ) NEW_LINE eDVBDB . getInstance ( ) . removeService ( current ) NEW_LINE refreshServiceList ( ) NEW_LINE if not self . atEnd ( ) : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT DEDENT def removeSatelliteServices ( self ) : NEW_LINE INDENT current = self . getCurrentSelection ( ) NEW_LINE unsigned_orbpos = current . getUnsignedData ( 4 ) >> 16 NEW_LINE if unsigned_orbpos == 0xFFFF : NEW_LINE INDENT messageText = _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ all ▁ cable ▁ services ? " ) NEW_LINE DEDENT elif unsigned_orbpos == 0xEEEE : NEW_LINE INDENT messageText = _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ all ▁ terrestrial ▁ services ? " ) NEW_LINE DEDENT else : NEW_LINE INDENT if unsigned_orbpos > 1800 : NEW_LINE INDENT unsigned_orbpos = 3600 - unsigned_orbpos NEW_LINE direction = _ ( " W " ) NEW_LINE DEDENT else : NEW_LINE INDENT direction = _ ( " E " ) NEW_LINE DEDENT messageText = _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ all ▁ % d . % d % s % s ▁ services ? " ) % ( unsigned_orbpos / 10 , unsigned_orbpos % 10 , " \xc2\xb0" , direction ) NEW_LINE DEDENT self . session . openWithCallback ( self . removeSatelliteServicesCallback , MessageBox , messageText ) NEW_LINE DEDENT def removeSatelliteServicesCallback ( self , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT currentIndex = self . servicelist . getCurrentIndex ( ) NEW_LINE current = self . getCurrentSelection ( ) NEW_LINE unsigned_orbpos = current . getUnsignedData ( 4 ) >> 16 NEW_LINE if unsigned_orbpos == 0xFFFF : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeServices ( int ( "0xFFFF0000" , 16 ) - 0x100000000 ) NEW_LINE DEDENT elif unsigned_orbpos == 0xEEEE : NEW_LINE INDENT eDVBDB . getInstance ( ) . removeServices ( int ( "0xEEEE0000" , 16 ) - 0x100000000 ) NEW_LINE DEDENT else : NEW_LINE INDENT curpath = current . getPath ( ) NEW_LINE idx = curpath . find ( " satellitePosition ▁ = = ▁ " ) NEW_LINE if idx != - 1 : NEW_LINE INDENT tmp = curpath [ idx + 21 : ] NEW_LINE idx = tmp . find ( ' ) ' ) NEW_LINE if idx != - 1 : NEW_LINE INDENT satpos = int ( tmp [ : idx ] ) NEW_LINE eDVBDB . getInstance ( ) . removeServices ( - 1 , - 1 , - 1 , satpos ) NEW_LINE DEDENT DEDENT DEDENT refreshServiceList ( ) NEW_LINE if hasattr ( self , ' showSatellites ' ) : NEW_LINE INDENT self . showSatellites ( ) NEW_LINE self . servicelist . moveToIndex ( currentIndex ) NEW_LINE if currentIndex != self . servicelist . getCurrentIndex ( ) : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . moveEnd ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def startMarkedEdit ( self , type ) : NEW_LINE INDENT self . savedPath = self . servicePath [ : ] NEW_LINE if type == EDIT_ALTERNATIVES : NEW_LINE INDENT self . current_ref = self . getCurrentSelection ( ) NEW_LINE self . enterPath ( self . current_ref ) NEW_LINE DEDENT self . mutableList = self . getMutableList ( ) NEW_LINE self . clearMarks ( ) NEW_LINE self . saved_title = self . getTitle ( ) NEW_LINE pos = self . saved_title . find ( ' ) ' ) NEW_LINE new_title = self . saved_title [ : pos + 1 ] NEW_LINE if type == EDIT_ALTERNATIVES : NEW_LINE INDENT self . bouquet_mark_edit = EDIT_ALTERNATIVES NEW_LINE new_title += ' ▁ ' + _ ( " [ alternative ▁ edit ] " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . bouquet_mark_edit = EDIT_BOUQUET NEW_LINE if config . usage . multibouquet . value : NEW_LINE INDENT new_title += ' ▁ ' + _ ( " [ bouquet ▁ edit ] " ) NEW_LINE DEDENT else : NEW_LINE INDENT new_title += ' ▁ ' + _ ( " [ favourite ▁ edit ] " ) NEW_LINE DEDENT DEDENT self . setTitle ( new_title ) NEW_LINE self . __marked = self . servicelist . getRootServices ( ) NEW_LINE for x in self . __marked : NEW_LINE INDENT self . servicelist . addMarked ( eServiceReference ( x ) ) NEW_LINE DEDENT self [ " Service " ] . editmode = True NEW_LINE DEDENT def endMarkedEdit ( self , abort ) : NEW_LINE INDENT if not abort and self . mutableList is not None : NEW_LINE INDENT new_marked = set ( self . servicelist . getMarked ( ) ) NEW_LINE old_marked = set ( self . __marked ) NEW_LINE removed = old_marked - new_marked NEW_LINE added = new_marked - old_marked NEW_LINE changed = False NEW_LINE for x in removed : NEW_LINE INDENT changed = True NEW_LINE self . mutableList . removeService ( eServiceReference ( x ) ) NEW_LINE DEDENT for x in added : NEW_LINE INDENT changed = True NEW_LINE self . mutableList . addService ( eServiceReference ( x ) ) NEW_LINE DEDENT if changed : NEW_LINE INDENT if self . bouquet_mark_edit == EDIT_ALTERNATIVES and not new_marked and self . __marked : NEW_LINE INDENT self . mutableList . addService ( eServiceReference ( self . __marked [ 0 ] ) ) NEW_LINE DEDENT self . mutableList . flushChanges ( ) NEW_LINE DEDENT DEDENT self . __marked = [ ] NEW_LINE self . clearMarks ( ) NEW_LINE self . bouquet_mark_edit = OFF NEW_LINE self . mutableList = None NEW_LINE self . setTitle ( self . saved_title ) NEW_LINE self . saved_title = None NEW_LINE del self . servicePath [ : ] NEW_LINE self . servicePath += self . savedPath NEW_LINE del self . savedPath NEW_LINE self . setRoot ( self . servicePath [ - 1 ] ) NEW_LINE if self . current_ref : NEW_LINE INDENT self . setCurrentSelection ( self . current_ref ) NEW_LINE self . current_ref = None NEW_LINE DEDENT DEDENT def clearMarks ( self ) : NEW_LINE INDENT self . servicelist . clearMarks ( ) NEW_LINE DEDENT def doMark ( self ) : NEW_LINE INDENT ref = self . servicelist . getCurrent ( ) NEW_LINE if self . servicelist . isMarked ( ref ) : NEW_LINE INDENT self . servicelist . removeMarked ( ref ) NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . addMarked ( ref ) NEW_LINE DEDENT DEDENT def removeCurrentEntry ( self , bouquet = False ) : NEW_LINE INDENT if self . confirmRemove : NEW_LINE INDENT list = [ ( _ ( " yes " ) , True ) , ( _ ( " no " ) , False ) , ( _ ( " yes " ) + " ▁ " + _ ( " and ▁ never ▁ ask ▁ again ▁ this ▁ session ▁ again " ) , " never " ) ] NEW_LINE self . session . openWithCallback ( boundFunction ( self . removeCurrentEntryCallback , bouquet ) , MessageBox , _ ( " Are ▁ you ▁ sure ▁ to ▁ remove ▁ this ▁ entry ? " ) , list = list ) NEW_LINE DEDENT else : NEW_LINE INDENT self . removeCurrentEntryCallback ( bouquet , True ) NEW_LINE DEDENT DEDENT def removeCurrentEntryCallback ( self , bouquet , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT if answer == " never " : NEW_LINE INDENT self . confirmRemove = False NEW_LINE DEDENT if bouquet : NEW_LINE INDENT self . removeBouquet ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . removeCurrentService ( ) NEW_LINE DEDENT DEDENT DEDENT def removeCurrentService ( self , bouquet = False ) : NEW_LINE INDENT self . editMode = True NEW_LINE ref = self . servicelist . getCurrent ( ) NEW_LINE mutableList = self . getMutableList ( ) NEW_LINE if ref . valid ( ) and mutableList is not None : NEW_LINE INDENT if not mutableList . removeService ( ref ) : NEW_LINE INDENT mutableList . flushChanges ( ) NEW_LINE self . servicelist . removeCurrent ( ) NEW_LINE self . servicelist . resetRoot ( ) NEW_LINE playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if not bouquet and playingref and ref == playingref : NEW_LINE INDENT self . channelSelected ( doClose = False ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def addServiceToBouquet ( self , dest , service = None ) : NEW_LINE INDENT mutableList = self . getMutableList ( dest ) NEW_LINE if not mutableList is None : NEW_LINE INDENT if service is None : NEW_LINE INDENT service = self . servicelist . getCurrent ( ) NEW_LINE DEDENT if not mutableList . addService ( service ) : NEW_LINE INDENT mutableList . flushChanges ( ) NEW_LINE cur_root = self . getRoot ( ) NEW_LINE ; str1 = cur_root and cur_root . toString ( ) or - 1 NEW_LINE str2 = dest . toString ( ) NEW_LINE pos1 = str1 . find ( " FROM ▁ BOUQUET " ) NEW_LINE pos2 = str2 . find ( " FROM ▁ BOUQUET " ) NEW_LINE if pos1 != - 1 and pos2 != - 1 and str1 [ pos1 : ] == str2 [ pos2 : ] : NEW_LINE INDENT self . servicelist . addService ( service ) NEW_LINE DEDENT self . servicelist . resetRoot ( ) NEW_LINE DEDENT DEDENT DEDENT def toggleMoveMode ( self , select = False ) : NEW_LINE INDENT self . editMode = True NEW_LINE if self . movemode : NEW_LINE INDENT if self . entry_marked : NEW_LINE INDENT self . toggleMoveMarked ( ) NEW_LINE DEDENT self . movemode = False NEW_LINE self . mutableList . flushChanges ( ) NEW_LINE self . mutableList = None NEW_LINE self . setTitle ( self . saved_title ) NEW_LINE self . saved_title = None NEW_LINE self . servicelist . resetRoot ( ) NEW_LINE self . servicelist . l . setHideNumberMarker ( config . usage . hide_number_markers . value ) NEW_LINE self . setCurrentSelection ( self . servicelist . getCurrent ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . mutableList = self . getMutableList ( ) NEW_LINE self . movemode = True NEW_LINE select and self . toggleMoveMarked ( ) NEW_LINE self . saved_title = self . getTitle ( ) NEW_LINE pos = self . saved_title . find ( ' ) ' ) NEW_LINE self . setTitle ( self . saved_title [ : pos + 1 ] + ' ▁ ' + _ ( " [ move ▁ mode ] " ) + self . saved_title [ pos + 1 : ] ) NEW_LINE ; self . servicelist . l . setHideNumberMarker ( False ) NEW_LINE self . setCurrentSelection ( self . servicelist . getCurrent ( ) ) NEW_LINE DEDENT self [ " Service " ] . editmode = True NEW_LINE DEDENT def handleEditCancel ( self ) : NEW_LINE INDENT if self . movemode : NEW_LINE INDENT self . toggleMoveMode ( ) NEW_LINE DEDENT elif self . bouquet_mark_edit != OFF : NEW_LINE INDENT self . endMarkedEdit ( True ) NEW_LINE DEDENT DEDENT def toggleMoveMarked ( self ) : NEW_LINE INDENT if self . entry_marked : NEW_LINE INDENT self . servicelist . setCurrentMarked ( False ) NEW_LINE self . entry_marked = False NEW_LINE self . pathChangeDisabled = False NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . setCurrentMarked ( True ) NEW_LINE self . entry_marked = True NEW_LINE self . pathChangeDisabled = True NEW_LINE DEDENT DEDENT def doContext ( self ) : NEW_LINE INDENT self . session . openWithCallback ( self . exitContext , ChannelContextMenu , self ) NEW_LINE DEDENT def exitContext ( self , close = False ) : NEW_LINE INDENT if close : NEW_LINE INDENT self . cancel ( ) NEW_LINE DEDENT DEDENT DEDENT MODE_TV = 0 NEW_LINE MODE_RADIO = 1 NEW_LINE service_types_tv = '1:7:1:0:0:0:0:0:0:0 : ( type ▁ = = ▁ 1 ) ▁ | | ▁ ( type ▁ = = ▁ 17 ) ▁ | | ▁ ( type ▁ = = ▁ 22 ) ▁ | | ▁ ( type ▁ = = ▁ 25 ) ▁ | | ▁ ( type ▁ = = ▁ 31 ) ▁ | | ▁ ( type ▁ = = ▁ 134 ) ▁ | | ▁ ( type ▁ = = ▁ 195 ) ' NEW_LINE service_types_radio = '1:7:2:0:0:0:0:0:0:0 : ( type ▁ = = ▁ 2 ) ▁ | | ▁ ( type ▁ = = ▁ 10 ) ' NEW_LINE class ChannelSelectionBase ( Screen ) : NEW_LINE INDENT def __init__ ( self , session ) : NEW_LINE INDENT Screen . __init__ ( self , session ) NEW_LINE self . setScreenPathMode ( None ) NEW_LINE self [ " key _ red " ] = Button ( _ ( " All " ) ) NEW_LINE self [ " key _ green " ] = Button ( _ ( " Satellites " ) ) NEW_LINE self [ " key _ yellow " ] = Button ( _ ( " Provider " ) ) NEW_LINE self [ " key _ blue " ] = Button ( _ ( " Favourites " ) ) NEW_LINE self [ " list " ] = ServiceList ( self ) NEW_LINE self . servicelist = self [ " list " ] NEW_LINE self . numericalTextInput = NumericalTextInput ( handleTimeout = False ) NEW_LINE self . numericalTextInput . setUseableChars ( u' 1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ ' ) NEW_LINE self . servicePathTV = [ ] NEW_LINE self . servicePathRadio = [ ] NEW_LINE self . servicePath = [ ] NEW_LINE self . history = [ ] NEW_LINE self . rootChanged = False NEW_LINE self . startRoot = None NEW_LINE self . selectionNumber = " " NEW_LINE self . clearNumberSelectionNumberTimer = eTimer ( ) NEW_LINE self . clearNumberSelectionNumberTimer . callback . append ( self . clearNumberSelectionNumber ) NEW_LINE self . protectContextMenu = True NEW_LINE self . mode = MODE_TV NEW_LINE self . dopipzap = False NEW_LINE self . pathChangeDisabled = False NEW_LINE self . movemode = False NEW_LINE self . showSatDetails = False NEW_LINE self [ " ChannelSelectBaseActions " ] = NumberActionMap ( [ " ChannelSelectBaseActions " , " NumberActions " , " InputAsciiActions " ] , { " showFavourites " : self . showFavourites , " showAllServices " : self . showAllServices , " showProviders " : self . showProviders , " showSatellites " : boundFunction ( self . showSatellites , changeMode = True ) , " nextBouquet " : self . nextBouquet , " prevBouquet " : self . prevBouquet , " nextMarker " : self . nextMarker , " prevMarker " : self . prevMarker , " gotAsciiCode " : self . keyAsciiCode , " keyLeft " : self . keyLeft , " keyRight " : self . keyRight , " keyRecord " : self . keyRecord , "1" : self . keyNumberGlobal , "2" : self . keyNumberGlobal , "3" : self . keyNumberGlobal , "4" : self . keyNumberGlobal , "5" : self . keyNumberGlobal , "6" : self . keyNumberGlobal , "7" : self . keyNumberGlobal , "8" : self . keyNumberGlobal , "9" : self . keyNumberGlobal , "0" : self . keyNumber0 } , - 2 ) NEW_LINE self . maintitle = _ ( " Channel ▁ selection " ) NEW_LINE self . recallBouquetMode ( ) NEW_LINE DEDENT def getBouquetNumOffset ( self , bouquet ) : NEW_LINE INDENT if not config . usage . multibouquet . value : NEW_LINE INDENT return 0 NEW_LINE DEDENT str = bouquet . toString ( ) NEW_LINE offset = 0 NEW_LINE if ' userbouquet . ' in bouquet . toCompareString ( ) : NEW_LINE INDENT serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE servicelist = serviceHandler . list ( bouquet ) NEW_LINE if not servicelist is None : NEW_LINE INDENT while True : NEW_LINE INDENT serviceIterator = servicelist . getNext ( ) NEW_LINE if not serviceIterator . valid ( ) : NEW_LINE INDENT break NEW_LINE DEDENT number = serviceIterator . getChannelNum ( ) NEW_LINE if number > 0 : NEW_LINE INDENT offset = number - 1 NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT DEDENT return offset NEW_LINE DEDENT def recallBouquetMode ( self ) : NEW_LINE INDENT if self . mode == MODE_TV : NEW_LINE INDENT self . service_types = service_types_tv NEW_LINE if config . usage . multibouquet . value : NEW_LINE INDENT self . bouquet_rootstr = '1:7:1:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ " bouquets . tv " ▁ ORDER ▁ BY ▁ bouquet ' NEW_LINE DEDENT else : NEW_LINE INDENT self . bouquet_rootstr = ' % s ▁ FROM ▁ BOUQUET ▁ " userbouquet . favourites . tv " ▁ ORDER ▁ BY ▁ bouquet ' % ( self . service_types ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . service_types = service_types_radio NEW_LINE if config . usage . multibouquet . value : NEW_LINE INDENT self . bouquet_rootstr = '1:7:1:0:0:0:0:0:0:0 : FROM ▁ BOUQUET ▁ " bouquets . radio " ▁ ORDER ▁ BY ▁ bouquet ' NEW_LINE DEDENT else : NEW_LINE INDENT self . bouquet_rootstr = ' % s ▁ FROM ▁ BOUQUET ▁ " userbouquet . favourites . radio " ▁ ORDER ▁ BY ▁ bouquet ' % ( self . service_types ) NEW_LINE DEDENT DEDENT self . bouquet_root = eServiceReference ( self . bouquet_rootstr ) NEW_LINE DEDENT def setTvMode ( self ) : NEW_LINE INDENT self . mode = MODE_TV NEW_LINE self . servicePath = self . servicePathTV NEW_LINE self . recallBouquetMode ( ) NEW_LINE title = self . maintitle NEW_LINE pos = title . find ( " ▁ ( " ) NEW_LINE if pos != - 1 : NEW_LINE INDENT title = title [ : pos ] NEW_LINE DEDENT title += _ ( " ▁ ( TV ) " ) NEW_LINE self . setTitle ( title ) NEW_LINE DEDENT def setRadioMode ( self ) : NEW_LINE INDENT self . mode = MODE_RADIO NEW_LINE self . servicePath = self . servicePathRadio NEW_LINE self . recallBouquetMode ( ) NEW_LINE title = self . maintitle NEW_LINE pos = title . find ( " ▁ ( " ) NEW_LINE if pos != - 1 : NEW_LINE INDENT title = title [ : pos ] NEW_LINE DEDENT title += _ ( " ▁ ( Radio ) " ) NEW_LINE self . setTitle ( title ) NEW_LINE DEDENT def setRoot ( self , root , justSet = False ) : NEW_LINE INDENT if self . startRoot is None : NEW_LINE INDENT self . startRoot = self . getRoot ( ) NEW_LINE DEDENT path = root . getPath ( ) NEW_LINE isBouquet = ' FROM ▁ BOUQUET ' in path and ( root . flags & eServiceReference . isDirectory ) NEW_LINE inBouquetRootList = ' FROM ▁ BOUQUET ▁ " bouquets . ' in path NEW_LINE if not inBouquetRootList and isBouquet : NEW_LINE INDENT self . servicelist . setMode ( ServiceList . MODE_FAVOURITES ) NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . setMode ( ServiceList . MODE_NORMAL ) NEW_LINE DEDENT self . servicelist . setRoot ( root , justSet ) NEW_LINE self . rootChanged = True NEW_LINE self . buildTitleString ( ) NEW_LINE DEDENT def removeModeStr ( self , str ) : NEW_LINE INDENT if self . mode == MODE_TV : NEW_LINE INDENT pos = str . find ( _ ( " ▁ ( TV ) " ) ) NEW_LINE DEDENT else : NEW_LINE INDENT pos = str . find ( _ ( " ▁ ( Radio ) " ) ) NEW_LINE DEDENT if pos != - 1 : NEW_LINE INDENT return str [ : pos ] NEW_LINE DEDENT return str NEW_LINE DEDENT def getServiceName ( self , ref ) : NEW_LINE INDENT str = self . removeModeStr ( ServiceReference ( ref ) . getServiceName ( ) ) NEW_LINE if ' bouquets ' in str . lower ( ) : NEW_LINE INDENT return _ ( " User ▁ - ▁ bouquets " ) NEW_LINE DEDENT if not str : NEW_LINE INDENT pathstr = ref . getPath ( ) NEW_LINE if ' FROM ▁ PROVIDERS ' in pathstr : NEW_LINE INDENT return _ ( " Provider " ) NEW_LINE DEDENT if ' FROM ▁ SATELLITES ' in pathstr : NEW_LINE INDENT return _ ( " Satellites " ) NEW_LINE DEDENT if ' ) ▁ ORDER ▁ BY ▁ name ' in pathstr : NEW_LINE INDENT return _ ( " All " ) NEW_LINE DEDENT DEDENT return str NEW_LINE DEDENT def buildTitleString ( self ) : NEW_LINE INDENT titleStr = self . getTitle ( ) NEW_LINE pos = titleStr . find ( ' ] ' ) NEW_LINE if pos == - 1 : NEW_LINE INDENT pos = titleStr . find ( ' ) ' ) NEW_LINE DEDENT if pos != - 1 : NEW_LINE INDENT titleStr = titleStr [ : pos + 1 ] NEW_LINE Len = len ( self . servicePath ) NEW_LINE if Len > 0 : NEW_LINE INDENT base_ref = self . servicePath [ 0 ] NEW_LINE if Len > 1 : NEW_LINE INDENT end_ref = self . servicePath [ Len - 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT end_ref = None NEW_LINE DEDENT nameStr = self . getServiceName ( base_ref ) NEW_LINE titleStr += ' ▁ - ▁ ' + nameStr NEW_LINE if end_ref is not None : NEW_LINE INDENT if Len > 2 : NEW_LINE INDENT titleStr += ' / . . / ' NEW_LINE DEDENT else : NEW_LINE INDENT titleStr += ' / ' NEW_LINE DEDENT nameStr = self . getServiceName ( end_ref ) NEW_LINE titleStr += nameStr NEW_LINE DEDENT self . setTitle ( titleStr ) NEW_LINE DEDENT DEDENT DEDENT def moveUp ( self ) : NEW_LINE INDENT self . servicelist . moveUp ( ) NEW_LINE DEDENT def moveDown ( self ) : NEW_LINE INDENT self . servicelist . moveDown ( ) NEW_LINE DEDENT def clearPath ( self ) : NEW_LINE INDENT del self . servicePath [ : ] NEW_LINE DEDENT def enterPath ( self , ref , justSet = False ) : NEW_LINE INDENT self . servicePath . append ( ref ) NEW_LINE self . setRoot ( ref , justSet ) NEW_LINE DEDENT def enterUserbouquet ( self , root , save_root = True ) : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . recallBouquetMode ( ) NEW_LINE if self . bouquet_root : NEW_LINE INDENT self . enterPath ( self . bouquet_root ) NEW_LINE DEDENT self . enterPath ( root ) NEW_LINE self . startRoot = None NEW_LINE if save_root : NEW_LINE INDENT self . saveRoot ( ) NEW_LINE DEDENT DEDENT def pathUp ( self , justSet = False ) : NEW_LINE INDENT prev = self . servicePath . pop ( ) NEW_LINE if self . servicePath : NEW_LINE INDENT current = self . servicePath [ - 1 ] NEW_LINE self . setRoot ( current , justSet ) NEW_LINE if not justSet : NEW_LINE INDENT self . setCurrentSelection ( prev ) NEW_LINE DEDENT DEDENT return prev NEW_LINE DEDENT def isBasePathEqual ( self , ref ) : NEW_LINE INDENT if len ( self . servicePath ) > 1 and self . servicePath [ 0 ] == ref : NEW_LINE INDENT return True NEW_LINE DEDENT return False NEW_LINE DEDENT def isPrevPathEqual ( self , ref ) : NEW_LINE INDENT length = len ( self . servicePath ) NEW_LINE if length > 1 and self . servicePath [ length - 2 ] == ref : NEW_LINE INDENT return True NEW_LINE DEDENT return False NEW_LINE DEDENT def preEnterPath ( self , refstr ) : NEW_LINE INDENT return False NEW_LINE DEDENT def showAllServices ( self ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT refstr = ' % s ▁ ORDER ▁ BY ▁ name ' % ( self . service_types ) NEW_LINE if not self . preEnterPath ( refstr ) : NEW_LINE INDENT ref = eServiceReference ( refstr ) NEW_LINE currentRoot = self . getRoot ( ) NEW_LINE if currentRoot is None or currentRoot != ref : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . enterPath ( ref ) NEW_LINE playingref = self . session . nav . getCurrentlyPlayingServiceReference ( ) NEW_LINE if playingref : NEW_LINE INDENT self . setCurrentSelectionAlternative ( playingref ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def showSatellites ( self , changeMode = False ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT refstr = ' % s ▁ FROM ▁ SATELLITES ▁ ORDER ▁ BY ▁ satellitePosition ' % ( self . service_types ) NEW_LINE if not self . preEnterPath ( refstr ) : NEW_LINE INDENT ref = eServiceReference ( refstr ) NEW_LINE justSet = False NEW_LINE prev = None NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT if self . isPrevPathEqual ( ref ) : NEW_LINE INDENT justSet = True NEW_LINE DEDENT prev = self . pathUp ( justSet ) NEW_LINE DEDENT else : NEW_LINE INDENT currentRoot = self . getRoot ( ) NEW_LINE if currentRoot is None or currentRoot != ref : NEW_LINE INDENT justSet = True NEW_LINE self . clearPath ( ) NEW_LINE self . enterPath ( ref , True ) NEW_LINE DEDENT if changeMode and currentRoot and currentRoot == ref : NEW_LINE INDENT self . showSatDetails = not self . showSatDetails NEW_LINE justSet = True NEW_LINE self . clearPath ( ) NEW_LINE self . enterPath ( ref , True ) NEW_LINE DEDENT DEDENT if justSet : NEW_LINE INDENT addCableAndTerrestrialLater = [ ] NEW_LINE serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE servicelist = serviceHandler . list ( ref ) NEW_LINE if not servicelist is None : NEW_LINE INDENT while True : NEW_LINE INDENT service = servicelist . getNext ( ) NEW_LINE if not service . valid ( ) : NEW_LINE INDENT break NEW_LINE DEDENT unsigned_orbpos = service . getUnsignedData ( 4 ) >> 16 NEW_LINE orbpos = service . getData ( 4 ) >> 16 NEW_LINE if orbpos < 0 : NEW_LINE INDENT orbpos += 3600 NEW_LINE DEDENT if " FROM ▁ PROVIDER " in service . getPath ( ) : NEW_LINE INDENT service_type = self . showSatDetails and _ ( " Providers " ) NEW_LINE DEDENT elif ( " flags ▁ = = ▁ % d " % ( FLAG_SERVICE_NEW_FOUND ) ) in service . getPath ( ) : NEW_LINE INDENT service_type = self . showSatDetails and _ ( " New " ) NEW_LINE DEDENT else : NEW_LINE INDENT service_type = _ ( " Services " ) NEW_LINE DEDENT if service_type : NEW_LINE INDENT if unsigned_orbpos == 0xFFFF : NEW_LINE INDENT service_name = _ ( " Cable " ) NEW_LINE addCableAndTerrestrialLater . append ( ( " % s ▁ - ▁ % s " % ( service_name , service_type ) , service . toString ( ) ) ) NEW_LINE DEDENT elif unsigned_orbpos == 0xEEEE : NEW_LINE INDENT service_name = _ ( " Terrestrial " ) NEW_LINE addCableAndTerrestrialLater . append ( ( " % s ▁ - ▁ % s " % ( service_name , service_type ) , service . toString ( ) ) ) NEW_LINE DEDENT else : NEW_LINE INDENT try : NEW_LINE INDENT service_name = str ( nimmanager . getSatDescription ( orbpos ) ) NEW_LINE DEDENT except : NEW_LINE INDENT if orbpos > 1800 : NEW_LINE INDENT orbpos = 3600 - orbpos NEW_LINE h = _ ( " W " ) NEW_LINE DEDENT else : NEW_LINE INDENT h = _ ( " E " ) NEW_LINE DEDENT service_name = ( " % d . % d " + h ) % ( orbpos / 10 , orbpos % 10 ) NEW_LINE DEDENT service . setName ( " % s ▁ - ▁ % s " % ( service_name , service_type ) ) NEW_LINE self . servicelist . addService ( service ) NEW_LINE DEDENT DEDENT DEDENT cur_ref = self . session . nav . getCurrentlyPlayingServiceReference ( ) NEW_LINE self . servicelist . l . sort ( ) NEW_LINE if cur_ref : NEW_LINE INDENT pos = self . service_types . rfind ( ' : ' ) NEW_LINE refstr = ' % s ▁ ( channelID ▁ = = ▁ % 08x % 04x % 04x ) ▁ & & ▁ % s ▁ ORDER ▁ BY ▁ name ' % ( self . service_types [ : pos + 1 ] , cur_ref . getUnsignedData ( 4 ) , cur_ref . getUnsignedData ( 2 ) , cur_ref . getUnsignedData ( 3 ) , self . service_types [ pos + 1 : ] ) NEW_LINE ref = eServiceReference ( refstr ) NEW_LINE ref . setName ( _ ( " Current ▁ transponder " ) ) NEW_LINE self . servicelist . addService ( ref , beforeCurrent = True ) NEW_LINE DEDENT for ( service_name , service_ref ) in addCableAndTerrestrialLater : NEW_LINE INDENT ref = eServiceReference ( service_ref ) NEW_LINE ref . setName ( service_name ) NEW_LINE self . servicelist . addService ( ref , beforeCurrent = True ) NEW_LINE DEDENT self . servicelist . l . FillFinished ( ) NEW_LINE if prev is not None : NEW_LINE INDENT self . setCurrentSelection ( prev ) NEW_LINE DEDENT elif cur_ref : NEW_LINE INDENT refstr = cur_ref . toString ( ) NEW_LINE op = " " . join ( refstr . split ( ' : ' , 10 ) [ 6 : 7 ] ) NEW_LINE if len ( op ) >= 4 : NEW_LINE INDENT hop = int ( op [ : - 4 ] , 16 ) NEW_LINE if len ( op ) >= 7 and not op . endswith ( '0000' ) : NEW_LINE INDENT op = op [ : - 4 ] + '0000' NEW_LINE DEDENT refstr = '1:7:0:0:0:0 : % s : 0:0:0 : ( satellitePosition ▁ = = ▁ % s ) ▁ & & ▁ % s ▁ ORDER ▁ BY ▁ name ' % ( op , hop , self . service_types [ self . service_types . rfind ( ' : ' ) + 1 : ] ) NEW_LINE self . setCurrentSelectionAlternative ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT def showProviders ( self ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT refstr = ' % s ▁ FROM ▁ PROVIDERS ▁ ORDER ▁ BY ▁ name ' % ( self . service_types ) NEW_LINE if not self . preEnterPath ( refstr ) : NEW_LINE INDENT ref = eServiceReference ( refstr ) NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT self . pathUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT currentRoot = self . getRoot ( ) NEW_LINE if currentRoot is None or currentRoot != ref : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . enterPath ( ref ) NEW_LINE service = self . session . nav . getCurrentService ( ) NEW_LINE if service : NEW_LINE INDENT info = service . info ( ) NEW_LINE if info : NEW_LINE INDENT provider = info . getInfoString ( iServiceInformation . sProvider ) NEW_LINE refstr = '1:7:0:0:0:0:0:0:0:0 : ( provider ▁ = = ▁ \ " % s\ " ) ▁ & & ▁ % s ▁ ORDER ▁ BY ▁ name : % s ' % ( provider , self . service_types [ self . service_types . rfind ( ' : ' ) + 1 : ] , provider ) NEW_LINE self . setCurrentSelectionAlternative ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT def changeBouquet ( self , direction ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT if len ( self . servicePath ) > 1 : NEW_LINE INDENT ref = eServiceReference ( ' % s ▁ FROM ▁ SATELLITES ▁ ORDER ▁ BY ▁ satellitePosition ' % ( self . service_types ) ) NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT self . showSatellites ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . pathUp ( ) NEW_LINE DEDENT if direction < 0 : NEW_LINE INDENT self . moveUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . moveDown ( ) NEW_LINE DEDENT ref = self . getCurrentSelection ( ) NEW_LINE self . enterPath ( ref ) NEW_LINE DEDENT DEDENT DEDENT def inBouquet ( self ) : NEW_LINE INDENT if self . servicePath and self . servicePath [ 0 ] == self . bouquet_root : NEW_LINE INDENT return True NEW_LINE DEDENT return False NEW_LINE DEDENT def atBegin ( self ) : NEW_LINE INDENT return self . servicelist . atBegin ( ) NEW_LINE DEDENT def atEnd ( self ) : NEW_LINE INDENT return self . servicelist . atEnd ( ) NEW_LINE DEDENT def nextBouquet ( self ) : NEW_LINE INDENT if self . shown and config . usage . oldstyle_channel_select_controls . value : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . pageUp ) NEW_LINE DEDENT elif " reverseB " in config . usage . servicelist_cursor_behavior . value : NEW_LINE INDENT self . changeBouquet ( - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . changeBouquet ( + 1 ) NEW_LINE DEDENT DEDENT def prevBouquet ( self ) : NEW_LINE INDENT if self . shown and config . usage . oldstyle_channel_select_controls . value : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . pageDown ) NEW_LINE DEDENT elif " reverseB " in config . usage . servicelist_cursor_behavior . value : NEW_LINE INDENT self . changeBouquet ( + 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . changeBouquet ( - 1 ) NEW_LINE DEDENT DEDENT def keyLeft ( self ) : NEW_LINE INDENT if config . usage . oldstyle_channel_select_controls . value : NEW_LINE INDENT self . changeBouquet ( - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . pageUp ) NEW_LINE DEDENT DEDENT def keyRight ( self ) : NEW_LINE INDENT if config . usage . oldstyle_channel_select_controls . value : NEW_LINE INDENT self . changeBouquet ( + 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . servicelist . instance . moveSelection ( self . servicelist . instance . pageDown ) NEW_LINE DEDENT DEDENT def keyRecord ( self ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if ref and not ( ref . flags & ( eServiceReference . isMarker | eServiceReference . isDirectory ) ) : NEW_LINE INDENT Screens . InfoBar . InfoBar . instance . instantRecord ( serviceRef = ref ) NEW_LINE DEDENT DEDENT def showFavourites ( self ) : NEW_LINE INDENT if not self . pathChangeDisabled : NEW_LINE INDENT if not self . preEnterPath ( self . bouquet_rootstr ) : NEW_LINE INDENT if self . isBasePathEqual ( self . bouquet_root ) : NEW_LINE INDENT self . pathUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT currentRoot = self . getRoot ( ) NEW_LINE if currentRoot is None or currentRoot != self . bouquet_root : NEW_LINE INDENT self . clearPath ( ) NEW_LINE self . enterPath ( self . bouquet_root ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def keyNumber0 ( self , number ) : NEW_LINE INDENT if len ( self . servicePath ) > 1 and not self . selectionNumber : NEW_LINE INDENT self . keyGoUp ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . keyNumberGlobal ( number ) NEW_LINE DEDENT DEDENT def keyNumberGlobal ( self , number ) : NEW_LINE INDENT if self . isBasePathEqual ( self . bouquet_root ) : NEW_LINE INDENT if hasattr ( self , " editMode " ) and self . editMode : NEW_LINE INDENT if number == 2 : NEW_LINE INDENT self . renameEntry ( ) NEW_LINE DEDENT if number == 6 : NEW_LINE INDENT self . toggleMoveMode ( select = True ) NEW_LINE DEDENT if number == 8 : NEW_LINE INDENT self . removeCurrentEntry ( bouquet = False ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . numberSelectionActions ( number ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT current_root = self . getRoot ( ) NEW_LINE if current_root and ' FROM ▁ BOUQUET ▁ " bouquets . ' in current_root . getPath ( ) : NEW_LINE INDENT if hasattr ( self , " editMode " ) and self . editMode : NEW_LINE INDENT if number == 2 : NEW_LINE INDENT self . renameEntry ( ) NEW_LINE DEDENT if number == 6 : NEW_LINE INDENT self . toggleMoveMode ( select = True ) NEW_LINE DEDENT if number == 8 : NEW_LINE INDENT self . removeCurrentEntry ( bouquet = True ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . numberSelectionActions ( number ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT unichar = self . numericalTextInput . getKey ( number ) NEW_LINE charstr = unichar . encode ( " utf - 8" ) NEW_LINE if len ( charstr ) == 1 : NEW_LINE INDENT self . servicelist . moveToChar ( charstr [ 0 ] ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def numberSelectionActions ( self , number ) : NEW_LINE INDENT if not ( hasattr ( self , " movemode " ) and self . movemode ) : NEW_LINE INDENT if len ( self . selectionNumber ) > 4 : NEW_LINE INDENT self . clearNumberSelectionNumber ( ) NEW_LINE DEDENT self . selectionNumber = self . selectionNumber + str ( number ) NEW_LINE ref , bouquet = Screens . InfoBar . InfoBar . instance . searchNumber ( int ( self . selectionNumber ) , bouquet = self . getRoot ( ) ) NEW_LINE if ref : NEW_LINE INDENT if not ref . flags & eServiceReference . isMarker : NEW_LINE INDENT self . enterUserbouquet ( bouquet , save_root = False ) NEW_LINE self . setCurrentSelection ( ref ) NEW_LINE DEDENT self . clearNumberSelectionNumberTimer . start ( 1000 , True ) NEW_LINE DEDENT else : NEW_LINE INDENT self . clearNumberSelectionNumber ( ) NEW_LINE DEDENT DEDENT DEDENT def clearNumberSelectionNumber ( self ) : NEW_LINE INDENT self . clearNumberSelectionNumberTimer . stop ( ) NEW_LINE self . selectionNumber = " " NEW_LINE DEDENT def keyAsciiCode ( self ) : NEW_LINE INDENT unichar = unichr ( getPrevAsciiCode ( ) ) NEW_LINE charstr = unichar . encode ( " utf - 8" ) NEW_LINE if len ( charstr ) == 1 : NEW_LINE INDENT self . servicelist . moveToChar ( charstr [ 0 ] ) NEW_LINE DEDENT DEDENT def getRoot ( self ) : NEW_LINE INDENT return self . servicelist . getRoot ( ) NEW_LINE DEDENT def getCurrentSelection ( self ) : NEW_LINE INDENT return self . servicelist . getCurrent ( ) NEW_LINE DEDENT def setCurrentSelection ( self , service ) : NEW_LINE INDENT if service : NEW_LINE INDENT self . servicelist . setCurrent ( service , adjust = False ) NEW_LINE DEDENT DEDENT def setCurrentSelectionAlternative ( self , ref ) : NEW_LINE INDENT if self . bouquet_mark_edit == EDIT_ALTERNATIVES and not ( ref . flags & eServiceReference . isDirectory ) : NEW_LINE INDENT for markedService in self . servicelist . getMarked ( ) : NEW_LINE INDENT markedService = eServiceReference ( markedService ) NEW_LINE self . setCurrentSelection ( markedService ) NEW_LINE if markedService == self . getCurrentSelection ( ) : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT DEDENT self . setCurrentSelection ( ref ) NEW_LINE DEDENT def getBouquetList ( self ) : NEW_LINE INDENT bouquets = [ ] NEW_LINE serviceHandler = eServiceCenter . getInstance ( ) NEW_LINE if config . usage . multibouquet . value : NEW_LINE INDENT list = serviceHandler . list ( self . bouquet_root ) NEW_LINE if list : NEW_LINE INDENT while True : NEW_LINE INDENT s = list . getNext ( ) NEW_LINE if not s . valid ( ) : NEW_LINE INDENT break NEW_LINE DEDENT if s . flags & eServiceReference . isDirectory and not s . flags & eServiceReference . isInvisible : NEW_LINE INDENT info = serviceHandler . info ( s ) NEW_LINE if info : NEW_LINE INDENT bouquets . append ( ( info . getName ( s ) , s ) ) NEW_LINE DEDENT DEDENT DEDENT return bouquets NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT info = serviceHandler . info ( self . bouquet_root ) NEW_LINE if info : NEW_LINE INDENT bouquets . append ( ( info . getName ( self . bouquet_root ) , self . bouquet_root ) ) NEW_LINE DEDENT return bouquets NEW_LINE DEDENT return None NEW_LINE DEDENT def keyGoUp ( self ) : NEW_LINE INDENT if len ( self . servicePath ) > 1 : NEW_LINE INDENT if self . isBasePathEqual ( self . bouquet_root ) : NEW_LINE INDENT self . showFavourites ( ) NEW_LINE DEDENT else : NEW_LINE INDENT ref = eServiceReference ( ' % s ▁ FROM ▁ SATELLITES ▁ ORDER ▁ BY ▁ satellitePosition ' % ( self . service_types ) ) NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT self . showSatellites ( ) NEW_LINE DEDENT else : NEW_LINE INDENT ref = eServiceReference ( ' % s ▁ FROM ▁ PROVIDERS ▁ ORDER ▁ BY ▁ name ' % ( self . service_types ) ) NEW_LINE if self . isBasePathEqual ( ref ) : NEW_LINE INDENT self . showProviders ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . showAllServices ( ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def nextMarker ( self ) : NEW_LINE INDENT self . servicelist . moveToNextMarker ( ) NEW_LINE DEDENT def prevMarker ( self ) : NEW_LINE INDENT self . servicelist . moveToPrevMarker ( ) NEW_LINE DEDENT def gotoCurrentServiceOrProvider ( self , ref ) : NEW_LINE INDENT str = ref . toString ( ) NEW_LINE if _ ( " Providers " ) in str : NEW_LINE INDENT service = self . session . nav . getCurrentService ( ) NEW_LINE if service : NEW_LINE INDENT info = service . info ( ) NEW_LINE if info : NEW_LINE INDENT provider = info . getInfoString ( iServiceInformation . sProvider ) NEW_LINE op = int ( self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) . toString ( ) . split ( ' : ' ) [ 6 ] [ : - 4 ] or "0" , 16 ) NEW_LINE refstr = '1:7:0:0:0:0:0:0:0:0 : ( provider ▁ = = ▁ \ " % s\ " ) ▁ & & ▁ ( satellitePosition ▁ = = ▁ % s ) ▁ & & ▁ % s ▁ ORDER ▁ BY ▁ name : % s ' % ( provider , op , self . service_types [ self . service_types . rfind ( ' : ' ) + 1 : ] , provider ) NEW_LINE self . setCurrentSelection ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT elif not self . isBasePathEqual ( self . bouquet_root ) or self . bouquet_mark_edit == EDIT_ALTERNATIVES : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if playingref : NEW_LINE INDENT self . setCurrentSelectionAlternative ( playingref ) NEW_LINE DEDENT DEDENT DEDENT DEDENT HISTORYSIZE = 20 NEW_LINE config . tv = ConfigSubsection ( ) NEW_LINE config . tv . lastservice = ConfigText ( ) NEW_LINE config . tv . lastroot = ConfigText ( ) NEW_LINE config . radio = ConfigSubsection ( ) NEW_LINE config . radio . lastservice = ConfigText ( ) NEW_LINE config . radio . lastroot = ConfigText ( ) NEW_LINE config . servicelist = ConfigSubsection ( ) NEW_LINE config . servicelist . lastmode = ConfigText ( default = " tv " ) NEW_LINE config . servicelist . startupservice = ConfigText ( ) NEW_LINE config . servicelist . startupservice_onstandby = ConfigYesNo ( default = False ) NEW_LINE config . servicelist . startuproot = ConfigText ( ) NEW_LINE config . servicelist . startupmode = ConfigText ( default = " tv " ) NEW_LINE class ChannelSelection ( ChannelSelectionBase , ChannelSelectionEdit , ChannelSelectionEPG , SelectionEventInfo ) : NEW_LINE INDENT def __init__ ( self , session ) : NEW_LINE INDENT ChannelSelectionBase . __init__ ( self , session ) NEW_LINE ChannelSelectionEdit . __init__ ( self ) NEW_LINE ChannelSelectionEPG . __init__ ( self ) NEW_LINE SelectionEventInfo . __init__ ( self ) NEW_LINE self [ " actions " ] = ActionMap ( [ " OkCancelActions " , " TvRadioActions " ] , { " cancel " : self . cancel , " ok " : self . channelSelected , " keyRadio " : self . doRadioButton , " keyTV " : self . doTVButton , } ) NEW_LINE self . __event_tracker = ServiceEventTracker ( screen = self , eventmap = { iPlayableService . evStart : self . __evServiceStart , iPlayableService . evEnd : self . __evServiceEnd } ) NEW_LINE self . startServiceRef = None NEW_LINE self . history = [ ] NEW_LINE self . history_pos = 0 NEW_LINE if config . servicelist . startupservice . value and config . servicelist . startuproot . value : NEW_LINE INDENT config . servicelist . lastmode . value = config . servicelist . startupmode . value NEW_LINE if config . servicelist . lastmode . value == " tv " : NEW_LINE INDENT config . tv . lastservice . value = config . servicelist . startupservice . value NEW_LINE config . tv . lastroot . value = config . servicelist . startuproot . value NEW_LINE DEDENT elif config . servicelist . lastmode . value == " radio " : NEW_LINE INDENT config . radio . lastservice . value = config . servicelist . startupservice . value NEW_LINE config . radio . lastroot . value = config . servicelist . startuproot . value NEW_LINE DEDENT DEDENT self . lastservice = config . tv . lastservice NEW_LINE self . lastroot = config . tv . lastroot NEW_LINE self . revertMode = None NEW_LINE config . usage . multibouquet . addNotifier ( self . multibouquet_config_changed ) NEW_LINE self . new_service_played = False NEW_LINE self . dopipzap = False NEW_LINE self . onExecBegin . append ( self . asciiOn ) NEW_LINE self . mainScreenMode = None NEW_LINE self . mainScreenRoot = None NEW_LINE self . lastChannelRootTimer = eTimer ( ) NEW_LINE self . lastChannelRootTimer . callback . append ( self . __onCreate ) NEW_LINE self . lastChannelRootTimer . start ( 100 , True ) NEW_LINE self . pipzaptimer = eTimer ( ) NEW_LINE DEDENT def asciiOn ( self ) : NEW_LINE INDENT rcinput = eRCInput . getInstance ( ) NEW_LINE rcinput . setKeyboardMode ( rcinput . kmAscii ) NEW_LINE DEDENT def asciiOff ( self ) : NEW_LINE INDENT rcinput = eRCInput . getInstance ( ) NEW_LINE rcinput . setKeyboardMode ( rcinput . kmNone ) NEW_LINE DEDENT def multibouquet_config_changed ( self , val ) : NEW_LINE INDENT self . recallBouquetMode ( ) NEW_LINE DEDENT def __evServiceStart ( self ) : NEW_LINE INDENT if self . dopipzap and hasattr ( self . session , ' pip ' ) : NEW_LINE INDENT self . servicelist . setPlayableIgnoreService ( self . session . pip . getCurrentServiceReference ( ) or eServiceReference ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT service = self . session . nav . getCurrentService ( ) NEW_LINE if service : NEW_LINE INDENT info = service . info ( ) NEW_LINE if info : NEW_LINE INDENT refstr = info . getInfoString ( iServiceInformation . sServiceref ) NEW_LINE self . servicelist . setPlayableIgnoreService ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def __evServiceEnd ( self ) : NEW_LINE INDENT self . servicelist . setPlayableIgnoreService ( eServiceReference ( ) ) NEW_LINE DEDENT def setMode ( self ) : NEW_LINE INDENT self . rootChanged = True NEW_LINE self . restoreRoot ( ) NEW_LINE lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE DEDENT DEDENT def doTVButton ( self ) : NEW_LINE INDENT if self . mode == MODE_TV : NEW_LINE INDENT self . channelSelected ( doClose = False ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT DEDENT def setModeTv ( self ) : NEW_LINE INDENT if self . revertMode is None : NEW_LINE INDENT self . revertMode = self . mode NEW_LINE DEDENT self . lastservice = config . tv . lastservice NEW_LINE self . lastroot = config . tv . lastroot NEW_LINE config . servicelist . lastmode . value = " tv " NEW_LINE self . setTvMode ( ) NEW_LINE self . setMode ( ) NEW_LINE DEDENT def doRadioButton ( self ) : NEW_LINE INDENT if self . mode == MODE_RADIO : NEW_LINE INDENT self . channelSelected ( doClose = False ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT DEDENT def setModeRadio ( self ) : NEW_LINE INDENT if self . revertMode is None : NEW_LINE INDENT self . revertMode = self . mode NEW_LINE DEDENT if config . usage . e1like_radio_mode . value : NEW_LINE INDENT self . lastservice = config . radio . lastservice NEW_LINE self . lastroot = config . radio . lastroot NEW_LINE config . servicelist . lastmode . value = " radio " NEW_LINE self . setRadioMode ( ) NEW_LINE self . setMode ( ) NEW_LINE DEDENT DEDENT def __onCreate ( self ) : NEW_LINE INDENT if config . usage . e1like_radio_mode . value : NEW_LINE INDENT if config . servicelist . lastmode . value == " tv " : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . zap ( ) NEW_LINE DEDENT DEDENT def channelSelected ( self , doClose = True ) : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if config . usage . channelselection_preview . value and ( playingref is None or self . getCurrentSelection ( ) and self . getCurrentSelection ( ) != playingref ) : NEW_LINE INDENT doClose = False NEW_LINE DEDENT if not self . startServiceRef and not doClose : NEW_LINE INDENT self . startServiceRef = playingref NEW_LINE DEDENT ref = self . getCurrentSelection ( ) NEW_LINE if self . movemode and ( self . isBasePathEqual ( self . bouquet_root ) or " userbouquet . " in ref . toString ( ) ) : NEW_LINE INDENT self . toggleMoveMarked ( ) NEW_LINE DEDENT elif ( ref . flags & eServiceReference . flagDirectory ) == eServiceReference . flagDirectory : NEW_LINE INDENT if Components . ParentalControl . parentalControl . isServicePlayable ( ref , self . bouquetParentalControlCallback , self . session ) : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE self . revertMode = None NEW_LINE DEDENT DEDENT elif self . bouquet_mark_edit != OFF : NEW_LINE INDENT if not ( self . bouquet_mark_edit == EDIT_ALTERNATIVES and ref . flags & eServiceReference . isGroup ) : NEW_LINE INDENT self . doMark ( ) NEW_LINE DEDENT DEDENT elif not ( ref . flags & eServiceReference . isMarker or ref . type == - 1 ) : NEW_LINE INDENT root = self . getRoot ( ) NEW_LINE if not root or not ( root . flags & eServiceReference . isGroup ) : NEW_LINE INDENT self . zap ( enable_pipzap = doClose , preview_zap = not doClose ) NEW_LINE self . asciiOff ( ) NEW_LINE if doClose : NEW_LINE INDENT if self . dopipzap : NEW_LINE INDENT self . zapBack ( ) NEW_LINE DEDENT self . startServiceRef = None NEW_LINE self . startRoot = None NEW_LINE self . correctChannelNumber ( ) NEW_LINE self . movemode and self . toggleMoveMode ( ) NEW_LINE self . editMode = False NEW_LINE self . protectContextMenu = True NEW_LINE self . close ( ref ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def bouquetParentalControlCallback ( self , ref ) : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE self . revertMode = None NEW_LINE DEDENT def togglePipzap ( self ) : NEW_LINE INDENT assert ( self . session . pip ) NEW_LINE title = self . instance . getTitle ( ) NEW_LINE pos = title . find ( " ▁ ( " ) NEW_LINE if pos != - 1 : NEW_LINE INDENT title = title [ : pos ] NEW_LINE DEDENT if self . dopipzap : NEW_LINE INDENT self . hidePipzapMessage ( ) NEW_LINE self . dopipzap = False NEW_LINE if self . session . pip . pipservice is None : NEW_LINE INDENT self . session . pipshown = False NEW_LINE del self . session . pip NEW_LINE DEDENT self . __evServiceStart ( ) NEW_LINE lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) and self . getCurrentSelection ( ) != lastservice : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE if self . getCurrentSelection ( ) != lastservice : NEW_LINE INDENT self . servicelist . setCurrent ( lastservice ) NEW_LINE DEDENT DEDENT title += _ ( " ▁ ( TV ) " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . showPipzapMessage ( ) NEW_LINE self . dopipzap = True NEW_LINE self . __evServiceStart ( ) NEW_LINE self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE title += _ ( " ▁ ( PiP ) " ) NEW_LINE DEDENT self . setTitle ( title ) NEW_LINE self . buildTitleString ( ) NEW_LINE DEDENT def showPipzapMessage ( self ) : NEW_LINE INDENT time = config . usage . infobar_timeout . index NEW_LINE if time : NEW_LINE INDENT self . pipzaptimer . callback . append ( self . hidePipzapMessage ) NEW_LINE self . pipzaptimer . startLongTimer ( time ) NEW_LINE DEDENT self . session . pip . active ( ) NEW_LINE DEDENT def hidePipzapMessage ( self ) : NEW_LINE INDENT if self . pipzaptimer . isActive ( ) : NEW_LINE INDENT self . pipzaptimer . callback . remove ( self . hidePipzapMessage ) NEW_LINE self . pipzaptimer . stop ( ) NEW_LINE DEDENT self . session . pip . inactive ( ) NEW_LINE DEDENT def zap ( self , enable_pipzap = False , preview_zap = False , checkParentalControl = True , ref = None ) : NEW_LINE INDENT self . curRoot = self . startRoot NEW_LINE nref = ref or self . getCurrentSelection ( ) NEW_LINE ref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if enable_pipzap and self . dopipzap : NEW_LINE INDENT ref = self . session . pip . getCurrentService ( ) NEW_LINE if ref is None or ref != nref : NEW_LINE INDENT nref = self . session . pip . resolveAlternatePipService ( nref ) NEW_LINE if nref and ( not checkParentalControl or Components . ParentalControl . parentalControl . isServicePlayable ( nref , boundFunction ( self . zap , enable_pipzap = True , checkParentalControl = False ) ) ) : NEW_LINE INDENT self . session . pip . playService ( nref ) NEW_LINE self . __evServiceStart ( ) NEW_LINE self . showPipzapMessage ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setStartRoot ( self . curRoot ) NEW_LINE self . setCurrentSelection ( ref ) NEW_LINE DEDENT DEDENT DEDENT elif ref is None or ref != nref : NEW_LINE INDENT Screens . InfoBar . InfoBar . instance . checkTimeshiftRunning ( boundFunction ( self . zapCheckTimeshiftCallback , enable_pipzap , preview_zap , nref ) ) NEW_LINE DEDENT elif not preview_zap : NEW_LINE INDENT self . saveRoot ( ) NEW_LINE self . saveChannel ( nref ) NEW_LINE config . servicelist . lastmode . save ( ) NEW_LINE self . setCurrentSelection ( nref ) NEW_LINE if self . startServiceRef is None or nref != self . startServiceRef : NEW_LINE INDENT self . addToHistory ( nref ) NEW_LINE DEDENT self . rootChanged = False NEW_LINE self . revertMode = None NEW_LINE DEDENT DEDENT def zapCheckTimeshiftCallback ( self , enable_pipzap , preview_zap , nref , answer ) : NEW_LINE INDENT if answer : NEW_LINE INDENT self . new_service_played = True NEW_LINE self . session . nav . playService ( nref ) NEW_LINE if not preview_zap : NEW_LINE INDENT self . saveRoot ( ) NEW_LINE self . saveChannel ( nref ) NEW_LINE config . servicelist . lastmode . save ( ) NEW_LINE if self . startServiceRef is None or nref != self . startServiceRef : NEW_LINE INDENT self . addToHistory ( nref ) NEW_LINE DEDENT if self . dopipzap : NEW_LINE INDENT self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . mainScreenMode = config . servicelist . lastmode . value NEW_LINE self . mainScreenRoot = self . getRoot ( ) NEW_LINE DEDENT self . revertMode = None NEW_LINE DEDENT else : NEW_LINE INDENT Notifications . RemovePopup ( " Parental ▁ control " ) NEW_LINE self . setCurrentSelection ( nref ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . setStartRoot ( self . curRoot ) NEW_LINE self . setCurrentSelection ( self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) ) NEW_LINE DEDENT if not preview_zap : NEW_LINE INDENT self . hide ( ) NEW_LINE DEDENT DEDENT def newServicePlayed ( self ) : NEW_LINE INDENT ret = self . new_service_played NEW_LINE self . new_service_played = False NEW_LINE return ret NEW_LINE DEDENT def addToHistory ( self , ref ) : NEW_LINE INDENT if self . servicePath is not None : NEW_LINE INDENT tmp = self . servicePath [ : ] NEW_LINE tmp . append ( ref ) NEW_LINE try : NEW_LINE INDENT del self . history [ self . history_pos + 1 : ] NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT self . history . append ( tmp ) NEW_LINE hlen = len ( self . history ) NEW_LINE if hlen > HISTORYSIZE : NEW_LINE INDENT del self . history [ 0 ] NEW_LINE hlen -= 1 NEW_LINE DEDENT self . history_pos = hlen - 1 NEW_LINE DEDENT DEDENT def historyBack ( self ) : NEW_LINE INDENT hlen = len ( self . history ) NEW_LINE currentPlayedRef = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if hlen > 0 and currentPlayedRef and self . history [ self . history_pos ] [ - 1 ] != currentPlayedRef : NEW_LINE INDENT self . addToHistory ( currentPlayedRef ) NEW_LINE hlen = len ( self . history ) NEW_LINE DEDENT if hlen > 1 and self . history_pos > 0 : NEW_LINE INDENT self . history_pos -= 1 NEW_LINE self . setHistoryPath ( ) NEW_LINE DEDENT DEDENT def historyNext ( self ) : NEW_LINE INDENT hlen = len ( self . history ) NEW_LINE if hlen > 1 and self . history_pos < ( hlen - 1 ) : NEW_LINE INDENT self . history_pos += 1 NEW_LINE self . setHistoryPath ( ) NEW_LINE DEDENT DEDENT def setHistoryPath ( self , doZap = True ) : NEW_LINE INDENT path = self . history [ self . history_pos ] [ : ] NEW_LINE ref = path . pop ( ) NEW_LINE del self . servicePath [ : ] NEW_LINE self . servicePath += path NEW_LINE self . saveRoot ( ) NEW_LINE root = path [ - 1 ] NEW_LINE cur_root = self . getRoot ( ) NEW_LINE if cur_root and cur_root != root : NEW_LINE INDENT self . setRoot ( root ) NEW_LINE DEDENT if doZap : NEW_LINE INDENT self . session . nav . playService ( ref , adjust = False ) NEW_LINE DEDENT if self . dopipzap : NEW_LINE INDENT self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . setCurrentSelection ( ref ) NEW_LINE DEDENT self . saveChannel ( ref ) NEW_LINE DEDENT def saveRoot ( self ) : NEW_LINE INDENT path = ' ' NEW_LINE for i in self . servicePath : NEW_LINE INDENT path += i . toString ( ) NEW_LINE path += ' ; ' NEW_LINE DEDENT if path and path != self . lastroot . value : NEW_LINE INDENT if self . mode == MODE_RADIO and ' FROM ▁ BOUQUET ▁ " bouquets . tv " ' in path : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif self . mode == MODE_TV and ' FROM ▁ BOUQUET ▁ " bouquets . radio " ' in path : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT self . lastroot . value = path NEW_LINE self . lastroot . save ( ) NEW_LINE DEDENT DEDENT def restoreRoot ( self ) : NEW_LINE INDENT tmp = [ x for x in self . lastroot . value . split ( ' ; ' ) if x != ' ' ] NEW_LINE current = [ x . toString ( ) for x in self . servicePath ] NEW_LINE if tmp != current or self . rootChanged : NEW_LINE INDENT self . clearPath ( ) NEW_LINE cnt = 0 NEW_LINE for i in tmp : NEW_LINE INDENT self . servicePath . append ( eServiceReference ( i ) ) NEW_LINE cnt += 1 NEW_LINE DEDENT if cnt : NEW_LINE INDENT path = self . servicePath . pop ( ) NEW_LINE self . enterPath ( path ) NEW_LINE DEDENT else : NEW_LINE INDENT self . showFavourites ( ) NEW_LINE self . saveRoot ( ) NEW_LINE DEDENT self . rootChanged = False NEW_LINE DEDENT DEDENT def preEnterPath ( self , refstr ) : NEW_LINE INDENT if self . servicePath and self . servicePath [ 0 ] != eServiceReference ( refstr ) : NEW_LINE INDENT pathstr = self . lastroot . value NEW_LINE if pathstr is not None and refstr in pathstr : NEW_LINE INDENT self . restoreRoot ( ) NEW_LINE lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE DEDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def saveChannel ( self , ref ) : NEW_LINE INDENT if ref is not None : NEW_LINE INDENT refstr = ref . toString ( ) NEW_LINE DEDENT else : NEW_LINE INDENT refstr = " " NEW_LINE DEDENT if refstr != self . lastservice . value and not Components . ParentalControl . parentalControl . isProtected ( ref ) : NEW_LINE INDENT self . lastservice . value = refstr NEW_LINE self . lastservice . save ( ) NEW_LINE DEDENT DEDENT def setCurrentServicePath ( self , path , doZap = True ) : NEW_LINE INDENT hlen = len ( self . history ) NEW_LINE if not hlen : NEW_LINE INDENT self . history . append ( path ) NEW_LINE self . history_pos = 0 NEW_LINE DEDENT if hlen == 1 : NEW_LINE INDENT self . history [ self . history_pos ] = path NEW_LINE DEDENT else : NEW_LINE INDENT if path in self . history : NEW_LINE INDENT self . history . remove ( path ) NEW_LINE self . history_pos -= 1 NEW_LINE DEDENT tmp = self . history [ self . history_pos ] [ : ] NEW_LINE self . history . append ( tmp ) NEW_LINE self . history_pos += 1 NEW_LINE self . history [ self . history_pos ] = path NEW_LINE DEDENT self . setHistoryPath ( doZap ) NEW_LINE DEDENT def getCurrentServicePath ( self ) : NEW_LINE INDENT if self . history : NEW_LINE INDENT return self . history [ self . history_pos ] NEW_LINE DEDENT return None NEW_LINE DEDENT def recallPrevService ( self ) : NEW_LINE INDENT hlen = len ( self . history ) NEW_LINE currentPlayedRef = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if hlen > 0 and currentPlayedRef and self . history [ self . history_pos ] [ - 1 ] != currentPlayedRef : NEW_LINE INDENT self . addToHistory ( currentPlayedRef ) NEW_LINE hlen = len ( self . history ) NEW_LINE DEDENT if hlen > 1 : NEW_LINE INDENT if self . history_pos == hlen - 1 : NEW_LINE INDENT tmp = self . history [ self . history_pos ] NEW_LINE self . history [ self . history_pos ] = self . history [ self . history_pos - 1 ] NEW_LINE self . history [ self . history_pos - 1 ] = tmp NEW_LINE DEDENT else : NEW_LINE INDENT tmp = self . history [ self . history_pos + 1 ] NEW_LINE self . history [ self . history_pos + 1 ] = self . history [ self . history_pos ] NEW_LINE self . history [ self . history_pos ] = tmp NEW_LINE DEDENT self . setHistoryPath ( ) NEW_LINE DEDENT DEDENT def cancel ( self ) : NEW_LINE INDENT if self . revertMode is None : NEW_LINE INDENT self . restoreRoot ( ) NEW_LINE if self . dopipzap : NEW_LINE INDENT self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) and self . getCurrentSelection ( ) != lastservice : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE DEDENT DEDENT DEDENT self . asciiOff ( ) NEW_LINE self . zapBack ( ) NEW_LINE self . correctChannelNumber ( ) NEW_LINE self . editMode = False NEW_LINE self . protectContextMenu = True NEW_LINE self . close ( None ) NEW_LINE DEDENT def zapBack ( self ) : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if self . startServiceRef and ( playingref is None or playingref != self . startServiceRef ) : NEW_LINE INDENT self . setStartRoot ( self . startRoot ) NEW_LINE self . new_service_played = True NEW_LINE self . session . nav . playService ( self . startServiceRef ) NEW_LINE self . saveChannel ( self . startServiceRef ) NEW_LINE DEDENT else : NEW_LINE INDENT self . restoreMode ( ) NEW_LINE DEDENT self . startServiceRef = None NEW_LINE self . startRoot = None NEW_LINE if self . dopipzap : NEW_LINE INDENT self . setCurrentSelection ( self . session . pip . getCurrentService ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT lastservice = eServiceReference ( self . lastservice . value ) NEW_LINE if lastservice . valid ( ) and self . getCurrentSelection ( ) == lastservice : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . setCurrentSelection ( playingref ) NEW_LINE DEDENT DEDENT DEDENT def setStartRoot ( self , root ) : NEW_LINE INDENT if root : NEW_LINE INDENT if self . revertMode == MODE_TV : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif self . revertMode == MODE_RADIO : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT self . revertMode = None NEW_LINE self . enterUserbouquet ( root ) NEW_LINE DEDENT DEDENT def restoreMode ( self ) : NEW_LINE INDENT if self . revertMode == MODE_TV : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif self . revertMode == MODE_RADIO : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT self . revertMode = None NEW_LINE DEDENT def correctChannelNumber ( self ) : NEW_LINE INDENT current_ref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if self . dopipzap : NEW_LINE INDENT tmp_mode = config . servicelist . lastmode . value NEW_LINE tmp_root = self . getRoot ( ) NEW_LINE tmp_ref = self . getCurrentSelection ( ) NEW_LINE pip_ref = self . session . pip . getCurrentService ( ) NEW_LINE if tmp_ref and pip_ref and tmp_ref != pip_ref : NEW_LINE INDENT self . revertMode = None NEW_LINE return NEW_LINE DEDENT if self . mainScreenMode == " tv " : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif self . mainScreenMode == " radio " : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT if self . mainScreenRoot : NEW_LINE INDENT self . setRoot ( self . mainScreenRoot ) NEW_LINE self . setCurrentSelection ( current_ref ) NEW_LINE DEDENT DEDENT selected_ref = self . getCurrentSelection ( ) NEW_LINE if selected_ref and current_ref and selected_ref . getChannelNum ( ) != current_ref . getChannelNum ( ) : NEW_LINE INDENT oldref = self . session . nav . currentlyPlayingServiceReference NEW_LINE if oldref and selected_ref == oldref or ( oldref != current_ref and selected_ref == current_ref ) : NEW_LINE INDENT self . session . nav . currentlyPlayingServiceOrGroup = selected_ref NEW_LINE self . session . nav . pnav . navEvent ( iPlayableService . evStart ) NEW_LINE DEDENT DEDENT if self . dopipzap : NEW_LINE INDENT if tmp_mode == " tv " : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE DEDENT elif tmp_mode == " radio " : NEW_LINE INDENT self . setModeRadio ( ) NEW_LINE DEDENT self . enterUserbouquet ( tmp_root ) NEW_LINE title = self . instance . getTitle ( ) NEW_LINE pos = title . find ( " ▁ ( " ) NEW_LINE if pos != - 1 : NEW_LINE INDENT title = title [ : pos ] NEW_LINE title += _ ( " ▁ ( PiP ) " ) NEW_LINE self . setTitle ( title ) NEW_LINE self . buildTitleString ( ) NEW_LINE DEDENT if tmp_ref and pip_ref and tmp_ref . getChannelNum ( ) != pip_ref . getChannelNum ( ) : NEW_LINE INDENT self . session . pip . currentService = tmp_ref NEW_LINE DEDENT self . setCurrentSelection ( tmp_ref ) NEW_LINE DEDENT self . revertMode = None NEW_LINE DEDENT DEDENT class RadioInfoBar ( Screen ) : NEW_LINE INDENT def __init__ ( self , session ) : NEW_LINE INDENT Screen . __init__ ( self , session ) NEW_LINE self [ " RdsDecoder " ] = RdsDecoder ( self . session . nav ) NEW_LINE DEDENT DEDENT class ChannelSelectionRadio ( ChannelSelectionBase , ChannelSelectionEdit , ChannelSelectionEPG , InfoBarBase , SelectionEventInfo ) : NEW_LINE INDENT ALLOW_SUSPEND = True NEW_LINE def __init__ ( self , session , infobar ) : NEW_LINE INDENT ChannelSelectionBase . __init__ ( self , session ) NEW_LINE ChannelSelectionEdit . __init__ ( self ) NEW_LINE ChannelSelectionEPG . __init__ ( self ) NEW_LINE InfoBarBase . __init__ ( self ) NEW_LINE SelectionEventInfo . __init__ ( self ) NEW_LINE self . infobar = infobar NEW_LINE self . startServiceRef = None NEW_LINE self . onLayoutFinish . append ( self . onCreate ) NEW_LINE self . info = session . instantiateDialog ( RadioInfoBar ) NEW_LINE self [ " actions " ] = ActionMap ( [ " OkCancelActions " , " TvRadioActions " ] , { " keyTV " : self . cancel , " keyRadio " : self . cancel , " cancel " : self . cancel , " ok " : self . channelSelected , } ) NEW_LINE self . __event_tracker = ServiceEventTracker ( screen = self , eventmap = { iPlayableService . evStart : self . __evServiceStart , iPlayableService . evEnd : self . __evServiceEnd } ) NEW_LINE self . infobar = infobar NEW_LINE self [ " RdsDecoder " ] = self . info [ " RdsDecoder " ] NEW_LINE self [ " RdsActions " ] = HelpableActionMap ( self , " InfobarRdsActions " , { " startRassInteractive " : ( self . startRassInteractive , _ ( " View ▁ Rass ▁ interactive . . . " ) ) } , - 1 ) NEW_LINE self [ " RdsActions " ] . setEnabled ( False ) NEW_LINE infobar . rds_display . onRassInteractivePossibilityChanged . append ( self . RassInteractivePossibilityChanged ) NEW_LINE self . onClose . append ( self . __onClose ) NEW_LINE self . onExecBegin . append ( self . __onExecBegin ) NEW_LINE self . onExecEnd . append ( self . __onExecEnd ) NEW_LINE DEDENT def __onClose ( self ) : NEW_LINE INDENT lastservice = eServiceReference ( config . tv . lastservice . value ) NEW_LINE self . session . nav . playService ( lastservice ) NEW_LINE DEDENT def startRassInteractive ( self ) : NEW_LINE INDENT self . info . hide ( ) NEW_LINE ; self . infobar . rass_interactive = self . session . openWithCallback ( self . RassInteractiveClosed , RassInteractive ) NEW_LINE DEDENT def RassInteractiveClosed ( self ) : NEW_LINE INDENT self . info . show ( ) NEW_LINE self . infobar . rass_interactive = None NEW_LINE self . infobar . RassSlidePicChanged ( ) NEW_LINE DEDENT def RassInteractivePossibilityChanged ( self , state ) : NEW_LINE INDENT self [ " RdsActions " ] . setEnabled ( state ) NEW_LINE DEDENT def __onExecBegin ( self ) : NEW_LINE INDENT self . info . show ( ) NEW_LINE DEDENT def __onExecEnd ( self ) : NEW_LINE INDENT self . info . hide ( ) NEW_LINE DEDENT def cancel ( self ) : NEW_LINE INDENT self . infobar . rds_display . onRassInteractivePossibilityChanged . remove ( self . RassInteractivePossibilityChanged ) NEW_LINE self . info . hide ( ) NEW_LINE self . close ( None ) NEW_LINE DEDENT def __evServiceStart ( self ) : NEW_LINE INDENT service = self . session . nav . getCurrentService ( ) NEW_LINE if service : NEW_LINE INDENT info = service . info ( ) NEW_LINE if info : NEW_LINE INDENT refstr = info . getInfoString ( iServiceInformation . sServiceref ) NEW_LINE self . servicelist . setPlayableIgnoreService ( eServiceReference ( refstr ) ) NEW_LINE DEDENT DEDENT DEDENT def __evServiceEnd ( self ) : NEW_LINE INDENT self . servicelist . setPlayableIgnoreService ( eServiceReference ( ) ) NEW_LINE DEDENT def saveRoot ( self ) : NEW_LINE INDENT path = ' ' NEW_LINE for i in self . servicePathRadio : NEW_LINE INDENT path += i . toString ( ) NEW_LINE path += ' ; ' NEW_LINE DEDENT if path and path != config . radio . lastroot . value : NEW_LINE INDENT config . radio . lastroot . value = path NEW_LINE config . radio . lastroot . save ( ) NEW_LINE DEDENT DEDENT def restoreRoot ( self ) : NEW_LINE INDENT tmp = [ x for x in config . radio . lastroot . value . split ( ' ; ' ) if x != ' ' ] NEW_LINE current = [ x . toString ( ) for x in self . servicePath ] NEW_LINE if tmp != current or self . rootChanged : NEW_LINE INDENT cnt = 0 NEW_LINE for i in tmp : NEW_LINE INDENT self . servicePathRadio . append ( eServiceReference ( i ) ) NEW_LINE cnt += 1 NEW_LINE DEDENT if cnt : NEW_LINE INDENT path = self . servicePathRadio . pop ( ) NEW_LINE self . enterPath ( path ) NEW_LINE DEDENT else : NEW_LINE INDENT self . showFavourites ( ) NEW_LINE self . saveRoot ( ) NEW_LINE DEDENT self . rootChanged = False NEW_LINE DEDENT DEDENT def preEnterPath ( self , refstr ) : NEW_LINE INDENT if self . servicePathRadio and self . servicePathRadio [ 0 ] != eServiceReference ( refstr ) : NEW_LINE INDENT pathstr = config . radio . lastroot . value NEW_LINE if pathstr is not None and refstr in pathstr : NEW_LINE INDENT self . restoreRoot ( ) NEW_LINE lastservice = eServiceReference ( config . radio . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . setCurrentSelection ( lastservice ) NEW_LINE DEDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def onCreate ( self ) : NEW_LINE INDENT self . setRadioMode ( ) NEW_LINE self . restoreRoot ( ) NEW_LINE lastservice = eServiceReference ( config . radio . lastservice . value ) NEW_LINE if lastservice . valid ( ) : NEW_LINE INDENT self . servicelist . setCurrent ( lastservice ) NEW_LINE self . session . nav . playService ( lastservice ) NEW_LINE DEDENT else : NEW_LINE INDENT self . session . nav . stopService ( ) NEW_LINE DEDENT self . info . show ( ) NEW_LINE DEDENT def channelSelected ( self , doClose = False ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if self . movemode : NEW_LINE INDENT self . toggleMoveMarked ( ) NEW_LINE DEDENT elif ( ref . flags & eServiceReference . flagDirectory ) == eServiceReference . flagDirectory : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE DEDENT elif self . bouquet_mark_edit != OFF : NEW_LINE INDENT if not ( self . bouquet_mark_edit == EDIT_ALTERNATIVES and ref . flags & eServiceReference . isGroup ) : NEW_LINE INDENT self . doMark ( ) NEW_LINE DEDENT DEDENT elif not ( ref . flags & eServiceReference . isMarker ) : NEW_LINE INDENT cur_root = self . getRoot ( ) NEW_LINE if not cur_root or not ( cur_root . flags & eServiceReference . isGroup ) : NEW_LINE INDENT playingref = self . session . nav . getCurrentlyPlayingServiceOrGroup ( ) NEW_LINE if playingref is None or playingref != ref : NEW_LINE INDENT self . session . nav . playService ( ref ) NEW_LINE config . radio . lastservice . value = ref . toString ( ) NEW_LINE config . radio . lastservice . save ( ) NEW_LINE DEDENT self . saveRoot ( ) NEW_LINE DEDENT DEDENT DEDENT def zapBack ( self ) : NEW_LINE INDENT self . channelSelected ( ) NEW_LINE DEDENT DEDENT class SimpleChannelSelection ( ChannelSelectionBase , SelectionEventInfo ) : NEW_LINE INDENT def __init__ ( self , session , title , currentBouquet = False , returnBouquet = False , setService = None , setBouquet = None ) : NEW_LINE INDENT ChannelSelectionBase . __init__ ( self , session ) NEW_LINE SelectionEventInfo . __init__ ( self ) NEW_LINE self [ " actions " ] = ActionMap ( [ " OkCancelActions " , " TvRadioActions " ] , { " cancel " : self . close , " ok " : self . channelSelected , " keyRadio " : self . setModeRadio , " keyTV " : self . setModeTv , } ) NEW_LINE self . bouquet_mark_edit = OFF NEW_LINE if isinstance ( title , str ) : NEW_LINE INDENT self . maintitle = title NEW_LINE DEDENT self . currentBouquet = currentBouquet NEW_LINE self . returnBouquet = returnBouquet NEW_LINE self . setService = setService NEW_LINE self . setBouquet = setBouquet NEW_LINE self . onLayoutFinish . append ( self . layoutFinished ) NEW_LINE DEDENT def layoutFinished ( self ) : NEW_LINE INDENT self . setModeTv ( ) NEW_LINE if self . currentBouquet or self . setBouquet : NEW_LINE INDENT ref = self . setBouquet or Screens . InfoBar . InfoBar . instance . servicelist . getRoot ( ) NEW_LINE if ref : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE DEDENT DEDENT if self . setService : NEW_LINE INDENT self . setCurrentSelection ( self . setService ) NEW_LINE DEDENT DEDENT def saveRoot ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def keyRecord ( self ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT def channelSelected ( self ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if ( ref . flags & eServiceReference . flagDirectory ) == eServiceReference . flagDirectory : NEW_LINE INDENT self . enterPath ( ref ) NEW_LINE self . gotoCurrentServiceOrProvider ( ref ) NEW_LINE DEDENT elif not ( ref . flags & eServiceReference . isMarker ) : NEW_LINE INDENT ref = self . getCurrentSelection ( ) NEW_LINE if self . returnBouquet and len ( self . servicePath ) : NEW_LINE INDENT self . close ( ref , self . servicePath [ - 1 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT self . close ( ref ) NEW_LINE DEDENT DEDENT DEDENT def setModeTv ( self ) : NEW_LINE INDENT self . setTvMode ( ) NEW_LINE self . showFavourites ( ) NEW_LINE DEDENT def setModeRadio ( self ) : NEW_LINE INDENT self . setRadioMode ( ) NEW_LINE self . showFavourites ( ) NEW_LINE DEDENT DEDENT
 import os NEW_LINE import sys NEW_LINE import struct NEW_LINE from . _compat import raw_input , text_type , string_types , \NEW_LINE isatty , strip_ansi , get_winterm_size , DEFAULT_COLUMNS , WIN NEW_LINE from . utils import echo NEW_LINE from . exceptions import Abort , UsageError NEW_LINE from . types import convert_type NEW_LINE from . globals import resolve_color_default NEW_LINE visible_prompt_func = raw_input NEW_LINE _ansi_colors = ( ' black ' , ' red ' , ' green ' , ' yellow ' , ' blue ' , ' magenta ' , ' cyan ' , ' white ' , ' reset ' ) NEW_LINE _ansi_reset_all = ' \033[0m ' NEW_LINE def hidden_prompt_func ( prompt ) : NEW_LINE INDENT import getpass NEW_LINE return getpass . getpass ( prompt ) NEW_LINE DEDENT def _build_prompt ( text , suffix , show_default = False , default = None ) : NEW_LINE INDENT prompt = text NEW_LINE if default is not None and show_default : NEW_LINE INDENT prompt = ' % s ▁ [ % s ] ' % ( prompt , default ) NEW_LINE DEDENT return prompt + suffix NEW_LINE DEDENT def prompt ( text , default = None , hide_input = False , confirmation_prompt = False , type = None , value_proc = None , prompt_suffix = ' : ▁ ' , show_default = True , err = False ) : NEW_LINE INDENT result = None NEW_LINE def prompt_func ( text ) : NEW_LINE INDENT f = hide_input and hidden_prompt_func or visible_prompt_func NEW_LINE try : NEW_LINE INDENT echo ( text , nl = False , err = err ) NEW_LINE return f ( ' ' ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT if hide_input : NEW_LINE INDENT echo ( None , err = err ) NEW_LINE DEDENT raise Abort ( ) NEW_LINE DEDENT DEDENT if value_proc is None : NEW_LINE INDENT value_proc = convert_type ( type , default ) NEW_LINE DEDENT prompt = _build_prompt ( text , prompt_suffix , show_default , default ) NEW_LINE while 1 : NEW_LINE INDENT while 1 : NEW_LINE INDENT value = prompt_func ( prompt ) NEW_LINE if value : NEW_LINE INDENT break NEW_LINE DEDENT elif default is not None : NEW_LINE INDENT return default NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT result = value_proc ( value ) NEW_LINE DEDENT except UsageError as e : NEW_LINE INDENT echo ( ' Error : ▁ % s ' % e . message , err = err ) NEW_LINE continue NEW_LINE DEDENT if not confirmation_prompt : NEW_LINE INDENT return result NEW_LINE DEDENT while 1 : NEW_LINE INDENT value2 = prompt_func ( ' Repeat ▁ for ▁ confirmation : ▁ ' ) NEW_LINE if value2 : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT if value == value2 : NEW_LINE INDENT return result NEW_LINE DEDENT echo ( ' Error : ▁ the ▁ two ▁ entered ▁ values ▁ do ▁ not ▁ match ' , err = err ) NEW_LINE DEDENT DEDENT def confirm ( text , default = False , abort = False , prompt_suffix = ' : ▁ ' , show_default = True , err = False ) : NEW_LINE INDENT prompt = _build_prompt ( text , prompt_suffix , show_default , default and ' Y / n ' or ' y / N ' ) NEW_LINE while 1 : NEW_LINE INDENT try : NEW_LINE INDENT echo ( prompt , nl = False , err = err ) NEW_LINE value = visible_prompt_func ( ' ' ) . lower ( ) . strip ( ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT raise Abort ( ) NEW_LINE DEDENT if value in ( ' y ' , ' yes ' ) : NEW_LINE INDENT rv = True NEW_LINE DEDENT elif value in ( ' n ' , ' no ' ) : NEW_LINE INDENT rv = False NEW_LINE DEDENT elif value == ' ' : NEW_LINE INDENT rv = default NEW_LINE DEDENT else : NEW_LINE INDENT echo ( ' Error : ▁ invalid ▁ input ' , err = err ) NEW_LINE continue NEW_LINE DEDENT break NEW_LINE DEDENT if abort and not rv : NEW_LINE INDENT raise Abort ( ) NEW_LINE DEDENT return rv NEW_LINE DEDENT def get_terminal_size ( ) : NEW_LINE INDENT if sys . version_info >= ( 3 , 3 ) : NEW_LINE INDENT import shutil NEW_LINE shutil_get_terminal_size = getattr ( shutil , ' get _ terminal _ size ' , None ) NEW_LINE if shutil_get_terminal_size : NEW_LINE INDENT sz = shutil_get_terminal_size ( ) NEW_LINE return sz . columns , sz . lines NEW_LINE DEDENT DEDENT if get_winterm_size is not None : NEW_LINE INDENT return get_winterm_size ( ) NEW_LINE DEDENT def ioctl_gwinsz ( fd ) : NEW_LINE INDENT try : NEW_LINE INDENT import fcntl NEW_LINE import termios NEW_LINE cr = struct . unpack ( ' hh ' , fcntl . ioctl ( fd , termios . TIOCGWINSZ , '1234' ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT return NEW_LINE DEDENT return cr NEW_LINE DEDENT cr = ioctl_gwinsz ( 0 ) or ioctl_gwinsz ( 1 ) or ioctl_gwinsz ( 2 ) NEW_LINE if not cr : NEW_LINE INDENT try : NEW_LINE INDENT fd = os . open ( os . ctermid ( ) , os . O_RDONLY ) NEW_LINE try : NEW_LINE INDENT cr = ioctl_gwinsz ( fd ) NEW_LINE DEDENT finally : NEW_LINE INDENT os . close ( fd ) NEW_LINE DEDENT DEDENT except Exception : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT if not cr or not cr [ 0 ] or not cr [ 1 ] : NEW_LINE INDENT cr = ( os . environ . get ( ' LINES ' , 25 ) , os . environ . get ( ' COLUMNS ' , DEFAULT_COLUMNS ) ) NEW_LINE DEDENT return int ( cr [ 1 ] ) , int ( cr [ 0 ] ) NEW_LINE DEDENT def echo_via_pager ( text , color = None ) : NEW_LINE INDENT color = resolve_color_default ( color ) NEW_LINE if not isinstance ( text , string_types ) : NEW_LINE INDENT text = text_type ( text ) NEW_LINE DEDENT from . _termui_impl import pager NEW_LINE return pager ( text + ' \n ' , color ) NEW_LINE DEDENT def progressbar ( iterable = None , length = None , label = None , show_eta = True , show_percent = None , show_pos = False , item_show_func = None , fill_char = ' # ' , empty_char = ' - ' , bar_template = ' % ( label ) s ▁ ▁ [ % ( bar ) s ] ▁ ▁ % ( info ) s ' , info_sep = ' ▁ ▁ ' , width = 36 , file = None , color = None ) : NEW_LINE INDENT from . _termui_impl import ProgressBar NEW_LINE color = resolve_color_default ( color ) NEW_LINE return ProgressBar ( iterable = iterable , length = length , show_eta = show_eta , show_percent = show_percent , show_pos = show_pos , item_show_func = item_show_func , fill_char = fill_char , empty_char = empty_char , bar_template = bar_template , info_sep = info_sep , file = file , label = label , width = width , color = color ) NEW_LINE DEDENT def clear ( ) : NEW_LINE INDENT if not isatty ( sys . stdout ) : NEW_LINE INDENT return NEW_LINE DEDENT if WIN : NEW_LINE INDENT os . system ( ' cls ' ) NEW_LINE DEDENT else : NEW_LINE INDENT sys . stdout . write ( ' \033[2J\033[1;1H ' ) NEW_LINE DEDENT DEDENT def style ( text , fg = None , bg = None , bold = None , dim = None , underline = None , blink = None , reverse = None , reset = True ) : NEW_LINE INDENT bits = [ ] NEW_LINE if fg : NEW_LINE INDENT try : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( _ansi_colors . index ( fg ) + 30 ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise TypeError ( ' Unknown ▁ color ▁ % r ' % fg ) NEW_LINE DEDENT DEDENT if bg : NEW_LINE INDENT try : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( _ansi_colors . index ( bg ) + 40 ) ) NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise TypeError ( ' Unknown ▁ color ▁ % r ' % bg ) NEW_LINE DEDENT DEDENT if bold is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 1 if bold else 22 ) ) NEW_LINE DEDENT if dim is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 2 if dim else 22 ) ) NEW_LINE DEDENT if underline is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 4 if underline else 24 ) ) NEW_LINE DEDENT if blink is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 5 if blink else 25 ) ) NEW_LINE DEDENT if reverse is not None : NEW_LINE INDENT bits . append ( ' \033 [ % dm ' % ( 7 if reverse else 27 ) ) NEW_LINE DEDENT bits . append ( text ) NEW_LINE if reset : NEW_LINE INDENT bits . append ( _ansi_reset_all ) NEW_LINE DEDENT return ' ' . join ( bits ) NEW_LINE DEDENT def unstyle ( text ) : NEW_LINE INDENT return strip_ansi ( text ) NEW_LINE DEDENT def secho ( text , file = None , nl = True , err = False , color = None , ** styles ) : NEW_LINE INDENT return echo ( style ( text , ** styles ) , file = file , nl = nl , err = err , color = color ) NEW_LINE DEDENT def edit ( text = None , editor = None , env = None , require_save = True , extension = ' . txt ' , filename = None ) : NEW_LINE INDENT from . _termui_impl import Editor NEW_LINE editor = Editor ( editor = editor , env = env , require_save = require_save , extension = extension ) NEW_LINE if filename is None : NEW_LINE INDENT return editor . edit ( text ) NEW_LINE DEDENT editor . edit_file ( filename ) NEW_LINE DEDENT def launch ( url , wait = False , locate = False ) : NEW_LINE INDENT from . _termui_impl import open_url NEW_LINE return open_url ( url , wait = wait , locate = locate ) NEW_LINE DEDENT _getchar = None NEW_LINE def getchar ( echo = False ) : NEW_LINE INDENT f = _getchar NEW_LINE if f is None : NEW_LINE INDENT from . _termui_impl import getchar as f NEW_LINE DEDENT return f ( echo ) NEW_LINE DEDENT def pause ( info = ' Press ▁ any ▁ key ▁ to ▁ continue ▁ . . . ' , err = False ) : NEW_LINE INDENT if not isatty ( sys . stdin ) or not isatty ( sys . stdout ) : NEW_LINE INDENT return NEW_LINE DEDENT try : NEW_LINE INDENT if info : NEW_LINE INDENT echo ( info , nl = False , err = err ) NEW_LINE DEDENT try : NEW_LINE INDENT getchar ( ) NEW_LINE DEDENT except ( KeyboardInterrupt , EOFError ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT finally : NEW_LINE INDENT if info : NEW_LINE INDENT echo ( err = err ) NEW_LINE DEDENT DEDENT DEDENT
 from django . contrib . gis . db . models . fields import GeoSelectFormatMixin NEW_LINE from django . contrib . gis . geometry . backend import Geometry NEW_LINE from django . contrib . gis . measure import Area , Distance NEW_LINE class BaseField ( object ) : NEW_LINE INDENT empty_strings_allowed = True NEW_LINE def get_db_converters ( self , connection ) : NEW_LINE INDENT return [ self . from_db_value ] NEW_LINE DEDENT def select_format ( self , compiler , sql , params ) : NEW_LINE INDENT return sql , params NEW_LINE DEDENT DEDENT class AreaField ( BaseField ) : NEW_LINE INDENT def __init__ ( self , area_att ) : NEW_LINE INDENT self . area_att = area_att NEW_LINE DEDENT def from_db_value ( self , value , expression , connection , context ) : NEW_LINE INDENT if value is not None : NEW_LINE INDENT value = Area ( ** { self . area_att : value } ) NEW_LINE DEDENT return value NEW_LINE DEDENT def get_internal_type ( self ) : NEW_LINE INDENT return ' AreaField ' NEW_LINE DEDENT DEDENT class DistanceField ( BaseField ) : NEW_LINE INDENT def __init__ ( self , distance_att ) : NEW_LINE INDENT self . distance_att = distance_att NEW_LINE DEDENT def from_db_value ( self , value , expression , connection , context ) : NEW_LINE INDENT if value is not None : NEW_LINE INDENT value = Distance ( ** { self . distance_att : value } ) NEW_LINE DEDENT return value NEW_LINE DEDENT def get_internal_type ( self ) : NEW_LINE INDENT return ' DistanceField ' NEW_LINE DEDENT DEDENT class GeomField ( GeoSelectFormatMixin , BaseField ) : NEW_LINE INDENT geom_type = None NEW_LINE def from_db_value ( self , value , expression , connection , context ) : NEW_LINE INDENT if value is not None : NEW_LINE INDENT value = Geometry ( value ) NEW_LINE DEDENT return value NEW_LINE DEDENT def get_internal_type ( self ) : NEW_LINE INDENT return ' GeometryField ' NEW_LINE DEDENT DEDENT class GMLField ( BaseField ) : NEW_LINE INDENT def get_internal_type ( self ) : NEW_LINE INDENT return ' GMLField ' NEW_LINE DEDENT def from_db_value ( self , value , expression , connection , context ) : NEW_LINE INDENT return value NEW_LINE DEDENT DEDENT
 import json NEW_LINE from urllib import urlopen NEW_LINE import requests NEW_LINE import getpass NEW_LINE from string import Template NEW_LINE import sys NEW_LINE import os NEW_LINE import subprocess NEW_LINE class RunError ( Exception ) : NEW_LINE INDENT def __init__ ( self , value ) : NEW_LINE INDENT self . value = value NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return repr ( self . value ) NEW_LINE DEDENT DEDENT def run ( command , ** kwargs ) : NEW_LINE INDENT fail_hard = kwargs . pop ( " fail _ hard " , True ) NEW_LINE kwargs . setdefault ( " stdout " , open ( ' / dev / null ' , ' w ' ) ) NEW_LINE kwargs . setdefault ( " stderr " , open ( ' / dev / null ' , ' w ' ) ) NEW_LINE command = Template ( command ) . substitute ( os . environ ) NEW_LINE if " TRACE " in os . environ : NEW_LINE INDENT if ' cwd ' in kwargs : NEW_LINE INDENT print ( " [ cwd = % s ] ▁ % s " % ( kwargs [ ' cwd ' ] , command ) ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( command ) NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT process = subprocess . Popen ( command . split ( ' ▁ ' ) , ** kwargs ) NEW_LINE process . wait ( ) NEW_LINE DEDENT except KeyboardInterrupt : NEW_LINE INDENT process . terminate ( ) NEW_LINE raise NEW_LINE DEDENT if process . returncode != 0 and fail_hard : NEW_LINE INDENT raise RunError ( " Failed : ▁ " + command ) NEW_LINE DEDENT return process . returncode NEW_LINE DEDENT def checkout_pull ( clone_url , commit , out ) : NEW_LINE INDENT build_dir = os . environ [ " BUILD _ DIR " ] NEW_LINE run ( " umount ▁ $ { CHROOT _ COPY } / proc " , fail_hard = False ) NEW_LINE run ( " rsync ▁ - - delete ▁ - apv ▁ $ { CHROOT _ MASTER } / ▁ $ { CHROOT _ COPY } " ) NEW_LINE run ( " rm ▁ - rf ▁ $ { CHROOT _ COPY } $ { SCRIPTS _ DIR } " ) NEW_LINE run ( " cp ▁ - a ▁ $ { SCRIPTS _ DIR } ▁ $ { CHROOT _ COPY } $ { SCRIPTS _ DIR } " ) NEW_LINE run ( " rm ▁ - rf ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " mkdir ▁ - p ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " git ▁ clone ▁ $ { CLONE _ URL } ▁ $ { BUILD _ DIR } " ) NEW_LINE run ( " git ▁ remote ▁ add ▁ pull ▁ " + clone_url , cwd = build_dir , stdout = out , stderr = out ) NEW_LINE run ( " git ▁ fetch ▁ pull " , cwd = build_dir , stdout = out , stderr = out ) NEW_LINE if run ( " git ▁ merge ▁ " + commit , fail_hard = False , cwd = build_dir , stdout = out , stderr = out ) != 0 : NEW_LINE INDENT return False NEW_LINE DEDENT run ( " chown ▁ - R ▁ $ { BUILD _ USER } : $ { BUILD _ GROUP } ▁ $ { BUILD _ DIR } " , stdout = out , stderr = out ) NEW_LINE run ( " mount ▁ - - bind ▁ / proc ▁ $ { CHROOT _ COPY } / proc " ) NEW_LINE return True NEW_LINE DEDENT def commentOn ( commentUrl , success , inMerge , needTests , linkUrl ) : NEW_LINE INDENT common_message = """ STRNEWLINE This ▁ test ▁ script ▁ verifies ▁ pulls ▁ every ▁ time ▁ they ▁ are ▁ updated . ▁ It , ▁ however , ▁ dies ▁ sometimes ▁ and ▁ fails ▁ to ▁ test ▁ properly . ▁ ▁ If ▁ you ▁ are ▁ waiting ▁ on ▁ a ▁ test , ▁ please ▁ check ▁ timestamps ▁ to ▁ verify ▁ that ▁ the ▁ test . log ▁ is ▁ moving ▁ at ▁ http : / / jenkins . bluematt . me / pull - tester / current / STRNEWLINE Contact ▁ BlueMatt ▁ on ▁ freenode ▁ if ▁ something ▁ looks ▁ broken . """ NEW_LINE recentcomments = requests . get ( commentUrl + " ? sort = created & direction = desc " , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) . json NEW_LINE for comment in recentcomments : NEW_LINE INDENT if comment [ " user " ] [ " login " ] == os . environ [ " GITHUB _ USER " ] and common_message in comment [ " body " ] : NEW_LINE INDENT requests . delete ( comment [ " url " ] , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) NEW_LINE DEDENT DEDENT if success == True : NEW_LINE INDENT if needTests : NEW_LINE INDENT message = " Automatic ▁ sanity - testing : ▁ PLEASE ▁ ADD ▁ TEST - CASES , ▁ though ▁ technically ▁ passed . ▁ See ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " NEW_LINE DEDENT else : NEW_LINE INDENT message = " Automatic ▁ sanity - testing : ▁ PASSED , ▁ see ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " NEW_LINE DEDENT post_data = { " body " : message + common_message } NEW_LINE DEDENT elif inMerge : NEW_LINE INDENT post_data = { " body " : " Automatic ▁ sanity - testing : ▁ FAILED ▁ MERGE , ▁ see ▁ " + linkUrl + " ▁ for ▁ test ▁ log . " + """ STRNEWLINE STRNEWLINE This ▁ pull ▁ does ▁ not ▁ merge ▁ cleanly ▁ onto ▁ current ▁ master """ + common_message } NEW_LINE DEDENT else : NEW_LINE INDENT post_data = { " body " : " Automatic ▁ sanity - testing : ▁ FAILED ▁ BUILD / TEST , ▁ see ▁ " + linkUrl + " ▁ for ▁ binaries ▁ and ▁ test ▁ log . " + """ STRNEWLINE STRNEWLINE This ▁ could ▁ happen ▁ for ▁ one ▁ of ▁ several ▁ reasons : STRNEWLINE 1 . ▁ It ▁ chanages ▁ changes ▁ build ▁ scripts ▁ in ▁ a ▁ way ▁ that ▁ made ▁ them ▁ incompatible ▁ with ▁ the ▁ automated ▁ testing ▁ scripts ▁ ( please ▁ tweak ▁ those ▁ patches ▁ in ▁ qa / pull - tester ) STRNEWLINE 2 . ▁ It ▁ adds / modifies ▁ tests ▁ which ▁ test ▁ network ▁ rules ▁ ( thanks ▁ for ▁ doing ▁ that ) , ▁ which ▁ conflicts ▁ with ▁ a ▁ patch ▁ applied ▁ at ▁ test ▁ time STRNEWLINE 3 . ▁ It ▁ does ▁ not ▁ build ▁ on ▁ either ▁ Linux ▁ i386 ▁ or ▁ Win32 ▁ ( via ▁ MinGW ▁ cross ▁ compile ) STRNEWLINE 4 . ▁ The ▁ test ▁ suite ▁ fails ▁ on ▁ either ▁ Linux ▁ i386 ▁ or ▁ Win32 STRNEWLINE 5 . ▁ The ▁ block ▁ test - cases ▁ failed ▁ ( lookup ▁ the ▁ first ▁ bNN ▁ identifier ▁ which ▁ failed ▁ in ▁ https : / / github . com / TheBlueMatt / test - scripts / blob / master / FullBlockTestGenerator . java ) STRNEWLINE STRNEWLINE If ▁ you ▁ believe ▁ this ▁ to ▁ be ▁ in ▁ error , ▁ please ▁ ping ▁ BlueMatt ▁ on ▁ freenode ▁ or ▁ TheBlueMatt ▁ here . STRNEWLINE """ + common_message } NEW_LINE DEDENT resp = requests . post ( commentUrl , json . dumps ( post_data ) , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) NEW_LINE DEDENT def testpull ( number , comment_url , clone_url , commit ) : NEW_LINE INDENT print ( " Testing ▁ pull ▁ % d : ▁ % s ▁ : ▁ % s " % ( number , clone_url , commit ) ) NEW_LINE dir = os . environ [ " RESULTS _ DIR " ] + " / " + commit + " / " NEW_LINE print ( " ▁ ouput ▁ to ▁ % s " % dir ) NEW_LINE if os . path . exists ( dir ) : NEW_LINE INDENT os . system ( " rm ▁ - r ▁ " + dir ) NEW_LINE DEDENT os . makedirs ( dir ) NEW_LINE currentdir = os . environ [ " RESULTS _ DIR " ] + " / current " NEW_LINE os . system ( " rm ▁ - r ▁ " + currentdir ) NEW_LINE os . system ( " ln ▁ - s ▁ " + dir + " ▁ " + currentdir ) NEW_LINE out = open ( dir + " test . log " , ' w + ' ) NEW_LINE resultsurl = os . environ [ " RESULTS _ URL " ] + commit NEW_LINE checkedout = checkout_pull ( clone_url , commit , out ) NEW_LINE if checkedout != True : NEW_LINE INDENT print ( " Failed ▁ to ▁ test ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , False , True , False , resultsurl ) NEW_LINE open ( os . environ [ " TESTED _ DB " ] , " a " ) . write ( commit + " \n " ) NEW_LINE return NEW_LINE DEDENT run ( " rm ▁ - rf ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) NEW_LINE ; run ( " mkdir ▁ - p ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) NEW_LINE ; run ( " chown ▁ - R ▁ $ { BUILD _ USER } : $ { BUILD _ GROUP } ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } " , fail_hard = False ) NEW_LINE script = os . environ [ " BUILD _ PATH " ] + " / qa / pull - tester / pull - tester . sh " NEW_LINE script += " ▁ $ { BUILD _ PATH } ▁ $ { MINGW _ DEPS _ DIR } ▁ $ { SCRIPTS _ DIR } / BitcoindComparisonTool _ jar / BitcoindComparisonTool . jar ▁ 0 ▁ 6 ▁ $ { OUT _ DIR } " NEW_LINE returncode = run ( " chroot ▁ $ { CHROOT _ COPY } ▁ sudo ▁ - u ▁ $ { BUILD _ USER } ▁ - H ▁ timeout ▁ $ { TEST _ TIMEOUT } ▁ " + script , fail_hard = False , stdout = out , stderr = out ) NEW_LINE run ( " mv ▁ $ { CHROOT _ COPY } / $ { OUT _ DIR } ▁ " + dir ) NEW_LINE run ( " mv ▁ $ { BUILD _ DIR } ▁ " + dir ) NEW_LINE if returncode == 42 : NEW_LINE INDENT print ( " Successfully ▁ tested ▁ pull ▁ ( needs ▁ tests ) ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , True , False , True , resultsurl ) NEW_LINE DEDENT elif returncode != 0 : NEW_LINE INDENT print ( " Failed ▁ to ▁ test ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , False , False , False , resultsurl ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " Successfully ▁ tested ▁ pull ▁ - ▁ sending ▁ comment ▁ to : ▁ " + comment_url ) NEW_LINE commentOn ( comment_url , True , False , False , resultsurl ) NEW_LINE DEDENT open ( os . environ [ " TESTED _ DB " ] , " a " ) . write ( commit + " \n " ) NEW_LINE DEDENT def environ_default ( setting , value ) : NEW_LINE INDENT if not setting in os . environ : NEW_LINE INDENT os . environ [ setting ] = value NEW_LINE DEDENT DEDENT if getpass . getuser ( ) != " root " : NEW_LINE INDENT print ( " Run ▁ me ▁ as ▁ root ! " ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT if " GITHUB _ USER " not in os . environ or " GITHUB _ AUTH _ TOKEN " not in os . environ : NEW_LINE INDENT print ( " GITHUB _ USER ▁ and / or ▁ GITHUB _ AUTH _ TOKEN ▁ environment ▁ variables ▁ not ▁ set " ) NEW_LINE sys . exit ( 1 ) NEW_LINE DEDENT environ_default ( " CLONE _ URL " , " https : / / github . com / bitcoin / bitcoin . git " ) NEW_LINE environ_default ( " MINGW _ DEPS _ DIR " , " / mnt / w32deps " ) NEW_LINE environ_default ( " SCRIPTS _ DIR " , " / mnt / test - scripts " ) NEW_LINE environ_default ( " CHROOT _ COPY " , " / mnt / chroot - tmp " ) NEW_LINE environ_default ( " CHROOT _ MASTER " , " / mnt / chroot " ) NEW_LINE environ_default ( " OUT _ DIR " , " / mnt / out " ) NEW_LINE environ_default ( " BUILD _ PATH " , " / mnt / bitcoin " ) NEW_LINE os . environ [ " BUILD _ DIR " ] = os . environ [ " CHROOT _ COPY " ] + os . environ [ " BUILD _ PATH " ] NEW_LINE environ_default ( " RESULTS _ DIR " , " / mnt / www / pull - tester " ) NEW_LINE environ_default ( " RESULTS _ URL " , " http : / / jenkins . bluematt . me / pull - tester / " ) NEW_LINE environ_default ( " GITHUB _ REPO " , " bitcoin / bitcoin " ) NEW_LINE environ_default ( " TESTED _ DB " , " / mnt / commits - tested . txt " ) NEW_LINE environ_default ( " BUILD _ USER " , " matt " ) NEW_LINE environ_default ( " BUILD _ GROUP " , " matt " ) NEW_LINE environ_default ( " TEST _ TIMEOUT " , str ( 60 * 60 * 2 ) ) NEW_LINE print ( " Optional ▁ usage : ▁ pull - tester . py ▁ 2112" ) NEW_LINE f = open ( os . environ [ " TESTED _ DB " ] ) NEW_LINE tested = set ( line . rstrip ( ) for line in f . readlines ( ) ) NEW_LINE f . close ( ) NEW_LINE if len ( sys . argv ) > 1 : NEW_LINE INDENT pull = requests . get ( " https : / / api . github . com / repos / " + os . environ [ " GITHUB _ REPO " ] + " / pulls / " + sys . argv [ 1 ] , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) . json NEW_LINE testpull ( pull [ " number " ] , pull [ " _ links " ] [ " comments " ] [ " href " ] , pull [ " head " ] [ " repo " ] [ " clone _ url " ] , pull [ " head " ] [ " sha " ] ) NEW_LINE DEDENT else : NEW_LINE INDENT for page in range ( 1 , 100 ) : NEW_LINE INDENT result = requests . get ( " https : / / api . github . com / repos / " + os . environ [ " GITHUB _ REPO " ] + " / pulls ? state = open & page = % d " % ( page , ) , auth = ( os . environ [ ' GITHUB _ USER ' ] , os . environ [ " GITHUB _ AUTH _ TOKEN " ] ) ) . json NEW_LINE if len ( result ) == 0 : NEW_LINE INDENT break NEW_LINE ; NEW_LINE DEDENT for pull in result : NEW_LINE INDENT if pull [ " head " ] [ " sha " ] in tested : NEW_LINE INDENT print ( " Pull ▁ % d ▁ already ▁ tested " % ( pull [ " number " ] , ) ) NEW_LINE continue NEW_LINE DEDENT testpull ( pull [ " number " ] , pull [ " _ links " ] [ " comments " ] [ " href " ] , pull [ " head " ] [ " repo " ] [ " clone _ url " ] , pull [ " head " ] [ " sha " ] ) NEW_LINE DEDENT DEDENT DEDENT
 import factory NEW_LINE from admin . common_auth . models import MyUser NEW_LINE class UserFactory ( factory . Factory ) : NEW_LINE INDENT class Meta : NEW_LINE INDENT model = MyUser NEW_LINE DEDENT id = 123 NEW_LINE email = ' cello @ email . org ' NEW_LINE first_name = ' Yo - yo ' NEW_LINE last_name = ' Ma ' NEW_LINE osf_id = ' abc12' NEW_LINE @ classmethod NEW_LINE def is_in_group ( cls , value ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT
 __docformat__ = ' restructuredtext ' NEW_LINE __version__ = ' $ Id $ ' NEW_LINE import ctypes NEW_LINE import pyglet NEW_LINE __all__ = [ ' link _ GL ' , ' link _ GLU ' , ' link _ AGL ' , ' link _ GLX ' , ' link _ WGL ' ] NEW_LINE _debug_gl = pyglet . options [ ' debug _ gl ' ] NEW_LINE _debug_gl_trace = pyglet . options [ ' debug _ gl _ trace ' ] NEW_LINE _debug_gl_trace_args = pyglet . options [ ' debug _ gl _ trace _ args ' ] NEW_LINE class MissingFunctionException ( Exception ) : NEW_LINE INDENT def __init__ ( self , name , requires = None , suggestions = None ) : NEW_LINE INDENT msg = ' % s ▁ is ▁ not ▁ exported ▁ by ▁ the ▁ available ▁ OpenGL ▁ driver . ' % name NEW_LINE if requires : NEW_LINE INDENT msg += ' ▁ ▁ % s ▁ is ▁ required ▁ for ▁ this ▁ functionality . ' % requires NEW_LINE DEDENT if suggestions : NEW_LINE INDENT msg += ' ▁ ▁ Consider ▁ alternative ( s ) ▁ % s . ' % ' , ▁ ' . join ( suggestions ) NEW_LINE DEDENT Exception . __init__ ( self , msg ) NEW_LINE DEDENT DEDENT def missing_function ( name , requires = None , suggestions = None ) : NEW_LINE INDENT def MissingFunction ( * args , ** kwargs ) : NEW_LINE INDENT raise MissingFunctionException ( name , requires , suggestions ) NEW_LINE DEDENT return MissingFunction NEW_LINE DEDENT _int_types = ( ctypes . c_int16 , ctypes . c_int32 ) NEW_LINE if hasattr ( ctypes , ' c _ int64' ) : NEW_LINE INDENT _int_types += ( ctypes . c_int64 , ) NEW_LINE DEDENT for t in _int_types : NEW_LINE INDENT if ctypes . sizeof ( t ) == ctypes . sizeof ( ctypes . c_size_t ) : NEW_LINE INDENT c_ptrdiff_t = t NEW_LINE DEDENT DEDENT class c_void ( ctypes . Structure ) : NEW_LINE INDENT _fields_ = [ ( ' dummy ' , ctypes . c_int ) ] NEW_LINE DEDENT class GLException ( Exception ) : NEW_LINE INDENT pass NEW_LINE DEDENT def errcheck ( result , func , arguments ) : NEW_LINE INDENT if _debug_gl_trace : NEW_LINE INDENT try : NEW_LINE INDENT name = func . __name__ NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT name = repr ( func ) NEW_LINE DEDENT if _debug_gl_trace_args : NEW_LINE INDENT trace_args = ' , ▁ ' . join ( [ repr ( arg ) [ : 20 ] for arg in arguments ] ) NEW_LINE print ' % s ( % s ) ' % ( name , trace_args ) NEW_LINE DEDENT else : NEW_LINE INDENT print name NEW_LINE DEDENT DEDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT if not context . _gl_begin : NEW_LINE INDENT error = gl . glGetError ( ) NEW_LINE if error : NEW_LINE INDENT msg = ctypes . cast ( gl . gluErrorString ( error ) , ctypes . c_char_p ) . value NEW_LINE raise GLException ( msg ) NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT def errcheck_glbegin ( result , func , arguments ) : NEW_LINE INDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT context . _gl_begin = True NEW_LINE return result NEW_LINE DEDENT def errcheck_glend ( result , func , arguments ) : NEW_LINE INDENT from pyglet import gl NEW_LINE context = gl . current_context NEW_LINE if not context : NEW_LINE INDENT raise GLException ( ' No ▁ GL ▁ context ; ▁ create ▁ a ▁ Window ▁ first ' ) NEW_LINE DEDENT context . _gl_begin = False NEW_LINE return errcheck ( result , func , arguments ) NEW_LINE DEDENT def decorate_function ( func , name ) : NEW_LINE INDENT if _debug_gl : NEW_LINE INDENT if name == ' glBegin ' : NEW_LINE INDENT func . errcheck = errcheck_glbegin NEW_LINE DEDENT elif name == ' glEnd ' : NEW_LINE INDENT func . errcheck = errcheck_glend NEW_LINE DEDENT elif name not in ( ' glGetError ' , ' gluErrorString ' ) and \NEW_LINE name [ : 3 ] not in ( ' glX ' , ' agl ' , ' wgl ' ) : NEW_LINE INDENT func . errcheck = errcheck NEW_LINE DEDENT DEDENT DEDENT link_AGL = None NEW_LINE link_GLX = None NEW_LINE link_WGL = None NEW_LINE if pyglet . compat_platform in ( ' win32' , ' cygwin ' ) : NEW_LINE INDENT from pyglet . gl . lib_wgl import link_GL , link_GLU , link_WGL NEW_LINE DEDENT elif pyglet . compat_platform == ' darwin ' : NEW_LINE INDENT from pyglet . gl . lib_agl import link_GL , link_GLU , link_AGL NEW_LINE DEDENT else : NEW_LINE INDENT from pyglet . gl . lib_glx import link_GL , link_GLU , link_GLX NEW_LINE DEDENT
 from __future__ import absolute_import , division , print_function NEW_LINE __metaclass__ = type NEW_LINE ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = ''' STRNEWLINE - - - STRNEWLINE module : ▁ azure _ rm _ securitygroup STRNEWLINE version _ added : ▁ " 2.1 " STRNEWLINE short _ description : ▁ Manage ▁ Azure ▁ network ▁ security ▁ groups . STRNEWLINE description : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ Create , ▁ update ▁ or ▁ delete ▁ a ▁ network ▁ security ▁ group . ▁ A ▁ security ▁ group ▁ contains ▁ Access ▁ Control ▁ List ▁ ( ACL ) ▁ rules STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ that ▁ allow ▁ or ▁ deny ▁ network ▁ traffic ▁ to ▁ subnets ▁ or ▁ individual ▁ network ▁ interfaces . ▁ A ▁ security ▁ group ▁ is ▁ created STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ with ▁ a ▁ set ▁ of ▁ default ▁ security ▁ rules ▁ and ▁ an ▁ empty ▁ set ▁ of ▁ security ▁ rules . ▁ Shape ▁ traffic ▁ flow ▁ by ▁ adding STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ rules ▁ to ▁ the ▁ empty ▁ set ▁ of ▁ security ▁ rules . STRNEWLINE STRNEWLINE options : STRNEWLINE ▁ ▁ ▁ ▁ default _ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ set ▁ of ▁ default ▁ rules ▁ automatically ▁ added ▁ to ▁ a ▁ security ▁ group ▁ at ▁ creation . ▁ In ▁ general ▁ default STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ rules ▁ will ▁ not ▁ be ▁ modified . ▁ Modify ▁ rules ▁ to ▁ shape ▁ the ▁ flow ▁ of ▁ traffic ▁ to ▁ or ▁ from ▁ a ▁ subnet ▁ or ▁ NIC . ▁ See STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ rules ▁ below ▁ for ▁ the ▁ makeup ▁ of ▁ a ▁ rule ▁ dict . STRNEWLINE ▁ ▁ ▁ ▁ location : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Valid ▁ azure ▁ location . ▁ Defaults ▁ to ▁ location ▁ of ▁ the ▁ resource ▁ group . STRNEWLINE ▁ ▁ ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ the ▁ security ▁ group ▁ to ▁ operate ▁ on . STRNEWLINE ▁ ▁ ▁ ▁ purge _ default _ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Remove ▁ any ▁ existing ▁ rules ▁ not ▁ matching ▁ those ▁ defined ▁ in ▁ the ▁ default _ rules ▁ parameter . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' no ' STRNEWLINE ▁ ▁ ▁ ▁ purge _ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Remove ▁ any ▁ existing ▁ rules ▁ not ▁ matching ▁ those ▁ defined ▁ in ▁ the ▁ rules ▁ parameters . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' no ' STRNEWLINE ▁ ▁ ▁ ▁ resource _ group : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ the ▁ resource ▁ group ▁ the ▁ security ▁ group ▁ belongs ▁ to . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Set ▁ of ▁ rules ▁ shaping ▁ traffic ▁ flow ▁ to ▁ or ▁ from ▁ a ▁ subnet ▁ or ▁ NIC . ▁ Each ▁ rule ▁ is ▁ a ▁ dictionary . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ suboptions : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Unique ▁ name ▁ for ▁ the ▁ rule . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Short ▁ description ▁ of ▁ the ▁ rule ' s ▁ purpose . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : ▁ Accepted ▁ traffic ▁ protocol . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Udp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ port _ range : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Port ▁ or ▁ range ▁ of ▁ ports ▁ from ▁ which ▁ traffic ▁ originates . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ It ▁ can ▁ accept ▁ string ▁ type ▁ or ▁ a ▁ list ▁ of ▁ string ▁ type . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Port ▁ or ▁ range ▁ of ▁ ports ▁ to ▁ which ▁ traffic ▁ is ▁ headed . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ It ▁ can ▁ accept ▁ string ▁ type ▁ or ▁ a ▁ list ▁ of ▁ string ▁ type . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ address _ prefix : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ CIDR ▁ or ▁ source ▁ IP ▁ range . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Asterisk ▁ C ( * ) ▁ can ▁ also ▁ be ▁ used ▁ to ▁ match ▁ all ▁ source ▁ IPs . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Default ▁ tags ▁ such ▁ as ▁ C ( VirtualNetwork ) , ▁ C ( AzureLoadBalancer ) ▁ and ▁ C ( Internet ) ▁ can ▁ also ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ this ▁ is ▁ an ▁ ingress ▁ rule , ▁ specifies ▁ where ▁ network ▁ traffic ▁ originates ▁ from . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ It ▁ can ▁ accept ▁ string ▁ type ▁ or ▁ a ▁ list ▁ of ▁ string ▁ type . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ address _ prefix : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ destination ▁ address ▁ prefix . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ CIDR ▁ or ▁ destination ▁ IP ▁ range . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Asterisk ▁ C ( * ) ▁ can ▁ also ▁ be ▁ used ▁ to ▁ match ▁ all ▁ source ▁ IPs . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Default ▁ tags ▁ such ▁ as ▁ C ( VirtualNetwork ) , ▁ C ( AzureLoadBalancer ) ▁ and ▁ C ( Internet ) ▁ can ▁ also ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ It ▁ can ▁ accept ▁ string ▁ type ▁ or ▁ a ▁ list ▁ of ▁ string ▁ type . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Whether ▁ or ▁ not ▁ to ▁ allow ▁ the ▁ traffic ▁ flow . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Deny STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Order ▁ in ▁ which ▁ to ▁ apply ▁ the ▁ rule . ▁ Must ▁ a ▁ unique ▁ integer ▁ between ▁ 100 ▁ and ▁ 4096 ▁ inclusive . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Indicates ▁ the ▁ direction ▁ of ▁ the ▁ traffic ▁ flow . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Outbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Assert ▁ the ▁ state ▁ of ▁ the ▁ security ▁ group . ▁ Set ▁ to ▁ C ( present ) ▁ to ▁ create ▁ or ▁ update ▁ a ▁ security ▁ group . ▁ Set ▁ to STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ C ( absent ) ▁ to ▁ remove ▁ a ▁ security ▁ group . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ absent STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ present STRNEWLINE STRNEWLINE extends _ documentation _ fragment : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ azure STRNEWLINE ▁ ▁ ▁ ▁ - ▁ azure _ tags STRNEWLINE STRNEWLINE author : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Chris ▁ Houseknecht ▁ ( @ chouseknecht ) " STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Matt ▁ Davis ▁ ( @ nitzmahone ) " STRNEWLINE STRNEWLINE ''' NEW_LINE EXAMPLES = ''' STRNEWLINE STRNEWLINE # ▁ Create ▁ a ▁ security ▁ group STRNEWLINE - ▁ azure _ rm _ securitygroup : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ resource _ group : ▁ myResourceGroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ mysecgroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ purge _ rules : ▁ yes STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ DenySSH STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : ▁ 22 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Deny STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 100 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ ' AllowSSH ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ address _ prefix : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' 174.109.158.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' 174.109.159.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : ▁ 22 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 101 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ ' AllowMultiplePorts ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ address _ prefix : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' 174.109.158.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' 174.109.159.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ 80 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ 443 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 102 STRNEWLINE STRNEWLINE # ▁ Update ▁ rules ▁ on ▁ existing ▁ security ▁ group STRNEWLINE - ▁ azure _ rm _ securitygroup : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ resource _ group : ▁ myResourceGroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ mysecgroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ rules : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ DenySSH STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : ▁ 22-23 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Deny STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 100 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name : ▁ AllowSSHFromHome STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ protocol : ▁ Tcp STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ source _ address _ prefix : ▁ ' 174.109.158.0/24 ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ destination _ port _ range : ▁ 22-23 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ access : ▁ Allow STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ priority : ▁ 102 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ direction : ▁ Inbound STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ tags : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ testing : ▁ testing STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ delete : ▁ on - exit STRNEWLINE STRNEWLINE # ▁ Delete ▁ security ▁ group STRNEWLINE - ▁ azure _ rm _ securitygroup : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ resource _ group : ▁ myResourceGroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ mysecgroup STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ absent STRNEWLINE ''' NEW_LINE RETURN = ''' STRNEWLINE state : STRNEWLINE ▁ ▁ ▁ ▁ description : ▁ Current ▁ state ▁ of ▁ the ▁ security ▁ group . STRNEWLINE ▁ ▁ ▁ ▁ returned : ▁ always STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ dict STRNEWLINE ▁ ▁ ▁ ▁ sample : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " default _ rules " : ▁ [ STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Allow ▁ inbound ▁ traffic ▁ from ▁ all ▁ VMs ▁ in ▁ VNET " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " VirtualNetwork " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / AllowVnetInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowVnetInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65000 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " VirtualNetwork " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Allow ▁ inbound ▁ traffic ▁ from ▁ azure ▁ load ▁ balancer " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / AllowAzureLoadBalancerInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowAzureLoadBalancerInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65001 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " AzureLoadBalancer " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Deny " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Deny ▁ all ▁ inbound ▁ traffic " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / DenyAllInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " DenyAllInBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65500 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Allow ▁ outbound ▁ traffic ▁ from ▁ all ▁ VMs ▁ to ▁ all ▁ VMs ▁ in ▁ VNET " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " VirtualNetwork " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Outbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / AllowVnetOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowVnetOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65000 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " VirtualNetwork " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Allow ▁ outbound ▁ traffic ▁ from ▁ all ▁ VMs ▁ to ▁ Internet " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " Internet " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Outbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / AllowInternetOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowInternetOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65001 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Deny " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ " Deny ▁ all ▁ outbound ▁ traffic " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Outbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / defaultSecurityRules / DenyAllOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " DenyAllOutBound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 65500 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " location " : ▁ " westus " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " mysecgroup " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " network _ interfaces " : ▁ [ ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " rules " : ▁ [ STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Deny " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ null , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " 22 " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / securityRules / DenySSH " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " DenySSH " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 100 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " Tcp " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " access " : ▁ " Allow " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " description " : ▁ null , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ address _ prefix " : ▁ " * " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " destination _ port _ range " : ▁ " 22 " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " direction " : ▁ " Inbound " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " etag " : ▁ ' W / " edf48d56 - b315-40ca - a85d - dbcb47f2da7d " ' , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " id " : ▁ " / subscriptions / xxxxxxxx - xxxx - xxxx - xxxx - xxxxxxxxxxxx / resourceGroup / myResourceGroup / providers / Microsoft . Network / networkSecurityGroups / mysecgroup / securityRules / AllowSSH " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " name " : ▁ " AllowSSH " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " priority " : ▁ 101 , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " protocol " : ▁ " Tcp " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " provisioning _ state " : ▁ " Succeeded " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ address _ prefix " : ▁ " 174.109.158.0/24 " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " source _ port _ range " : ▁ " * " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " subnets " : ▁ [ ] , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " tags " : ▁ { STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " delete " : ▁ " on - exit " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " foo " : ▁ " bar " , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " testing " : ▁ " testing " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ } , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ " type " : ▁ " Microsoft . Network / networkSecurityGroups " STRNEWLINE ▁ ▁ ▁ ▁ } STRNEWLINE ''' NEW_LINE try : NEW_LINE INDENT from msrestazure . azure_exceptions import CloudError NEW_LINE from azure . mgmt . network import NetworkManagementClient NEW_LINE DEDENT except ImportError : NEW_LINE INDENT pass NEW_LINE DEDENT from ansible . module_utils . azure_rm_common import AzureRMModuleBase NEW_LINE from ansible . module_utils . six import integer_types NEW_LINE from ansible . module_utils . _text import to_native NEW_LINE def validate_rule ( self , rule , rule_type = None ) : NEW_LINE INDENT priority = rule . get ( ' priority ' , 0 ) NEW_LINE if rule_type != ' default ' and ( priority < 100 or priority > 4096 ) : NEW_LINE INDENT raise Exception ( " Rule ▁ priority ▁ must ▁ be ▁ between ▁ 100 ▁ and ▁ 4096" ) NEW_LINE DEDENT def check_plural ( src , dest ) : NEW_LINE INDENT if isinstance ( rule . get ( src ) , list ) : NEW_LINE INDENT rule [ dest ] = rule [ src ] NEW_LINE rule [ src ] = None NEW_LINE DEDENT DEDENT check_plural ( ' destination _ address _ prefix ' , ' destination _ address _ prefixes ' ) NEW_LINE check_plural ( ' source _ address _ prefix ' , ' source _ address _ prefixes ' ) NEW_LINE check_plural ( ' source _ port _ range ' , ' source _ port _ ranges ' ) NEW_LINE check_plural ( ' destination _ port _ range ' , ' destination _ port _ ranges ' ) NEW_LINE DEDENT def compare_rules_change ( old_list , new_list , purge_list ) : NEW_LINE INDENT old_list = old_list or [ ] NEW_LINE new_list = new_list or [ ] NEW_LINE changed = False NEW_LINE for old_rule in old_list : NEW_LINE INDENT matched = next ( ( x for x in new_list if x [ ' name ' ] == old_rule [ ' name ' ] ) , [ ] ) NEW_LINE if matched : NEW_LINE INDENT changed = changed or compare_rules ( old_rule , matched ) NEW_LINE DEDENT elif not purge_list : NEW_LINE INDENT new_list . append ( old_rule ) NEW_LINE DEDENT else : NEW_LINE INDENT changed = True NEW_LINE DEDENT DEDENT if not changed : NEW_LINE INDENT new_names = [ to_native ( x [ ' name ' ] ) for x in new_list ] NEW_LINE old_names = [ to_native ( x [ ' name ' ] ) for x in old_list ] NEW_LINE changed = ( set ( new_names ) != set ( old_names ) ) NEW_LINE DEDENT return changed , new_list NEW_LINE DEDENT def compare_rules ( old_rule , rule ) : NEW_LINE INDENT changed = False NEW_LINE if old_rule [ ' name ' ] != rule [ ' name ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule . get ( ' description ' , None ) != old_rule [ ' description ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule [ ' protocol ' ] != old_rule [ ' protocol ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if str ( rule [ ' source _ port _ range ' ] ) != str ( old_rule [ ' source _ port _ range ' ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if str ( rule [ ' destination _ port _ range ' ] ) != str ( old_rule [ ' destination _ port _ range ' ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule [ ' access ' ] != old_rule [ ' access ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule [ ' priority ' ] != old_rule [ ' priority ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if rule [ ' direction ' ] != old_rule [ ' direction ' ] : NEW_LINE INDENT changed = True NEW_LINE DEDENT if str ( rule [ ' source _ address _ prefix ' ] ) != str ( old_rule [ ' source _ address _ prefix ' ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if str ( rule [ ' destination _ address _ prefix ' ] ) != str ( old_rule [ ' destination _ address _ prefix ' ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if set ( rule . get ( ' source _ address _ prefixes ' ) or [ ] ) != set ( old_rule . get ( ' source _ address _ prefixes ' ) or [ ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if set ( rule . get ( ' destination _ address _ prefixes ' ) or [ ] ) != set ( old_rule . get ( ' destination _ address _ prefixes ' ) or [ ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if set ( rule . get ( ' source _ port _ ranges ' ) or [ ] ) != set ( old_rule . get ( ' source _ port _ ranges ' ) or [ ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT if set ( rule . get ( ' destination _ port _ ranges ' ) or [ ] ) != set ( old_rule . get ( ' destination _ port _ ranges ' ) or [ ] ) : NEW_LINE INDENT changed = True NEW_LINE DEDENT return changed NEW_LINE DEDENT def create_rule_instance ( self , rule ) : NEW_LINE INDENT return self . nsg_models . SecurityRule ( description = rule . get ( ' description ' , None ) , protocol = rule . get ( ' protocol ' , None ) , source_port_range = rule . get ( ' source _ port _ range ' , None ) , destination_port_range = rule . get ( ' destination _ port _ range ' , None ) , source_address_prefix = rule . get ( ' source _ address _ prefix ' , None ) , source_address_prefixes = rule . get ( ' source _ address _ prefixes ' , None ) , destination_address_prefix = rule . get ( ' destination _ address _ prefix ' , None ) , destination_address_prefixes = rule . get ( ' destination _ address _ prefixes ' , None ) , source_port_ranges = rule . get ( ' source _ port _ ranges ' , None ) , destination_port_ranges = rule . get ( ' destination _ port _ ranges ' , None ) , access = rule . get ( ' access ' , None ) , priority = rule . get ( ' priority ' , None ) , direction = rule . get ( ' direction ' , None ) , provisioning_state = rule . get ( ' provisioning _ state ' , None ) , name = rule . get ( ' name ' , None ) , etag = rule . get ( ' etag ' , None ) ) NEW_LINE DEDENT def create_rule_dict_from_obj ( rule ) : NEW_LINE INDENT return dict ( id = rule . id , name = rule . name , description = rule . description , protocol = rule . protocol , source_port_range = rule . source_port_range , destination_port_range = rule . destination_port_range , source_address_prefix = rule . source_address_prefix , destination_address_prefix = rule . destination_address_prefix , source_port_ranges = rule . source_port_ranges , destination_port_ranges = rule . destination_port_ranges , source_address_prefixes = rule . source_address_prefixes , destination_address_prefixes = rule . destination_address_prefixes , access = rule . access , priority = rule . priority , direction = rule . direction , provisioning_state = rule . provisioning_state , etag = rule . etag ) NEW_LINE DEDENT def create_network_security_group_dict ( nsg ) : NEW_LINE INDENT results = dict ( id = nsg . id , name = nsg . name , type = nsg . type , location = nsg . location , tags = nsg . tags , ) NEW_LINE results [ ' rules ' ] = [ ] NEW_LINE if nsg . security_rules : NEW_LINE INDENT for rule in nsg . security_rules : NEW_LINE INDENT results [ ' rules ' ] . append ( create_rule_dict_from_obj ( rule ) ) NEW_LINE DEDENT DEDENT results [ ' default _ rules ' ] = [ ] NEW_LINE if nsg . default_security_rules : NEW_LINE INDENT for rule in nsg . default_security_rules : NEW_LINE INDENT results [ ' default _ rules ' ] . append ( create_rule_dict_from_obj ( rule ) ) NEW_LINE DEDENT DEDENT results [ ' network _ interfaces ' ] = [ ] NEW_LINE if nsg . network_interfaces : NEW_LINE INDENT for interface in nsg . network_interfaces : NEW_LINE INDENT results [ ' network _ interfaces ' ] . append ( interface . id ) NEW_LINE DEDENT DEDENT results [ ' subnets ' ] = [ ] NEW_LINE if nsg . subnets : NEW_LINE INDENT for subnet in nsg . subnets : NEW_LINE INDENT results [ ' subnets ' ] . append ( subnet . id ) NEW_LINE DEDENT DEDENT return results NEW_LINE DEDENT rule_spec = dict ( name = dict ( type = ' str ' , required = True ) , description = dict ( type = ' str ' ) , protocol = dict ( type = ' str ' , choices = [ ' Udp ' , ' Tcp ' , ' * ' ] , default = ' * ' ) , source_port_range = dict ( type = ' raw ' , default = ' * ' ) , destination_port_range = dict ( type = ' raw ' , default = ' * ' ) , source_address_prefix = dict ( type = ' raw ' , default = ' * ' ) , destination_address_prefix = dict ( type = ' raw ' , default = ' * ' ) , access = dict ( type = ' str ' , choices = [ ' Allow ' , ' Deny ' ] , default = ' Allow ' ) , priority = dict ( type = ' int ' , required = True ) , direction = dict ( type = ' str ' , choices = [ ' Inbound ' , ' Outbound ' ] , default = ' Inbound ' ) ) NEW_LINE class AzureRMSecurityGroup ( AzureRMModuleBase ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT self . module_arg_spec = dict ( default_rules = dict ( type = ' list ' , elements = ' dict ' , options = rule_spec ) , location = dict ( type = ' str ' ) , name = dict ( type = ' str ' , required = True ) , purge_default_rules = dict ( type = ' bool ' , default = False ) , purge_rules = dict ( type = ' bool ' , default = False ) , resource_group = dict ( required = True , type = ' str ' ) , rules = dict ( type = ' list ' , elements = ' dict ' , options = rule_spec ) , state = dict ( type = ' str ' , default = ' present ' , choices = [ ' present ' , ' absent ' ] ) , ) NEW_LINE self . default_rules = None NEW_LINE self . location = None NEW_LINE self . name = None NEW_LINE self . purge_default_rules = None NEW_LINE self . purge_rules = None NEW_LINE self . resource_group = None NEW_LINE self . rules = None NEW_LINE self . state = None NEW_LINE self . tags = None NEW_LINE self . nsg_models = None NEW_LINE self . results = dict ( changed = False , state = dict ( ) ) NEW_LINE super ( AzureRMSecurityGroup , self ) . __init__ ( self . module_arg_spec , supports_check_mode = True ) NEW_LINE DEDENT def exec_module ( self , ** kwargs ) : NEW_LINE INDENT self . network_client . config . long_running_operation_timeout = 3 NEW_LINE self . nsg_models = self . network_client . network_security_groups . models NEW_LINE for key in list ( self . module_arg_spec . keys ( ) ) + [ ' tags ' ] : NEW_LINE INDENT setattr ( self , key , kwargs [ key ] ) NEW_LINE DEDENT changed = False NEW_LINE results = dict ( ) NEW_LINE resource_group = self . get_resource_group ( self . resource_group ) NEW_LINE if not self . location : NEW_LINE INDENT self . location = resource_group . location NEW_LINE DEDENT if self . rules : NEW_LINE INDENT for rule in self . rules : NEW_LINE INDENT try : NEW_LINE INDENT validate_rule ( self , rule ) NEW_LINE DEDENT except Exception as exc : NEW_LINE INDENT self . fail ( " Error ▁ validating ▁ rule ▁ { 0 } ▁ - ▁ { 1 } " . format ( rule , str ( exc ) ) ) NEW_LINE DEDENT DEDENT DEDENT if self . default_rules : NEW_LINE INDENT for rule in self . default_rules : NEW_LINE INDENT try : NEW_LINE INDENT validate_rule ( self , rule , ' default ' ) NEW_LINE DEDENT except Exception as exc : NEW_LINE INDENT self . fail ( " Error ▁ validating ▁ default ▁ rule ▁ { 0 } ▁ - ▁ { 1 } " . format ( rule , str ( exc ) ) ) NEW_LINE DEDENT DEDENT DEDENT try : NEW_LINE INDENT nsg = self . network_client . network_security_groups . get ( self . resource_group , self . name ) NEW_LINE results = create_network_security_group_dict ( nsg ) NEW_LINE self . log ( " Found ▁ security ▁ group : " ) NEW_LINE self . log ( results , pretty_print = True ) NEW_LINE self . check_provisioning_state ( nsg , self . state ) NEW_LINE if self . state == ' present ' : NEW_LINE INDENT pass NEW_LINE DEDENT elif self . state == ' absent ' : NEW_LINE INDENT self . log ( " CHANGED : ▁ security ▁ group ▁ found ▁ but ▁ state ▁ is ▁ ' absent ' " ) NEW_LINE changed = True NEW_LINE DEDENT DEDENT except CloudError : NEW_LINE INDENT if self . state == ' present ' : NEW_LINE INDENT self . log ( " CHANGED : ▁ security ▁ group ▁ not ▁ found ▁ and ▁ state ▁ is ▁ ' present ' " ) NEW_LINE changed = True NEW_LINE DEDENT DEDENT if self . state == ' present ' and not changed : NEW_LINE INDENT self . log ( " Update ▁ security ▁ group ▁ { 0 } " . format ( self . name ) ) NEW_LINE update_tags , results [ ' tags ' ] = self . update_tags ( results [ ' tags ' ] ) NEW_LINE if update_tags : NEW_LINE INDENT changed = True NEW_LINE DEDENT rule_changed , new_rule = compare_rules_change ( results [ ' rules ' ] , self . rules , self . purge_rules ) NEW_LINE if rule_changed : NEW_LINE INDENT changed = True NEW_LINE results [ ' rules ' ] = new_rule NEW_LINE DEDENT rule_changed , new_rule = compare_rules_change ( results [ ' default _ rules ' ] , self . default_rules , self . purge_default_rules ) NEW_LINE if rule_changed : NEW_LINE INDENT changed = True NEW_LINE results [ ' default _ rules ' ] = new_rule NEW_LINE DEDENT self . results [ ' changed ' ] = changed NEW_LINE self . results [ ' state ' ] = results NEW_LINE if not self . check_mode and changed : NEW_LINE INDENT self . results [ ' state ' ] = self . create_or_update ( results ) NEW_LINE DEDENT DEDENT elif self . state == ' present ' and changed : NEW_LINE INDENT self . log ( " Create ▁ security ▁ group ▁ { 0 } " . format ( self . name ) ) NEW_LINE if not self . location : NEW_LINE INDENT self . fail ( " Parameter ▁ error : ▁ location ▁ required ▁ when ▁ creating ▁ a ▁ security ▁ group . " ) NEW_LINE DEDENT results [ ' name ' ] = self . name NEW_LINE results [ ' location ' ] = self . location NEW_LINE results [ ' rules ' ] = [ ] NEW_LINE results [ ' default _ rules ' ] = [ ] NEW_LINE results [ ' tags ' ] = { } NEW_LINE if self . rules : NEW_LINE INDENT results [ ' rules ' ] = self . rules NEW_LINE DEDENT if self . default_rules : NEW_LINE INDENT results [ ' default _ rules ' ] = self . default_rules NEW_LINE DEDENT if self . tags : NEW_LINE INDENT results [ ' tags ' ] = self . tags NEW_LINE DEDENT self . results [ ' changed ' ] = changed NEW_LINE self . results [ ' state ' ] = results NEW_LINE if not self . check_mode : NEW_LINE INDENT self . results [ ' state ' ] = self . create_or_update ( results ) NEW_LINE DEDENT DEDENT elif self . state == ' absent ' and changed : NEW_LINE INDENT self . log ( " Delete ▁ security ▁ group ▁ { 0 } " . format ( self . name ) ) NEW_LINE self . results [ ' changed ' ] = changed NEW_LINE self . results [ ' state ' ] = dict ( ) NEW_LINE if not self . check_mode : NEW_LINE INDENT self . delete ( ) NEW_LINE self . results [ ' state ' ] [ ' status ' ] = ' Deleted ' NEW_LINE DEDENT DEDENT return self . results NEW_LINE DEDENT def create_or_update ( self , results ) : NEW_LINE INDENT parameters = self . nsg_models . NetworkSecurityGroup ( ) NEW_LINE if results . get ( ' rules ' ) : NEW_LINE INDENT parameters . security_rules = [ ] NEW_LINE for rule in results . get ( ' rules ' ) : NEW_LINE INDENT parameters . security_rules . append ( create_rule_instance ( self , rule ) ) NEW_LINE DEDENT DEDENT if results . get ( ' default _ rules ' ) : NEW_LINE INDENT parameters . default_security_rules = [ ] NEW_LINE for rule in results . get ( ' default _ rules ' ) : NEW_LINE INDENT parameters . default_security_rules . append ( create_rule_instance ( self , rule ) ) NEW_LINE DEDENT DEDENT parameters . tags = results . get ( ' tags ' ) NEW_LINE parameters . location = results . get ( ' location ' ) NEW_LINE try : NEW_LINE INDENT poller = self . network_client . network_security_groups . create_or_update ( resource_group_name = self . resource_group , network_security_group_name = self . name , parameters = parameters ) NEW_LINE result = self . get_poller_result ( poller ) NEW_LINE DEDENT except CloudError as exc : NEW_LINE INDENT self . fail ( " Error ▁ creating / updating ▁ security ▁ group ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . name , str ( exc ) ) ) NEW_LINE DEDENT return create_network_security_group_dict ( result ) NEW_LINE DEDENT def delete ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT poller = self . network_client . network_security_groups . delete ( resource_group_name = self . resource_group , network_security_group_name = self . name ) NEW_LINE result = self . get_poller_result ( poller ) NEW_LINE DEDENT except CloudError as exc : NEW_LINE INDENT raise Exception ( " Error ▁ deleting ▁ security ▁ group ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . name , str ( exc ) ) ) NEW_LINE DEDENT return result NEW_LINE DEDENT DEDENT def main ( ) : NEW_LINE INDENT AzureRMSecurityGroup ( ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT
 AF_APPLETALK = 16 NEW_LINE AF_DECnet = 12 NEW_LINE AF_INET = 2 NEW_LINE AF_INET6 = 23 NEW_LINE AF_IPX = 6 NEW_LINE AF_IRDA = 26 NEW_LINE AF_SNA = 11 NEW_LINE AF_UNSPEC = 0 NEW_LINE AI_ADDRCONFIG = 1024 NEW_LINE AI_ALL = 256 NEW_LINE AI_CANONNAME = 2 NEW_LINE AI_NUMERICHOST = 4 NEW_LINE AI_NUMERICSERV = 8 NEW_LINE AI_PASSIVE = 1 NEW_LINE AI_V4MAPPED = 2048 NEW_LINE CAPI = ' < capsule ▁ object ▁ " _ socket . CAPI " ▁ at ▁ 0x00BC4F38 > ' NEW_LINE EAI_AGAIN = 11002 NEW_LINE EAI_BADFLAGS = 10022 NEW_LINE EAI_FAIL = 11003 NEW_LINE EAI_FAMILY = 10047 NEW_LINE EAI_MEMORY = 8 NEW_LINE EAI_NODATA = 11001 NEW_LINE EAI_NONAME = 11001 NEW_LINE EAI_SERVICE = 10109 NEW_LINE EAI_SOCKTYPE = 10044 NEW_LINE INADDR_ALLHOSTS_GROUP = - 536870911 NEW_LINE INADDR_ANY = 0 NEW_LINE INADDR_BROADCAST = - 1 NEW_LINE INADDR_LOOPBACK = 2130706433 NEW_LINE INADDR_MAX_LOCAL_GROUP = - 536870657 NEW_LINE INADDR_NONE = - 1 NEW_LINE INADDR_UNSPEC_GROUP = - 536870912 NEW_LINE IPPORT_RESERVED = 1024 NEW_LINE IPPORT_USERRESERVED = 5000 NEW_LINE IPPROTO_ICMP = 1 NEW_LINE IPPROTO_IP = 0 NEW_LINE IPPROTO_RAW = 255 NEW_LINE IPPROTO_TCP = 6 NEW_LINE IPPROTO_UDP = 17 NEW_LINE IPV6_CHECKSUM = 26 NEW_LINE IPV6_DONTFRAG = 14 NEW_LINE IPV6_HOPLIMIT = 21 NEW_LINE IPV6_HOPOPTS = 1 NEW_LINE IPV6_JOIN_GROUP = 12 NEW_LINE IPV6_LEAVE_GROUP = 13 NEW_LINE IPV6_MULTICAST_HOPS = 10 NEW_LINE IPV6_MULTICAST_IF = 9 NEW_LINE IPV6_MULTICAST_LOOP = 11 NEW_LINE IPV6_PKTINFO = 19 NEW_LINE IPV6_RECVRTHDR = 38 NEW_LINE IPV6_RECVTCLASS = 40 NEW_LINE IPV6_RTHDR = 32 NEW_LINE IPV6_TCLASS = 39 NEW_LINE IPV6_UNICAST_HOPS = 4 NEW_LINE IPV6_V6ONLY = 27 NEW_LINE IP_ADD_MEMBERSHIP = 12 NEW_LINE IP_DROP_MEMBERSHIP = 13 NEW_LINE IP_HDRINCL = 2 NEW_LINE IP_MULTICAST_IF = 9 NEW_LINE IP_MULTICAST_LOOP = 11 NEW_LINE IP_MULTICAST_TTL = 10 NEW_LINE IP_OPTIONS = 1 NEW_LINE IP_RECVDSTADDR = 25 NEW_LINE IP_TOS = 3 NEW_LINE IP_TTL = 4 NEW_LINE MSG_BCAST = 1024 NEW_LINE MSG_CTRUNC = 512 NEW_LINE MSG_DONTROUTE = 4 NEW_LINE MSG_MCAST = 2048 NEW_LINE MSG_OOB = 1 NEW_LINE MSG_PEEK = 2 NEW_LINE MSG_TRUNC = 256 NEW_LINE NI_DGRAM = 16 NEW_LINE NI_MAXHOST = 1025 NEW_LINE NI_MAXSERV = 32 NEW_LINE NI_NAMEREQD = 4 NEW_LINE NI_NOFQDN = 1 NEW_LINE NI_NUMERICHOST = 2 NEW_LINE NI_NUMERICSERV = 8 NEW_LINE RCVALL_MAX = 3 NEW_LINE RCVALL_OFF = 0 NEW_LINE RCVALL_ON = 1 NEW_LINE RCVALL_SOCKETLEVELONLY = 2 NEW_LINE SHUT_RD = 0 NEW_LINE SHUT_RDWR = 2 NEW_LINE SHUT_WR = 1 NEW_LINE SIO_KEEPALIVE_VALS = 2550136836 NEW_LINE SIO_RCVALL = 2550136833 NEW_LINE SOCK_DGRAM = 2 NEW_LINE SOCK_RAW = 3 NEW_LINE SOCK_RDM = 4 NEW_LINE SOCK_SEQPACKET = 5 NEW_LINE SOCK_STREAM = 1 NEW_LINE SOL_IP = 0 NEW_LINE SOL_SOCKET = 65535 NEW_LINE SOL_TCP = 6 NEW_LINE SOL_UDP = 17 NEW_LINE SOMAXCONN = 2147483647 NEW_LINE SO_ACCEPTCONN = 2 NEW_LINE SO_BROADCAST = 32 NEW_LINE SO_DEBUG = 1 NEW_LINE SO_DONTROUTE = 16 NEW_LINE SO_ERROR = 4103 NEW_LINE SO_EXCLUSIVEADDRUSE = - 5 NEW_LINE SO_KEEPALIVE = 8 NEW_LINE SO_LINGER = 128 NEW_LINE SO_OOBINLINE = 256 NEW_LINE SO_RCVBUF = 4098 NEW_LINE SO_RCVLOWAT = 4100 NEW_LINE SO_RCVTIMEO = 4102 NEW_LINE SO_REUSEADDR = 4 NEW_LINE SO_SNDBUF = 4097 NEW_LINE SO_SNDLOWAT = 4099 NEW_LINE SO_SNDTIMEO = 4101 NEW_LINE SO_TYPE = 4104 NEW_LINE SO_USELOOPBACK = 64 NEW_LINE class SocketType : NEW_LINE INDENT pass NEW_LINE DEDENT TCP_MAXSEG = 4 NEW_LINE TCP_NODELAY = 1 NEW_LINE __loader__ = ' < _ frozen _ importlib . ExtensionFileLoader ▁ object ▁ at ▁ 0x00CA2D90 > ' NEW_LINE def dup ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT class error : NEW_LINE INDENT pass NEW_LINE DEDENT class gaierror : NEW_LINE INDENT pass NEW_LINE DEDENT def getaddrinfo ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def getdefaulttimeout ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def gethostbyaddr ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def gethostbyname ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def gethostbyname_ex ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def gethostname ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def getnameinfo ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def getprotobyname ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def getservbyname ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def getservbyport ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT has_ipv6 = True NEW_LINE class herror : NEW_LINE INDENT pass NEW_LINE DEDENT def htonl ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def htons ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def inet_aton ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def inet_ntoa ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def ntohl ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def ntohs ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def setdefaulttimeout ( * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT class socket : NEW_LINE INDENT def __init__ ( self , * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def bind ( self , * args , ** kw ) : NEW_LINE INDENT pass NEW_LINE DEDENT def close ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT class timeout : NEW_LINE INDENT pass NEW_LINE DEDENT
 from __future__ import absolute_import , division , print_function NEW_LINE __metaclass__ = type NEW_LINE ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = ''' STRNEWLINE - - - STRNEWLINE module : ▁ lxd _ profile STRNEWLINE short _ description : ▁ Manage ▁ LXD ▁ profiles STRNEWLINE version _ added : ▁ " 2.2 " STRNEWLINE description : STRNEWLINE ▁ ▁ - ▁ Management ▁ of ▁ LXD ▁ profiles STRNEWLINE author : ▁ " Hiroaki ▁ Nakamura ▁ ( @ hnakamur ) " STRNEWLINE options : STRNEWLINE ▁ ▁ ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ a ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Description ▁ of ▁ the ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ " 2.5 " STRNEWLINE ▁ ▁ ▁ ▁ config : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' The ▁ config ▁ for ▁ the ▁ container ▁ ( e . g . ▁ { " limits . memory " : ▁ " 4GB " } ) . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ See ▁ U ( https : / / github . com / lxc / lxd / blob / master / doc / rest - api . md # patch - 3 ) ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ the ▁ profile ▁ already ▁ exists ▁ and ▁ its ▁ " config " ▁ value ▁ in ▁ metadata STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ obtained ▁ from STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ GET ▁ / 1.0 / profiles / < name > STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ U ( https : / / github . com / lxc / lxd / blob / master / doc / rest - api . md # get - 19 ) STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ are ▁ different , ▁ they ▁ this ▁ module ▁ tries ▁ to ▁ apply ▁ the ▁ configurations . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Not ▁ all ▁ config ▁ values ▁ are ▁ supported ▁ to ▁ apply ▁ the ▁ existing ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ Maybe ▁ you ▁ need ▁ to ▁ delete ▁ and ▁ recreate ▁ a ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ devices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ' The ▁ devices ▁ for ▁ the ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ( e . g . ▁ { " rootfs " : ▁ { " path " : ▁ " / dev / kvm " , ▁ " type " : ▁ " unix - char " } ) . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ See ▁ U ( https : / / github . com / lxc / lxd / blob / master / doc / rest - api . md # patch - 3 ) ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ new _ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ new ▁ name ▁ of ▁ a ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ this ▁ parameter ▁ is ▁ specified ▁ a ▁ profile ▁ will ▁ be ▁ renamed ▁ to ▁ this ▁ name . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ See ▁ U ( https : / / github . com / lxc / lxd / blob / master / doc / rest - api . md # post - 11 ) STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ present STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ absent STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Define ▁ the ▁ state ▁ of ▁ a ▁ profile . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ url : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ unix ▁ domain ▁ socket ▁ path ▁ or ▁ the ▁ https ▁ URL ▁ for ▁ the ▁ LXD ▁ server . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ unix : / var / lib / lxd / unix . socket STRNEWLINE ▁ ▁ ▁ ▁ key _ file : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ client ▁ certificate ▁ key ▁ file ▁ path . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' " { } / . config / lxc / client . key " ▁ . format ( os . environ [ " HOME " ] ) ' STRNEWLINE ▁ ▁ ▁ ▁ cert _ file : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ client ▁ certificate ▁ file ▁ path . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' " { } / . config / lxc / client . crt " ▁ . format ( os . environ [ " HOME " ] ) ' STRNEWLINE ▁ ▁ ▁ ▁ trust _ password : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ client ▁ trusted ▁ password . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ You ▁ need ▁ to ▁ set ▁ this ▁ password ▁ on ▁ the ▁ LXD ▁ server ▁ before STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ running ▁ this ▁ module ▁ using ▁ the ▁ following ▁ command . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ lxc ▁ config ▁ set ▁ core . trust _ password ▁ < some ▁ random ▁ password > STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ See ▁ U ( https : / / www . stgraber . org / 2016/04/18 / lxd - api - direct - interaction / ) STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ trust _ password ▁ is ▁ set , ▁ this ▁ module ▁ send ▁ a ▁ request ▁ for STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ authentication ▁ before ▁ sending ▁ any ▁ requests . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE notes : STRNEWLINE ▁ ▁ - ▁ Profiles ▁ must ▁ have ▁ a ▁ unique ▁ name . ▁ If ▁ you ▁ attempt ▁ to ▁ create ▁ a ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ with ▁ a ▁ name ▁ that ▁ already ▁ existed ▁ in ▁ the ▁ users ▁ namespace ▁ the ▁ module ▁ will STRNEWLINE ▁ ▁ ▁ ▁ simply ▁ return ▁ as ▁ " unchanged " . STRNEWLINE ''' NEW_LINE EXAMPLES = ''' STRNEWLINE # ▁ An ▁ example ▁ for ▁ creating ▁ a ▁ profile STRNEWLINE - ▁ hosts : ▁ localhost STRNEWLINE ▁ ▁ connection : ▁ local STRNEWLINE ▁ ▁ tasks : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ name : ▁ Create ▁ a ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ lxd _ profile : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ config : ▁ { } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : ▁ my ▁ macvlan ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ devices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ eth0 : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ nictype : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ parent : ▁ br0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ type : ▁ nic STRNEWLINE STRNEWLINE # ▁ An ▁ example ▁ for ▁ creating ▁ a ▁ profile ▁ via ▁ http ▁ connection STRNEWLINE - ▁ hosts : ▁ localhost STRNEWLINE ▁ ▁ connection : ▁ local STRNEWLINE ▁ ▁ tasks : STRNEWLINE ▁ ▁ - ▁ name : ▁ create ▁ macvlan ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ lxd _ profile : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ url : ▁ https : / / 127.0.0.1:8443 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ # ▁ These ▁ cert _ file ▁ and ▁ key _ file ▁ values ▁ are ▁ equal ▁ to ▁ the ▁ default ▁ values . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ # cert _ file : ▁ " { { ▁ lookup ( ' env ' , ▁ ' HOME ' ) ▁ } } / . config / lxc / client . crt " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ # key _ file : ▁ " { { ▁ lookup ( ' env ' , ▁ ' HOME ' ) ▁ } } / . config / lxc / client . key " STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ trust _ password : ▁ mypassword STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ config : ▁ { } STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ description : ▁ my ▁ macvlan ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ devices : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ eth0 : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ nictype : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ parent : ▁ br0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ type : ▁ nic STRNEWLINE STRNEWLINE # ▁ An ▁ example ▁ for ▁ deleting ▁ a ▁ profile STRNEWLINE - ▁ hosts : ▁ localhost STRNEWLINE ▁ ▁ connection : ▁ local STRNEWLINE ▁ ▁ tasks : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ name : ▁ Delete ▁ a ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ lxd _ profile : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ absent STRNEWLINE STRNEWLINE # ▁ An ▁ example ▁ for ▁ renaming ▁ a ▁ profile STRNEWLINE - ▁ hosts : ▁ localhost STRNEWLINE ▁ ▁ connection : ▁ local STRNEWLINE ▁ ▁ tasks : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ name : ▁ Rename ▁ a ▁ profile STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ lxd _ profile : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ name : ▁ macvlan STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ new _ name : ▁ macvlan2 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ''' NEW_LINE RETURN = ''' STRNEWLINE old _ state : STRNEWLINE ▁ ▁ description : ▁ The ▁ old ▁ state ▁ of ▁ the ▁ profile STRNEWLINE ▁ ▁ returned : ▁ success STRNEWLINE ▁ ▁ type : ▁ string STRNEWLINE ▁ ▁ sample : ▁ " absent " STRNEWLINE logs : STRNEWLINE ▁ ▁ description : ▁ The ▁ logs ▁ of ▁ requests ▁ and ▁ responses . STRNEWLINE ▁ ▁ returned : ▁ when ▁ ansible - playbook ▁ is ▁ invoked ▁ with ▁ - vvvv . STRNEWLINE ▁ ▁ type : ▁ list STRNEWLINE ▁ ▁ sample : ▁ " ( too ▁ long ▁ to ▁ be ▁ placed ▁ here ) " STRNEWLINE actions : STRNEWLINE ▁ ▁ description : ▁ List ▁ of ▁ actions ▁ performed ▁ for ▁ the ▁ profile . STRNEWLINE ▁ ▁ returned : ▁ success STRNEWLINE ▁ ▁ type : ▁ list STRNEWLINE ▁ ▁ sample : ▁ ' [ " create " ] ' STRNEWLINE ''' NEW_LINE import os NEW_LINE from ansible . module_utils . basic import AnsibleModule NEW_LINE from ansible . module_utils . lxd import LXDClient , LXDClientException NEW_LINE PROFILES_STATES = [ ' present ' , ' absent ' ] NEW_LINE CONFIG_PARAMS = [ ' config ' , ' description ' , ' devices ' ] NEW_LINE class LXDProfileManagement ( object ) : NEW_LINE INDENT def __init__ ( self , module ) : NEW_LINE INDENT self . module = module NEW_LINE self . name = self . module . params [ ' name ' ] NEW_LINE self . _build_config ( ) NEW_LINE self . state = self . module . params [ ' state ' ] NEW_LINE self . new_name = self . module . params . get ( ' new _ name ' , None ) NEW_LINE self . url = self . module . params [ ' url ' ] NEW_LINE self . key_file = self . module . params . get ( ' key _ file ' , None ) NEW_LINE self . cert_file = self . module . params . get ( ' cert _ file ' , None ) NEW_LINE self . debug = self . module . _verbosity >= 4 NEW_LINE try : NEW_LINE INDENT self . client = LXDClient ( self . url , key_file = self . key_file , cert_file = self . cert_file , debug = self . debug ) NEW_LINE DEDENT except LXDClientException as e : NEW_LINE INDENT self . module . fail_json ( msg = e . msg ) NEW_LINE DEDENT self . trust_password = self . module . params . get ( ' trust _ password ' , None ) NEW_LINE self . actions = [ ] NEW_LINE DEDENT def _build_config ( self ) : NEW_LINE INDENT self . config = { } NEW_LINE for attr in CONFIG_PARAMS : NEW_LINE INDENT param_val = self . module . params . get ( attr , None ) NEW_LINE if param_val is not None : NEW_LINE INDENT self . config [ attr ] = param_val NEW_LINE DEDENT DEDENT DEDENT def _get_profile_json ( self ) : NEW_LINE INDENT return self . client . do ( ' GET ' , ' / 1.0 / profiles / {0 } ' . format ( self . name ) , ok_error_codes = [ 404 ] ) NEW_LINE DEDENT @ staticmethod NEW_LINE def _profile_json_to_module_state ( resp_json ) : NEW_LINE INDENT if resp_json [ ' type ' ] == ' error ' : NEW_LINE INDENT return ' absent ' NEW_LINE DEDENT return ' present ' NEW_LINE DEDENT def _update_profile ( self ) : NEW_LINE INDENT if self . state == ' present ' : NEW_LINE INDENT if self . old_state == ' absent ' : NEW_LINE INDENT if self . new_name is None : NEW_LINE INDENT self . _create_profile ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = ' new _ name ▁ must ▁ not ▁ be ▁ set ▁ when ▁ the ▁ profile ▁ does ▁ not ▁ exist ▁ and ▁ the ▁ specified ▁ state ▁ is ▁ present ' , changed = False ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if self . new_name is not None and self . new_name != self . name : NEW_LINE INDENT self . _rename_profile ( ) NEW_LINE DEDENT if self . _needs_to_apply_profile_configs ( ) : NEW_LINE INDENT self . _apply_profile_configs ( ) NEW_LINE DEDENT DEDENT DEDENT elif self . state == ' absent ' : NEW_LINE INDENT if self . old_state == ' present ' : NEW_LINE INDENT if self . new_name is None : NEW_LINE INDENT self . _delete_profile ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = ' new _ name ▁ must ▁ not ▁ be ▁ set ▁ when ▁ the ▁ profile ▁ exists ▁ and ▁ the ▁ specified ▁ state ▁ is ▁ absent ' , changed = False ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def _create_profile ( self ) : NEW_LINE INDENT config = self . config . copy ( ) NEW_LINE config [ ' name ' ] = self . name NEW_LINE self . client . do ( ' POST ' , ' / 1.0 / profiles ' , config ) NEW_LINE self . actions . append ( ' create ' ) NEW_LINE DEDENT def _rename_profile ( self ) : NEW_LINE INDENT config = { ' name ' : self . new_name } NEW_LINE self . client . do ( ' POST ' , ' / 1.0 / profiles / { } ' . format ( self . name ) , config ) NEW_LINE self . actions . append ( ' rename ' ) NEW_LINE self . name = self . new_name NEW_LINE DEDENT def _needs_to_change_profile_config ( self , key ) : NEW_LINE INDENT if key not in self . config : NEW_LINE INDENT return False NEW_LINE DEDENT old_configs = self . old_profile_json [ ' metadata ' ] . get ( key , None ) NEW_LINE return self . config [ key ] != old_configs NEW_LINE DEDENT def _needs_to_apply_profile_configs ( self ) : NEW_LINE INDENT return ( self . _needs_to_change_profile_config ( ' config ' ) or self . _needs_to_change_profile_config ( ' description ' ) or self . _needs_to_change_profile_config ( ' devices ' ) ) NEW_LINE DEDENT def _apply_profile_configs ( self ) : NEW_LINE INDENT config = self . old_profile_json . copy ( ) NEW_LINE for k , v in self . config . items ( ) : NEW_LINE INDENT config [ k ] = v NEW_LINE DEDENT self . client . do ( ' PUT ' , ' / 1.0 / profiles / { } ' . format ( self . name ) , config ) NEW_LINE self . actions . append ( ' apply _ profile _ configs ' ) NEW_LINE DEDENT def _delete_profile ( self ) : NEW_LINE INDENT self . client . do ( ' DELETE ' , ' / 1.0 / profiles / { } ' . format ( self . name ) ) NEW_LINE self . actions . append ( ' delete ' ) NEW_LINE DEDENT def run ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT if self . trust_password is not None : NEW_LINE INDENT self . client . authenticate ( self . trust_password ) NEW_LINE DEDENT self . old_profile_json = self . _get_profile_json ( ) NEW_LINE self . old_state = self . _profile_json_to_module_state ( self . old_profile_json ) NEW_LINE self . _update_profile ( ) NEW_LINE state_changed = len ( self . actions ) > 0 NEW_LINE result_json = { ' changed ' : state_changed , ' old _ state ' : self . old_state , ' actions ' : self . actions } NEW_LINE if self . client . debug : NEW_LINE INDENT result_json [ ' logs ' ] = self . client . logs NEW_LINE DEDENT self . module . exit_json ( ** result_json ) NEW_LINE DEDENT except LXDClientException as e : NEW_LINE INDENT state_changed = len ( self . actions ) > 0 NEW_LINE fail_params = { ' msg ' : e . msg , ' changed ' : state_changed , ' actions ' : self . actions } NEW_LINE if self . client . debug : NEW_LINE INDENT fail_params [ ' logs ' ] = e . kwargs [ ' logs ' ] NEW_LINE DEDENT self . module . fail_json ( ** fail_params ) NEW_LINE DEDENT DEDENT DEDENT def main ( ) : NEW_LINE INDENT module = AnsibleModule ( argument_spec = dict ( name = dict ( type = ' str ' , required = True ) , new_name = dict ( type = ' str ' , ) , config = dict ( type = ' dict ' , ) , description = dict ( type = ' str ' , ) , devices = dict ( type = ' dict ' , ) , state = dict ( choices = PROFILES_STATES , default = ' present ' ) , url = dict ( type = ' str ' , default = ' unix : / var / lib / lxd / unix . socket ' ) , key_file = dict ( type = ' str ' , default = ' { } / . config / lxc / client . key ' . format ( os . environ [ ' HOME ' ] ) ) , cert_file = dict ( type = ' str ' , default = ' { } / . config / lxc / client . crt ' . format ( os . environ [ ' HOME ' ] ) ) , trust_password = dict ( type = ' str ' , no_log = True ) ) , supports_check_mode = False , ) NEW_LINE lxd_manage = LXDProfileManagement ( module = module ) NEW_LINE lxd_manage . run ( ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT
 from msrest . serialization import Model NEW_LINE class GenerateUpgradedDefinitionParameters ( Model ) : NEW_LINE INDENT _attribute_map = { ' target _ schema _ version ' : { ' key ' : ' targetSchemaVersion ' , ' type ' : ' str ' } , } NEW_LINE def __init__ ( self , target_schema_version = None ) : NEW_LINE INDENT self . target_schema_version = target_schema_version NEW_LINE DEDENT DEDENT
 from statsmodels . compat . python import range , next NEW_LINE import numpy as np NEW_LINE from scipy import optimize NEW_LINE from scipy . stats . mstats import mquantiles NEW_LINE from statsmodels . nonparametric . api import KDEMultivariate , KernelReg NEW_LINE from statsmodels . nonparametric . _kernel_base import \NEW_LINE gpke , LeaveOneOut , _get_type_pos , _adjust_shape NEW_LINE __all__ = [ ' SingleIndexModel ' , ' SemiLinear ' , ' TestFForm ' ] NEW_LINE class TestFForm ( object ) : NEW_LINE INDENT def __init__ ( self , endog , exog , bw , var_type , fform , estimator , nboot = 100 ) : NEW_LINE INDENT self . endog = endog NEW_LINE self . exog = exog NEW_LINE self . var_type = var_type NEW_LINE self . fform = fform NEW_LINE self . estimator = estimator NEW_LINE self . nboot = nboot NEW_LINE self . bw = KDEMultivariate ( exog , bw = bw , var_type = var_type ) . bw NEW_LINE self . sig = self . _compute_sig ( ) NEW_LINE DEDENT def _compute_sig ( self ) : NEW_LINE INDENT Y = self . endog NEW_LINE X = self . exog NEW_LINE b = self . estimator ( Y , X ) NEW_LINE m = self . fform ( X , b ) NEW_LINE n = np . shape ( X ) [ 0 ] NEW_LINE resid = Y - m NEW_LINE resid = resid - np . mean ( resid ) NEW_LINE self . test_stat = self . _compute_test_stat ( resid ) NEW_LINE sqrt5 = np . sqrt ( 5. ) NEW_LINE fct1 = ( 1 - sqrt5 ) / 2. NEW_LINE fct2 = ( 1 + sqrt5 ) / 2. NEW_LINE u1 = fct1 * resid NEW_LINE u2 = fct2 * resid NEW_LINE r = fct2 / sqrt5 NEW_LINE I_dist = np . empty ( ( self . nboot , 1 ) ) NEW_LINE for j in range ( self . nboot ) : NEW_LINE INDENT u_boot = u2 . copy ( ) NEW_LINE prob = np . random . uniform ( 0 , 1 , size = ( n , ) ) NEW_LINE ind = prob < r NEW_LINE u_boot [ ind ] = u1 [ ind ] NEW_LINE Y_boot = m + u_boot NEW_LINE b_hat = self . estimator ( Y_boot , X ) NEW_LINE m_hat = self . fform ( X , b_hat ) NEW_LINE u_boot_hat = Y_boot - m_hat NEW_LINE I_dist [ j ] = self . _compute_test_stat ( u_boot_hat ) NEW_LINE DEDENT self . boots_results = I_dist NEW_LINE sig = " Not ▁ Significant " NEW_LINE if self . test_stat > mquantiles ( I_dist , 0.9 ) : NEW_LINE INDENT sig = " * " NEW_LINE DEDENT if self . test_stat > mquantiles ( I_dist , 0.95 ) : NEW_LINE INDENT sig = " * * " NEW_LINE DEDENT if self . test_stat > mquantiles ( I_dist , 0.99 ) : NEW_LINE INDENT sig = " * * * " NEW_LINE DEDENT return sig NEW_LINE DEDENT def _compute_test_stat ( self , u ) : NEW_LINE INDENT n = np . shape ( u ) [ 0 ] NEW_LINE XLOO = LeaveOneOut ( self . exog ) NEW_LINE uLOO = LeaveOneOut ( u [ : , None ] ) . __iter__ ( ) NEW_LINE I = 0 NEW_LINE S2 = 0 NEW_LINE for i , X_not_i in enumerate ( XLOO ) : NEW_LINE INDENT u_j = next ( uLOO ) NEW_LINE u_j = np . squeeze ( u_j ) NEW_LINE K = gpke ( self . bw , data = - X_not_i , data_predict = - self . exog [ i , : ] , var_type = self . var_type , tosum = False ) NEW_LINE f_i = ( u [ i ] * u_j * K ) NEW_LINE assert u_j . shape == K . shape NEW_LINE I += f_i . sum ( ) NEW_LINE S2 += ( f_i ** 2 ) . sum ( ) NEW_LINE assert np . size ( I ) == 1 NEW_LINE assert np . size ( S2 ) == 1 NEW_LINE DEDENT I *= 1. / ( n * ( n - 1 ) ) NEW_LINE ix_cont = _get_type_pos ( self . var_type ) [ 0 ] NEW_LINE hp = self . bw [ ix_cont ] . prod ( ) NEW_LINE S2 *= 2 * hp / ( n * ( n - 1 ) ) NEW_LINE T = n * I * np . sqrt ( hp / S2 ) NEW_LINE return T NEW_LINE DEDENT DEDENT class SingleIndexModel ( KernelReg ) : NEW_LINE INDENT def __init__ ( self , endog , exog , var_type ) : NEW_LINE INDENT self . var_type = var_type NEW_LINE self . K = len ( var_type ) NEW_LINE self . var_type = self . var_type [ 0 ] NEW_LINE self . endog = _adjust_shape ( endog , 1 ) NEW_LINE self . exog = _adjust_shape ( exog , self . K ) NEW_LINE self . nobs = np . shape ( self . exog ) [ 0 ] NEW_LINE self . data_type = self . var_type NEW_LINE self . func = self . _est_loc_linear NEW_LINE self . b , self . bw = self . _est_b_bw ( ) NEW_LINE DEDENT def _est_b_bw ( self ) : NEW_LINE INDENT params0 = np . random . uniform ( size = ( self . K + 1 , ) ) NEW_LINE b_bw = optimize . fmin ( self . cv_loo , params0 , disp = 0 ) NEW_LINE b = b_bw [ 0 : self . K ] NEW_LINE bw = b_bw [ self . K : ] NEW_LINE bw = self . _set_bw_bounds ( bw ) NEW_LINE return b , bw NEW_LINE DEDENT def cv_loo ( self , params ) : NEW_LINE INDENT params = np . asarray ( params ) NEW_LINE b = params [ 0 : self . K ] NEW_LINE bw = params [ self . K : ] NEW_LINE LOO_X = LeaveOneOut ( self . exog ) NEW_LINE LOO_Y = LeaveOneOut ( self . endog ) . __iter__ ( ) NEW_LINE L = 0 NEW_LINE for i , X_not_i in enumerate ( LOO_X ) : NEW_LINE INDENT Y = next ( LOO_Y ) NEW_LINE G = self . func ( bw , endog = Y , exog = - np . dot ( X_not_i , b ) [ : , None ] , data_predict = - np . dot ( self . exog [ i : i + 1 , : ] , b ) ) [ 0 ] NEW_LINE L += ( self . endog [ i ] - G ) ** 2 NEW_LINE DEDENT return L / self . nobs NEW_LINE DEDENT def fit ( self , data_predict = None ) : NEW_LINE INDENT if data_predict is None : NEW_LINE INDENT data_predict = self . exog NEW_LINE DEDENT else : NEW_LINE INDENT data_predict = _adjust_shape ( data_predict , self . K ) NEW_LINE DEDENT N_data_predict = np . shape ( data_predict ) [ 0 ] NEW_LINE mean = np . empty ( ( N_data_predict , ) ) NEW_LINE mfx = np . empty ( ( N_data_predict , self . K ) ) NEW_LINE for i in range ( N_data_predict ) : NEW_LINE INDENT mean_mfx = self . func ( self . bw , self . endog , np . dot ( self . exog , self . b ) [ : , None ] , data_predict = np . dot ( data_predict [ i : i + 1 , : ] , self . b ) ) NEW_LINE mean [ i ] = mean_mfx [ 0 ] NEW_LINE mfx_c = np . squeeze ( mean_mfx [ 1 ] ) NEW_LINE mfx [ i , : ] = mfx_c NEW_LINE DEDENT return mean , mfx NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT repr = " Single ▁ Index ▁ Model ▁ \n " NEW_LINE repr += " Number ▁ of ▁ variables : ▁ K ▁ = ▁ " + str ( self . K ) + " \n " NEW_LINE repr += " Number ▁ of ▁ samples : ▁ ▁ ▁ nobs ▁ = ▁ " + str ( self . nobs ) + " \n " NEW_LINE repr += " Variable ▁ types : ▁ ▁ ▁ ▁ ▁ ▁ " + self . var_type + " \n " NEW_LINE repr += " BW ▁ selection ▁ method : ▁ cv _ ls " + " \n " NEW_LINE repr += " Estimator ▁ type : ▁ local ▁ constant " + " \n " NEW_LINE return repr NEW_LINE DEDENT DEDENT class SemiLinear ( KernelReg ) : NEW_LINE INDENT def __init__ ( self , endog , exog , exog_nonparametric , var_type , k_linear ) : NEW_LINE INDENT self . endog = _adjust_shape ( endog , 1 ) NEW_LINE self . exog = _adjust_shape ( exog , k_linear ) NEW_LINE self . K = len ( var_type ) NEW_LINE self . exog_nonparametric = _adjust_shape ( exog_nonparametric , self . K ) NEW_LINE self . k_linear = k_linear NEW_LINE self . nobs = np . shape ( self . exog ) [ 0 ] NEW_LINE self . var_type = var_type NEW_LINE self . data_type = self . var_type NEW_LINE self . func = self . _est_loc_linear NEW_LINE self . b , self . bw = self . _est_b_bw ( ) NEW_LINE DEDENT def _est_b_bw ( self ) : NEW_LINE INDENT params0 = np . random . uniform ( size = ( self . k_linear + self . K , ) ) NEW_LINE b_bw = optimize . fmin ( self . cv_loo , params0 , disp = 0 ) NEW_LINE b = b_bw [ 0 : self . k_linear ] NEW_LINE bw = b_bw [ self . k_linear : ] NEW_LINE return b , bw NEW_LINE DEDENT def cv_loo ( self , params ) : NEW_LINE INDENT params = np . asarray ( params ) NEW_LINE b = params [ 0 : self . k_linear ] NEW_LINE bw = params [ self . k_linear : ] NEW_LINE LOO_X = LeaveOneOut ( self . exog ) NEW_LINE LOO_Y = LeaveOneOut ( self . endog ) . __iter__ ( ) NEW_LINE LOO_Z = LeaveOneOut ( self . exog_nonparametric ) . __iter__ ( ) NEW_LINE Xb = np . dot ( self . exog , b ) [ : , None ] NEW_LINE L = 0 NEW_LINE for ii , X_not_i in enumerate ( LOO_X ) : NEW_LINE INDENT Y = next ( LOO_Y ) NEW_LINE Z = next ( LOO_Z ) NEW_LINE Xb_j = np . dot ( X_not_i , b ) [ : , None ] NEW_LINE Yx = Y - Xb_j NEW_LINE G = self . func ( bw , endog = Yx , exog = - Z , data_predict = - self . exog_nonparametric [ ii , : ] ) [ 0 ] NEW_LINE lt = Xb [ ii , : ] NEW_LINE L += ( self . endog [ ii ] - lt - G ) ** 2 NEW_LINE DEDENT return L NEW_LINE DEDENT def fit ( self , exog_predict = None , exog_nonparametric_predict = None ) : NEW_LINE INDENT if exog_predict is None : NEW_LINE INDENT exog_predict = self . exog NEW_LINE DEDENT else : NEW_LINE INDENT exog_predict = _adjust_shape ( exog_predict , self . k_linear ) NEW_LINE DEDENT if exog_nonparametric_predict is None : NEW_LINE INDENT exog_nonparametric_predict = self . exog_nonparametric NEW_LINE DEDENT else : NEW_LINE INDENT exog_nonparametric_predict = _adjust_shape ( exog_nonparametric_predict , self . K ) NEW_LINE DEDENT N_data_predict = np . shape ( exog_nonparametric_predict ) [ 0 ] NEW_LINE mean = np . empty ( ( N_data_predict , ) ) NEW_LINE mfx = np . empty ( ( N_data_predict , self . K ) ) NEW_LINE Y = self . endog - np . dot ( exog_predict , self . b ) [ : , None ] NEW_LINE for i in range ( N_data_predict ) : NEW_LINE INDENT mean_mfx = self . func ( self . bw , Y , self . exog_nonparametric , data_predict = exog_nonparametric_predict [ i , : ] ) NEW_LINE mean [ i ] = mean_mfx [ 0 ] NEW_LINE mfx_c = np . squeeze ( mean_mfx [ 1 ] ) NEW_LINE mfx [ i , : ] = mfx_c NEW_LINE DEDENT return mean , mfx NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT repr = " Semiparamatric ▁ Partially ▁ Linear ▁ Model ▁ \n " NEW_LINE repr += " Number ▁ of ▁ variables : ▁ K ▁ = ▁ " + str ( self . K ) + " \n " NEW_LINE repr += " Number ▁ of ▁ samples : ▁ ▁ ▁ N ▁ = ▁ " + str ( self . nobs ) + " \n " NEW_LINE repr += " Variable ▁ types : ▁ ▁ ▁ ▁ ▁ ▁ " + self . var_type + " \n " NEW_LINE repr += " BW ▁ selection ▁ method : ▁ cv _ ls " + " \n " NEW_LINE repr += " Estimator ▁ type : ▁ local ▁ constant " + " \n " NEW_LINE return repr NEW_LINE DEDENT DEDENT
 from __future__ import absolute_import , division , print_function NEW_LINE __metaclass__ = type NEW_LINE ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = """ STRNEWLINE - - - STRNEWLINE module : ▁ pn _ vtep STRNEWLINE author : ▁ " Pluribus ▁ Networks ▁ ( @ rajaspachipulusu17 ) " STRNEWLINE version _ added : ▁ " 2.9 " STRNEWLINE short _ description : ▁ CLI ▁ command ▁ to ▁ create / delete ▁ vtep STRNEWLINE description : STRNEWLINE ▁ ▁ - ▁ This ▁ module ▁ can ▁ be ▁ used ▁ to ▁ create ▁ a ▁ vtep ▁ and ▁ delete ▁ a ▁ vtep . STRNEWLINE options : STRNEWLINE ▁ ▁ pn _ cliswitch : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Target ▁ switch ▁ to ▁ run ▁ the ▁ CLI ▁ on . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ vtep ▁ configuration ▁ command . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ choices : ▁ [ ' present ' , ▁ ' absent ' ] STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ ' present ' STRNEWLINE ▁ ▁ pn _ name : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ vtep ▁ name . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ ip : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Primary ▁ IP ▁ address . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ vrouter _ name : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ name ▁ of ▁ the ▁ vrouter ▁ service . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ virtual _ ip : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Virtual / Secondary ▁ IP ▁ address . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ location : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ switch ▁ name . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ str STRNEWLINE ▁ ▁ pn _ switch _ in _ cluster : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Tells ▁ whether ▁ switch ▁ in ▁ cluster ▁ or ▁ not . STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ True STRNEWLINE """ NEW_LINE EXAMPLES = """ STRNEWLINE - ▁ name : ▁ create ▁ vtep STRNEWLINE ▁ ▁ pn _ vtep : STRNEWLINE ▁ ▁ ▁ ▁ pn _ cliswitch : ▁ ' sw01 ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ name : ▁ ' foo ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ vrouter _ name : ▁ ' foo - vrouter ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ ip : ▁ ' 22.22.22.2 ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ location : ▁ ' sw01 ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ virtual _ ip : ▁ " 22.22.22.1 " STRNEWLINE STRNEWLINE - ▁ name : ▁ delete ▁ vtep STRNEWLINE ▁ ▁ pn _ vtep : STRNEWLINE ▁ ▁ ▁ ▁ pn _ cliswitch : ▁ ' sw01 ' STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ ' absent ' STRNEWLINE ▁ ▁ ▁ ▁ pn _ name : ▁ ' foo ' STRNEWLINE """ NEW_LINE RETURN = """ STRNEWLINE command : STRNEWLINE ▁ ▁ description : ▁ the ▁ CLI ▁ command ▁ run ▁ on ▁ the ▁ target ▁ node . STRNEWLINE ▁ ▁ returned : ▁ always STRNEWLINE ▁ ▁ type : ▁ str STRNEWLINE stdout : STRNEWLINE ▁ ▁ description : ▁ set ▁ of ▁ responses ▁ from ▁ the ▁ vtep ▁ command . STRNEWLINE ▁ ▁ returned : ▁ always STRNEWLINE ▁ ▁ type : ▁ list STRNEWLINE stderr : STRNEWLINE ▁ ▁ description : ▁ set ▁ of ▁ error ▁ responses ▁ from ▁ the ▁ vtep ▁ command . STRNEWLINE ▁ ▁ returned : ▁ on ▁ error STRNEWLINE ▁ ▁ type : ▁ list STRNEWLINE changed : STRNEWLINE ▁ ▁ description : ▁ indicates ▁ whether ▁ the ▁ CLI ▁ caused ▁ changes ▁ on ▁ the ▁ target . STRNEWLINE ▁ ▁ returned : ▁ always STRNEWLINE ▁ ▁ type : ▁ bool STRNEWLINE """ NEW_LINE from ansible . module_utils . basic import AnsibleModule NEW_LINE from ansible . module_utils . network . netvisor . pn_nvos import pn_cli , run_cli NEW_LINE from ansible . module_utils . network . netvisor . netvisor import run_commands NEW_LINE def check_cli ( module , cli ) : NEW_LINE INDENT name = module . params [ ' pn _ name ' ] NEW_LINE cli += ' ▁ vtep - show ▁ format ▁ name ▁ no - show - headers ' NEW_LINE out = run_commands ( module , cli ) [ 1 ] NEW_LINE if out : NEW_LINE INDENT out = out . split ( ) NEW_LINE DEDENT return True if name in out else False NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT state_map = dict ( present = ' vtep - create ' , absent = ' vtep - delete ' ) NEW_LINE argument_spec = dict ( pn_cliswitch = dict ( required = False , type = ' str ' ) , state = dict ( required = False , type = ' str ' , choices = state_map . keys ( ) , default = ' present ' ) , pn_name = dict ( required = False , type = ' str ' ) , pn_ip = dict ( required = False , type = ' str ' ) , pn_vrouter_name = dict ( required = False , type = ' str ' ) , pn_virtual_ip = dict ( required = False , type = ' str ' ) , pn_location = dict ( required = False , type = ' str ' ) , pn_switch_in_cluster = dict ( required = False , type = ' bool ' , default = ' True ' ) ) NEW_LINE module = AnsibleModule ( argument_spec = argument_spec , required_if = ( [ " state " , " present " , [ " pn _ name " , " pn _ ip " , " pn _ vrouter _ name " , " pn _ location " ] ] , [ " state " , " absent " , [ " pn _ name " ] ] , ) , ) NEW_LINE cliswitch = module . params [ ' pn _ cliswitch ' ] NEW_LINE state = module . params [ ' state ' ] NEW_LINE name = module . params [ ' pn _ name ' ] NEW_LINE ip = module . params [ ' pn _ ip ' ] NEW_LINE vrouter_name = module . params [ ' pn _ vrouter _ name ' ] NEW_LINE virtual_ip = module . params [ ' pn _ virtual _ ip ' ] NEW_LINE location = module . params [ ' pn _ location ' ] NEW_LINE switch_in_cluster = module . params [ ' pn _ switch _ in _ cluster ' ] NEW_LINE if switch_in_cluster and not virtual_ip and state == ' present ' : NEW_LINE INDENT module . exit_json ( failed = True , msg = ' virtual ▁ ip ▁ is ▁ required ▁ when ▁ switch ▁ is ▁ in ▁ cluster ' ) NEW_LINE DEDENT command = state_map [ state ] NEW_LINE cli = pn_cli ( module , cliswitch ) NEW_LINE NAME_EXISTS = check_cli ( module , cli ) NEW_LINE cli += ' ▁ % s ▁ name ▁ % s ▁ ' % ( command , name ) NEW_LINE if command == ' vtep - delete ' : NEW_LINE INDENT if NAME_EXISTS is False : NEW_LINE INDENT module . exit_json ( skipped = True , msg = ' vtep ▁ with ▁ name ▁ % s ▁ does ▁ not ▁ exist ' % name ) NEW_LINE DEDENT DEDENT if command == ' vtep - create ' : NEW_LINE INDENT if NAME_EXISTS is True : NEW_LINE INDENT module . exit_json ( skipped = True , msg = ' vtpe ▁ with ▁ name ▁ % s ▁ already ▁ exists ' % name ) NEW_LINE DEDENT cli += ' vrouter - name ▁ % s ▁ ' % vrouter_name NEW_LINE cli += ' ip ▁ % s ▁ ' % ip NEW_LINE cli += ' location ▁ % s ▁ ' % location NEW_LINE if virtual_ip : NEW_LINE INDENT cli += ' virtual - ip ▁ % s ▁ ' % virtual_ip NEW_LINE DEDENT DEDENT run_cli ( module , cli , state_map ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT
 ANSIBLE_METADATA = { ' metadata _ version ' : '1.1' , ' status ' : [ ' preview ' ] , ' supported _ by ' : ' community ' } NEW_LINE DOCUMENTATION = """ STRNEWLINE - - - STRNEWLINE module : ▁ elasticache STRNEWLINE short _ description : ▁ Manage ▁ cache ▁ clusters ▁ in ▁ Amazon ▁ Elasticache . STRNEWLINE description : STRNEWLINE ▁ ▁ - ▁ Manage ▁ cache ▁ clusters ▁ in ▁ Amazon ▁ Elasticache . STRNEWLINE ▁ ▁ - ▁ Returns ▁ information ▁ about ▁ the ▁ specified ▁ cache ▁ cluster . STRNEWLINE version _ added : ▁ " 1.4 " STRNEWLINE requirements : ▁ [ ▁ boto3 ▁ ] STRNEWLINE author : ▁ " Jim ▁ Dalton ▁ ( @ jsdalton ) " STRNEWLINE options : STRNEWLINE ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ C ( absent ) ▁ or ▁ C ( present ) ▁ are ▁ idempotent ▁ actions ▁ that ▁ will ▁ create ▁ or ▁ destroy ▁ a ▁ cache ▁ cluster ▁ as ▁ needed . ▁ C ( rebooted ) ▁ will ▁ reboot ▁ the ▁ cluster , STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ resulting ▁ in ▁ a ▁ momentary ▁ outage . STRNEWLINE ▁ ▁ ▁ ▁ choices : ▁ [ ' present ' , ▁ ' absent ' , ▁ ' rebooted ' ] STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ cache ▁ cluster ▁ identifier STRNEWLINE ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ engine : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Name ▁ of ▁ the ▁ cache ▁ engine ▁ to ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ memcached STRNEWLINE ▁ ▁ ▁ ▁ choices : ▁ [ ' redis ' , ▁ ' memcached ' ] STRNEWLINE ▁ ▁ cache _ engine _ version : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ version ▁ number ▁ of ▁ the ▁ cache ▁ engine STRNEWLINE ▁ ▁ node _ type : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ compute ▁ and ▁ memory ▁ capacity ▁ of ▁ the ▁ nodes ▁ in ▁ the ▁ cache ▁ cluster STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ cache . m1 . small STRNEWLINE ▁ ▁ num _ nodes : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ initial ▁ number ▁ of ▁ cache ▁ nodes ▁ that ▁ the ▁ cache ▁ cluster ▁ will ▁ have . ▁ Required ▁ when ▁ state = present . STRNEWLINE ▁ ▁ cache _ port : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ port ▁ number ▁ on ▁ which ▁ each ▁ of ▁ the ▁ cache ▁ nodes ▁ will ▁ accept ▁ connections STRNEWLINE ▁ ▁ cache _ parameter _ group : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ name ▁ of ▁ the ▁ cache ▁ parameter ▁ group ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ If ▁ this ▁ argument ▁ is ▁ omitted , ▁ the ▁ default ▁ cache ▁ parameter ▁ group STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ for ▁ the ▁ specified ▁ engine ▁ will ▁ be ▁ used . STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 2.0 " STRNEWLINE ▁ ▁ ▁ ▁ aliases : ▁ [ ▁ ' parameter _ group ' ▁ ] STRNEWLINE ▁ ▁ cache _ subnet _ group : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ subnet ▁ group ▁ name ▁ to ▁ associate ▁ with . ▁ Only ▁ use ▁ if ▁ inside ▁ a ▁ vpc . ▁ Required ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 2.0 " STRNEWLINE ▁ ▁ security _ group _ ids : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ list ▁ of ▁ vpc ▁ security ▁ group ▁ names ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ Only ▁ use ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ ▁ ▁ version _ added : ▁ " 1.6 " STRNEWLINE ▁ ▁ cache _ security _ groups : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ list ▁ of ▁ cache ▁ security ▁ group ▁ names ▁ to ▁ associate ▁ with ▁ this ▁ cache ▁ cluster . ▁ Must ▁ be ▁ an ▁ empty ▁ list ▁ if ▁ inside ▁ a ▁ vpc STRNEWLINE ▁ ▁ zone : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ The ▁ EC2 ▁ Availability ▁ Zone ▁ in ▁ which ▁ the ▁ cache ▁ cluster ▁ will ▁ be ▁ created STRNEWLINE ▁ ▁ wait : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Wait ▁ for ▁ cache ▁ cluster ▁ result ▁ before ▁ returning STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ ' yes ' STRNEWLINE ▁ ▁ hard _ modify : STRNEWLINE ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Whether ▁ to ▁ destroy ▁ and ▁ recreate ▁ an ▁ existing ▁ cache ▁ cluster ▁ if ▁ necessary ▁ in ▁ order ▁ to ▁ modify ▁ its ▁ state STRNEWLINE ▁ ▁ ▁ ▁ type : ▁ bool STRNEWLINE ▁ ▁ ▁ ▁ default : ▁ ' no ' STRNEWLINE extends _ documentation _ fragment : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ aws STRNEWLINE ▁ ▁ ▁ ▁ - ▁ ec2 STRNEWLINE """ NEW_LINE EXAMPLES = """ STRNEWLINE # ▁ Note : ▁ None ▁ of ▁ these ▁ examples ▁ set ▁ aws _ access _ key , ▁ aws _ secret _ key , ▁ or ▁ region . STRNEWLINE # ▁ It ▁ is ▁ assumed ▁ that ▁ their ▁ matching ▁ environment ▁ variables ▁ are ▁ set . STRNEWLINE STRNEWLINE # ▁ Basic ▁ example STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ present STRNEWLINE ▁ ▁ ▁ ▁ engine : ▁ memcached STRNEWLINE ▁ ▁ ▁ ▁ cache _ engine _ version : ▁ 1.4.14 STRNEWLINE ▁ ▁ ▁ ▁ node _ type : ▁ cache . m1 . small STRNEWLINE ▁ ▁ ▁ ▁ num _ nodes : ▁ 1 STRNEWLINE ▁ ▁ ▁ ▁ cache _ port : ▁ 11211 STRNEWLINE ▁ ▁ ▁ ▁ cache _ security _ groups : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ - ▁ default STRNEWLINE ▁ ▁ ▁ ▁ zone : ▁ us - east - 1d STRNEWLINE STRNEWLINE STRNEWLINE # ▁ Ensure ▁ cache ▁ cluster ▁ is ▁ gone STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ absent STRNEWLINE STRNEWLINE # ▁ Reboot ▁ cache ▁ cluster STRNEWLINE - ▁ elasticache : STRNEWLINE ▁ ▁ ▁ ▁ name : ▁ " test - please - delete " STRNEWLINE ▁ ▁ ▁ ▁ state : ▁ rebooted STRNEWLINE STRNEWLINE """ NEW_LINE from time import sleep NEW_LINE from traceback import format_exc NEW_LINE from ansible . module_utils . basic import AnsibleModule NEW_LINE from ansible . module_utils . ec2 import ec2_argument_spec , get_aws_connection_info , boto3_conn , HAS_BOTO3 , camel_dict_to_snake_dict NEW_LINE try : NEW_LINE INDENT import boto3 NEW_LINE import botocore NEW_LINE DEDENT except ImportError : NEW_LINE INDENT pass NEW_LINE DEDENT class ElastiCacheManager ( object ) : NEW_LINE INDENT EXIST_STATUSES = [ ' available ' , ' creating ' , ' rebooting ' , ' modifying ' ] NEW_LINE def __init__ ( self , module , name , engine , cache_engine_version , node_type , num_nodes , cache_port , cache_parameter_group , cache_subnet_group , cache_security_groups , security_group_ids , zone , wait , hard_modify , region , ** aws_connect_kwargs ) : NEW_LINE INDENT self . module = module NEW_LINE self . name = name NEW_LINE self . engine = engine . lower ( ) NEW_LINE self . cache_engine_version = cache_engine_version NEW_LINE self . node_type = node_type NEW_LINE self . num_nodes = num_nodes NEW_LINE self . cache_port = cache_port NEW_LINE self . cache_parameter_group = cache_parameter_group NEW_LINE self . cache_subnet_group = cache_subnet_group NEW_LINE self . cache_security_groups = cache_security_groups NEW_LINE self . security_group_ids = security_group_ids NEW_LINE self . zone = zone NEW_LINE self . wait = wait NEW_LINE self . hard_modify = hard_modify NEW_LINE self . region = region NEW_LINE self . aws_connect_kwargs = aws_connect_kwargs NEW_LINE self . changed = False NEW_LINE self . data = None NEW_LINE self . status = ' gone ' NEW_LINE self . conn = self . _get_elasticache_connection ( ) NEW_LINE self . _refresh_data ( ) NEW_LINE DEDENT def ensure_present ( self ) : NEW_LINE INDENT if self . exists ( ) : NEW_LINE INDENT self . sync ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . create ( ) NEW_LINE DEDENT DEDENT def ensure_absent ( self ) : NEW_LINE INDENT self . delete ( ) NEW_LINE DEDENT def ensure_rebooted ( self ) : NEW_LINE INDENT self . reboot ( ) NEW_LINE DEDENT def exists ( self ) : NEW_LINE INDENT return self . status in self . EXIST_STATUSES NEW_LINE DEDENT def create ( self ) : NEW_LINE INDENT if self . status == ' available ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT return NEW_LINE DEDENT if self . status == ' deleting ' : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ deleting . ▁ Cannot ▁ create . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT DEDENT kwargs = dict ( CacheClusterId = self . name , NumCacheNodes = self . num_nodes , CacheNodeType = self . node_type , Engine = self . engine , EngineVersion = self . cache_engine_version , CacheSecurityGroupNames = self . cache_security_groups , SecurityGroupIds = self . security_group_ids , CacheParameterGroupName = self . cache_parameter_group , CacheSubnetGroupName = self . cache_subnet_group ) NEW_LINE if self . cache_port is not None : NEW_LINE INDENT kwargs [ ' Port ' ] = self . cache_port NEW_LINE DEDENT if self . zone is not None : NEW_LINE INDENT kwargs [ ' PreferredAvailabilityZone ' ] = self . zone NEW_LINE DEDENT try : NEW_LINE INDENT self . conn . create_cache_cluster ( ** kwargs ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT return True NEW_LINE DEDENT def delete ( self ) : NEW_LINE INDENT if self . status == ' gone ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status == ' deleting ' : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ % s . ▁ Cannot ▁ delete . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT response = self . conn . delete_cache_cluster ( CacheClusterId = self . name ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT cache_cluster_data = response [ ' CacheCluster ' ] NEW_LINE self . _refresh_data ( cache_cluster_data ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' gone ' ) NEW_LINE DEDENT DEDENT def sync ( self ) : NEW_LINE INDENT if not self . exists ( ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ % s . ▁ Cannot ▁ sync . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT if self . status in [ ' creating ' , ' rebooting ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT if self . _requires_destroy_and_create ( ) : NEW_LINE INDENT if not self . hard_modify : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ destructive ▁ modification . ▁ ' hard _ modify ' ▁ must ▁ be ▁ set ▁ to ▁ true ▁ to ▁ proceed . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT if not self . wait : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ destructive ▁ modification . ▁ ' wait ' ▁ must ▁ be ▁ set ▁ to ▁ true . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT self . delete ( ) NEW_LINE self . create ( ) NEW_LINE return NEW_LINE DEDENT if self . _requires_modification ( ) : NEW_LINE INDENT self . modify ( ) NEW_LINE DEDENT DEDENT def modify ( self ) : NEW_LINE INDENT nodes_to_remove = self . _get_nodes_to_remove ( ) NEW_LINE try : NEW_LINE INDENT self . conn . modify_cache_cluster ( CacheClusterId = self . name , NumCacheNodes = self . num_nodes , CacheNodeIdsToRemove = nodes_to_remove , CacheSecurityGroupNames = self . cache_security_groups , CacheParameterGroupName = self . cache_parameter_group , SecurityGroupIds = self . security_group_ids , ApplyImmediately = True , EngineVersion = self . cache_engine_version ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT DEDENT def reboot ( self ) : NEW_LINE INDENT if not self . exists ( ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ % s . ▁ Cannot ▁ reboot . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT if self . status == ' rebooting ' : NEW_LINE INDENT return NEW_LINE DEDENT if self . status in [ ' creating ' , ' modifying ' ] : NEW_LINE INDENT if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT else : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ currently ▁ % s . ▁ Cannot ▁ reboot . " NEW_LINE self . module . fail_json ( msg = msg % ( self . name , self . status ) ) NEW_LINE DEDENT DEDENT cache_node_ids = [ cn [ ' CacheNodeId ' ] for cn in self . data [ ' CacheNodes ' ] ] NEW_LINE try : NEW_LINE INDENT self . conn . reboot_cache_cluster ( CacheClusterId = self . name , CacheNodeIdsToReboot = cache_node_ids ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT self . _refresh_data ( ) NEW_LINE self . changed = True NEW_LINE if self . wait : NEW_LINE INDENT self . _wait_for_status ( ' available ' ) NEW_LINE DEDENT DEDENT def get_info ( self ) : NEW_LINE INDENT info = { ' name ' : self . name , ' status ' : self . status } NEW_LINE if self . data : NEW_LINE INDENT info [ ' data ' ] = self . data NEW_LINE DEDENT return info NEW_LINE DEDENT def _wait_for_status ( self , awaited_status ) : NEW_LINE INDENT status_map = { ' creating ' : ' available ' , ' rebooting ' : ' available ' , ' modifying ' : ' available ' , ' deleting ' : ' gone ' } NEW_LINE if self . status == awaited_status : NEW_LINE INDENT return NEW_LINE DEDENT if status_map [ self . status ] != awaited_status : NEW_LINE INDENT msg = " Invalid ▁ awaited ▁ status . ▁ ' % s ' ▁ cannot ▁ transition ▁ to ▁ ' % s ' " NEW_LINE self . module . fail_json ( msg = msg % ( self . status , awaited_status ) ) NEW_LINE DEDENT if awaited_status not in set ( status_map . values ( ) ) : NEW_LINE INDENT msg = " ' % s ' ▁ is ▁ not ▁ a ▁ valid ▁ awaited ▁ status . " NEW_LINE self . module . fail_json ( msg = msg % awaited_status ) NEW_LINE DEDENT while True : NEW_LINE INDENT sleep ( 1 ) NEW_LINE self . _refresh_data ( ) NEW_LINE if self . status == awaited_status : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT DEDENT def _requires_modification ( self ) : NEW_LINE INDENT modifiable_data = { ' NumCacheNodes ' : self . num_nodes , ' EngineVersion ' : self . cache_engine_version } NEW_LINE for key , value in modifiable_data . items ( ) : NEW_LINE INDENT if value is not None and value and self . data [ key ] != value : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT cache_security_groups = [ ] NEW_LINE for sg in self . data [ ' CacheSecurityGroups ' ] : NEW_LINE INDENT cache_security_groups . append ( sg [ ' CacheSecurityGroupName ' ] ) NEW_LINE DEDENT if set ( cache_security_groups ) != set ( self . cache_security_groups ) : NEW_LINE INDENT return True NEW_LINE DEDENT if self . security_group_ids : NEW_LINE INDENT vpc_security_groups = [ ] NEW_LINE security_groups = self . data [ ' SecurityGroups ' ] or [ ] NEW_LINE for sg in security_groups : NEW_LINE INDENT vpc_security_groups . append ( sg [ ' SecurityGroupId ' ] ) NEW_LINE DEDENT if set ( vpc_security_groups ) != set ( self . security_group_ids ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def _requires_destroy_and_create ( self ) : NEW_LINE INDENT unmodifiable_data = { ' node _ type ' : self . data [ ' CacheNodeType ' ] , ' engine ' : self . data [ ' Engine ' ] , ' cache _ port ' : self . _get_port ( ) } NEW_LINE if self . zone is not None : NEW_LINE INDENT unmodifiable_data [ ' zone ' ] = self . data [ ' PreferredAvailabilityZone ' ] NEW_LINE DEDENT for key , value in unmodifiable_data . items ( ) : NEW_LINE INDENT if getattr ( self , key ) is not None and getattr ( self , key ) != value : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def _get_elasticache_connection ( self ) : NEW_LINE INDENT region , ec2_url , aws_connect_params = get_aws_connection_info ( self . module , boto3 = True ) NEW_LINE if region : NEW_LINE INDENT return boto3_conn ( self . module , conn_type = ' client ' , resource = ' elasticache ' , region = region , endpoint = ec2_url , ** aws_connect_params ) NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = " region ▁ must ▁ be ▁ specified " ) NEW_LINE DEDENT DEDENT def _get_port ( self ) : NEW_LINE INDENT if self . data [ ' Engine ' ] == ' memcached ' : NEW_LINE INDENT return self . data [ ' ConfigurationEndpoint ' ] [ ' Port ' ] NEW_LINE DEDENT elif self . data [ ' Engine ' ] == ' redis ' : NEW_LINE INDENT return self . data [ ' CacheNodes ' ] [ 0 ] [ ' Endpoint ' ] [ ' Port ' ] NEW_LINE DEDENT DEDENT def _refresh_data ( self , cache_cluster_data = None ) : NEW_LINE INDENT if cache_cluster_data is None : NEW_LINE INDENT try : NEW_LINE INDENT response = self . conn . describe_cache_clusters ( CacheClusterId = self . name , ShowCacheNodeInfo = True ) NEW_LINE DEDENT except botocore . exceptions . ClientError as e : NEW_LINE INDENT if e . response [ ' Error ' ] [ ' Code ' ] == ' CacheClusterNotFound ' : NEW_LINE INDENT self . data = None NEW_LINE self . status = ' gone ' NEW_LINE return NEW_LINE DEDENT else : NEW_LINE INDENT self . module . fail_json ( msg = e . message , exception = format_exc ( ) , ** camel_dict_to_snake_dict ( e . response ) ) NEW_LINE DEDENT DEDENT cache_cluster_data = response [ ' CacheClusters ' ] [ 0 ] NEW_LINE DEDENT self . data = cache_cluster_data NEW_LINE self . status = self . data [ ' CacheClusterStatus ' ] NEW_LINE if self . status == ' rebooting ▁ cache ▁ cluster ▁ nodes ' : NEW_LINE INDENT self . status = ' rebooting ' NEW_LINE DEDENT DEDENT def _get_nodes_to_remove ( self ) : NEW_LINE INDENT num_nodes_to_remove = self . data [ ' NumCacheNodes ' ] - self . num_nodes NEW_LINE if num_nodes_to_remove <= 0 : NEW_LINE INDENT return [ ] NEW_LINE DEDENT if not self . hard_modify : NEW_LINE INDENT msg = " ' % s ' ▁ requires ▁ removal ▁ of ▁ cache ▁ nodes . ▁ ' hard _ modify ' ▁ must ▁ be ▁ set ▁ to ▁ true ▁ to ▁ proceed . " NEW_LINE self . module . fail_json ( msg = msg % self . name ) NEW_LINE DEDENT cache_node_ids = [ cn [ ' CacheNodeId ' ] for cn in self . data [ ' CacheNodes ' ] ] NEW_LINE return cache_node_ids [ - num_nodes_to_remove : ] NEW_LINE DEDENT DEDENT def main ( ) : NEW_LINE INDENT argument_spec = ec2_argument_spec ( ) NEW_LINE argument_spec . update ( dict ( state = dict ( required = True , choices = [ ' present ' , ' absent ' , ' rebooted ' ] ) , name = dict ( required = True ) , engine = dict ( default = ' memcached ' ) , cache_engine_version = dict ( default = " " ) , node_type = dict ( default = ' cache . t2 . small ' ) , num_nodes = dict ( default = 1 , type = ' int ' ) , cache_parameter_group = dict ( default = " " , aliases = [ ' parameter _ group ' ] ) , cache_port = dict ( type = ' int ' ) , cache_subnet_group = dict ( default = " " ) , cache_security_groups = dict ( default = [ ] , type = ' list ' ) , security_group_ids = dict ( default = [ ] , type = ' list ' ) , zone = dict ( ) , wait = dict ( default = True , type = ' bool ' ) , hard_modify = dict ( type = ' bool ' ) ) ) NEW_LINE module = AnsibleModule ( argument_spec = argument_spec , ) NEW_LINE if not HAS_BOTO3 : NEW_LINE INDENT module . fail_json ( msg = ' boto3 ▁ required ▁ for ▁ this ▁ module ' ) NEW_LINE DEDENT region , ec2_url , aws_connect_kwargs = get_aws_connection_info ( module ) NEW_LINE name = module . params [ ' name ' ] NEW_LINE state = module . params [ ' state ' ] NEW_LINE engine = module . params [ ' engine ' ] NEW_LINE cache_engine_version = module . params [ ' cache _ engine _ version ' ] NEW_LINE node_type = module . params [ ' node _ type ' ] NEW_LINE num_nodes = module . params [ ' num _ nodes ' ] NEW_LINE cache_port = module . params [ ' cache _ port ' ] NEW_LINE cache_subnet_group = module . params [ ' cache _ subnet _ group ' ] NEW_LINE cache_security_groups = module . params [ ' cache _ security _ groups ' ] NEW_LINE security_group_ids = module . params [ ' security _ group _ ids ' ] NEW_LINE zone = module . params [ ' zone ' ] NEW_LINE wait = module . params [ ' wait ' ] NEW_LINE hard_modify = module . params [ ' hard _ modify ' ] NEW_LINE cache_parameter_group = module . params [ ' cache _ parameter _ group ' ] NEW_LINE if cache_subnet_group and cache_security_groups : NEW_LINE INDENT module . fail_json ( msg = " Can ' t ▁ specify ▁ both ▁ cache _ subnet _ group ▁ and ▁ cache _ security _ groups " ) NEW_LINE DEDENT if state == ' present ' and not num_nodes : NEW_LINE INDENT module . fail_json ( msg = " ' num _ nodes ' ▁ is ▁ a ▁ required ▁ parameter . ▁ Please ▁ specify ▁ num _ nodes ▁ > ▁ 0" ) NEW_LINE DEDENT elasticache_manager = ElastiCacheManager ( module , name , engine , cache_engine_version , node_type , num_nodes , cache_port , cache_parameter_group , cache_subnet_group , cache_security_groups , security_group_ids , zone , wait , hard_modify , region , ** aws_connect_kwargs ) NEW_LINE if state == ' present ' : NEW_LINE INDENT elasticache_manager . ensure_present ( ) NEW_LINE DEDENT elif state == ' absent ' : NEW_LINE INDENT elasticache_manager . ensure_absent ( ) NEW_LINE DEDENT elif state == ' rebooted ' : NEW_LINE INDENT elasticache_manager . ensure_rebooted ( ) NEW_LINE DEDENT facts_result = dict ( changed = elasticache_manager . changed , elasticache = elasticache_manager . get_info ( ) ) NEW_LINE module . exit_json ( ** facts_result ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT
 import unittest NEW_LINE import sys NEW_LINE import os . path NEW_LINE from copy import copy NEW_LINE sys . path . append ( os . path . dirname ( __file__ ) + " / . . / . . / . . " ) NEW_LINE from pox . lib . mock_socket import MockSocket NEW_LINE class MockSocketTest ( unittest . TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT def test_simple_send ( self ) : NEW_LINE INDENT ( a , b ) = MockSocket . pair ( ) NEW_LINE a . send ( " Hallo " ) NEW_LINE self . assertEquals ( b . recv ( ) , " Hallo " ) NEW_LINE b . send ( " Servus " ) NEW_LINE self . assertEquals ( a . recv ( ) , " Servus " ) NEW_LINE DEDENT def test_ready_to_recv ( self ) : NEW_LINE INDENT ( a , b ) = MockSocket . pair ( ) NEW_LINE a . send ( " Hallo " ) NEW_LINE self . assertFalse ( a . ready_to_recv ( ) ) NEW_LINE self . assertTrue ( b . ready_to_recv ( ) ) NEW_LINE self . assertEquals ( b . recv ( ) , " Hallo " ) NEW_LINE self . assertFalse ( b . ready_to_recv ( ) ) NEW_LINE self . assertFalse ( a . ready_to_recv ( ) ) NEW_LINE b . send ( " Servus " ) NEW_LINE self . assertTrue ( a . ready_to_recv ( ) ) NEW_LINE self . assertEquals ( a . recv ( ) , " Servus " ) NEW_LINE self . assertFalse ( a . ready_to_recv ( ) ) NEW_LINE DEDENT def test_on_ready_to_recv ( self ) : NEW_LINE INDENT self . seen_size = - 1 NEW_LINE self . called = 0 NEW_LINE def ready ( socket , size ) : NEW_LINE INDENT self . called += 1 NEW_LINE self . seen_size = size NEW_LINE DEDENT ( a , b ) = MockSocket . pair ( ) NEW_LINE b . set_on_ready_to_recv ( ready ) NEW_LINE self . assertEquals ( self . called , 0 ) NEW_LINE a . send ( " Hallo " ) NEW_LINE self . assertEquals ( self . called , 1 ) NEW_LINE self . assertEquals ( self . seen_size , 5 ) NEW_LINE b . send ( " Huhu " ) NEW_LINE self . assertEquals ( self . called , 1 ) NEW_LINE DEDENT def test_empty_recv ( self ) : NEW_LINE INDENT ( a , b ) = MockSocket . pair ( ) NEW_LINE self . assertEquals ( a . recv ( ) , " " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT unittest . main ( ) NEW_LINE DEDENT
 from __future__ import absolute_import , division , print_function , with_statement NEW_LINE import sys NEW_LINE import time NEW_LINE import copy NEW_LINE import tornado NEW_LINE from tornado import escape NEW_LINE from tornado import httputil NEW_LINE from tornado . log import access_log NEW_LINE from tornado import web NEW_LINE from tornado . escape import native_str , parse_qs_bytes NEW_LINE from tornado . util import bytes_type , unicode_type NEW_LINE try : NEW_LINE INDENT from io import BytesIO NEW_LINE DEDENT except ImportError : NEW_LINE INDENT from cStringIO import StringIO as BytesIO NEW_LINE DEDENT try : NEW_LINE INDENT import Cookie NEW_LINE DEDENT except ImportError : NEW_LINE INDENT import http . cookies as Cookie NEW_LINE DEDENT try : NEW_LINE INDENT import urllib . parse as urllib_parse NEW_LINE DEDENT except ImportError : NEW_LINE INDENT import urllib as urllib_parse NEW_LINE DEDENT if str is unicode_type : NEW_LINE INDENT def to_wsgi_str ( s ) : NEW_LINE INDENT assert isinstance ( s , bytes_type ) NEW_LINE return s . decode ( ' latin1' ) NEW_LINE DEDENT def from_wsgi_str ( s ) : NEW_LINE INDENT assert isinstance ( s , str ) NEW_LINE return s . encode ( ' latin1' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT def to_wsgi_str ( s ) : NEW_LINE INDENT assert isinstance ( s , bytes_type ) NEW_LINE return s NEW_LINE DEDENT def from_wsgi_str ( s ) : NEW_LINE INDENT assert isinstance ( s , str ) NEW_LINE return s NEW_LINE DEDENT DEDENT class WSGIApplication ( web . Application ) : NEW_LINE INDENT def __init__ ( self , handlers = None , default_host = " " , ** settings ) : NEW_LINE INDENT web . Application . __init__ ( self , handlers , default_host , transforms = [ ] , wsgi = True , ** settings ) NEW_LINE DEDENT def __call__ ( self , environ , start_response ) : NEW_LINE INDENT handler = web . Application . __call__ ( self , HTTPRequest ( environ ) ) NEW_LINE assert handler . _finished NEW_LINE reason = handler . _reason NEW_LINE status = str ( handler . _status_code ) + " ▁ " + reason NEW_LINE headers = list ( handler . _headers . get_all ( ) ) NEW_LINE if hasattr ( handler , " _ new _ cookie " ) : NEW_LINE INDENT for cookie in handler . _new_cookie . values ( ) : NEW_LINE INDENT headers . append ( ( " Set - Cookie " , cookie . OutputString ( None ) ) ) NEW_LINE DEDENT DEDENT start_response ( status , [ ( native_str ( k ) , native_str ( v ) ) for ( k , v ) in headers ] ) NEW_LINE return handler . _write_buffer NEW_LINE DEDENT DEDENT class HTTPRequest ( object ) : NEW_LINE INDENT def __init__ ( self , environ ) : NEW_LINE INDENT self . method = environ [ " REQUEST _ METHOD " ] NEW_LINE self . path = urllib_parse . quote ( from_wsgi_str ( environ . get ( " SCRIPT _ NAME " , " " ) ) ) NEW_LINE self . path += urllib_parse . quote ( from_wsgi_str ( environ . get ( " PATH _ INFO " , " " ) ) ) NEW_LINE self . uri = self . path NEW_LINE self . arguments = { } NEW_LINE self . query_arguments = { } NEW_LINE self . body_arguments = { } NEW_LINE self . query = environ . get ( " QUERY _ STRING " , " " ) NEW_LINE if self . query : NEW_LINE INDENT self . uri += " ? " + self . query NEW_LINE self . arguments = parse_qs_bytes ( native_str ( self . query ) , keep_blank_values = True ) NEW_LINE self . query_arguments = copy . deepcopy ( self . arguments ) NEW_LINE DEDENT self . version = " HTTP / 1.1" NEW_LINE self . headers = httputil . HTTPHeaders ( ) NEW_LINE if environ . get ( " CONTENT _ TYPE " ) : NEW_LINE INDENT self . headers [ " Content - Type " ] = environ [ " CONTENT _ TYPE " ] NEW_LINE DEDENT if environ . get ( " CONTENT _ LENGTH " ) : NEW_LINE INDENT self . headers [ " Content - Length " ] = environ [ " CONTENT _ LENGTH " ] NEW_LINE DEDENT for key in environ : NEW_LINE INDENT if key . startswith ( " HTTP _ " ) : NEW_LINE INDENT self . headers [ key [ 5 : ] . replace ( " _ " , " - " ) ] = environ [ key ] NEW_LINE DEDENT DEDENT if self . headers . get ( " Content - Length " ) : NEW_LINE INDENT self . body = environ [ " wsgi . input " ] . read ( int ( self . headers [ " Content - Length " ] ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . body = " " NEW_LINE DEDENT self . protocol = environ [ " wsgi . url _ scheme " ] NEW_LINE self . remote_ip = environ . get ( " REMOTE _ ADDR " , " " ) NEW_LINE if environ . get ( " HTTP _ HOST " ) : NEW_LINE INDENT self . host = environ [ " HTTP _ HOST " ] NEW_LINE DEDENT else : NEW_LINE INDENT self . host = environ [ " SERVER _ NAME " ] NEW_LINE DEDENT self . files = { } NEW_LINE httputil . parse_body_arguments ( self . headers . get ( " Content - Type " , " " ) , self . body , self . body_arguments , self . files ) NEW_LINE for k , v in self . body_arguments . items ( ) : NEW_LINE INDENT self . arguments . setdefault ( k , [ ] ) . extend ( v ) NEW_LINE DEDENT self . _start_time = time . time ( ) NEW_LINE self . _finish_time = None NEW_LINE DEDENT def supports_http_1_1 ( self ) : NEW_LINE INDENT return self . version == " HTTP / 1.1" NEW_LINE DEDENT @ property NEW_LINE def cookies ( self ) : NEW_LINE INDENT if not hasattr ( self , " _ cookies " ) : NEW_LINE INDENT self . _cookies = Cookie . SimpleCookie ( ) NEW_LINE if " Cookie " in self . headers : NEW_LINE INDENT try : NEW_LINE INDENT self . _cookies . load ( native_str ( self . headers [ " Cookie " ] ) ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT self . _cookies = None NEW_LINE DEDENT DEDENT DEDENT return self . _cookies NEW_LINE DEDENT def full_url ( self ) : NEW_LINE INDENT return self . protocol + " : / / " + self . host + self . uri NEW_LINE DEDENT def request_time ( self ) : NEW_LINE INDENT if self . _finish_time is None : NEW_LINE INDENT return time . time ( ) - self . _start_time NEW_LINE DEDENT else : NEW_LINE INDENT return self . _finish_time - self . _start_time NEW_LINE DEDENT DEDENT DEDENT class WSGIContainer ( object ) : NEW_LINE INDENT def __init__ ( self , wsgi_application ) : NEW_LINE INDENT self . wsgi_application = wsgi_application NEW_LINE DEDENT def __call__ ( self , request ) : NEW_LINE INDENT data = { } NEW_LINE response = [ ] NEW_LINE def start_response ( status , response_headers , exc_info = None ) : NEW_LINE INDENT data [ " status " ] = status NEW_LINE data [ " headers " ] = response_headers NEW_LINE return response . append NEW_LINE DEDENT app_response = self . wsgi_application ( WSGIContainer . environ ( request ) , start_response ) NEW_LINE try : NEW_LINE INDENT response . extend ( app_response ) NEW_LINE body = b" " . join ( response ) NEW_LINE DEDENT finally : NEW_LINE INDENT if hasattr ( app_response , " close " ) : NEW_LINE INDENT app_response . close ( ) NEW_LINE DEDENT DEDENT if not data : NEW_LINE INDENT raise Exception ( " WSGI ▁ app ▁ did ▁ not ▁ call ▁ start _ response " ) NEW_LINE DEDENT status_code = int ( data [ " status " ] . split ( ) [ 0 ] ) NEW_LINE headers = data [ " headers " ] NEW_LINE header_set = set ( k . lower ( ) for ( k , v ) in headers ) NEW_LINE body = escape . utf8 ( body ) NEW_LINE if status_code != 304 : NEW_LINE INDENT if " content - length " not in header_set : NEW_LINE INDENT headers . append ( ( " Content - Length " , str ( len ( body ) ) ) ) NEW_LINE DEDENT if " content - type " not in header_set : NEW_LINE INDENT headers . append ( ( " Content - Type " , " text / html ; ▁ charset = UTF - 8" ) ) NEW_LINE DEDENT DEDENT if " server " not in header_set : NEW_LINE INDENT headers . append ( ( " Server " , " TornadoServer / % s " % tornado . version ) ) NEW_LINE DEDENT parts = [ escape . utf8 ( " HTTP / 1.1 ▁ " + data [ " status " ] + " \r \n " ) ] NEW_LINE for key , value in headers : NEW_LINE INDENT parts . append ( escape . utf8 ( key ) + b" : ▁ " + escape . utf8 ( value ) + b" \r \n " ) NEW_LINE DEDENT parts . append ( b" \r \n " ) NEW_LINE parts . append ( body ) NEW_LINE request . write ( b" " . join ( parts ) ) NEW_LINE request . finish ( ) NEW_LINE self . _log ( status_code , request ) NEW_LINE DEDENT @ staticmethod NEW_LINE def environ ( request ) : NEW_LINE INDENT hostport = request . host . split ( " : " ) NEW_LINE if len ( hostport ) == 2 : NEW_LINE INDENT host = hostport [ 0 ] NEW_LINE port = int ( hostport [ 1 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT host = request . host NEW_LINE port = 443 if request . protocol == " https " else 80 NEW_LINE DEDENT environ = { " REQUEST _ METHOD " : request . method , " SCRIPT _ NAME " : " " , " PATH _ INFO " : to_wsgi_str ( escape . url_unescape ( request . path , encoding = None , plus = False ) ) , " QUERY _ STRING " : request . query , " REMOTE _ ADDR " : request . remote_ip , " SERVER _ NAME " : host , " SERVER _ PORT " : str ( port ) , " SERVER _ PROTOCOL " : request . version , " wsgi . version " : ( 1 , 0 ) , " wsgi . url _ scheme " : request . protocol , " wsgi . input " : BytesIO ( escape . utf8 ( request . body ) ) , " wsgi . errors " : sys . stderr , " wsgi . multithread " : False , " wsgi . multiprocess " : True , " wsgi . run _ once " : False , } NEW_LINE if " Content - Type " in request . headers : NEW_LINE INDENT environ [ " CONTENT _ TYPE " ] = request . headers . pop ( " Content - Type " ) NEW_LINE DEDENT if " Content - Length " in request . headers : NEW_LINE INDENT environ [ " CONTENT _ LENGTH " ] = request . headers . pop ( " Content - Length " ) NEW_LINE DEDENT for key , value in request . headers . items ( ) : NEW_LINE INDENT environ [ " HTTP _ " + key . replace ( " - " , " _ " ) . upper ( ) ] = value NEW_LINE DEDENT return environ NEW_LINE DEDENT def _log ( self , status_code , request ) : NEW_LINE INDENT if status_code < 400 : NEW_LINE INDENT log_method = access_log . info NEW_LINE DEDENT elif status_code < 500 : NEW_LINE INDENT log_method = access_log . warning NEW_LINE DEDENT else : NEW_LINE INDENT log_method = access_log . error NEW_LINE DEDENT request_time = 1000.0 * request . request_time ( ) NEW_LINE summary = request . method + " ▁ " + request . uri + " ▁ ( " + \NEW_LINE request . remote_ip + " ) " NEW_LINE log_method ( " % d ▁ % s ▁ % .2fms " , status_code , summary , request_time ) NEW_LINE DEDENT DEDENT
 import os . path , shutil , re NEW_LINE from waflib import Context , Task , Utils , Logs , Options , Errors NEW_LINE from waflib . TaskGen import extension , taskgen_method NEW_LINE from waflib . Configure import conf NEW_LINE class valac ( Task . Task ) : NEW_LINE INDENT vars = [ " VALAC " , " VALAC _ VERSION " , " VALAFLAGS " ] NEW_LINE ext_out = [ ' . h ' ] NEW_LINE def run ( self ) : NEW_LINE INDENT cmd = [ self . env [ ' VALAC ' ] ] + self . env [ ' VALAFLAGS ' ] NEW_LINE cmd . extend ( [ a . abspath ( ) for a in self . inputs ] ) NEW_LINE ret = self . exec_command ( cmd , cwd = self . outputs [ 0 ] . parent . abspath ( ) ) NEW_LINE if ret : NEW_LINE INDENT return ret NEW_LINE DEDENT for x in self . outputs : NEW_LINE INDENT if id ( x . parent ) != id ( self . outputs [ 0 ] . parent ) : NEW_LINE INDENT shutil . move ( self . outputs [ 0 ] . parent . abspath ( ) + os . sep + x . name , x . abspath ( ) ) NEW_LINE DEDENT DEDENT if self . generator . dump_deps_node : NEW_LINE INDENT self . generator . dump_deps_node . write ( ' \n ' . join ( self . generator . packages ) ) NEW_LINE DEDENT return ret NEW_LINE DEDENT DEDENT valac = Task . update_outputs ( valac ) NEW_LINE @ taskgen_method NEW_LINE def init_vala_task ( self ) : NEW_LINE INDENT self . profile = getattr ( self , ' profile ' , ' gobject ' ) NEW_LINE if self . profile == ' gobject ' : NEW_LINE INDENT self . uselib = Utils . to_list ( getattr ( self , ' uselib ' , [ ] ) ) NEW_LINE if not ' GOBJECT ' in self . uselib : NEW_LINE INDENT self . uselib . append ( ' GOBJECT ' ) NEW_LINE DEDENT DEDENT def addflags ( flags ) : NEW_LINE INDENT self . env . append_value ( ' VALAFLAGS ' , flags ) NEW_LINE DEDENT if self . profile : NEW_LINE INDENT addflags ( ' - - profile = % s ' % self . profile ) NEW_LINE DEDENT if hasattr ( self , ' threading ' ) : NEW_LINE INDENT if self . profile == ' gobject ' : NEW_LINE INDENT if not ' GTHREAD ' in self . uselib : NEW_LINE INDENT self . uselib . append ( ' GTHREAD ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT Logs . warn ( " Profile ▁ % s ▁ means ▁ no ▁ threading ▁ support " % self . profile ) NEW_LINE self . threading = False NEW_LINE DEDENT if self . threading : NEW_LINE INDENT addflags ( ' - - threading ' ) NEW_LINE DEDENT DEDENT valatask = self . valatask NEW_LINE self . is_lib = ' cprogram ' not in self . features NEW_LINE if self . is_lib : NEW_LINE INDENT addflags ( ' - - library = % s ' % self . target ) NEW_LINE h_node = self . path . find_or_declare ( ' % s . h ' % self . target ) NEW_LINE valatask . outputs . append ( h_node ) NEW_LINE addflags ( ' - - header = % s ' % h_node . name ) NEW_LINE valatask . outputs . append ( self . path . find_or_declare ( ' % s . vapi ' % self . target ) ) NEW_LINE if getattr ( self , ' gir ' , None ) : NEW_LINE INDENT gir_node = self . path . find_or_declare ( ' % s . gir ' % self . gir ) NEW_LINE addflags ( ' - - gir = % s ' % gir_node . name ) NEW_LINE valatask . outputs . append ( gir_node ) NEW_LINE DEDENT DEDENT self . vala_target_glib = getattr ( self , ' vala _ target _ glib ' , getattr ( Options . options , ' vala _ target _ glib ' , None ) ) NEW_LINE if self . vala_target_glib : NEW_LINE INDENT addflags ( ' - - target - glib = % s ' % self . vala_target_glib ) NEW_LINE DEDENT addflags ( [ ' - - define = % s ' % x for x in getattr ( self , ' vala _ defines ' , [ ] ) ] ) NEW_LINE packages_private = Utils . to_list ( getattr ( self , ' packages _ private ' , [ ] ) ) NEW_LINE addflags ( [ ' - - pkg = % s ' % x for x in packages_private ] ) NEW_LINE def _get_api_version ( ) : NEW_LINE INDENT api_version = '1.0' NEW_LINE if hasattr ( Context . g_module , ' API _ VERSION ' ) : NEW_LINE INDENT version = Context . g_module . API_VERSION . split ( " . " ) NEW_LINE if version [ 0 ] == "0" : NEW_LINE INDENT api_version = "0 . " + version [ 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT api_version = version [ 0 ] + " . 0" NEW_LINE DEDENT DEDENT return api_version NEW_LINE DEDENT self . includes = Utils . to_list ( getattr ( self , ' includes ' , [ ] ) ) NEW_LINE self . uselib = self . to_list ( getattr ( self , ' uselib ' , [ ] ) ) NEW_LINE valatask . install_path = getattr ( self , ' install _ path ' , ' ' ) NEW_LINE valatask . vapi_path = getattr ( self , ' vapi _ path ' , ' $ { DATAROOTDIR } / vala / vapi ' ) NEW_LINE valatask . pkg_name = getattr ( self , ' pkg _ name ' , self . env [ ' PACKAGE ' ] ) NEW_LINE valatask . header_path = getattr ( self , ' header _ path ' , ' $ { INCLUDEDIR } / % s - % s ' % ( valatask . pkg_name , _get_api_version ( ) ) ) NEW_LINE valatask . install_binding = getattr ( self , ' install _ binding ' , True ) NEW_LINE self . packages = packages = Utils . to_list ( getattr ( self , ' packages ' , [ ] ) ) NEW_LINE self . vapi_dirs = vapi_dirs = Utils . to_list ( getattr ( self , ' vapi _ dirs ' , [ ] ) ) NEW_LINE includes = [ ] NEW_LINE if hasattr ( self , ' use ' ) : NEW_LINE INDENT local_packages = Utils . to_list ( self . use ) [ : ] NEW_LINE seen = [ ] NEW_LINE while len ( local_packages ) > 0 : NEW_LINE INDENT package = local_packages . pop ( ) NEW_LINE if package in seen : NEW_LINE INDENT continue NEW_LINE DEDENT seen . append ( package ) NEW_LINE try : NEW_LINE INDENT package_obj = self . bld . get_tgen_by_name ( package ) NEW_LINE DEDENT except Errors . WafError : NEW_LINE INDENT continue NEW_LINE DEDENT package_name = package_obj . target NEW_LINE package_node = package_obj . path NEW_LINE package_dir = package_node . path_from ( self . path ) NEW_LINE for task in package_obj . tasks : NEW_LINE INDENT for output in task . outputs : NEW_LINE INDENT if output . name == package_name + " . vapi " : NEW_LINE INDENT valatask . set_run_after ( task ) NEW_LINE if package_name not in packages : NEW_LINE INDENT packages . append ( package_name ) NEW_LINE DEDENT if package_dir not in vapi_dirs : NEW_LINE INDENT vapi_dirs . append ( package_dir ) NEW_LINE DEDENT if package_dir not in includes : NEW_LINE INDENT includes . append ( package_dir ) NEW_LINE DEDENT DEDENT DEDENT DEDENT if hasattr ( package_obj , ' use ' ) : NEW_LINE INDENT lst = self . to_list ( package_obj . use ) NEW_LINE lst . reverse ( ) NEW_LINE local_packages = [ pkg for pkg in lst if pkg not in seen ] + local_packages NEW_LINE DEDENT DEDENT DEDENT addflags ( [ ' - - pkg = % s ' % p for p in packages ] ) NEW_LINE for vapi_dir in vapi_dirs : NEW_LINE INDENT v_node = self . path . find_dir ( vapi_dir ) NEW_LINE if not v_node : NEW_LINE INDENT Logs . warn ( ' Unable ▁ to ▁ locate ▁ Vala ▁ API ▁ directory : ▁ % r ' % vapi_dir ) NEW_LINE DEDENT else : NEW_LINE INDENT addflags ( ' - - vapidir = % s ' % v_node . abspath ( ) ) NEW_LINE addflags ( ' - - vapidir = % s ' % v_node . get_bld ( ) . abspath ( ) ) NEW_LINE DEDENT DEDENT self . dump_deps_node = None NEW_LINE if self . is_lib and self . packages : NEW_LINE INDENT self . dump_deps_node = self . path . find_or_declare ( ' % s . deps ' % self . target ) NEW_LINE valatask . outputs . append ( self . dump_deps_node ) NEW_LINE DEDENT self . includes . append ( self . bld . srcnode . abspath ( ) ) NEW_LINE self . includes . append ( self . bld . bldnode . abspath ( ) ) NEW_LINE for include in includes : NEW_LINE INDENT try : NEW_LINE INDENT self . includes . append ( self . path . find_dir ( include ) . abspath ( ) ) NEW_LINE self . includes . append ( self . path . find_dir ( include ) . get_bld ( ) . abspath ( ) ) NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT Logs . warn ( " Unable ▁ to ▁ locate ▁ include ▁ directory : ▁ ' % s ' " % include ) NEW_LINE DEDENT DEDENT if self . is_lib and valatask . install_binding : NEW_LINE INDENT headers_list = [ o for o in valatask . outputs if o . suffix ( ) == " . h " ] NEW_LINE try : NEW_LINE INDENT self . install_vheader . source = headers_list NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT self . install_vheader = self . bld . install_files ( valatask . header_path , headers_list , self . env ) NEW_LINE DEDENT vapi_list = [ o for o in valatask . outputs if ( o . suffix ( ) in ( " . vapi " , " . deps " ) ) ] NEW_LINE try : NEW_LINE INDENT self . install_vapi . source = vapi_list NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT self . install_vapi = self . bld . install_files ( valatask . vapi_path , vapi_list , self . env ) NEW_LINE DEDENT gir_list = [ o for o in valatask . outputs if o . suffix ( ) == ' . gir ' ] NEW_LINE try : NEW_LINE INDENT self . install_gir . source = gir_list NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT self . install_gir = self . bld . install_files ( getattr ( self , ' gir _ path ' , ' $ { DATAROOTDIR } / gir - 1.0' ) , gir_list , self . env ) NEW_LINE DEDENT DEDENT DEDENT @ extension ( ' . vala ' , ' . gs ' ) NEW_LINE def vala_file ( self , node ) : NEW_LINE INDENT try : NEW_LINE INDENT valatask = self . valatask NEW_LINE DEDENT except AttributeError : NEW_LINE INDENT valatask = self . valatask = self . create_task ( ' valac ' ) NEW_LINE self . init_vala_task ( ) NEW_LINE DEDENT valatask . inputs . append ( node ) NEW_LINE c_node = node . change_ext ( ' . c ' ) NEW_LINE valatask . outputs . append ( c_node ) NEW_LINE self . source . append ( c_node ) NEW_LINE DEDENT @ conf NEW_LINE def find_valac ( self , valac_name , min_version ) : NEW_LINE INDENT valac = self . find_program ( valac_name , var = ' VALAC ' ) NEW_LINE try : NEW_LINE INDENT output = self . cmd_and_log ( valac + ' ▁ - - version ' ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT valac_version = None NEW_LINE DEDENT else : NEW_LINE INDENT ver = re . search ( r' \d + . \d + . \d + ' , output ) . group ( 0 ) . split ( ' . ' ) NEW_LINE valac_version = tuple ( [ int ( x ) for x in ver ] ) NEW_LINE DEDENT self . msg ( ' Checking ▁ for ▁ % s ▁ version ▁ > = ▁ % r ' % ( valac_name , min_version ) , valac_version , valac_version and valac_version >= min_version ) NEW_LINE if valac and valac_version < min_version : NEW_LINE INDENT self . fatal ( " % s ▁ version ▁ % r ▁ is ▁ too ▁ old , ▁ need ▁ > = ▁ % r " % ( valac_name , valac_version , min_version ) ) NEW_LINE DEDENT self . env [ ' VALAC _ VERSION ' ] = valac_version NEW_LINE return valac NEW_LINE DEDENT @ conf NEW_LINE def check_vala ( self , min_version = ( 0 , 8 , 0 ) , branch = None ) : NEW_LINE INDENT if not branch : NEW_LINE INDENT branch = min_version [ : 2 ] NEW_LINE DEDENT try : NEW_LINE INDENT find_valac ( self , ' valac - % d . % d ' % ( branch [ 0 ] , branch [ 1 ] ) , min_version ) NEW_LINE DEDENT except self . errors . ConfigurationError : NEW_LINE INDENT find_valac ( self , ' valac ' , min_version ) NEW_LINE DEDENT DEDENT @ conf NEW_LINE def check_vala_deps ( self ) : NEW_LINE INDENT if not self . env [ ' HAVE _ GOBJECT ' ] : NEW_LINE INDENT pkg_args = { ' package ' : ' gobject - 2.0' , ' uselib _ store ' : ' GOBJECT ' , ' args ' : ' - - cflags ▁ - - libs ' } NEW_LINE if getattr ( Options . options , ' vala _ target _ glib ' , None ) : NEW_LINE INDENT pkg_args [ ' atleast _ version ' ] = Options . options . vala_target_glib NEW_LINE DEDENT self . check_cfg ( ** pkg_args ) NEW_LINE DEDENT if not self . env [ ' HAVE _ GTHREAD ' ] : NEW_LINE INDENT pkg_args = { ' package ' : ' gthread - 2.0' , ' uselib _ store ' : ' GTHREAD ' , ' args ' : ' - - cflags ▁ - - libs ' } NEW_LINE if getattr ( Options . options , ' vala _ target _ glib ' , None ) : NEW_LINE INDENT pkg_args [ ' atleast _ version ' ] = Options . options . vala_target_glib NEW_LINE DEDENT self . check_cfg ( ** pkg_args ) NEW_LINE DEDENT DEDENT def configure ( self ) : NEW_LINE INDENT self . load ( ' gnu _ dirs ' ) NEW_LINE self . check_vala_deps ( ) NEW_LINE self . check_vala ( ) NEW_LINE self . env . VALAFLAGS = [ ' - C ' , ' - - quiet ' ] NEW_LINE DEDENT def options ( opt ) : NEW_LINE INDENT opt . load ( ' gnu _ dirs ' ) NEW_LINE valaopts = opt . add_option_group ( ' Vala ▁ Compiler ▁ Options ' ) NEW_LINE valaopts . add_option ( ' - - vala - target - glib ' , default = None , dest = ' vala _ target _ glib ' , metavar = ' MAJOR . MINOR ' , help = ' Target ▁ version ▁ of ▁ glib ▁ for ▁ Vala ▁ GObject ▁ code ▁ generation ' ) NEW_LINE DEDENT
 import warnings NEW_LINE from enable . api import Container NEW_LINE from traits . api import Bool , Instance , Property , Str , Tuple NEW_LINE from plot_component import DEFAULT_DRAWING_ORDER , PlotComponent NEW_LINE class BasePlotContainer ( Container ) : NEW_LINE INDENT container_under_layers = Tuple ( " background " , " image " , " underlay " , " plot " ) NEW_LINE draw_order = Instance ( list , args = ( DEFAULT_DRAWING_ORDER , ) ) NEW_LINE draw_layer = Str ( " plot " ) NEW_LINE use_draw_order = Bool ( True ) NEW_LINE plot_components = Property NEW_LINE def _get_plot_components ( self ) : NEW_LINE INDENT warnings . warn ( " Use ▁ of ▁ plot _ components ▁ attribute ▁ deprecated . " " Use ▁ components ▁ attribute ▁ instead . " , DeprecationWarning ) NEW_LINE return self . _components NEW_LINE DEDENT def _set_plot_components ( self , new ) : NEW_LINE INDENT warnings . warn ( " Use ▁ of ▁ plot _ components ▁ attribute ▁ deprecated . " " Use ▁ components ▁ attribute ▁ instead . " , DeprecationWarning ) NEW_LINE self . _components = new NEW_LINE DEDENT def _use_draw_order_changed ( self , old , new ) : NEW_LINE INDENT if new == False : NEW_LINE INDENT raise RuntimeError ( " The ▁ old - style ▁ drawing ▁ mechanism ▁ is ▁ no ▁ longer ▁ " " supported ▁ in ▁ Chaco . " ) NEW_LINE DEDENT DEDENT DEDENT
 from tempest . api . object_storage import base NEW_LINE from tempest import clients NEW_LINE from tempest import exceptions NEW_LINE from tempest import test NEW_LINE class AccountNegativeTest ( base . BaseObjectTest ) : NEW_LINE INDENT @ test . attr ( type = [ ' negative ' , ' gate ' ] ) NEW_LINE def test_list_containers_with_non_authorized_user ( self ) : NEW_LINE INDENT self . data . setup_test_user ( ) NEW_LINE test_os = clients . Manager ( self . data . test_credentials ) NEW_LINE test_auth_provider = test_os . auth_provider NEW_LINE test_auth_provider . auth_data NEW_LINE delattr ( test_auth_provider , ' auth _ data ' ) NEW_LINE test_auth_new_data = test_auth_provider . auth_data NEW_LINE self . custom_account_client . auth_provider . set_alt_auth_data ( request_part = ' headers ' , auth_data = test_auth_new_data ) NEW_LINE params = { ' format ' : ' json ' } NEW_LINE self . assertRaises ( exceptions . Unauthorized , self . custom_account_client . list_account_containers , params = params ) NEW_LINE DEDENT DEDENT
 from esc import NUL , blank NEW_LINE import escargs NEW_LINE import esccmd NEW_LINE import escio NEW_LINE from esctypes import Point , Rect NEW_LINE from escutil import AssertEQ , AssertScreenCharsInRectEqual , GetCursorPosition , knownBug NEW_LINE class ELTests ( object ) : NEW_LINE INDENT def prepare ( self ) : NEW_LINE INDENT esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE escio . Write ( " abcdefghij " ) NEW_LINE esccmd . CUP ( Point ( 5 , 1 ) ) NEW_LINE DEDENT def test_EL_Default ( self ) : NEW_LINE INDENT self . prepare ( ) NEW_LINE esccmd . EL ( ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ " abcd " + 6 * NUL ] ) NEW_LINE DEDENT def test_EL_0 ( self ) : NEW_LINE INDENT self . prepare ( ) NEW_LINE esccmd . EL ( 0 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ " abcd " + 6 * NUL ] ) NEW_LINE DEDENT def test_EL_1 ( self ) : NEW_LINE INDENT self . prepare ( ) NEW_LINE esccmd . EL ( 1 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 5 * blank ( ) + " fghij " ] ) NEW_LINE DEDENT def test_EL_2 ( self ) : NEW_LINE INDENT self . prepare ( ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 10 * NUL ] ) NEW_LINE DEDENT def test_EL_IgnoresScrollRegion ( self ) : NEW_LINE INDENT self . prepare ( ) NEW_LINE esccmd . DECSET ( esccmd . DECLRMM ) NEW_LINE esccmd . DECSLRM ( 2 , 4 ) NEW_LINE esccmd . CUP ( Point ( 5 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE esccmd . DECRESET ( esccmd . DECLRMM ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 10 * NUL ] ) NEW_LINE DEDENT def test_EL_doesNotRespectDECProtection ( self ) : NEW_LINE INDENT escio . Write ( " a " ) NEW_LINE escio . Write ( " b " ) NEW_LINE esccmd . DECSCA ( 1 ) NEW_LINE escio . Write ( " c " ) NEW_LINE esccmd . DECSCA ( 0 ) NEW_LINE esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 3 , 1 ) , [ NUL * 3 ] ) NEW_LINE DEDENT @ knownBug ( terminal = " iTerm2" , reason = " Protection ▁ not ▁ implemented . " ) NEW_LINE def test_EL_respectsISOProtection ( self ) : NEW_LINE INDENT escio . Write ( " a " ) NEW_LINE escio . Write ( " b " ) NEW_LINE esccmd . SPA ( ) NEW_LINE escio . Write ( " c " ) NEW_LINE esccmd . EPA ( ) NEW_LINE esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 3 , 1 ) , [ blank ( ) * 2 + " c " ] ) NEW_LINE DEDENT DEDENT
 __author__ = " Dilawar ▁ Singh " NEW_LINE __copyright__ = " Copyright ▁ 2015 , ▁ Dilawar ▁ Singh ▁ and ▁ NCBS ▁ Bangalore " NEW_LINE __credits__ = [ " NCBS ▁ Bangalore " ] NEW_LINE __license__ = " GNU ▁ GPL " NEW_LINE __version__ = "1.0.0" NEW_LINE __maintainer__ = " Dilawar ▁ Singh " NEW_LINE __email__ = " dilawars @ ncbs . res . in " NEW_LINE __status__ = " Development " NEW_LINE import moose NEW_LINE import pylab NEW_LINE model = None NEW_LINE soma = None NEW_LINE vmtab = None NEW_LINE def buildModel ( ) : NEW_LINE INDENT global model NEW_LINE global soma NEW_LINE model = moose . Neutral ( ' / model ' ) NEW_LINE soma = moose . Compartment ( ' / model / soma ' ) NEW_LINE soma . Em = - 60e-3 NEW_LINE soma . Rm = 1e10 NEW_LINE soma . Cm = 1e-10 NEW_LINE return model NEW_LINE DEDENT def stimulus ( ) : NEW_LINE INDENT global soma NEW_LINE global vmtab NEW_LINE pulse = moose . PulseGen ( ' / model / pulse ' ) NEW_LINE pulse . delay [ 0 ] = 50e-3 NEW_LINE pulse . width [ 0 ] = 100e-3 NEW_LINE pulse . level [ 0 ] = 1e-9 NEW_LINE pulse . delay [ 1 ] = 1e9 NEW_LINE vmtab = moose . Table ( ' / soma _ Vm ' ) NEW_LINE moose . connect ( pulse , ' output ' , soma , ' injectMsg ' ) NEW_LINE moose . connect ( vmtab , ' requestOut ' , soma , ' getVm ' ) NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT global vmtab NEW_LINE buildModel ( ) NEW_LINE stimulus ( ) NEW_LINE moose . reinit ( ) NEW_LINE t = 500e-2 NEW_LINE moose . start ( t ) NEW_LINE time_vector = pylab . linspace ( 0 , t , len ( vmtab . vector ) ) NEW_LINE pylab . plot ( time_vector , vmtab . vector ) NEW_LINE pylab . show ( ) NEW_LINE NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT main ( ) NEW_LINE DEDENT
 def upgrade ( migrate_engine ) : NEW_LINE INDENT pass NEW_LINE DEDENT
 from telemetry . page import page as page_module NEW_LINE from telemetry . page import page_set as page_set_module NEW_LINE class SkiaBuildbotDesktopPage ( page_module . Page ) : NEW_LINE INDENT def __init__ ( self , url , page_set ) : NEW_LINE INDENT super ( SkiaBuildbotDesktopPage , self ) . __init__ ( url = url , page_set = page_set , credentials_path = ' data / credentials . json ' ) NEW_LINE self . user_agent_type = ' desktop ' NEW_LINE self . archive_data_file = ' data / skia _ youtube _ desktop . json ' NEW_LINE DEDENT def RunNavigateSteps ( self , action_runner ) : NEW_LINE INDENT action_runner . NavigateToPage ( self ) NEW_LINE action_runner . Wait ( 25 ) NEW_LINE DEDENT DEDENT class SkiaYoutubeDesktopPageSet ( page_set_module . PageSet ) : NEW_LINE INDENT def __init__ ( self ) : NEW_LINE INDENT super ( SkiaYoutubeDesktopPageSet , self ) . __init__ ( user_agent_type = ' desktop ' , archive_data_file = ' data / skia _ youtube _ desktop . json ' ) NEW_LINE urls_list = [ ' http : / / www . youtube . com / watch ? v = PC57z - oDPLs ' , ] NEW_LINE for url in urls_list : NEW_LINE INDENT self . AddPage ( SkiaBuildbotDesktopPage ( url , self ) ) NEW_LINE DEDENT DEDENT DEDENT
 __author__ = ' robbyw @ google . com ▁ ( Robert ▁ Walker ) ' NEW_LINE import re NEW_LINE import gflags as flags NEW_LINE from closure_linter import errors NEW_LINE from closure_linter import javascriptstatetracker NEW_LINE from closure_linter import javascripttokens NEW_LINE from closure_linter import requireprovidesorter NEW_LINE from closure_linter import tokenutil NEW_LINE from closure_linter . common import errorhandler NEW_LINE Token = javascripttokens . JavaScriptToken NEW_LINE Type = javascripttokens . JavaScriptTokenType NEW_LINE END_OF_FLAG_TYPE = re . compile ( r' ( } ? \s * ) $ ' ) NEW_LINE INVERTED_AUTHOR_SPEC = re . compile ( r' ( ? P < leading _ whitespace > \s * ) ' ' ( ? P < name > [ ^ ( ] + ) ' ' ( ? P < whitespace _ after _ name > \s + ) ' ' \ ( ' ' ( ? P < email > [ ^ \s ] + @ [ ^ ) \s ] + ) ' ' \ ) ' ' ( ? P < trailing _ characters > . * ) ' ) NEW_LINE FLAGS = flags . FLAGS NEW_LINE flags . DEFINE_boolean ( ' disable _ indentation _ fixing ' , False , ' Whether ▁ to ▁ disable ▁ automatic ▁ fixing ▁ of ▁ indentation . ' ) NEW_LINE class ErrorFixer ( errorhandler . ErrorHandler ) : NEW_LINE INDENT def __init__ ( self , external_file = None ) : NEW_LINE INDENT errorhandler . ErrorHandler . __init__ ( self ) NEW_LINE self . _file_name = None NEW_LINE self . _file_token = None NEW_LINE self . _external_file = external_file NEW_LINE DEDENT def HandleFile ( self , filename , first_token ) : NEW_LINE INDENT self . _file_name = filename NEW_LINE self . _file_token = first_token NEW_LINE self . _file_fix_count = 0 NEW_LINE self . _file_changed_lines = set ( ) NEW_LINE DEDENT def _AddFix ( self , tokens ) : NEW_LINE INDENT self . _file_fix_count += 1 NEW_LINE if hasattr ( tokens , ' line _ number ' ) : NEW_LINE INDENT self . _file_changed_lines . add ( tokens . line_number ) NEW_LINE DEDENT else : NEW_LINE INDENT for token in tokens : NEW_LINE INDENT self . _file_changed_lines . add ( token . line_number ) NEW_LINE DEDENT DEDENT DEDENT def HandleError ( self , error ) : NEW_LINE INDENT code = error . code NEW_LINE token = error . token NEW_LINE if code == errors . JSDOC_PREFER_QUESTION_TO_PIPE_NULL : NEW_LINE INDENT iterator = token . attached_object . type_start_token NEW_LINE if iterator . type == Type . DOC_START_BRACE or iterator . string . isspace ( ) : NEW_LINE INDENT iterator = iterator . next NEW_LINE DEDENT leading_space = len ( iterator . string ) - len ( iterator . string . lstrip ( ) ) NEW_LINE iterator . string = ' % s ? % s ' % ( ' ▁ ' * leading_space , iterator . string . lstrip ( ) ) NEW_LINE while iterator and iterator != token . attached_object . type_end_token . next : NEW_LINE INDENT iterator . string = iterator . string . replace ( ' null | ' , ' ' ) . replace ( ' | null ' , ' ' ) NEW_LINE iterator = iterator . next NEW_LINE DEDENT token . attached_object = javascriptstatetracker . JsDocFlag ( token ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . JSDOC_MISSING_OPTIONAL_TYPE : NEW_LINE INDENT iterator = token . attached_object . type_end_token NEW_LINE if iterator . type == Type . DOC_END_BRACE or iterator . string . isspace ( ) : NEW_LINE INDENT iterator = iterator . previous NEW_LINE DEDENT ending_space = len ( iterator . string ) - len ( iterator . string . rstrip ( ) ) NEW_LINE iterator . string = ' % s = % s ' % ( iterator . string . rstrip ( ) , ' ▁ ' * ending_space ) NEW_LINE token . attached_object = javascriptstatetracker . JsDocFlag ( token ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code in ( errors . MISSING_SEMICOLON_AFTER_FUNCTION , errors . MISSING_SEMICOLON ) : NEW_LINE INDENT semicolon_token = Token ( ' ; ' , Type . SEMICOLON , token . line , token . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( semicolon_token , token ) NEW_LINE token . metadata . is_implied_semicolon = False NEW_LINE semicolon_token . metadata . is_implied_semicolon = False NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code in ( errors . ILLEGAL_SEMICOLON_AFTER_FUNCTION , errors . REDUNDANT_SEMICOLON , errors . COMMA_AT_END_OF_LITERAL ) : NEW_LINE INDENT tokenutil . DeleteToken ( token ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . INVALID_JSDOC_TAG : NEW_LINE INDENT if token . string == ' @ returns ' : NEW_LINE INDENT token . string = ' @ return ' NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif code == errors . FILE_MISSING_NEWLINE : NEW_LINE INDENT self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . MISSING_SPACE : NEW_LINE INDENT if error . position : NEW_LINE INDENT if error . position . IsAtBeginning ( ) : NEW_LINE INDENT tokenutil . InsertSpaceTokenAfter ( token . previous ) NEW_LINE DEDENT elif error . position . IsAtEnd ( token . string ) : NEW_LINE INDENT tokenutil . InsertSpaceTokenAfter ( token ) NEW_LINE DEDENT else : NEW_LINE INDENT token . string = error . position . Set ( token . string , ' ▁ ' ) NEW_LINE DEDENT self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif code == errors . EXTRA_SPACE : NEW_LINE INDENT if error . position : NEW_LINE INDENT token . string = error . position . Set ( token . string , ' ' ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif code == errors . JSDOC_TAG_DESCRIPTION_ENDS_WITH_INVALID_CHARACTER : NEW_LINE INDENT token . string = error . position . Set ( token . string , ' . ' ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . MISSING_LINE : NEW_LINE INDENT if error . position . IsAtBeginning ( ) : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( token . previous ) NEW_LINE DEDENT else : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( token ) NEW_LINE DEDENT self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . EXTRA_LINE : NEW_LINE INDENT tokenutil . DeleteToken ( token ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT elif code == errors . WRONG_BLANK_LINE_COUNT : NEW_LINE INDENT if not token . previous : NEW_LINE INDENT return NEW_LINE DEDENT num_lines = error . fix_data NEW_LINE should_delete = False NEW_LINE if num_lines < 0 : NEW_LINE INDENT num_lines *= - 1 NEW_LINE should_delete = True NEW_LINE DEDENT for i in xrange ( 1 , num_lines + 1 ) : NEW_LINE INDENT if should_delete : NEW_LINE INDENT tokenutil . DeleteToken ( token . previous ) NEW_LINE DEDENT else : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( token . previous ) NEW_LINE DEDENT self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif code == errors . UNNECESSARY_DOUBLE_QUOTED_STRING : NEW_LINE INDENT end_quote = tokenutil . Search ( token , Type . DOUBLE_QUOTE_STRING_END ) NEW_LINE if end_quote : NEW_LINE INDENT single_quote_start = Token ( " ' " , Type . SINGLE_QUOTE_STRING_START , token . line , token . line_number ) NEW_LINE single_quote_end = Token ( " ' " , Type . SINGLE_QUOTE_STRING_START , end_quote . line , token . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( single_quote_start , token ) NEW_LINE tokenutil . InsertTokenAfter ( single_quote_end , end_quote ) NEW_LINE tokenutil . DeleteToken ( token ) NEW_LINE tokenutil . DeleteToken ( end_quote ) NEW_LINE self . _AddFix ( [ token , end_quote ] ) NEW_LINE DEDENT DEDENT elif code == errors . MISSING_BRACES_AROUND_TYPE : NEW_LINE INDENT fixed_tokens = [ ] NEW_LINE start_token = token . attached_object . type_start_token NEW_LINE if start_token . type != Type . DOC_START_BRACE : NEW_LINE INDENT leading_space = ( len ( start_token . string ) - len ( start_token . string . lstrip ( ) ) ) NEW_LINE if leading_space : NEW_LINE INDENT start_token = tokenutil . SplitToken ( start_token , leading_space ) NEW_LINE if token . attached_object . type_end_token == start_token . previous : NEW_LINE INDENT token . attached_object . type_end_token = start_token NEW_LINE DEDENT DEDENT new_token = Token ( ' { ' , Type . DOC_START_BRACE , start_token . line , start_token . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( new_token , start_token . previous ) NEW_LINE token . attached_object . type_start_token = new_token NEW_LINE fixed_tokens . append ( new_token ) NEW_LINE DEDENT end_token = token . attached_object . type_end_token NEW_LINE if end_token . type != Type . DOC_END_BRACE : NEW_LINE INDENT last_type = end_token NEW_LINE if not fixed_tokens : NEW_LINE INDENT last_type = end_token . previous NEW_LINE DEDENT while last_type . string . isspace ( ) : NEW_LINE INDENT last_type = last_type . previous NEW_LINE DEDENT if last_type . type != Type . DOC_END_BRACE : NEW_LINE INDENT trailing_space = ( len ( last_type . string ) - len ( last_type . string . rstrip ( ) ) ) NEW_LINE if trailing_space : NEW_LINE INDENT tokenutil . SplitToken ( last_type , len ( last_type . string ) - trailing_space ) NEW_LINE DEDENT new_token = Token ( ' } ' , Type . DOC_END_BRACE , last_type . line , last_type . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( new_token , last_type ) NEW_LINE token . attached_object . type_end_token = new_token NEW_LINE fixed_tokens . append ( new_token ) NEW_LINE DEDENT DEDENT self . _AddFix ( fixed_tokens ) NEW_LINE DEDENT elif code == errors . GOOG_REQUIRES_NOT_ALPHABETIZED : NEW_LINE INDENT require_start_token = error . fix_data NEW_LINE sorter = requireprovidesorter . RequireProvideSorter ( ) NEW_LINE sorter . FixRequires ( require_start_token ) NEW_LINE self . _AddFix ( require_start_token ) NEW_LINE DEDENT elif code == errors . GOOG_PROVIDES_NOT_ALPHABETIZED : NEW_LINE INDENT provide_start_token = error . fix_data NEW_LINE sorter = requireprovidesorter . RequireProvideSorter ( ) NEW_LINE sorter . FixProvides ( provide_start_token ) NEW_LINE self . _AddFix ( provide_start_token ) NEW_LINE DEDENT elif code == errors . UNNECESSARY_BRACES_AROUND_INHERIT_DOC : NEW_LINE INDENT if token . previous . string == ' { ' and token . next . string == ' } ' : NEW_LINE INDENT tokenutil . DeleteToken ( token . previous ) NEW_LINE tokenutil . DeleteToken ( token . next ) NEW_LINE self . _AddFix ( [ token ] ) NEW_LINE DEDENT DEDENT elif code == errors . INVALID_AUTHOR_TAG_DESCRIPTION : NEW_LINE INDENT match = INVERTED_AUTHOR_SPEC . match ( token . string ) NEW_LINE if match : NEW_LINE INDENT token . string = ' % s % s % s ( % s ) % s ' % ( match . group ( ' leading _ whitespace ' ) , match . group ( ' email ' ) , match . group ( ' whitespace _ after _ name ' ) , match . group ( ' name ' ) , match . group ( ' trailing _ characters ' ) ) NEW_LINE self . _AddFix ( token ) NEW_LINE DEDENT DEDENT elif ( code == errors . WRONG_INDENTATION and not FLAGS . disable_indentation_fixing ) : NEW_LINE INDENT token = tokenutil . GetFirstTokenInSameLine ( token ) NEW_LINE actual = error . position . start NEW_LINE expected = error . position . length NEW_LINE if token . type in ( Type . WHITESPACE , Type . PARAMETERS ) and actual != 0 : NEW_LINE INDENT token . string = token . string . lstrip ( ) + ( ' ▁ ' * expected ) NEW_LINE self . _AddFix ( [ token ] ) NEW_LINE DEDENT else : NEW_LINE INDENT new_token = Token ( ' ▁ ' * expected , Type . WHITESPACE , token . line , token . line_number ) NEW_LINE tokenutil . InsertTokenAfter ( new_token , token . previous ) NEW_LINE self . _AddFix ( [ token ] ) NEW_LINE DEDENT DEDENT elif code in [ errors . MALFORMED_END_OF_SCOPE_COMMENT , errors . MISSING_END_OF_SCOPE_COMMENT ] : NEW_LINE INDENT if ( token . type == Type . END_BLOCK and token . next . type == Type . END_PAREN and token . next . next . type == Type . SEMICOLON ) : NEW_LINE INDENT current_token = token . next . next . next NEW_LINE removed_tokens = [ ] NEW_LINE while current_token and current_token . line_number == token . line_number : NEW_LINE INDENT if current_token . IsAnyType ( Type . WHITESPACE , Type . START_SINGLE_LINE_COMMENT , Type . COMMENT ) : NEW_LINE INDENT removed_tokens . append ( current_token ) NEW_LINE current_token = current_token . next NEW_LINE DEDENT else : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT if removed_tokens : NEW_LINE INDENT tokenutil . DeleteTokens ( removed_tokens [ 0 ] , len ( removed_tokens ) ) NEW_LINE DEDENT whitespace_token = Token ( ' ▁ ▁ ' , Type . WHITESPACE , token . line , token . line_number ) NEW_LINE start_comment_token = Token ( ' / / ' , Type . START_SINGLE_LINE_COMMENT , token . line , token . line_number ) NEW_LINE comment_token = Token ( ' ▁ goog . scope ' , Type . COMMENT , token . line , token . line_number ) NEW_LINE insertion_tokens = [ whitespace_token , start_comment_token , comment_token ] NEW_LINE tokenutil . InsertTokensAfter ( insertion_tokens , token . next . next ) NEW_LINE self . _AddFix ( removed_tokens + insertion_tokens ) NEW_LINE DEDENT DEDENT elif code in [ errors . EXTRA_GOOG_PROVIDE , errors . EXTRA_GOOG_REQUIRE ] : NEW_LINE INDENT tokens_in_line = tokenutil . GetAllTokensInSameLine ( token ) NEW_LINE tokenutil . DeleteTokens ( tokens_in_line [ 0 ] , len ( tokens_in_line ) ) NEW_LINE self . _AddFix ( tokens_in_line ) NEW_LINE DEDENT elif code in [ errors . MISSING_GOOG_PROVIDE , errors . MISSING_GOOG_REQUIRE ] : NEW_LINE INDENT is_provide = code == errors . MISSING_GOOG_PROVIDE NEW_LINE is_require = code == errors . MISSING_GOOG_REQUIRE NEW_LINE missing_namespaces = error . fix_data [ 0 ] NEW_LINE need_blank_line = error . fix_data [ 1 ] NEW_LINE if need_blank_line is None : NEW_LINE INDENT return NEW_LINE DEDENT insert_location = token . previous NEW_LINE if need_blank_line and is_require : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( insert_location ) NEW_LINE insert_location = insert_location . next NEW_LINE DEDENT for missing_namespace in missing_namespaces : NEW_LINE INDENT new_tokens = self . _GetNewRequireOrProvideTokens ( is_provide , missing_namespace , insert_location . line_number + 1 ) NEW_LINE tokenutil . InsertLineAfter ( insert_location , new_tokens ) NEW_LINE insert_location = new_tokens [ - 1 ] NEW_LINE self . _AddFix ( new_tokens ) NEW_LINE DEDENT if need_blank_line and is_provide : NEW_LINE INDENT tokenutil . InsertBlankLineAfter ( insert_location ) NEW_LINE DEDENT DEDENT DEDENT def _GetNewRequireOrProvideTokens ( self , is_provide , namespace , line_number ) : NEW_LINE INDENT string = ' goog . require ' NEW_LINE if is_provide : NEW_LINE INDENT string = ' goog . provide ' NEW_LINE DEDENT line_text = string + ' ( \ ' ' + namespace + ' \ ' ) ; \n ' NEW_LINE return [ Token ( string , Type . IDENTIFIER , line_text , line_number ) , Token ( ' ( ' , Type . START_PAREN , line_text , line_number ) , Token ( ' \ ' ' , Type . SINGLE_QUOTE_STRING_START , line_text , line_number ) , Token ( namespace , Type . STRING_TEXT , line_text , line_number ) , Token ( ' \ ' ' , Type . SINGLE_QUOTE_STRING_END , line_text , line_number ) , Token ( ' ) ' , Type . END_PAREN , line_text , line_number ) , Token ( ' ; ' , Type . SEMICOLON , line_text , line_number ) ] NEW_LINE DEDENT def FinishFile ( self ) : NEW_LINE INDENT if self . _file_fix_count : NEW_LINE INDENT f = self . _external_file NEW_LINE if not f : NEW_LINE INDENT print ' Fixed ▁ % d ▁ errors ▁ in ▁ % s ' % ( self . _file_fix_count , self . _file_name ) NEW_LINE f = open ( self . _file_name , ' w ' ) NEW_LINE DEDENT token = self . _file_token NEW_LINE char_count = 0 NEW_LINE while token : NEW_LINE INDENT f . write ( token . string ) NEW_LINE char_count += len ( token . string ) NEW_LINE if token . IsLastInLine ( ) : NEW_LINE INDENT f . write ( ' \n ' ) NEW_LINE if char_count > 80 and token . line_number in self . _file_changed_lines : NEW_LINE INDENT print ' WARNING : ▁ Line ▁ % d ▁ of ▁ % s ▁ is ▁ now ▁ longer ▁ than ▁ 80 ▁ characters . ' % ( token . line_number , self . _file_name ) NEW_LINE DEDENT char_count = 0 NEW_LINE DEDENT token = token . next NEW_LINE DEDENT if not self . _external_file : NEW_LINE INDENT f . close ( ) NEW_LINE DEDENT DEDENT DEDENT DEDENT
 import asyncore NEW_LINE import base64 NEW_LINE import mimetypes NEW_LINE import os NEW_LINE import shutil NEW_LINE import smtpd NEW_LINE import socket NEW_LINE import sys NEW_LINE import tempfile NEW_LINE import threading NEW_LINE from email import message_from_binary_file , message_from_bytes NEW_LINE from email . header import Header NEW_LINE from email . mime . text import MIMEText NEW_LINE from email . utils import parseaddr NEW_LINE from io import StringIO NEW_LINE from smtplib import SMTP , SMTPAuthenticationError , SMTPException NEW_LINE from ssl import SSLError NEW_LINE from django . core import mail NEW_LINE from django . core . mail import ( EmailMessage , EmailMultiAlternatives , mail_admins , mail_managers , send_mail , send_mass_mail , ) NEW_LINE from django . core . mail . backends import console , dummy , filebased , locmem , smtp NEW_LINE from django . core . mail . message import BadHeaderError , sanitize_address NEW_LINE from django . test import SimpleTestCase , override_settings NEW_LINE from django . test . utils import requires_tz_support NEW_LINE from django . utils . encoding import force_bytes , force_text NEW_LINE from django . utils . translation import gettext_lazy NEW_LINE class HeadersCheckMixin : NEW_LINE INDENT def assertMessageHasHeaders ( self , message , headers ) : NEW_LINE INDENT if isinstance ( message , bytes ) : NEW_LINE INDENT message = message_from_bytes ( message ) NEW_LINE DEDENT msg_headers = set ( message . items ( ) ) NEW_LINE self . assertTrue ( headers . issubset ( msg_headers ) , msg = ' Message ▁ is ▁ missing ▁ ' ' the ▁ following ▁ headers : ▁ % s ' % ( headers - msg_headers ) , ) NEW_LINE DEDENT DEDENT class MailTests ( HeadersCheckMixin , SimpleTestCase ) : NEW_LINE INDENT def get_decoded_attachments ( self , django_message ) : NEW_LINE INDENT msg_bytes = django_message . message ( ) . as_bytes ( ) NEW_LINE email_message = message_from_bytes ( msg_bytes ) NEW_LINE def iter_attachments ( ) : NEW_LINE INDENT for i in email_message . walk ( ) : NEW_LINE INDENT content_disposition = i . get ( ' content - disposition ' , ' ' ) . split ( ' ; ' ) [ 0 ] . lower ( ) NEW_LINE if content_disposition == ' attachment ' : NEW_LINE INDENT filename = i . get_filename ( ) NEW_LINE content = i . get_payload ( decode = True ) NEW_LINE mimetype = i . get_content_type ( ) NEW_LINE yield filename , content , mimetype NEW_LINE DEDENT DEDENT DEDENT return list ( iter_attachments ( ) ) NEW_LINE DEDENT def test_ascii ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Subject ' ] , ' Subject ' ) NEW_LINE self . assertEqual ( message . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE self . assertEqual ( message [ ' To ' ] , ' to @ example . com ' ) NEW_LINE DEDENT def test_multiple_recipients ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' , ' other @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Subject ' ] , ' Subject ' ) NEW_LINE self . assertEqual ( message . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE self . assertEqual ( message [ ' To ' ] , ' to @ example . com , ▁ other @ example . com ' ) NEW_LINE DEDENT def test_recipients_with_empty_strings ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' , ' ' ] , cc = [ ' cc @ example . com ' , ' ' ] , bcc = [ ' ' , ' bcc @ example . com ' ] , reply_to = [ ' ' , None ] , ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' cc @ example . com ' , ' bcc @ example . com ' ] ) NEW_LINE DEDENT def test_cc ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , cc = [ ' cc @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Cc ' ] , ' cc @ example . com ' ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' cc @ example . com ' ] ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' , ' other @ example . com ' ] , cc = [ ' cc @ example . com ' , ' cc . other @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Cc ' ] , ' cc @ example . com , ▁ cc . other @ example . com ' ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' other @ example . com ' , ' cc @ example . com ' , ' cc . other @ example . com ' ] ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' , ' other @ example . com ' ] , cc = [ ' cc @ example . com ' , ' cc . other @ example . com ' ] , bcc = [ ' bcc @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Cc ' ] , ' cc @ example . com , ▁ cc . other @ example . com ' ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' other @ example . com ' , ' cc @ example . com ' , ' cc . other @ example . com ' , ' bcc @ example . com ' ] ) NEW_LINE DEDENT def test_reply_to ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , reply_to = [ ' reply _ to @ example . com ' ] , ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Reply - To ' ] , ' reply _ to @ example . com ' ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , reply_to = [ ' reply _ to1 @ example . com ' , ' reply _ to2 @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Reply - To ' ] , ' reply _ to1 @ example . com , ▁ reply _ to2 @ example . com ' ) NEW_LINE DEDENT def test_recipients_as_tuple ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , ( ' to @ example . com ' , ' other @ example . com ' ) , cc = ( ' cc @ example . com ' , ' cc . other @ example . com ' ) , bcc = ( ' bcc @ example . com ' , ) ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Cc ' ] , ' cc @ example . com , ▁ cc . other @ example . com ' ) NEW_LINE self . assertEqual ( email . recipients ( ) , [ ' to @ example . com ' , ' other @ example . com ' , ' cc @ example . com ' , ' cc . other @ example . com ' , ' bcc @ example . com ' ] ) NEW_LINE DEDENT def test_recipients_as_string ( self ) : NEW_LINE INDENT with self . assertRaisesMessage ( TypeError , ' " to " ▁ argument ▁ must ▁ be ▁ a ▁ list ▁ or ▁ tuple ' ) : NEW_LINE INDENT EmailMessage ( to = ' foo @ example . com ' ) NEW_LINE DEDENT with self . assertRaisesMessage ( TypeError , ' " cc " ▁ argument ▁ must ▁ be ▁ a ▁ list ▁ or ▁ tuple ' ) : NEW_LINE INDENT EmailMessage ( cc = ' foo @ example . com ' ) NEW_LINE DEDENT with self . assertRaisesMessage ( TypeError , ' " bcc " ▁ argument ▁ must ▁ be ▁ a ▁ list ▁ or ▁ tuple ' ) : NEW_LINE INDENT EmailMessage ( bcc = ' foo @ example . com ' ) NEW_LINE DEDENT with self . assertRaisesMessage ( TypeError , ' " reply _ to " ▁ argument ▁ must ▁ be ▁ a ▁ list ▁ or ▁ tuple ' ) : NEW_LINE INDENT EmailMessage ( reply_to = ' reply _ to @ example . com ' ) NEW_LINE DEDENT DEDENT def test_header_injection ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject \n Injection ▁ Test ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE with self . assertRaises ( BadHeaderError ) : NEW_LINE INDENT email . message ( ) NEW_LINE DEDENT email = EmailMessage ( gettext_lazy ( ' Subject \n Injection ▁ Test ' ) , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE with self . assertRaises ( BadHeaderError ) : NEW_LINE INDENT email . message ( ) NEW_LINE DEDENT DEDENT def test_space_continuation ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Long ▁ subject ▁ lines ▁ that ▁ get ▁ wrapped ▁ should ▁ contain ▁ a ▁ space ▁ ' ' continuation ▁ character ▁ to ▁ get ▁ expected ▁ behavior ▁ in ▁ Outlook ▁ and ▁ Thunderbird ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Subject ' ] . encode ( ) , b' Long ▁ subject ▁ lines ▁ that ▁ get ▁ wrapped ▁ should ▁ contain ▁ a ▁ space ▁ continuation \n ' b' ▁ character ▁ to ▁ get ▁ expected ▁ behavior ▁ in ▁ Outlook ▁ and ▁ Thunderbird ' ) NEW_LINE DEDENT def test_message_header_overrides ( self ) : NEW_LINE INDENT headers = { " date " : " Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000" , " Message - ID " : " foo " } NEW_LINE email = EmailMessage ( ' subject ' , ' content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , headers = headers ) NEW_LINE self . assertMessageHasHeaders ( email . message ( ) , { ( ' Content - Transfer - Encoding ' , '7bit ' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " utf - 8 " ' ) , ( ' From ' , ' from @ example . com ' ) , ( ' MIME - Version ' , '1.0' ) , ( ' Message - ID ' , ' foo ' ) , ( ' Subject ' , ' subject ' ) , ( ' To ' , ' to @ example . com ' ) , ( ' date ' , ' Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000' ) , } ) NEW_LINE DEDENT def test_from_header ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE DEDENT def test_to_header ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' list - subscriber @ example . com ' , ' list - subscriber2 @ example . com ' ] , headers = { ' To ' : ' mailing - list @ example . com ' } ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' To ' ] , ' mailing - list @ example . com ' ) NEW_LINE self . assertEqual ( email . to , [ ' list - subscriber @ example . com ' , ' list - subscriber2 @ example . com ' ] ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' list - subscriber @ example . com ' , ' list - subscriber2 @ example . com ' ] ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' To ' ] , ' list - subscriber @ example . com , ▁ list - subscriber2 @ example . com ' ) NEW_LINE self . assertEqual ( email . to , [ ' list - subscriber @ example . com ' , ' list - subscriber2 @ example . com ' ] ) NEW_LINE DEDENT def test_reply_to_header ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , reply_to = [ ' foo @ example . com ' ] , headers = { ' Reply - To ' : ' override @ example . com ' } , ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Reply - To ' ] , ' override @ example . com ' ) NEW_LINE DEDENT def test_multiple_message_call ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' From ' ] , ' from @ example . com ' ) NEW_LINE DEDENT def test_unicode_address_header ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' " Firstname ▁ Sürname " ▁ < to @ example . com > ' , ' other @ example . com ' ] , ) NEW_LINE self . assertEqual ( email . message ( ) [ ' To ' ] , ' = ? utf - 8 ? q ? Firstname _ S = C3 = BCrname ? = ▁ < to @ example . com > , ▁ other @ example . com ' ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' " Sürname , ▁ Firstname " ▁ < to @ example . com > ' , ' other @ example . com ' ] , ) NEW_LINE self . assertEqual ( email . message ( ) [ ' To ' ] , ' = ? utf - 8 ? q ? S = C3 = BCrname = 2C _ Firstname ? = ▁ < to @ example . com > , ▁ other @ example . com ' ) NEW_LINE DEDENT def test_unicode_headers ( self ) : NEW_LINE INDENT email = EmailMessage ( " Gżegżółka " , " Content " , " from @ example . com " , [ " to @ example . com " ] , headers = { " Sender " : ' " Firstname ▁ Sürname " ▁ < sender @ example . com > ' , " Comments " : ' My ▁ Sürname ▁ is ▁ non - ASCII ' } ) NEW_LINE message = email . message ( ) NEW_LINE self . assertEqual ( message [ ' Subject ' ] , ' = ? utf - 8 ? b ? R8W8ZWfFvMOzxYJrYQ = = ? = ' ) NEW_LINE self . assertEqual ( message [ ' Sender ' ] , ' = ? utf - 8 ? q ? Firstname _ S = C3 = BCrname ? = ▁ < sender @ example . com > ' ) NEW_LINE self . assertEqual ( message [ ' Comments ' ] , ' = ? utf - 8 ? q ? My _ S = C3 = BCrname _ is _ non - ASCII ? = ' ) NEW_LINE DEDENT def test_safe_mime_multipart ( self ) : NEW_LINE INDENT headers = { " Date " : " Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000" , " Message - ID " : " foo " } NEW_LINE from_email , to = ' from @ example . com ' , ' " Sürname , ▁ Firstname " ▁ < to @ example . com > ' NEW_LINE text_content = ' This ▁ is ▁ an ▁ important ▁ message . ' NEW_LINE html_content = ' < p > This ▁ is ▁ an ▁ < strong > important < / strong > ▁ message . < / p > ' NEW_LINE msg = EmailMultiAlternatives ( ' Message ▁ from ▁ Firstname ▁ Sürname ' , text_content , from_email , [ to ] , headers = headers ) NEW_LINE msg . attach_alternative ( html_content , " text / html " ) NEW_LINE msg . encoding = ' iso - 8859-1' NEW_LINE self . assertEqual ( msg . message ( ) [ ' To ' ] , ' = ? iso - 8859-1 ? q ? S = FCrname = 2C _ Firstname ? = ▁ < to @ example . com > ' ) NEW_LINE self . assertEqual ( msg . message ( ) [ ' Subject ' ] , ' = ? iso - 8859-1 ? q ? Message _ from _ Firstname _ S = FCrname ? = ' ) NEW_LINE DEDENT def test_encoding ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Firstname ▁ Sürname ▁ is ▁ a ▁ great ▁ guy . ' , ' from @ example . com ' , [ ' other @ example . com ' ] ) NEW_LINE email . encoding = ' iso - 8859-1' NEW_LINE message = email . message ( ) NEW_LINE self . assertMessageHasHeaders ( message , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " iso - 8859-1 " ' ) , ( ' Content - Transfer - Encoding ' , ' quoted - printable ' ) , ( ' Subject ' , ' Subject ' ) , ( ' From ' , ' from @ example . com ' ) , ( ' To ' , ' other @ example . com ' ) } ) NEW_LINE self . assertEqual ( message . get_payload ( ) , ' Firstname ▁ S = FCrname ▁ is ▁ a ▁ great ▁ guy . ' ) NEW_LINE text_content = ' Firstname ▁ Sürname ▁ is ▁ a ▁ great ▁ guy . ' NEW_LINE html_content = ' < p > Firstname ▁ Sürname ▁ is ▁ a ▁ < strong > great < / strong > ▁ guy . < / p > ' NEW_LINE msg = EmailMultiAlternatives ( ' Subject ' , text_content , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE msg . encoding = ' iso - 8859-1' NEW_LINE msg . attach_alternative ( html_content , " text / html " ) NEW_LINE payload0 = msg . message ( ) . get_payload ( 0 ) NEW_LINE self . assertMessageHasHeaders ( payload0 , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " iso - 8859-1 " ' ) , ( ' Content - Transfer - Encoding ' , ' quoted - printable ' ) } ) NEW_LINE self . assertTrue ( payload0 . as_bytes ( ) . endswith ( b' \n \n Firstname ▁ S = FCrname ▁ is ▁ a ▁ great ▁ guy . ' ) ) NEW_LINE payload1 = msg . message ( ) . get_payload ( 1 ) NEW_LINE self . assertMessageHasHeaders ( payload1 , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / html ; ▁ charset = " iso - 8859-1 " ' ) , ( ' Content - Transfer - Encoding ' , ' quoted - printable ' ) } ) NEW_LINE self . assertTrue ( payload1 . as_bytes ( ) . endswith ( b' \n \n < p > Firstname ▁ S = FCrname ▁ is ▁ a ▁ < strong > great < / strong > ▁ guy . < / p > ' ) ) NEW_LINE DEDENT def test_attachments ( self ) : NEW_LINE INDENT headers = { " Date " : " Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000" , " Message - ID " : " foo " } NEW_LINE subject , from_email , to = ' hello ' , ' from @ example . com ' , ' to @ example . com ' NEW_LINE text_content = ' This ▁ is ▁ an ▁ important ▁ message . ' NEW_LINE html_content = ' < p > This ▁ is ▁ an ▁ < strong > important < / strong > ▁ message . < / p > ' NEW_LINE msg = EmailMultiAlternatives ( subject , text_content , from_email , [ to ] , headers = headers ) NEW_LINE msg . attach_alternative ( html_content , " text / html " ) NEW_LINE msg . attach ( " an ▁ attachment . pdf " , b" % PDF - 1.4 . % . . . " , mimetype = " application / pdf " ) NEW_LINE msg_bytes = msg . message ( ) . as_bytes ( ) NEW_LINE message = message_from_bytes ( msg_bytes ) NEW_LINE self . assertTrue ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( message . get_content_type ( ) , ' multipart / mixed ' ) NEW_LINE self . assertEqual ( message . get_default_type ( ) , ' text / plain ' ) NEW_LINE payload = message . get_payload ( ) NEW_LINE self . assertEqual ( payload [ 0 ] . get_content_type ( ) , ' multipart / alternative ' ) NEW_LINE self . assertEqual ( payload [ 1 ] . get_content_type ( ) , ' application / pdf ' ) NEW_LINE DEDENT def test_non_ascii_attachment_filename ( self ) : NEW_LINE INDENT headers = { " Date " : " Fri , ▁ 09 ▁ Nov ▁ 2001 ▁ 01:08:47 ▁ - 0000" , " Message - ID " : " foo " } NEW_LINE subject , from_email , to = ' hello ' , ' from @ example . com ' , ' to @ example . com ' NEW_LINE content = ' This ▁ is ▁ the ▁ message . ' NEW_LINE msg = EmailMessage ( subject , content , from_email , [ to ] , headers = headers ) NEW_LINE msg . attach ( " une ▁ pièce ▁ jointe . pdf " , b" % PDF - 1.4 . % . . . " , mimetype = " application / pdf " ) NEW_LINE msg_bytes = msg . message ( ) . as_bytes ( ) NEW_LINE message = message_from_bytes ( msg_bytes ) NEW_LINE payload = message . get_payload ( ) NEW_LINE self . assertEqual ( payload [ 1 ] . get_filename ( ) , ' une ▁ pièce ▁ jointe . pdf ' ) NEW_LINE DEDENT def test_attach_file ( self ) : NEW_LINE INDENT files = ( ( ' file . txt ' , ' text / plain ' ) , ( ' file . png ' , ' image / png ' ) , ( ' file _ txt ' , None ) , ( ' file _ png ' , None ) , ( ' file _ txt . png ' , ' image / png ' ) , ( ' file _ png . txt ' , ' text / plain ' ) , ( ' file . eml ' , ' message / rfc822' ) , ) NEW_LINE test_mimetypes = [ ' text / plain ' , ' image / png ' , None ] NEW_LINE for basename , real_mimetype in files : NEW_LINE INDENT for mimetype in test_mimetypes : NEW_LINE INDENT email = EmailMessage ( ' subject ' , ' body ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE self . assertEqual ( mimetypes . guess_type ( basename ) [ 0 ] , real_mimetype ) NEW_LINE self . assertEqual ( email . attachments , [ ] ) NEW_LINE file_path = os . path . join ( os . path . dirname ( __file__ ) , ' attachments ' , basename ) NEW_LINE email . attach_file ( file_path , mimetype = mimetype ) NEW_LINE self . assertEqual ( len ( email . attachments ) , 1 ) NEW_LINE self . assertIn ( basename , email . attachments [ 0 ] ) NEW_LINE msgs_sent_num = email . send ( ) NEW_LINE self . assertEqual ( msgs_sent_num , 1 ) NEW_LINE DEDENT DEDENT DEDENT def test_attach_text_as_bytes ( self ) : NEW_LINE INDENT msg = EmailMessage ( ' subject ' , ' body ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE msg . attach ( ' file . txt ' , b' file ▁ content ' ) NEW_LINE sent_num = msg . send ( ) NEW_LINE self . assertEqual ( sent_num , 1 ) NEW_LINE filename , content , mimetype = self . get_decoded_attachments ( msg ) [ 0 ] NEW_LINE self . assertEqual ( filename , ' file . txt ' ) NEW_LINE self . assertEqual ( content , b' file ▁ content ' ) NEW_LINE self . assertEqual ( mimetype , ' text / plain ' ) NEW_LINE DEDENT def test_attach_utf8_text_as_bytes ( self ) : NEW_LINE INDENT msg = EmailMessage ( ' subject ' , ' body ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE msg . attach ( ' file . txt ' , b' \xc3\xa4' ) NEW_LINE filename , content , mimetype = self . get_decoded_attachments ( msg ) [ 0 ] NEW_LINE self . assertEqual ( filename , ' file . txt ' ) NEW_LINE self . assertEqual ( content , b' \xc3\xa4' ) NEW_LINE self . assertEqual ( mimetype , ' text / plain ' ) NEW_LINE DEDENT def test_attach_non_utf8_text_as_bytes ( self ) : NEW_LINE INDENT msg = EmailMessage ( ' subject ' , ' body ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE msg . attach ( ' file . txt ' , b' \xff ' ) NEW_LINE filename , content , mimetype = self . get_decoded_attachments ( msg ) [ 0 ] NEW_LINE self . assertEqual ( filename , ' file . txt ' ) NEW_LINE self . assertEqual ( content , b' \xff ' ) NEW_LINE self . assertEqual ( mimetype , ' application / octet - stream ' ) NEW_LINE DEDENT def test_dummy_backend ( self ) : NEW_LINE INDENT connection = dummy . EmailBackend ( ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE self . assertEqual ( connection . send_messages ( [ email , email , email ] ) , 3 ) NEW_LINE DEDENT def test_arbitrary_keyword ( self ) : NEW_LINE INDENT c = mail . get_connection ( fail_silently = True , foo = ' bar ' ) NEW_LINE self . assertTrue ( c . fail_silently ) NEW_LINE DEDENT def test_custom_backend ( self ) : NEW_LINE INDENT conn = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE self . assertTrue ( hasattr ( conn , ' test _ outbox ' ) ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE conn . send_messages ( [ email ] ) NEW_LINE self . assertEqual ( len ( conn . test_outbox ) , 1 ) NEW_LINE DEDENT def test_backend_arg ( self ) : NEW_LINE INDENT self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . smtp . EmailBackend ' ) , smtp . EmailBackend ) NEW_LINE self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . locmem . EmailBackend ' ) , locmem . EmailBackend ) NEW_LINE self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . dummy . EmailBackend ' ) , dummy . EmailBackend ) NEW_LINE self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . console . EmailBackend ' ) , console . EmailBackend ) NEW_LINE with tempfile . TemporaryDirectory ( ) as tmp_dir : NEW_LINE INDENT self . assertIsInstance ( mail . get_connection ( ' django . core . mail . backends . filebased . EmailBackend ' , file_path = tmp_dir ) , filebased . EmailBackend ) NEW_LINE DEDENT self . assertIsInstance ( mail . get_connection ( ) , locmem . EmailBackend ) NEW_LINE DEDENT @ override_settings ( EMAIL_BACKEND = ' django . core . mail . backends . locmem . EmailBackend ' , ADMINS = [ ( ' nobody ' , ' nobody @ example . com ' ) ] , MANAGERS = [ ( ' nobody ' , ' nobody @ example . com ' ) ] ) NEW_LINE def test_connection_arg ( self ) : NEW_LINE INDENT mail . outbox = [ ] NEW_LINE connection = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE send_mail ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , connection = connection ) NEW_LINE self . assertEqual ( mail . outbox , [ ] ) NEW_LINE self . assertEqual ( len ( connection . test_outbox ) , 1 ) NEW_LINE self . assertEqual ( connection . test_outbox [ 0 ] . subject , ' Subject ' ) NEW_LINE connection = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE send_mass_mail ( [ ( ' Subject1' , ' Content1' , ' from1 @ example . com ' , [ ' to1 @ example . com ' ] ) , ( ' Subject2' , ' Content2' , ' from2 @ example . com ' , [ ' to2 @ example . com ' ] ) , ] , connection = connection ) NEW_LINE self . assertEqual ( mail . outbox , [ ] ) NEW_LINE self . assertEqual ( len ( connection . test_outbox ) , 2 ) NEW_LINE self . assertEqual ( connection . test_outbox [ 0 ] . subject , ' Subject1' ) NEW_LINE self . assertEqual ( connection . test_outbox [ 1 ] . subject , ' Subject2' ) NEW_LINE connection = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE mail_admins ( ' Admin ▁ message ' , ' Content ' , connection = connection ) NEW_LINE self . assertEqual ( mail . outbox , [ ] ) NEW_LINE self . assertEqual ( len ( connection . test_outbox ) , 1 ) NEW_LINE self . assertEqual ( connection . test_outbox [ 0 ] . subject , ' [ Django ] ▁ Admin ▁ message ' ) NEW_LINE connection = mail . get_connection ( ' mail . custombackend . EmailBackend ' ) NEW_LINE mail_managers ( ' Manager ▁ message ' , ' Content ' , connection = connection ) NEW_LINE self . assertEqual ( mail . outbox , [ ] ) NEW_LINE self . assertEqual ( len ( connection . test_outbox ) , 1 ) NEW_LINE self . assertEqual ( connection . test_outbox [ 0 ] . subject , ' [ Django ] ▁ Manager ▁ message ' ) NEW_LINE DEDENT def test_dont_mangle_from_in_body ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' From ▁ the ▁ future ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE self . assertNotIn ( b' > From ▁ the ▁ future ' , email . message ( ) . as_bytes ( ) ) NEW_LINE DEDENT def test_dont_base64_encode ( self ) : NEW_LINE INDENT msg = EmailMessage ( ' Subject ' , ' UTF - 8 ▁ encoded ▁ body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE self . assertIn ( b' Content - Transfer - Encoding : ▁ 7bit ' , msg . message ( ) . as_bytes ( ) ) NEW_LINE msg = EmailMessage ( ' Subject ' , ' Body ▁ with ▁ only ▁ ASCII ▁ characters . ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE s = msg . message ( ) . as_bytes ( ) NEW_LINE self . assertIn ( b' Content - Transfer - Encoding : ▁ 7bit ' , s ) NEW_LINE msg = EmailMessage ( ' Subject ' , ' Body ▁ with ▁ latin ▁ characters : ▁ àáä . ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE s = msg . message ( ) . as_bytes ( ) NEW_LINE self . assertIn ( b' Content - Transfer - Encoding : ▁ 8bit ' , s ) NEW_LINE s = msg . message ( ) . as_string ( ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ 8bit ' , s ) NEW_LINE msg = EmailMessage ( ' Subject ' , ' Body ▁ with ▁ non ▁ latin ▁ characters : ▁ А ▁ Б ▁ В ▁ Г ▁ Д ▁ Е ▁ Ж ▁ Ѕ ▁ З ▁ И ▁ І ▁ К ▁ Л ▁ М ▁ Н ▁ О ▁ П . ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE s = msg . message ( ) . as_bytes ( ) NEW_LINE self . assertIn ( b' Content - Transfer - Encoding : ▁ 8bit ' , s ) NEW_LINE s = msg . message ( ) . as_string ( ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ 8bit ' , s ) NEW_LINE DEDENT def test_dont_base64_encode_message_rfc822 ( self ) : NEW_LINE INDENT child_msg = EmailMessage ( ' Child ▁ Subject ' , ' Some ▁ body ▁ of ▁ child ▁ message ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE child_s = child_msg . message ( ) . as_string ( ) NEW_LINE parent_msg = EmailMessage ( ' Parent ▁ Subject ' , ' Some ▁ parent ▁ body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE parent_msg . attach ( content = child_s , mimetype = ' message / rfc822' ) NEW_LINE parent_s = parent_msg . message ( ) . as_string ( ) NEW_LINE self . assertIn ( ' Child ▁ Subject ' , parent_s ) NEW_LINE parent_msg = EmailMessage ( ' Parent ▁ Subject ' , ' Some ▁ parent ▁ body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE parent_msg . attach ( content = child_msg . message ( ) , mimetype = ' message / rfc822' ) NEW_LINE parent_s = parent_msg . message ( ) . as_string ( ) NEW_LINE self . assertIn ( ' Child ▁ Subject ' , parent_s ) NEW_LINE parent_msg = EmailMessage ( ' Parent ▁ Subject ' , ' Some ▁ parent ▁ body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE parent_msg . attach ( content = child_msg , mimetype = ' message / rfc822' ) NEW_LINE parent_s = parent_msg . message ( ) . as_string ( ) NEW_LINE self . assertIn ( ' Child ▁ Subject ' , parent_s ) NEW_LINE DEDENT def test_sanitize_address ( self ) : NEW_LINE INDENT self . assertEqual ( sanitize_address ( ' to @ example . com ' , ' ascii ' ) , ' to @ example . com ' ) NEW_LINE self . assertEqual ( sanitize_address ( ' to @ example . com ' , ' utf - 8' ) , ' to @ example . com ' ) NEW_LINE self . assertEqual ( sanitize_address ( ( ' A ▁ name ' , ' to @ example . com ' ) , ' ascii ' ) , ' A ▁ name ▁ < to @ example . com > ' ) NEW_LINE self . assertEqual ( sanitize_address ( ( ' A ▁ name ' , ' to @ example . com ' ) , ' utf - 8' ) , ' = ? utf - 8 ? q ? A _ name ? = ▁ < to @ example . com > ' ) NEW_LINE self . assertEqual ( sanitize_address ( ' tó @ example . com ' , ' utf - 8' ) , ' = ? utf - 8 ? b ? dMOz ? = @ example . com ' ) NEW_LINE self . assertEqual ( sanitize_address ( ( ' Tó ▁ Example ' , ' tó @ example . com ' ) , ' utf - 8' ) , ' = ? utf - 8 ? q ? T = C3 = B3 _ Example ? = ▁ < = ? utf - 8 ? b ? dMOz ? = @ example . com > ' ) NEW_LINE DEDENT DEDENT @ requires_tz_support NEW_LINE class MailTimeZoneTests ( SimpleTestCase ) : NEW_LINE INDENT @ override_settings ( EMAIL_USE_LOCALTIME = False , USE_TZ = True , TIME_ZONE = ' Africa / Algiers ' ) NEW_LINE def test_date_header_utc ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE self . assertTrue ( email . message ( ) [ ' Date ' ] . endswith ( ' - 0000' ) ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_LOCALTIME = True , USE_TZ = True , TIME_ZONE = ' Africa / Algiers ' ) NEW_LINE def test_date_header_localtime ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Body ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE self . assertTrue ( email . message ( ) [ ' Date ' ] . endswith ( ' + 0100' ) ) NEW_LINE DEDENT DEDENT class PythonGlobalState ( SimpleTestCase ) : NEW_LINE INDENT def test_utf8 ( self ) : NEW_LINE INDENT txt = MIMEText ( ' UTF - 8 ▁ encoded ▁ body ' , ' plain ' , ' utf - 8' ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ base64' , txt . as_string ( ) ) NEW_LINE DEDENT def test_7bit ( self ) : NEW_LINE INDENT txt = MIMEText ( ' Body ▁ with ▁ only ▁ ASCII ▁ characters . ' , ' plain ' , ' utf - 8' ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ base64' , txt . as_string ( ) ) NEW_LINE DEDENT def test_8bit_latin ( self ) : NEW_LINE INDENT txt = MIMEText ( ' Body ▁ with ▁ latin ▁ characters : ▁ àáä . ' , ' plain ' , ' utf - 8' ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ base64' , txt . as_string ( ) ) NEW_LINE DEDENT def test_8bit_non_latin ( self ) : NEW_LINE INDENT txt = MIMEText ( ' Body ▁ with ▁ non ▁ latin ▁ characters : ▁ А ▁ Б ▁ В ▁ Г ▁ Д ▁ Е ▁ Ж ▁ Ѕ ▁ З ▁ И ▁ І ▁ К ▁ Л ▁ М ▁ Н ▁ О ▁ П . ' , ' plain ' , ' utf - 8' ) NEW_LINE self . assertIn ( ' Content - Transfer - Encoding : ▁ base64' , txt . as_string ( ) ) NEW_LINE DEDENT DEDENT class BaseEmailBackendTests ( HeadersCheckMixin ) : NEW_LINE INDENT email_backend = None NEW_LINE def setUp ( self ) : NEW_LINE INDENT self . settings_override = override_settings ( EMAIL_BACKEND = self . email_backend ) NEW_LINE self . settings_override . enable ( ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT self . settings_override . disable ( ) NEW_LINE DEDENT def assertStartsWith ( self , first , second ) : NEW_LINE INDENT if not first . startswith ( second ) : NEW_LINE INDENT self . longMessage = True NEW_LINE self . assertEqual ( first [ : len ( second ) ] , second , " First ▁ string ▁ doesn ' t ▁ start ▁ with ▁ the ▁ second . " ) NEW_LINE DEDENT DEDENT def get_mailbox_content ( self ) : NEW_LINE INDENT raise NotImplementedError ( ' subclasses ▁ of ▁ BaseEmailBackendTests ▁ must ▁ provide ▁ a ▁ get _ mailbox _ content ( ) ▁ method ' ) NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT raise NotImplementedError ( ' subclasses ▁ of ▁ BaseEmailBackendTests ▁ may ▁ require ▁ a ▁ flush _ mailbox ( ) ▁ method ' ) NEW_LINE DEDENT def get_the_message ( self ) : NEW_LINE INDENT mailbox = self . get_mailbox_content ( ) NEW_LINE self . assertEqual ( len ( mailbox ) , 1 , " Expected ▁ exactly ▁ one ▁ message , ▁ got ▁ % d . \n % r " % ( len ( mailbox ) , [ m . as_string ( ) for m in mailbox ] ) ) NEW_LINE return mailbox [ 0 ] NEW_LINE DEDENT def test_send ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE num_sent = mail . get_connection ( ) . send_messages ( [ email ] ) NEW_LINE self . assertEqual ( num_sent , 1 ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message [ " subject " ] , " Subject " ) NEW_LINE self . assertEqual ( message . get_payload ( ) , " Content " ) NEW_LINE self . assertEqual ( message [ " from " ] , " from @ example . com " ) NEW_LINE self . assertEqual ( message . get_all ( " to " ) , [ " to @ example . com " ] ) NEW_LINE DEDENT def test_send_unicode ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Chère ▁ maman ' , ' Je ▁ t\ ' aime ▁ très ▁ fort ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE num_sent = mail . get_connection ( ) . send_messages ( [ email ] ) NEW_LINE self . assertEqual ( num_sent , 1 ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message [ " subject " ] , ' = ? utf - 8 ? q ? Ch = C3 = A8re _ maman ? = ' ) NEW_LINE self . assertEqual ( force_text ( message . get_payload ( decode = True ) ) , ' Je ▁ t\ ' aime ▁ très ▁ fort ' ) NEW_LINE DEDENT def test_send_long_lines ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' В ▁ южных ▁ морях ▁ ' * 60 , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE email . send ( ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertMessageHasHeaders ( message , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " utf - 8 " ' ) , ( ' Content - Transfer - Encoding ' , ' quoted - printable ' ) , } ) NEW_LINE DEDENT def test_send_many ( self ) : NEW_LINE INDENT email1 = EmailMessage ( ' Subject ' , ' Content1' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE email2 = EmailMessage ( ' Subject ' , ' Content2' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE emails_lists = ( [ email1 , email2 ] , ( email for email in [ email1 , email2 ] ) ) NEW_LINE for emails_list in emails_lists : NEW_LINE INDENT num_sent = mail . get_connection ( ) . send_messages ( emails_list ) NEW_LINE self . assertEqual ( num_sent , 2 ) NEW_LINE messages = self . get_mailbox_content ( ) NEW_LINE self . assertEqual ( len ( messages ) , 2 ) NEW_LINE self . assertEqual ( messages [ 0 ] . get_payload ( ) , ' Content1' ) NEW_LINE self . assertEqual ( messages [ 1 ] . get_payload ( ) , ' Content2' ) NEW_LINE self . flush_mailbox ( ) NEW_LINE DEDENT DEDENT def test_send_verbose_name ( self ) : NEW_LINE INDENT email = EmailMessage ( " Subject " , " Content " , ' " Firstname ▁ Sürname " ▁ < from @ example . com > ' , [ " to @ example . com " ] ) NEW_LINE email . send ( ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message [ " subject " ] , " Subject " ) NEW_LINE self . assertEqual ( message . get_payload ( ) , " Content " ) NEW_LINE self . assertEqual ( message [ " from " ] , " = ? utf - 8 ? q ? Firstname _ S = C3 = BCrname ? = ▁ < from @ example . com > " ) NEW_LINE DEDENT def test_plaintext_send_mail ( self ) : NEW_LINE INDENT send_mail ( ' Subject ' , ' Content ' , ' sender @ example . com ' , [ ' nobody @ example . com ' ] ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get_all ( ' to ' ) , [ ' nobody @ example . com ' ] ) NEW_LINE self . assertFalse ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( message . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message . get_content_type ( ) , ' text / plain ' ) NEW_LINE DEDENT def test_html_send_mail ( self ) : NEW_LINE INDENT send_mail ( ' Subject ' , ' Content ' , ' sender @ example . com ' , [ ' nobody @ example . com ' ] , html_message = ' HTML ▁ Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get_all ( ' to ' ) , [ ' nobody @ example . com ' ] ) NEW_LINE self . assertTrue ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( len ( message . get_payload ( ) ) , 2 ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_content_type ( ) , ' text / plain ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_payload ( ) , ' HTML ▁ Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_content_type ( ) , ' text / html ' ) NEW_LINE DEDENT @ override_settings ( MANAGERS = [ ( ' nobody ' , ' nobody @ example . com ' ) ] ) NEW_LINE def test_html_mail_managers ( self ) : NEW_LINE INDENT mail_managers ( ' Subject ' , ' Content ' , html_message = ' HTML ▁ Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' [ Django ] ▁ Subject ' ) NEW_LINE self . assertEqual ( message . get_all ( ' to ' ) , [ ' nobody @ example . com ' ] ) NEW_LINE self . assertTrue ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( len ( message . get_payload ( ) ) , 2 ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_content_type ( ) , ' text / plain ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_payload ( ) , ' HTML ▁ Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_content_type ( ) , ' text / html ' ) NEW_LINE DEDENT @ override_settings ( ADMINS = [ ( ' nobody ' , ' nobody @ example . com ' ) ] ) NEW_LINE def test_html_mail_admins ( self ) : NEW_LINE INDENT mail_admins ( ' Subject ' , ' Content ' , html_message = ' HTML ▁ Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' [ Django ] ▁ Subject ' ) NEW_LINE self . assertEqual ( message . get_all ( ' to ' ) , [ ' nobody @ example . com ' ] ) NEW_LINE self . assertTrue ( message . is_multipart ( ) ) NEW_LINE self . assertEqual ( len ( message . get_payload ( ) ) , 2 ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_payload ( ) , ' Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 0 ) . get_content_type ( ) , ' text / plain ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_payload ( ) , ' HTML ▁ Content ' ) NEW_LINE self . assertEqual ( message . get_payload ( 1 ) . get_content_type ( ) , ' text / html ' ) NEW_LINE DEDENT @ override_settings ( ADMINS = [ ( ' nobody ' , ' nobody + admin @ example . com ' ) ] , MANAGERS = [ ( ' nobody ' , ' nobody + manager @ example . com ' ) ] ) NEW_LINE def test_manager_and_admin_mail_prefix ( self ) : NEW_LINE INDENT mail_managers ( gettext_lazy ( ' Subject ' ) , ' Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' [ Django ] ▁ Subject ' ) NEW_LINE self . flush_mailbox ( ) NEW_LINE mail_admins ( gettext_lazy ( ' Subject ' ) , ' Content ' ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' [ Django ] ▁ Subject ' ) NEW_LINE DEDENT @ override_settings ( ADMINS = [ ] , MANAGERS = [ ] ) NEW_LINE def test_empty_admins ( self ) : NEW_LINE INDENT mail_admins ( ' hi ' , ' there ' ) NEW_LINE self . assertEqual ( self . get_mailbox_content ( ) , [ ] ) NEW_LINE mail_managers ( ' hi ' , ' there ' ) NEW_LINE self . assertEqual ( self . get_mailbox_content ( ) , [ ] ) NEW_LINE DEDENT def test_message_cc_header ( self ) : NEW_LINE INDENT email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , cc = [ ' cc @ example . com ' ] ) NEW_LINE mail . get_connection ( ) . send_messages ( [ email ] ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertMessageHasHeaders ( message , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " utf - 8 " ' ) , ( ' Content - Transfer - Encoding ' , '7bit ' ) , ( ' Subject ' , ' Subject ' ) , ( ' From ' , ' from @ example . com ' ) , ( ' To ' , ' to @ example . com ' ) , ( ' Cc ' , ' cc @ example . com ' ) } ) NEW_LINE self . assertIn ( ' \n Date : ▁ ' , message . as_string ( ) ) NEW_LINE DEDENT def test_idn_send ( self ) : NEW_LINE INDENT self . assertTrue ( send_mail ( ' Subject ' , ' Content ' , ' from @ öäü . com ' , [ ' to @ öäü . com ' ] ) ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' from @ xn - -4ca9at . com ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' to @ xn - -4ca9at . com ' ) NEW_LINE self . flush_mailbox ( ) NEW_LINE m = EmailMessage ( ' Subject ' , ' Content ' , ' from @ öäü . com ' , [ ' to @ öäü . com ' ] , cc = [ ' cc @ öäü . com ' ] ) NEW_LINE m . send ( ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' from @ xn - -4ca9at . com ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' to @ xn - -4ca9at . com ' ) NEW_LINE self . assertEqual ( message . get ( ' cc ' ) , ' cc @ xn - -4ca9at . com ' ) NEW_LINE DEDENT def test_recipient_without_domain ( self ) : NEW_LINE INDENT self . assertTrue ( send_mail ( " Subject " , " Content " , " tester " , [ " django " ] ) ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , " tester " ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , " django " ) NEW_LINE DEDENT def test_lazy_addresses ( self ) : NEW_LINE INDENT _ = gettext_lazy NEW_LINE self . assertTrue ( send_mail ( ' Subject ' , ' Content ' , _ ( ' tester ' ) , [ _ ( ' django ' ) ] ) ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' tester ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' django ' ) NEW_LINE self . flush_mailbox ( ) NEW_LINE m = EmailMessage ( ' Subject ' , ' Content ' , _ ( ' tester ' ) , [ _ ( ' to1' ) , _ ( ' to2' ) ] , cc = [ _ ( ' cc1' ) , _ ( ' cc2' ) ] , bcc = [ _ ( ' bcc ' ) ] , reply_to = [ _ ( ' reply ' ) ] , ) NEW_LINE self . assertEqual ( m . recipients ( ) , [ ' to1' , ' to2' , ' cc1' , ' cc2' , ' bcc ' ] ) NEW_LINE m . send ( ) NEW_LINE message = self . get_the_message ( ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' tester ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' to1 , ▁ to2' ) NEW_LINE self . assertEqual ( message . get ( ' cc ' ) , ' cc1 , ▁ cc2' ) NEW_LINE self . assertEqual ( message . get ( ' Reply - To ' ) , ' reply ' ) NEW_LINE DEDENT def test_close_connection ( self ) : NEW_LINE INDENT conn = mail . get_connection ( username = ' ' , password = ' ' ) NEW_LINE conn . close ( ) NEW_LINE DEDENT def test_use_as_contextmanager ( self ) : NEW_LINE INDENT opened = [ False ] NEW_LINE closed = [ False ] NEW_LINE conn = mail . get_connection ( username = ' ' , password = ' ' ) NEW_LINE def open ( ) : NEW_LINE INDENT opened [ 0 ] = True NEW_LINE DEDENT conn . open = open NEW_LINE def close ( ) : NEW_LINE INDENT closed [ 0 ] = True NEW_LINE DEDENT conn . close = close NEW_LINE with conn as same_conn : NEW_LINE INDENT self . assertTrue ( opened [ 0 ] ) NEW_LINE self . assertIs ( same_conn , conn ) NEW_LINE self . assertFalse ( closed [ 0 ] ) NEW_LINE DEDENT self . assertTrue ( closed [ 0 ] ) NEW_LINE DEDENT DEDENT class LocmemBackendTests ( BaseEmailBackendTests , SimpleTestCase ) : NEW_LINE INDENT email_backend = ' django . core . mail . backends . locmem . EmailBackend ' NEW_LINE def get_mailbox_content ( self ) : NEW_LINE INDENT return [ m . message ( ) for m in mail . outbox ] NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT mail . outbox = [ ] NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT super ( ) . tearDown ( ) NEW_LINE mail . outbox = [ ] NEW_LINE DEDENT def test_locmem_shared_messages ( self ) : NEW_LINE INDENT connection = locmem . EmailBackend ( ) NEW_LINE connection2 = locmem . EmailBackend ( ) NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE connection . send_messages ( [ email ] ) NEW_LINE connection2 . send_messages ( [ email ] ) NEW_LINE self . assertEqual ( len ( mail . outbox ) , 2 ) NEW_LINE DEDENT def test_validate_multiline_headers ( self ) : NEW_LINE INDENT with self . assertRaises ( BadHeaderError ) : NEW_LINE INDENT send_mail ( ' Subject \n Multiline ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE DEDENT DEDENT DEDENT class FileBackendTests ( BaseEmailBackendTests , SimpleTestCase ) : NEW_LINE INDENT email_backend = ' django . core . mail . backends . filebased . EmailBackend ' NEW_LINE def setUp ( self ) : NEW_LINE INDENT super ( ) . setUp ( ) NEW_LINE self . tmp_dir = tempfile . mkdtemp ( ) NEW_LINE self . addCleanup ( shutil . rmtree , self . tmp_dir ) NEW_LINE self . _settings_override = override_settings ( EMAIL_FILE_PATH = self . tmp_dir ) NEW_LINE self . _settings_override . enable ( ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT self . _settings_override . disable ( ) NEW_LINE super ( ) . tearDown ( ) NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT for filename in os . listdir ( self . tmp_dir ) : NEW_LINE INDENT os . unlink ( os . path . join ( self . tmp_dir , filename ) ) NEW_LINE DEDENT DEDENT def get_mailbox_content ( self ) : NEW_LINE INDENT messages = [ ] NEW_LINE for filename in os . listdir ( self . tmp_dir ) : NEW_LINE INDENT with open ( os . path . join ( self . tmp_dir , filename ) , ' rb ' ) as fp : NEW_LINE INDENT session = fp . read ( ) . split ( force_bytes ( ' \n ' + ( ' - ' * 79 ) + ' \n ' , encoding = ' ascii ' ) ) NEW_LINE DEDENT messages . extend ( message_from_bytes ( m ) for m in session if m ) NEW_LINE DEDENT return messages NEW_LINE DEDENT def test_file_sessions ( self ) : NEW_LINE INDENT msg = EmailMessage ( ' Subject ' , ' Content ' , ' bounce @ example . com ' , [ ' to @ example . com ' ] , headers = { ' From ' : ' from @ example . com ' } , ) NEW_LINE connection = mail . get_connection ( ) NEW_LINE connection . send_messages ( [ msg ] ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 1 ) NEW_LINE with open ( os . path . join ( self . tmp_dir , os . listdir ( self . tmp_dir ) [ 0 ] ) , ' rb ' ) as fp : NEW_LINE INDENT message = message_from_binary_file ( fp ) NEW_LINE DEDENT self . assertEqual ( message . get_content_type ( ) , ' text / plain ' ) NEW_LINE self . assertEqual ( message . get ( ' subject ' ) , ' Subject ' ) NEW_LINE self . assertEqual ( message . get ( ' from ' ) , ' from @ example . com ' ) NEW_LINE self . assertEqual ( message . get ( ' to ' ) , ' to @ example . com ' ) NEW_LINE connection2 = mail . get_connection ( ) NEW_LINE connection2 . send_messages ( [ msg ] ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 2 ) NEW_LINE connection . send_messages ( [ msg ] ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 2 ) NEW_LINE msg . connection = mail . get_connection ( ) NEW_LINE self . assertTrue ( connection . open ( ) ) NEW_LINE msg . send ( ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 3 ) NEW_LINE msg . send ( ) NEW_LINE self . assertEqual ( len ( os . listdir ( self . tmp_dir ) ) , 3 ) NEW_LINE connection . close ( ) NEW_LINE DEDENT DEDENT class ConsoleBackendTests ( BaseEmailBackendTests , SimpleTestCase ) : NEW_LINE INDENT email_backend = ' django . core . mail . backends . console . EmailBackend ' NEW_LINE def setUp ( self ) : NEW_LINE INDENT super ( ) . setUp ( ) NEW_LINE self . __stdout = sys . stdout NEW_LINE self . stream = sys . stdout = StringIO ( ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT del self . stream NEW_LINE sys . stdout = self . __stdout NEW_LINE del self . __stdout NEW_LINE super ( ) . tearDown ( ) NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT self . stream = sys . stdout = StringIO ( ) NEW_LINE DEDENT def get_mailbox_content ( self ) : NEW_LINE INDENT messages = self . stream . getvalue ( ) . split ( ' \n ' + ( ' - ' * 79 ) + ' \n ' ) NEW_LINE return [ message_from_bytes ( force_bytes ( m ) ) for m in messages if m ] NEW_LINE DEDENT def test_console_stream_kwarg ( self ) : NEW_LINE INDENT s = StringIO ( ) NEW_LINE connection = mail . get_connection ( ' django . core . mail . backends . console . EmailBackend ' , stream = s ) NEW_LINE send_mail ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] , connection = connection ) NEW_LINE message = force_bytes ( s . getvalue ( ) . split ( ' \n ' + ( ' - ' * 79 ) + ' \n ' ) [ 0 ] ) NEW_LINE self . assertMessageHasHeaders ( message , { ( ' MIME - Version ' , '1.0' ) , ( ' Content - Type ' , ' text / plain ; ▁ charset = " utf - 8 " ' ) , ( ' Content - Transfer - Encoding ' , '7bit ' ) , ( ' Subject ' , ' Subject ' ) , ( ' From ' , ' from @ example . com ' ) , ( ' To ' , ' to @ example . com ' ) } ) NEW_LINE self . assertIn ( b' \n Date : ▁ ' , message ) NEW_LINE DEDENT DEDENT class FakeSMTPChannel ( smtpd . SMTPChannel ) : NEW_LINE INDENT def collect_incoming_data ( self , data ) : NEW_LINE INDENT try : NEW_LINE INDENT smtpd . SMTPChannel . collect_incoming_data ( self , data ) NEW_LINE DEDENT except UnicodeDecodeError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT def smtp_AUTH ( self , arg ) : NEW_LINE INDENT if arg == ' CRAM - MD5' : NEW_LINE INDENT challenge = base64 . b64encode ( b' somerandomstring13579' ) NEW_LINE self . push ( '334 ▁ % s ' % challenge . decode ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . push ( '502 ▁ Error : ▁ login ▁ " % s " ▁ not ▁ implemented ' % arg ) NEW_LINE DEDENT DEDENT DEDENT class FakeSMTPServer ( smtpd . SMTPServer , threading . Thread ) : NEW_LINE INDENT channel_class = FakeSMTPChannel NEW_LINE def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT threading . Thread . __init__ ( self ) NEW_LINE if sys . version_info >= ( 3 , 5 ) : NEW_LINE INDENT kwargs [ ' decode _ data ' ] = True NEW_LINE DEDENT smtpd . SMTPServer . __init__ ( self , * args , ** kwargs ) NEW_LINE self . _sink = [ ] NEW_LINE self . active = False NEW_LINE self . active_lock = threading . Lock ( ) NEW_LINE self . sink_lock = threading . Lock ( ) NEW_LINE DEDENT def process_message ( self , peer , mailfrom , rcpttos , data ) : NEW_LINE INDENT data = data . encode ( ) NEW_LINE m = message_from_bytes ( data ) NEW_LINE maddr = parseaddr ( m . get ( ' from ' ) ) [ 1 ] NEW_LINE if mailfrom != maddr : NEW_LINE INDENT lp , domain = mailfrom . split ( ' @ ' , 1 ) NEW_LINE lp = Header ( lp , ' utf - 8' ) . encode ( ) NEW_LINE mailfrom = ' @ ' . join ( [ lp , domain ] ) NEW_LINE DEDENT if mailfrom != maddr : NEW_LINE INDENT return "553 ▁ ' % s ' ▁ ! = ▁ ' % s ' " % ( mailfrom , maddr ) NEW_LINE DEDENT with self . sink_lock : NEW_LINE INDENT self . _sink . append ( m ) NEW_LINE DEDENT DEDENT def get_sink ( self ) : NEW_LINE INDENT with self . sink_lock : NEW_LINE INDENT return self . _sink [ : ] NEW_LINE DEDENT DEDENT def flush_sink ( self ) : NEW_LINE INDENT with self . sink_lock : NEW_LINE INDENT self . _sink [ : ] = [ ] NEW_LINE DEDENT DEDENT def start ( self ) : NEW_LINE INDENT assert not self . active NEW_LINE self . __flag = threading . Event ( ) NEW_LINE threading . Thread . start ( self ) NEW_LINE self . __flag . wait ( ) NEW_LINE DEDENT def run ( self ) : NEW_LINE INDENT self . active = True NEW_LINE self . __flag . set ( ) NEW_LINE while self . active and asyncore . socket_map : NEW_LINE INDENT with self . active_lock : NEW_LINE INDENT asyncore . loop ( timeout = 0.1 , count = 1 ) NEW_LINE DEDENT DEDENT asyncore . close_all ( ) NEW_LINE DEDENT def stop ( self ) : NEW_LINE INDENT if self . active : NEW_LINE INDENT self . active = False NEW_LINE self . join ( ) NEW_LINE DEDENT DEDENT DEDENT class FakeAUTHSMTPConnection ( SMTP ) : NEW_LINE INDENT def ehlo ( self , name = ' ' ) : NEW_LINE INDENT response = SMTP . ehlo ( self , name = name ) NEW_LINE self . esmtp_features . update ( { ' auth ' : ' CRAM - MD5 ▁ PLAIN ▁ LOGIN ' , } ) NEW_LINE return response NEW_LINE DEDENT DEDENT class SMTPBackendTestsBase ( SimpleTestCase ) : NEW_LINE INDENT @ classmethod NEW_LINE def setUpClass ( cls ) : NEW_LINE INDENT super ( ) . setUpClass ( ) NEW_LINE cls . server = FakeSMTPServer ( ( '127.0.0.1' , 0 ) , None ) NEW_LINE cls . _settings_override = override_settings ( EMAIL_HOST = "127.0.0.1" , EMAIL_PORT = cls . server . socket . getsockname ( ) [ 1 ] ) NEW_LINE cls . _settings_override . enable ( ) NEW_LINE cls . server . start ( ) NEW_LINE DEDENT @ classmethod NEW_LINE def tearDownClass ( cls ) : NEW_LINE INDENT cls . _settings_override . disable ( ) NEW_LINE cls . server . stop ( ) NEW_LINE super ( ) . tearDownClass ( ) NEW_LINE DEDENT DEDENT class SMTPBackendTests ( BaseEmailBackendTests , SMTPBackendTestsBase ) : NEW_LINE INDENT email_backend = ' django . core . mail . backends . smtp . EmailBackend ' NEW_LINE def setUp ( self ) : NEW_LINE INDENT super ( ) . setUp ( ) NEW_LINE self . server . flush_sink ( ) NEW_LINE DEDENT def tearDown ( self ) : NEW_LINE INDENT self . server . flush_sink ( ) NEW_LINE super ( ) . tearDown ( ) NEW_LINE DEDENT def flush_mailbox ( self ) : NEW_LINE INDENT self . server . flush_sink ( ) NEW_LINE DEDENT def get_mailbox_content ( self ) : NEW_LINE INDENT return self . server . get_sink ( ) NEW_LINE DEDENT @ override_settings ( EMAIL_HOST_USER = " not ▁ empty ▁ username " , EMAIL_HOST_PASSWORD = " not ▁ empty ▁ password " ) NEW_LINE def test_email_authentication_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertEqual ( backend . username , ' not ▁ empty ▁ username ' ) NEW_LINE self . assertEqual ( backend . password , ' not ▁ empty ▁ password ' ) NEW_LINE DEDENT @ override_settings ( EMAIL_HOST_USER = " not ▁ empty ▁ username " , EMAIL_HOST_PASSWORD = " not ▁ empty ▁ password " ) NEW_LINE def test_email_authentication_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( username = ' username ' , password = ' password ' ) NEW_LINE self . assertEqual ( backend . username , ' username ' ) NEW_LINE self . assertEqual ( backend . password , ' password ' ) NEW_LINE DEDENT @ override_settings ( EMAIL_HOST_USER = " not ▁ empty ▁ username " , EMAIL_HOST_PASSWORD = " not ▁ empty ▁ password " ) NEW_LINE def test_email_disabled_authentication ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( username = ' ' , password = ' ' ) NEW_LINE self . assertEqual ( backend . username , ' ' ) NEW_LINE self . assertEqual ( backend . password , ' ' ) NEW_LINE DEDENT def test_auth_attempted ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( username = ' not ▁ empty ▁ username ' , password = ' not ▁ empty ▁ password ' ) NEW_LINE with self . assertRaisesMessage ( SMTPException , ' SMTP ▁ AUTH ▁ extension ▁ not ▁ supported ▁ by ▁ server . ' ) : NEW_LINE INDENT with backend : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT DEDENT def test_server_open ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( username = ' ' , password = ' ' ) NEW_LINE self . assertFalse ( backend . connection ) NEW_LINE opened = backend . open ( ) NEW_LINE backend . close ( ) NEW_LINE self . assertTrue ( opened ) NEW_LINE DEDENT def test_server_login ( self ) : NEW_LINE INDENT class CustomEmailBackend ( smtp . EmailBackend ) : NEW_LINE INDENT connection_class = FakeAUTHSMTPConnection NEW_LINE DEDENT backend = CustomEmailBackend ( username = ' username ' , password = ' password ' ) NEW_LINE with self . assertRaises ( SMTPAuthenticationError ) : NEW_LINE INDENT with backend : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT DEDENT @ override_settings ( EMAIL_USE_TLS = True ) NEW_LINE def test_email_tls_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertTrue ( backend . use_tls ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_TLS = True ) NEW_LINE def test_email_tls_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( use_tls = False ) NEW_LINE self . assertFalse ( backend . use_tls ) NEW_LINE DEDENT def test_email_tls_default_disabled ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertFalse ( backend . use_tls ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_SSL = True ) NEW_LINE def test_email_ssl_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertTrue ( backend . use_ssl ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_SSL = True ) NEW_LINE def test_email_ssl_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( use_ssl = False ) NEW_LINE self . assertFalse ( backend . use_ssl ) NEW_LINE DEDENT def test_email_ssl_default_disabled ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertFalse ( backend . use_ssl ) NEW_LINE DEDENT @ override_settings ( EMAIL_SSL_CERTFILE = ' foo ' ) NEW_LINE def test_email_ssl_certfile_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertEqual ( backend . ssl_certfile , ' foo ' ) NEW_LINE DEDENT @ override_settings ( EMAIL_SSL_CERTFILE = ' foo ' ) NEW_LINE def test_email_ssl_certfile_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ssl_certfile = ' bar ' ) NEW_LINE self . assertEqual ( backend . ssl_certfile , ' bar ' ) NEW_LINE DEDENT def test_email_ssl_certfile_default_disabled ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertIsNone ( backend . ssl_certfile ) NEW_LINE DEDENT @ override_settings ( EMAIL_SSL_KEYFILE = ' foo ' ) NEW_LINE def test_email_ssl_keyfile_use_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertEqual ( backend . ssl_keyfile , ' foo ' ) NEW_LINE DEDENT @ override_settings ( EMAIL_SSL_KEYFILE = ' foo ' ) NEW_LINE def test_email_ssl_keyfile_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ssl_keyfile = ' bar ' ) NEW_LINE self . assertEqual ( backend . ssl_keyfile , ' bar ' ) NEW_LINE DEDENT def test_email_ssl_keyfile_default_disabled ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertIsNone ( backend . ssl_keyfile ) NEW_LINE DEDENT @ override_settings ( EMAIL_USE_TLS = True ) NEW_LINE def test_email_tls_attempts_starttls ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertTrue ( backend . use_tls ) NEW_LINE with self . assertRaisesMessage ( SMTPException , ' STARTTLS ▁ extension ▁ not ▁ supported ▁ by ▁ server . ' ) : NEW_LINE INDENT with backend : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT DEDENT @ override_settings ( EMAIL_USE_SSL = True ) NEW_LINE def test_email_ssl_attempts_ssl_connection ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertTrue ( backend . use_ssl ) NEW_LINE with self . assertRaises ( SSLError ) : NEW_LINE INDENT with backend : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT DEDENT def test_connection_timeout_default ( self ) : NEW_LINE INDENT connection = mail . get_connection ( ' django . core . mail . backends . smtp . EmailBackend ' ) NEW_LINE self . assertIsNone ( connection . timeout ) NEW_LINE DEDENT def test_connection_timeout_custom ( self ) : NEW_LINE INDENT class MyEmailBackend ( smtp . EmailBackend ) : NEW_LINE INDENT def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT kwargs . setdefault ( ' timeout ' , 42 ) NEW_LINE super ( ) . __init__ ( * args , ** kwargs ) NEW_LINE DEDENT DEDENT myemailbackend = MyEmailBackend ( ) NEW_LINE myemailbackend . open ( ) NEW_LINE self . assertEqual ( myemailbackend . timeout , 42 ) NEW_LINE self . assertEqual ( myemailbackend . connection . timeout , 42 ) NEW_LINE myemailbackend . close ( ) NEW_LINE DEDENT @ override_settings ( EMAIL_TIMEOUT = 10 ) NEW_LINE def test_email_timeout_override_settings ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE self . assertEqual ( backend . timeout , 10 ) NEW_LINE DEDENT def test_email_msg_uses_crlf ( self ) : NEW_LINE INDENT send = SMTP . send NEW_LINE try : NEW_LINE INDENT smtp_messages = [ ] NEW_LINE def mock_send ( self , s ) : NEW_LINE INDENT smtp_messages . append ( s ) NEW_LINE return send ( self , s ) NEW_LINE DEDENT SMTP . send = mock_send NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE mail . get_connection ( ) . send_messages ( [ email ] ) NEW_LINE msg = None NEW_LINE for i , m in enumerate ( smtp_messages ) : NEW_LINE INDENT if m [ : 4 ] == ' data ' : NEW_LINE INDENT msg = smtp_messages [ i + 1 ] NEW_LINE break NEW_LINE DEDENT DEDENT self . assertTrue ( msg ) NEW_LINE msg = msg . decode ( ) NEW_LINE msg = msg . replace ( ' \r \n ' , ' ' ) NEW_LINE self . assertNotIn ( ' \r ' , msg ) NEW_LINE self . assertNotIn ( ' \n ' , msg ) NEW_LINE DEDENT finally : NEW_LINE INDENT SMTP . send = send NEW_LINE DEDENT DEDENT def test_send_messages_after_open_failed ( self ) : NEW_LINE INDENT backend = smtp . EmailBackend ( ) NEW_LINE backend . connection = True NEW_LINE backend . open = lambda : None NEW_LINE email = EmailMessage ( ' Subject ' , ' Content ' , ' from @ example . com ' , [ ' to @ example . com ' ] ) NEW_LINE self . assertEqual ( backend . send_messages ( [ email ] ) , None ) NEW_LINE DEDENT DEDENT class SMTPBackendStoppedServerTests ( SMTPBackendTestsBase ) : NEW_LINE INDENT @ classmethod NEW_LINE def setUpClass ( cls ) : NEW_LINE INDENT super ( ) . setUpClass ( ) NEW_LINE cls . backend = smtp . EmailBackend ( username = ' ' , password = ' ' ) NEW_LINE cls . server . stop ( ) NEW_LINE DEDENT def test_server_stopped ( self ) : NEW_LINE INDENT self . backend . close ( ) NEW_LINE DEDENT def test_fail_silently_on_connection_error ( self ) : NEW_LINE INDENT with self . assertRaises ( socket . error ) : NEW_LINE INDENT self . backend . open ( ) NEW_LINE DEDENT self . backend . fail_silently = True NEW_LINE self . backend . open ( ) NEW_LINE DEDENT DEDENT
 import BaseHTTPServer , CGIHTTPServer NEW_LINE import sys , os , urllib , select NEW_LINE import random , time NEW_LINE php_path = None NEW_LINE possible_php_paths = [ ' / usr / lib / cgi - bin / php4' , ' PROGRAM _ PATH / fake _ php . py ' ] NEW_LINE def setup_php ( program_path ) : NEW_LINE INDENT global php_path NEW_LINE for p in possible_php_paths : NEW_LINE INDENT p = p . replace ( ' PROGRAM _ PATH ' , program_path ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT php_path = p NEW_LINE return NEW_LINE DEDENT DEDENT raise Exception ( " No ▁ php ▁ binary ▁ found ▁ - ▁ not ▁ even ▁ fake _ php . py ▁ ( program _ path = % s ) ▁ ! " % program_path ) NEW_LINE DEDENT class PHPHTTPRequestHandler ( CGIHTTPServer . CGIHTTPRequestHandler ) : NEW_LINE INDENT def is_cgi ( self ) : NEW_LINE INDENT if os . path . split ( self . path ) [ 1 ] == ' ' : NEW_LINE INDENT index_php = os . path . join ( self . path , ' index . php ' ) NEW_LINE if os . path . exists ( self . translate_path ( index_php ) ) : NEW_LINE INDENT self . path = index_php NEW_LINE DEDENT DEDENT if self . path . find ( ' . php ' ) != - 1 : NEW_LINE INDENT self . cgi_info = os . path . split ( self . path ) NEW_LINE return True NEW_LINE DEDENT for p in self . cgi_directories : NEW_LINE INDENT p = os . path . join ( p , ' ' ) NEW_LINE if self . path . startswith ( p ) : NEW_LINE INDENT self . cgi_info = os . path . split ( self . path ) NEW_LINE return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def run_cgi ( self ) : NEW_LINE INDENT dir , rest = self . cgi_info NEW_LINE i = rest . rfind ( ' ? ' ) NEW_LINE if i >= 0 : NEW_LINE INDENT rest , query = rest [ : i ] , rest [ i + 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT query = ' ' NEW_LINE DEDENT i = rest . find ( ' / ' ) NEW_LINE if i >= 0 : NEW_LINE INDENT script , rest = rest [ : i ] , rest [ i : ] NEW_LINE DEDENT else : NEW_LINE INDENT script , rest = rest , ' ' NEW_LINE DEDENT scriptname = dir + ' / ' + script NEW_LINE is_php = script . endswith ( ' . php ' ) NEW_LINE if is_php : NEW_LINE INDENT if not php_path : NEW_LINE INDENT raise Exception ( ' php _ path ▁ not ▁ set ' ) NEW_LINE DEDENT scriptfile = php_path NEW_LINE sourcefile = self . translate_path ( scriptname ) NEW_LINE DEDENT else : NEW_LINE INDENT scriptfile = self . translate_path ( scriptname ) NEW_LINE DEDENT if not os . path . exists ( scriptfile ) : NEW_LINE INDENT self . send_error ( 404 , " No ▁ such ▁ CGI ▁ script ▁ ( % s ) " % ` scriptname ` ) NEW_LINE return NEW_LINE DEDENT if not os . path . isfile ( scriptfile ) : NEW_LINE INDENT self . send_error ( 403 , " CGI ▁ script ▁ is ▁ not ▁ a ▁ plain ▁ file ▁ ( % s ) " % ` scriptname ` ) NEW_LINE return NEW_LINE DEDENT ispy = self . is_python ( scriptname ) NEW_LINE if not ispy : NEW_LINE INDENT if not ( self . have_fork or self . have_popen2 or self . have_popen3 ) : NEW_LINE INDENT self . send_error ( 403 , " CGI ▁ script ▁ is ▁ not ▁ a ▁ Python ▁ script ▁ ( % s ) " % ` scriptname ` ) NEW_LINE return NEW_LINE DEDENT if not self . is_executable ( scriptfile ) : NEW_LINE INDENT self . send_error ( 403 , " CGI ▁ script ▁ is ▁ not ▁ executable ▁ ( % s ) " % ` scriptname ` ) NEW_LINE return NEW_LINE DEDENT DEDENT env = { } NEW_LINE env [ ' DOCUMENT _ ROOT ' ] = os . getcwd ( ) NEW_LINE env [ ' SERVER _ SOFTWARE ' ] = self . version_string ( ) NEW_LINE env [ ' SERVER _ NAME ' ] = self . server . server_name NEW_LINE env [ ' GATEWAY _ INTERFACE ' ] = ' CGI / 1.1' NEW_LINE env [ ' SERVER _ PROTOCOL ' ] = self . protocol_version NEW_LINE env [ ' SERVER _ PORT ' ] = str ( self . server . server_port ) NEW_LINE env [ ' REQUEST _ METHOD ' ] = self . command NEW_LINE uqrest = urllib . unquote ( self . cgi_info [ 1 ] ) NEW_LINE env [ ' REQUEST _ URI ' ] = self . path NEW_LINE env [ ' SCRIPT _ NAME ' ] = scriptname NEW_LINE env [ ' SCRIPT _ FILENAME ' ] = self . translate_path ( scriptname ) NEW_LINE if query : NEW_LINE INDENT env [ ' QUERY _ STRING ' ] = query NEW_LINE DEDENT host = self . address_string ( ) NEW_LINE if host != self . client_address [ 0 ] : NEW_LINE INDENT env [ ' REMOTE _ HOST ' ] = host NEW_LINE DEDENT env [ ' REMOTE _ ADDR ' ] = self . client_address [ 0 ] NEW_LINE env [ ' REDIRECT _ STATUS ' ] = '1' NEW_LINE if self . headers . typeheader is None : NEW_LINE INDENT env [ ' CONTENT _ TYPE ' ] = self . headers . type NEW_LINE DEDENT else : NEW_LINE INDENT env [ ' CONTENT _ TYPE ' ] = self . headers . typeheader NEW_LINE DEDENT length = self . headers . getheader ( ' content - length ' ) NEW_LINE if length : NEW_LINE INDENT env [ ' CONTENT _ LENGTH ' ] = length NEW_LINE DEDENT accept = [ ] NEW_LINE for line in self . headers . getallmatchingheaders ( ' accept ' ) : NEW_LINE INDENT if line [ : 1 ] in " \t \n \r ▁ " : NEW_LINE INDENT accept . append ( line . strip ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT accept = accept + line [ 7 : ] . split ( ' , ' ) NEW_LINE DEDENT DEDENT env [ ' HTTP _ ACCEPT ' ] = ' , ' . join ( accept ) NEW_LINE ua = self . headers . getheader ( ' user - agent ' ) NEW_LINE if ua : NEW_LINE INDENT env [ ' HTTP _ USER _ AGENT ' ] = ua NEW_LINE DEDENT co = filter ( None , self . headers . getheaders ( ' cookie ' ) ) NEW_LINE if co : NEW_LINE INDENT env [ ' HTTP _ COOKIE ' ] = ' , ▁ ' . join ( co ) NEW_LINE DEDENT if not self . have_fork : NEW_LINE INDENT for k in ( ' QUERY _ STRING ' , ' REMOTE _ HOST ' , ' CONTENT _ LENGTH ' , ' HTTP _ USER _ AGENT ' , ' HTTP _ COOKIE ' ) : NEW_LINE INDENT env . setdefault ( k , " " ) NEW_LINE DEDENT DEDENT os . environ . update ( env ) NEW_LINE self . send_response ( 200 , " Script ▁ output ▁ follows " ) NEW_LINE decoded_query = query . replace ( ' + ' , ' ▁ ' ) NEW_LINE if self . have_fork : NEW_LINE INDENT if is_php : NEW_LINE INDENT args = [ php_path , sourcefile ] NEW_LINE DEDENT else : NEW_LINE INDENT args = [ script ] NEW_LINE DEDENT if ' = ' not in decoded_query : NEW_LINE INDENT args . append ( decoded_query ) NEW_LINE DEDENT self . wfile . flush ( ) NEW_LINE pid = os . fork ( ) NEW_LINE if pid != 0 : NEW_LINE INDENT pid , sts = os . waitpid ( pid , 0 ) NEW_LINE while select . select ( [ self . rfile ] , [ ] , [ ] , 0 ) [ 0 ] : NEW_LINE INDENT try : NEW_LINE INDENT if not self . rfile . read ( 1 ) : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT if sts : NEW_LINE INDENT self . log_error ( " CGI ▁ script ▁ exit ▁ status ▁ % # x " , sts ) NEW_LINE DEDENT return NEW_LINE DEDENT try : NEW_LINE INDENT if 0 : NEW_LINE INDENT time . sleep ( .1 ) NEW_LINE fn = ' / tmp / a % d ' % random . randint ( 1000 , 10000 ) NEW_LINE f = open ( fn , ' w ' ) NEW_LINE s = ' ' NEW_LINE while select . select ( [ self . rfile ] , [ ] , [ ] , 0 ) [ 0 ] : NEW_LINE INDENT try : NEW_LINE INDENT c = self . rfile . read ( 1 ) NEW_LINE if not c : NEW_LINE INDENT break NEW_LINE DEDENT s += c NEW_LINE DEDENT except : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT print ' # # # ▁ input : ' , repr ( s ) NEW_LINE print >> f , s NEW_LINE f . close ( ) NEW_LINE self . rfile = open ( fn , ' r ' ) NEW_LINE DEDENT os . dup2 ( self . rfile . fileno ( ) , 0 ) NEW_LINE os . dup2 ( self . wfile . fileno ( ) , 1 ) NEW_LINE os . chdir ( self . translate_path ( dir ) ) NEW_LINE os . execve ( scriptfile , args , os . environ ) NEW_LINE DEDENT except : NEW_LINE INDENT self . server . handle_error ( self . request , self . client_address ) NEW_LINE os . _exit ( 127 ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise SystemExit ( ' need ▁ fork ( ) ' ) NEW_LINE DEDENT DEDENT DEDENT def serve ( bind = ' localhost ' , port = 8000 , handler = PHPHTTPRequestHandler ) : NEW_LINE INDENT httpd = BaseHTTPServer . HTTPServer ( ( bind , port ) , handler ) NEW_LINE httpd . serve_forever ( ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT setup_php ( os . path . realpath ( os . path . dirname ( sys . argv [ 0 ] ) ) ) NEW_LINE serve ( ) NEW_LINE DEDENT
 from __future__ import unicode_literals NEW_LINE import contextlib NEW_LINE import errno NEW_LINE import os NEW_LINE import socket NEW_LINE from django . core . exceptions import ImproperlyConfigured NEW_LINE from django . test import LiveServerTestCase , override_settings NEW_LINE from django . utils . _os import upath NEW_LINE from django . utils . http import urlencode NEW_LINE from django . utils . six import text_type NEW_LINE from django . utils . six . moves . urllib . error import HTTPError NEW_LINE from django . utils . six . moves . urllib . request import urlopen NEW_LINE from . models import Person NEW_LINE TEST_ROOT = os . path . dirname ( upath ( __file__ ) ) NEW_LINE TEST_SETTINGS = { ' MEDIA _ URL ' : ' / media / ' , ' MEDIA _ ROOT ' : os . path . join ( TEST_ROOT , ' media ' ) , ' STATIC _ URL ' : ' / static / ' , ' STATIC _ ROOT ' : os . path . join ( TEST_ROOT , ' static ' ) , } NEW_LINE @ override_settings ( ROOT_URLCONF = ' servers . urls ' , ** TEST_SETTINGS ) NEW_LINE class LiveServerBase ( LiveServerTestCase ) : NEW_LINE INDENT available_apps = [ ' servers ' , ' django . contrib . auth ' , ' django . contrib . contenttypes ' , ' django . contrib . sessions ' , ] NEW_LINE fixtures = [ ' testdata . json ' ] NEW_LINE def urlopen ( self , url ) : NEW_LINE INDENT return urlopen ( self . live_server_url + url ) NEW_LINE DEDENT DEDENT class LiveServerAddress ( LiveServerBase ) : NEW_LINE INDENT @ classmethod NEW_LINE def setUpClass ( cls ) : NEW_LINE INDENT address_predefined = ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' in os . environ NEW_LINE old_address = os . environ . get ( ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' ) NEW_LINE cls . raises_exception ( ' localhost ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' blahblahblah : 8081' , socket . error ) NEW_LINE cls . raises_exception ( ' localhost : 8081 , ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' localhost : 8081 , blah ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' localhost : 8081 - ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' localhost : 8081 - blah ' , ImproperlyConfigured ) NEW_LINE cls . raises_exception ( ' localhost : 8081-8082-8083' , ImproperlyConfigured ) NEW_LINE if address_predefined : NEW_LINE INDENT os . environ [ ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' ] = old_address NEW_LINE DEDENT else : NEW_LINE INDENT del os . environ [ ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' ] NEW_LINE DEDENT cls . live_server_url_test = [ cls . live_server_url ] NEW_LINE DEDENT @ classmethod NEW_LINE def tearDownClass ( cls ) : NEW_LINE INDENT pass NEW_LINE DEDENT @ classmethod NEW_LINE def raises_exception ( cls , address , exception ) : NEW_LINE INDENT os . environ [ ' DJANGO _ LIVE _ TEST _ SERVER _ ADDRESS ' ] = address NEW_LINE try : NEW_LINE INDENT super ( LiveServerAddress , cls ) . setUpClass ( ) NEW_LINE raise Exception ( " The ▁ line ▁ above ▁ should ▁ have ▁ raised ▁ an ▁ exception " ) NEW_LINE DEDENT except exception : NEW_LINE INDENT pass NEW_LINE DEDENT finally : NEW_LINE INDENT super ( LiveServerAddress , cls ) . tearDownClass ( ) NEW_LINE DEDENT DEDENT def test_live_server_url_is_class_property ( self ) : NEW_LINE INDENT self . assertIsInstance ( self . live_server_url_test [ 0 ] , text_type ) NEW_LINE self . assertEqual ( self . live_server_url_test [ 0 ] , self . live_server_url ) NEW_LINE DEDENT DEDENT class LiveServerViews ( LiveServerBase ) : NEW_LINE INDENT def test_404 ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT self . urlopen ( ' / ' ) NEW_LINE DEDENT except HTTPError as err : NEW_LINE INDENT self . assertEqual ( err . code , 404 , ' Expected ▁ 404 ▁ response ' ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Expected ▁ 404 ▁ response ' ) NEW_LINE DEDENT DEDENT def test_view ( self ) : NEW_LINE INDENT with contextlib . closing ( self . urlopen ( ' / example _ view / ' ) ) as f : NEW_LINE INDENT self . assertEqual ( f . read ( ) , b' example ▁ view ' ) NEW_LINE DEDENT DEDENT def test_static_files ( self ) : NEW_LINE INDENT with contextlib . closing ( self . urlopen ( ' / static / example _ static _ file . txt ' ) ) as f : NEW_LINE INDENT self . assertEqual ( f . read ( ) . rstrip ( b' \r \n ' ) , b' example ▁ static ▁ file ' ) NEW_LINE DEDENT DEDENT def test_no_collectstatic_emulation ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT self . urlopen ( ' / static / another _ app / another _ app _ static _ file . txt ' ) NEW_LINE DEDENT except HTTPError as err : NEW_LINE INDENT self . assertEqual ( err . code , 404 , ' Expected ▁ 404 ▁ response ' ) NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Expected ▁ 404 ▁ response ▁ ( got ▁ % d ) ' % err . code ) NEW_LINE DEDENT DEDENT def test_media_files ( self ) : NEW_LINE INDENT with contextlib . closing ( self . urlopen ( ' / media / example _ media _ file . txt ' ) ) as f : NEW_LINE INDENT self . assertEqual ( f . read ( ) . rstrip ( b' \r \n ' ) , b' example ▁ media ▁ file ' ) NEW_LINE DEDENT DEDENT def test_environ ( self ) : NEW_LINE INDENT with contextlib . closing ( self . urlopen ( ' / environ _ view / ? % s ' % urlencode ( { ' q ' : ' тест ' } ) ) ) as f : NEW_LINE INDENT self . assertIn ( b" QUERY _ STRING : ▁ ' q = % D1%82 % D0 % B5 % D1%81 % D1%82 ' " , f . read ( ) ) NEW_LINE DEDENT DEDENT DEDENT class LiveServerDatabase ( LiveServerBase ) : NEW_LINE INDENT def test_fixtures_loaded ( self ) : NEW_LINE INDENT with contextlib . closing ( self . urlopen ( ' / model _ view / ' ) ) as f : NEW_LINE INDENT self . assertEqual ( f . read ( ) . splitlines ( ) , [ b' jane ' , b' robert ' ] ) NEW_LINE DEDENT DEDENT def test_database_writes ( self ) : NEW_LINE INDENT self . urlopen ( ' / create _ model _ instance / ' ) NEW_LINE self . assertQuerysetEqual ( Person . objects . all ( ) . order_by ( ' pk ' ) , [ ' jane ' , ' robert ' , ' emily ' ] , lambda b : b . name ) NEW_LINE DEDENT DEDENT class LiveServerPort ( LiveServerBase ) : NEW_LINE INDENT def test_port_bind ( self ) : NEW_LINE INDENT TestCase = type ( str ( " TestCase " ) , ( LiveServerBase , ) , { } ) NEW_LINE try : NEW_LINE INDENT TestCase . setUpClass ( ) NEW_LINE DEDENT except socket . error as e : NEW_LINE INDENT if e . errno == errno . EADDRINUSE : NEW_LINE INDENT return NEW_LINE DEDENT raise NEW_LINE DEDENT try : NEW_LINE INDENT self . assertNotEqual ( self . live_server_url , TestCase . live_server_url , " Acquired ▁ duplicate ▁ server ▁ addresses ▁ for ▁ server ▁ threads : ▁ % s " % self . live_server_url ) NEW_LINE DEDENT finally : NEW_LINE INDENT TestCase . tearDownClass ( ) NEW_LINE DEDENT DEDENT DEDENT
 from openerp import models , fields , api NEW_LINE class IrAttachment ( models . Model ) : NEW_LINE INDENT _inherit = ' ir . attachment ' NEW_LINE res_reference = fields . Reference ( selection = ' _ selection _ res _ reference ' , string = ' Resource ▁ reference ' , compute = ' _ compute _ res _ reference ' , inverse = ' _ inverse _ res _ reference ' ) NEW_LINE @ api . one NEW_LINE @ api . depends ( ' res _ id ' , ' res _ model ' ) NEW_LINE def _compute_res_reference ( self ) : NEW_LINE INDENT if self . res_model and self . res_id : NEW_LINE INDENT self . res_reference = ' % s , % s ' % ( self . res_model , self . res_id ) NEW_LINE DEDENT DEDENT @ api . one NEW_LINE def _inverse_res_reference ( self ) : NEW_LINE INDENT if self . res_reference : NEW_LINE INDENT self . write ( { ' res _ model ' : self . res_reference . _model . _model , ' res _ id ' : self . res_reference . id , } ) NEW_LINE DEDENT else : NEW_LINE INDENT self . write ( { ' res _ model ' : False , ' res _ id ' : False } ) NEW_LINE DEDENT DEDENT @ api . model NEW_LINE def _selection_res_reference ( self ) : NEW_LINE INDENT return self . env [ ' ir . model ' ] . search ( [ ( ' osv _ memory ' , ' = ' , False ) , ( ' access _ ids . group _ id . users ' , ' = ' , self . env . uid ) ] ) . mapped ( lambda rec : ( rec . model , rec . name ) ) NEW_LINE DEDENT DEDENT
 import logging NEW_LINE from homematicip . aio . device import ( AsyncWeatherSensor , AsyncWeatherSensorPlus , AsyncWeatherSensorPro ) NEW_LINE from homematicip . aio . home import AsyncHome NEW_LINE from homeassistant . components . weather import WeatherEntity NEW_LINE from homeassistant . config_entries import ConfigEntry NEW_LINE from homeassistant . const import TEMP_CELSIUS NEW_LINE from homeassistant . core import HomeAssistant NEW_LINE from . import DOMAIN as HMIPC_DOMAIN , HMIPC_HAPID , HomematicipGenericDevice NEW_LINE _LOGGER = logging . getLogger ( __name__ ) NEW_LINE async def async_setup_platform ( hass , config , async_add_entities , discovery_info = None ) : NEW_LINE INDENT pass NEW_LINE DEDENT async def async_setup_entry ( hass : HomeAssistant , config_entry : ConfigEntry , async_add_entities ) -> None : NEW_LINE INDENT home = hass . data [ HMIPC_DOMAIN ] [ config_entry . data [ HMIPC_HAPID ] ] . home NEW_LINE devices = [ ] NEW_LINE for device in home . devices : NEW_LINE INDENT if isinstance ( device , AsyncWeatherSensorPro ) : NEW_LINE INDENT devices . append ( HomematicipWeatherSensorPro ( home , device ) ) NEW_LINE DEDENT elif isinstance ( device , ( AsyncWeatherSensor , AsyncWeatherSensorPlus ) ) : NEW_LINE INDENT devices . append ( HomematicipWeatherSensor ( home , device ) ) NEW_LINE DEDENT DEDENT if devices : NEW_LINE INDENT async_add_entities ( devices ) NEW_LINE DEDENT DEDENT class HomematicipWeatherSensor ( HomematicipGenericDevice , WeatherEntity ) : NEW_LINE INDENT def __init__ ( self , home : AsyncHome , device ) -> None : NEW_LINE INDENT super ( ) . __init__ ( home , device ) NEW_LINE DEDENT @ property NEW_LINE def name ( self ) -> str : NEW_LINE INDENT return self . _device . label NEW_LINE DEDENT @ property NEW_LINE def temperature ( self ) -> float : NEW_LINE INDENT return self . _device . actualTemperature NEW_LINE DEDENT @ property NEW_LINE def temperature_unit ( self ) -> str : NEW_LINE INDENT return TEMP_CELSIUS NEW_LINE DEDENT @ property NEW_LINE def humidity ( self ) -> int : NEW_LINE INDENT return self . _device . humidity NEW_LINE DEDENT @ property NEW_LINE def wind_speed ( self ) -> float : NEW_LINE INDENT return self . _device . windSpeed NEW_LINE DEDENT @ property NEW_LINE def attribution ( self ) -> str : NEW_LINE INDENT return " Powered ▁ by ▁ Homematic ▁ IP " NEW_LINE DEDENT @ property NEW_LINE def condition ( self ) -> str : NEW_LINE INDENT if hasattr ( self . _device , " raining " ) and self . _device . raining : NEW_LINE INDENT return ' rainy ' NEW_LINE DEDENT if self . _device . storm : NEW_LINE INDENT return ' windy ' NEW_LINE DEDENT if self . _device . sunshine : NEW_LINE INDENT return ' sunny ' NEW_LINE DEDENT return ' ' NEW_LINE DEDENT DEDENT class HomematicipWeatherSensorPro ( HomematicipWeatherSensor ) : NEW_LINE INDENT @ property NEW_LINE def wind_bearing ( self ) -> float : NEW_LINE INDENT return self . _device . windDirection NEW_LINE DEDENT DEDENT
 from openerp . osv import fields , osv NEW_LINE from openerp . tools import float_compare NEW_LINE from openerp . tools . translate import _ NEW_LINE import openerp . addons . decimal_precision as dp NEW_LINE class stock_move_consume ( osv . osv_memory ) : NEW_LINE INDENT _name = " stock . move . consume " NEW_LINE _description = " Consume ▁ Products " NEW_LINE _columns = { ' product _ id ' : fields . many2one ( ' product . product ' , ' Product ' , required = True , select = True ) , ' product _ qty ' : fields . float ( ' Quantity ' , digits_compute = dp . get_precision ( ' Product ▁ Unit ▁ of ▁ Measure ' ) , required = True ) , ' product _ uom ' : fields . many2one ( ' product . uom ' , ' Product ▁ Unit ▁ of ▁ Measure ' , required = True ) , ' location _ id ' : fields . many2one ( ' stock . location ' , ' Location ' , required = True ) , ' restrict _ lot _ id ' : fields . many2one ( ' stock . production . lot ' , ' Lot ' ) , } NEW_LINE def default_get ( self , cr , uid , fields , context = None ) : NEW_LINE INDENT if context is None : NEW_LINE INDENT context = { } NEW_LINE DEDENT res = super ( stock_move_consume , self ) . default_get ( cr , uid , fields , context = context ) NEW_LINE move = self . pool . get ( ' stock . move ' ) . browse ( cr , uid , context [ ' active _ id ' ] , context = context ) NEW_LINE if ' product _ id ' in fields : NEW_LINE INDENT res . update ( { ' product _ id ' : move . product_id . id } ) NEW_LINE DEDENT if ' product _ uom ' in fields : NEW_LINE INDENT res . update ( { ' product _ uom ' : move . product_uom . id } ) NEW_LINE DEDENT if ' product _ qty ' in fields : NEW_LINE INDENT res . update ( { ' product _ qty ' : move . product_uom_qty } ) NEW_LINE DEDENT if ' location _ id ' in fields : NEW_LINE INDENT res . update ( { ' location _ id ' : move . location_id . id } ) NEW_LINE DEDENT return res NEW_LINE DEDENT def do_move_consume ( self , cr , uid , ids , context = None ) : NEW_LINE INDENT if context is None : NEW_LINE INDENT context = { } NEW_LINE DEDENT move_obj = self . pool . get ( ' stock . move ' ) NEW_LINE uom_obj = self . pool . get ( ' product . uom ' ) NEW_LINE production_obj = self . pool . get ( ' mrp . production ' ) NEW_LINE move_ids = context [ ' active _ ids ' ] NEW_LINE move = move_obj . browse ( cr , uid , move_ids [ 0 ] , context = context ) NEW_LINE production_id = move . raw_material_production_id . id NEW_LINE production = production_obj . browse ( cr , uid , production_id , context = context ) NEW_LINE precision = self . pool [ ' decimal . precision ' ] . precision_get ( cr , uid , ' Product ▁ Unit ▁ of ▁ Measure ' ) NEW_LINE for data in self . browse ( cr , uid , ids , context = context ) : NEW_LINE INDENT qty = uom_obj . _compute_qty ( cr , uid , data [ ' product _ uom ' ] . id , data . product_qty , data . product_id . uom_id . id ) NEW_LINE remaining_qty = move . product_qty - qty NEW_LINE if float_compare ( remaining_qty , 0 , precision_digits = precision ) >= 0 : NEW_LINE INDENT move_obj . action_consume ( cr , uid , move_ids , qty , data . location_id . id , restrict_lot_id = data . restrict_lot_id . id , context = context ) NEW_LINE DEDENT else : NEW_LINE INDENT consumed_qty = min ( move . product_qty , qty ) NEW_LINE new_moves = move_obj . action_consume ( cr , uid , move_ids , consumed_qty , data . location_id . id , restrict_lot_id = data . restrict_lot_id . id , context = context ) NEW_LINE extra_more_qty = qty - consumed_qty NEW_LINE extra_move_id = production_obj . _make_consume_line_from_data ( cr , uid , production , data . product_id , data . product_id . uom_id . id , extra_more_qty , False , 0 , context = context ) NEW_LINE move_obj . write ( cr , uid , [ extra_move_id ] , { ' restrict _ lot _ id ' : data . restrict_lot_id . id } , context = context ) NEW_LINE move_obj . action_done ( cr , uid , [ extra_move_id ] , context = context ) NEW_LINE DEDENT DEDENT return { ' type ' : ' ir . actions . act _ window _ close ' } NEW_LINE DEDENT DEDENT
 import sys NEW_LINE import traceback NEW_LINE from oslo . config import cfg NEW_LINE from nova . conductor import rpcapi as conductor_rpcapi NEW_LINE from nova import config NEW_LINE import nova . db . api NEW_LINE from nova import exception NEW_LINE from nova . i18n import _ NEW_LINE from nova import objects NEW_LINE from nova . objects import base as objects_base NEW_LINE from nova . openstack . common import log as logging NEW_LINE from nova . openstack . common . report import guru_meditation_report as gmr NEW_LINE from nova import service NEW_LINE from nova import utils NEW_LINE from nova import version NEW_LINE CONF = cfg . CONF NEW_LINE CONF . import_opt ( ' network _ topic ' , ' nova . network . rpcapi ' ) NEW_LINE CONF . import_opt ( ' use _ local ' , ' nova . conductor . api ' , group = ' conductor ' ) NEW_LINE def block_db_access ( ) : NEW_LINE INDENT class NoDB ( object ) : NEW_LINE INDENT def __getattr__ ( self , attr ) : NEW_LINE INDENT return self NEW_LINE DEDENT def __call__ ( self , * args , ** kwargs ) : NEW_LINE INDENT stacktrace = " " . join ( traceback . format_stack ( ) ) NEW_LINE LOG = logging . getLogger ( ' nova . network ' ) NEW_LINE LOG . error ( _ ( ' No ▁ db ▁ access ▁ allowed ▁ in ▁ nova - network : ▁ % s ' ) , stacktrace ) NEW_LINE raise exception . DBNotAllowed ( ' nova - network ' ) NEW_LINE DEDENT DEDENT nova . db . api . IMPL = NoDB ( ) NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT config . parse_args ( sys . argv ) NEW_LINE logging . setup ( " nova " ) NEW_LINE utils . monkey_patch ( ) NEW_LINE objects . register_all ( ) NEW_LINE gmr . TextGuruMeditation . setup_autorun ( version ) NEW_LINE if not CONF . conductor . use_local : NEW_LINE INDENT block_db_access ( ) NEW_LINE objects_base . NovaObject . indirection_api = \NEW_LINE conductor_rpcapi . ConductorAPI ( ) NEW_LINE DEDENT server = service . Service . create ( binary = ' nova - network ' , topic = CONF . network_topic , db_allowed = CONF . conductor . use_local ) NEW_LINE service . serve ( server ) NEW_LINE service . wait ( ) NEW_LINE DEDENT
 from django . db import models NEW_LINE from django . utils . encoding import python_2_unicode_compatible , smart_text NEW_LINE from django . utils . translation import ugettext as _ , ugettext_lazy NEW_LINE from django . contrib . contenttypes . fields import GenericRelation NEW_LINE from reversion import revisions as reversion NEW_LINE from modoboa . core import models as core_models NEW_LINE from modoboa . core import signals as core_signals NEW_LINE from modoboa . lib . exceptions import BadRequest , Conflict NEW_LINE from . base import AdminObject NEW_LINE from . domain import Domain NEW_LINE class DomainAliasManager ( models . Manager ) : NEW_LINE INDENT def get_for_admin ( self , admin ) : NEW_LINE INDENT if admin . is_superuser : NEW_LINE INDENT return self . get_queryset ( ) NEW_LINE DEDENT return self . get_queryset ( ) . filter ( owners__user = admin ) NEW_LINE DEDENT DEDENT @ python_2_unicode_compatible NEW_LINE class DomainAlias ( AdminObject ) : NEW_LINE INDENT name = models . CharField ( ugettext_lazy ( " name " ) , max_length = 100 , unique = True , help_text = ugettext_lazy ( " The ▁ alias ▁ name " ) ) NEW_LINE target = models . ForeignKey ( Domain , verbose_name = ugettext_lazy ( ' target ' ) , help_text = ugettext_lazy ( " The ▁ domain ▁ this ▁ alias ▁ points ▁ to " ) ) NEW_LINE enabled = models . BooleanField ( ugettext_lazy ( ' enabled ' ) , help_text = ugettext_lazy ( " Check ▁ to ▁ activate ▁ this ▁ alias " ) , default = True ) NEW_LINE owners = GenericRelation ( core_models . ObjectAccess ) NEW_LINE objects = DomainAliasManager ( ) NEW_LINE class Meta : NEW_LINE INDENT permissions = ( ( " view _ domaliases " , " View ▁ domain ▁ aliases " ) , ) NEW_LINE app_label = " admin " NEW_LINE DEDENT def __str__ ( self ) : NEW_LINE INDENT return smart_text ( self . name ) NEW_LINE DEDENT def from_csv ( self , user , row ) : NEW_LINE INDENT if len ( row ) < 4 : NEW_LINE INDENT raise BadRequest ( _ ( " Invalid ▁ line " ) ) NEW_LINE DEDENT self . name = row [ 1 ] . strip ( ) NEW_LINE for model in [ DomainAlias , Domain ] : NEW_LINE INDENT if model . objects . filter ( name = self . name ) . exists ( ) : NEW_LINE INDENT raise Conflict NEW_LINE DEDENT DEDENT domname = row [ 2 ] . strip ( ) NEW_LINE try : NEW_LINE INDENT self . target = Domain . objects . get ( name = domname ) NEW_LINE DEDENT except Domain . DoesNotExist : NEW_LINE INDENT raise BadRequest ( _ ( " Unknown ▁ domain ▁ % s " ) % domname ) NEW_LINE DEDENT core_signals . can_create_object . send ( sender = " import " , context = self . target , object_type = " domain _ aliases " ) NEW_LINE self . enabled = row [ 3 ] . strip ( ) in [ " True " , "1" , " yes " , " y " ] NEW_LINE self . save ( creator = user ) NEW_LINE DEDENT def to_csv ( self , csvwriter ) : NEW_LINE INDENT csvwriter . writerow ( [ " domainalias " , self . name , self . target . name , self . enabled ] ) NEW_LINE DEDENT DEDENT reversion . register ( DomainAlias ) NEW_LINE
 from __future__ import print_function NEW_LINE import array NEW_LINE import struct NEW_LINE import io NEW_LINE import warnings NEW_LINE from struct import unpack_from NEW_LINE from PIL import Image , ImageFile , TiffImagePlugin , _binary NEW_LINE from PIL . JpegPresets import presets NEW_LINE from PIL . _util import isStringType NEW_LINE i8 = _binary . i8 NEW_LINE o8 = _binary . o8 NEW_LINE i16 = _binary . i16be NEW_LINE i32 = _binary . i32be NEW_LINE __version__ = "0.6" NEW_LINE def Skip ( self , marker ) : NEW_LINE INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE ImageFile . _safe_read ( self . fp , n ) NEW_LINE DEDENT def APP ( self , marker ) : NEW_LINE INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE s = ImageFile . _safe_read ( self . fp , n ) NEW_LINE app = " APP % d " % ( marker & 15 ) NEW_LINE self . app [ app ] = s NEW_LINE self . applist . append ( ( app , s ) ) NEW_LINE if marker == 0xFFE0 and s [ : 4 ] == b" JFIF " : NEW_LINE INDENT self . info [ " jfif " ] = version = i16 ( s , 5 ) NEW_LINE self . info [ " jfif _ version " ] = divmod ( version , 256 ) NEW_LINE try : NEW_LINE INDENT jfif_unit = i8 ( s [ 7 ] ) NEW_LINE jfif_density = i16 ( s , 8 ) , i16 ( s , 10 ) NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT if jfif_unit == 1 : NEW_LINE INDENT self . info [ " dpi " ] = jfif_density NEW_LINE DEDENT self . info [ " jfif _ unit " ] = jfif_unit NEW_LINE self . info [ " jfif _ density " ] = jfif_density NEW_LINE DEDENT DEDENT elif marker == 0xFFE1 and s [ : 5 ] == b" Exif\0" : NEW_LINE INDENT self . info [ " exif " ] = s NEW_LINE DEDENT elif marker == 0xFFE2 and s [ : 5 ] == b" FPXR\0" : NEW_LINE INDENT self . info [ " flashpix " ] = s NEW_LINE DEDENT elif marker == 0xFFE2 and s [ : 12 ] == b" ICC _ PROFILE\0" : NEW_LINE INDENT self . icclist . append ( s ) NEW_LINE DEDENT elif marker == 0xFFEE and s [ : 5 ] == b" Adobe " : NEW_LINE INDENT self . info [ " adobe " ] = i16 ( s , 5 ) NEW_LINE try : NEW_LINE INDENT adobe_transform = i8 ( s [ 1 ] ) NEW_LINE DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . info [ " adobe _ transform " ] = adobe_transform NEW_LINE DEDENT DEDENT elif marker == 0xFFE2 and s [ : 4 ] == b" MPF\0" : NEW_LINE INDENT self . info [ " mp " ] = s [ 4 : ] NEW_LINE self . info [ " mpoffset " ] = self . fp . tell ( ) - n + 4 NEW_LINE DEDENT DEDENT def COM ( self , marker ) : NEW_LINE INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE s = ImageFile . _safe_read ( self . fp , n ) NEW_LINE self . app [ " COM " ] = s NEW_LINE self . applist . append ( ( " COM " , s ) ) NEW_LINE DEDENT def SOF ( self , marker ) : NEW_LINE INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE s = ImageFile . _safe_read ( self . fp , n ) NEW_LINE self . size = i16 ( s [ 3 : ] ) , i16 ( s [ 1 : ] ) NEW_LINE self . bits = i8 ( s [ 0 ] ) NEW_LINE if self . bits != 8 : NEW_LINE INDENT raise SyntaxError ( " cannot ▁ handle ▁ % d - bit ▁ layers " % self . bits ) NEW_LINE DEDENT self . layers = i8 ( s [ 5 ] ) NEW_LINE if self . layers == 1 : NEW_LINE INDENT self . mode = " L " NEW_LINE DEDENT elif self . layers == 3 : NEW_LINE INDENT self . mode = " RGB " NEW_LINE DEDENT elif self . layers == 4 : NEW_LINE INDENT self . mode = " CMYK " NEW_LINE DEDENT else : NEW_LINE INDENT raise SyntaxError ( " cannot ▁ handle ▁ % d - layer ▁ images " % self . layers ) NEW_LINE DEDENT if marker in [ 0xFFC2 , 0xFFC6 , 0xFFCA , 0xFFCE ] : NEW_LINE INDENT self . info [ " progressive " ] = self . info [ " progression " ] = 1 NEW_LINE DEDENT if self . icclist : NEW_LINE INDENT self . icclist . sort ( ) NEW_LINE if i8 ( self . icclist [ 0 ] [ 13 ] ) == len ( self . icclist ) : NEW_LINE INDENT profile = [ ] NEW_LINE for p in self . icclist : NEW_LINE INDENT profile . append ( p [ 14 : ] ) NEW_LINE DEDENT icc_profile = b" " . join ( profile ) NEW_LINE DEDENT else : NEW_LINE INDENT icc_profile = None NEW_LINE DEDENT self . info [ " icc _ profile " ] = icc_profile NEW_LINE self . icclist = None NEW_LINE DEDENT for i in range ( 6 , len ( s ) , 3 ) : NEW_LINE INDENT t = s [ i : i + 3 ] NEW_LINE self . layer . append ( ( t [ 0 ] , i8 ( t [ 1 ] ) // 16 , i8 ( t [ 1 ] ) & 15 , i8 ( t [ 2 ] ) ) ) NEW_LINE DEDENT DEDENT def DQT ( self , marker ) : NEW_LINE INDENT n = i16 ( self . fp . read ( 2 ) ) - 2 NEW_LINE s = ImageFile . _safe_read ( self . fp , n ) NEW_LINE while len ( s ) : NEW_LINE INDENT if len ( s ) < 65 : NEW_LINE INDENT raise SyntaxError ( " bad ▁ quantization ▁ table ▁ marker " ) NEW_LINE DEDENT v = i8 ( s [ 0 ] ) NEW_LINE if v // 16 == 0 : NEW_LINE INDENT self . quantization [ v & 15 ] = array . array ( " B " , s [ 1 : 65 ] ) NEW_LINE s = s [ 65 : ] NEW_LINE DEDENT else : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT DEDENT MARKER = { 0xFFC0 : ( " SOF0" , " Baseline ▁ DCT " , SOF ) , 0xFFC1 : ( " SOF1" , " Extended ▁ Sequential ▁ DCT " , SOF ) , 0xFFC2 : ( " SOF2" , " Progressive ▁ DCT " , SOF ) , 0xFFC3 : ( " SOF3" , " Spatial ▁ lossless " , SOF ) , 0xFFC4 : ( " DHT " , " Define ▁ Huffman ▁ table " , Skip ) , 0xFFC5 : ( " SOF5" , " Differential ▁ sequential ▁ DCT " , SOF ) , 0xFFC6 : ( " SOF6" , " Differential ▁ progressive ▁ DCT " , SOF ) , 0xFFC7 : ( " SOF7" , " Differential ▁ spatial " , SOF ) , 0xFFC8 : ( " JPG " , " Extension " , None ) , 0xFFC9 : ( " SOF9" , " Extended ▁ sequential ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCA : ( " SOF10" , " Progressive ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCB : ( " SOF11" , " Spatial ▁ lossless ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCC : ( " DAC " , " Define ▁ arithmetic ▁ coding ▁ conditioning " , Skip ) , 0xFFCD : ( " SOF13" , " Differential ▁ sequential ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCE : ( " SOF14" , " Differential ▁ progressive ▁ DCT ▁ ( AC ) " , SOF ) , 0xFFCF : ( " SOF15" , " Differential ▁ spatial ▁ ( AC ) " , SOF ) , 0xFFD0 : ( " RST0" , " Restart ▁ 0" , None ) , 0xFFD1 : ( " RST1" , " Restart ▁ 1" , None ) , 0xFFD2 : ( " RST2" , " Restart ▁ 2" , None ) , 0xFFD3 : ( " RST3" , " Restart ▁ 3" , None ) , 0xFFD4 : ( " RST4" , " Restart ▁ 4" , None ) , 0xFFD5 : ( " RST5" , " Restart ▁ 5" , None ) , 0xFFD6 : ( " RST6" , " Restart ▁ 6" , None ) , 0xFFD7 : ( " RST7" , " Restart ▁ 7" , None ) , 0xFFD8 : ( " SOI " , " Start ▁ of ▁ image " , None ) , 0xFFD9 : ( " EOI " , " End ▁ of ▁ image " , None ) , 0xFFDA : ( " SOS " , " Start ▁ of ▁ scan " , Skip ) , 0xFFDB : ( " DQT " , " Define ▁ quantization ▁ table " , DQT ) , 0xFFDC : ( " DNL " , " Define ▁ number ▁ of ▁ lines " , Skip ) , 0xFFDD : ( " DRI " , " Define ▁ restart ▁ interval " , Skip ) , 0xFFDE : ( " DHP " , " Define ▁ hierarchical ▁ progression " , SOF ) , 0xFFDF : ( " EXP " , " Expand ▁ reference ▁ component " , Skip ) , 0xFFE0 : ( " APP0" , " Application ▁ segment ▁ 0" , APP ) , 0xFFE1 : ( " APP1" , " Application ▁ segment ▁ 1" , APP ) , 0xFFE2 : ( " APP2" , " Application ▁ segment ▁ 2" , APP ) , 0xFFE3 : ( " APP3" , " Application ▁ segment ▁ 3" , APP ) , 0xFFE4 : ( " APP4" , " Application ▁ segment ▁ 4" , APP ) , 0xFFE5 : ( " APP5" , " Application ▁ segment ▁ 5" , APP ) , 0xFFE6 : ( " APP6" , " Application ▁ segment ▁ 6" , APP ) , 0xFFE7 : ( " APP7" , " Application ▁ segment ▁ 7" , APP ) , 0xFFE8 : ( " APP8" , " Application ▁ segment ▁ 8" , APP ) , 0xFFE9 : ( " APP9" , " Application ▁ segment ▁ 9" , APP ) , 0xFFEA : ( " APP10" , " Application ▁ segment ▁ 10" , APP ) , 0xFFEB : ( " APP11" , " Application ▁ segment ▁ 11" , APP ) , 0xFFEC : ( " APP12" , " Application ▁ segment ▁ 12" , APP ) , 0xFFED : ( " APP13" , " Application ▁ segment ▁ 13" , APP ) , 0xFFEE : ( " APP14" , " Application ▁ segment ▁ 14" , APP ) , 0xFFEF : ( " APP15" , " Application ▁ segment ▁ 15" , APP ) , 0xFFF0 : ( " JPG0" , " Extension ▁ 0" , None ) , 0xFFF1 : ( " JPG1" , " Extension ▁ 1" , None ) , 0xFFF2 : ( " JPG2" , " Extension ▁ 2" , None ) , 0xFFF3 : ( " JPG3" , " Extension ▁ 3" , None ) , 0xFFF4 : ( " JPG4" , " Extension ▁ 4" , None ) , 0xFFF5 : ( " JPG5" , " Extension ▁ 5" , None ) , 0xFFF6 : ( " JPG6" , " Extension ▁ 6" , None ) , 0xFFF7 : ( " JPG7" , " Extension ▁ 7" , None ) , 0xFFF8 : ( " JPG8" , " Extension ▁ 8" , None ) , 0xFFF9 : ( " JPG9" , " Extension ▁ 9" , None ) , 0xFFFA : ( " JPG10" , " Extension ▁ 10" , None ) , 0xFFFB : ( " JPG11" , " Extension ▁ 11" , None ) , 0xFFFC : ( " JPG12" , " Extension ▁ 12" , None ) , 0xFFFD : ( " JPG13" , " Extension ▁ 13" , None ) , 0xFFFE : ( " COM " , " Comment " , COM ) } NEW_LINE def _accept ( prefix ) : NEW_LINE INDENT return prefix [ 0 : 1 ] == b" \377" NEW_LINE DEDENT class JpegImageFile ( ImageFile . ImageFile ) : NEW_LINE INDENT format = " JPEG " NEW_LINE format_description = " JPEG ▁ ( ISO ▁ 10918 ) " NEW_LINE def _open ( self ) : NEW_LINE INDENT s = self . fp . read ( 1 ) NEW_LINE if i8 ( s ) != 255 : NEW_LINE INDENT raise SyntaxError ( " not ▁ a ▁ JPEG ▁ file " ) NEW_LINE DEDENT self . bits = self . layers = 0 NEW_LINE self . layer = [ ] NEW_LINE self . huffman_dc = { } NEW_LINE self . huffman_ac = { } NEW_LINE self . quantization = { } NEW_LINE self . app = { } NEW_LINE self . applist = [ ] NEW_LINE self . icclist = [ ] NEW_LINE while True : NEW_LINE INDENT i = i8 ( s ) NEW_LINE if i == 0xFF : NEW_LINE INDENT s = s + self . fp . read ( 1 ) NEW_LINE i = i16 ( s ) NEW_LINE DEDENT else : NEW_LINE INDENT s = self . fp . read ( 1 ) NEW_LINE continue NEW_LINE DEDENT if i in MARKER : NEW_LINE INDENT name , description , handler = MARKER [ i ] NEW_LINE if handler is not None : NEW_LINE INDENT handler ( self , i ) NEW_LINE DEDENT if i == 0xFFDA : NEW_LINE INDENT rawmode = self . mode NEW_LINE if self . mode == " CMYK " : NEW_LINE INDENT rawmode = " CMYK ; I " NEW_LINE DEDENT self . tile = [ ( " jpeg " , ( 0 , 0 ) + self . size , 0 , ( rawmode , " " ) ) ] NEW_LINE break NEW_LINE DEDENT s = self . fp . read ( 1 ) NEW_LINE DEDENT elif i == 0 or i == 0xFFFF : NEW_LINE INDENT s = b" \xff " NEW_LINE DEDENT elif i == 0xFF00 : NEW_LINE INDENT s = self . fp . read ( 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT raise SyntaxError ( " no ▁ marker ▁ found " ) NEW_LINE DEDENT DEDENT DEDENT def draft ( self , mode , size ) : NEW_LINE INDENT if len ( self . tile ) != 1 : NEW_LINE INDENT return NEW_LINE DEDENT if self . decoderconfig : NEW_LINE INDENT return NEW_LINE DEDENT d , e , o , a = self . tile [ 0 ] NEW_LINE scale = 0 NEW_LINE if a [ 0 ] == " RGB " and mode in [ " L " , " YCbCr " ] : NEW_LINE INDENT self . mode = mode NEW_LINE a = mode , " " NEW_LINE DEDENT if size : NEW_LINE INDENT scale = min ( self . size [ 0 ] // size [ 0 ] , self . size [ 1 ] // size [ 1 ] ) NEW_LINE for s in [ 8 , 4 , 2 , 1 ] : NEW_LINE INDENT if scale >= s : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT e = e [ 0 ] , e [ 1 ] , ( e [ 2 ] - e [ 0 ] + s - 1 ) // s + e [ 0 ] , ( e [ 3 ] - e [ 1 ] + s - 1 ) // s + e [ 1 ] NEW_LINE self . size = ( ( self . size [ 0 ] + s - 1 ) // s , ( self . size [ 1 ] + s - 1 ) // s ) NEW_LINE scale = s NEW_LINE DEDENT self . tile = [ ( d , e , o , a ) ] NEW_LINE self . decoderconfig = ( scale , 0 ) NEW_LINE return self NEW_LINE DEDENT def load_djpeg ( self ) : NEW_LINE INDENT import subprocess NEW_LINE import tempfile NEW_LINE import os NEW_LINE f , path = tempfile . mkstemp ( ) NEW_LINE os . close ( f ) NEW_LINE if os . path . exists ( self . filename ) : NEW_LINE INDENT subprocess . check_call ( [ " djpeg " , " - outfile " , path , self . filename ] ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( " Invalid ▁ Filename " ) NEW_LINE DEDENT try : NEW_LINE INDENT _im = Image . open ( path ) NEW_LINE _im . load ( ) NEW_LINE self . im = _im . im NEW_LINE DEDENT finally : NEW_LINE INDENT try : NEW_LINE INDENT os . unlink ( path ) NEW_LINE DEDENT except OSError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT self . mode = self . im . mode NEW_LINE self . size = self . im . size NEW_LINE self . tile = [ ] NEW_LINE DEDENT def _getexif ( self ) : NEW_LINE INDENT return _getexif ( self ) NEW_LINE DEDENT def _getmp ( self ) : NEW_LINE INDENT return _getmp ( self ) NEW_LINE DEDENT DEDENT def _fixup_dict ( src_dict ) : NEW_LINE INDENT def _fixup ( value ) : NEW_LINE INDENT try : NEW_LINE INDENT if len ( value ) == 1 and not isinstance ( value , dict ) : NEW_LINE INDENT return value [ 0 ] NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT return value NEW_LINE DEDENT return { k : _fixup ( v ) for k , v in src_dict . items ( ) } NEW_LINE DEDENT def _getexif ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT data = self . info [ " exif " ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return None NEW_LINE DEDENT file = io . BytesIO ( data [ 6 : ] ) NEW_LINE head = file . read ( 8 ) NEW_LINE info = TiffImagePlugin . ImageFileDirectory_v1 ( head ) NEW_LINE info . load ( file ) NEW_LINE exif = dict ( _fixup_dict ( info ) ) NEW_LINE try : NEW_LINE INDENT file . seek ( exif [ 0x8769 ] ) NEW_LINE DEDENT except ( KeyError , TypeError ) : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT info = TiffImagePlugin . ImageFileDirectory_v1 ( head ) NEW_LINE info . load ( file ) NEW_LINE exif . update ( _fixup_dict ( info ) ) NEW_LINE DEDENT try : NEW_LINE INDENT file . seek ( exif [ 0x8825 ] ) NEW_LINE DEDENT except ( KeyError , TypeError ) : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT info = TiffImagePlugin . ImageFileDirectory_v1 ( head ) NEW_LINE info . load ( file ) NEW_LINE exif [ 0x8825 ] = _fixup_dict ( info ) NEW_LINE DEDENT return exif NEW_LINE DEDENT def _getmp ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT data = self . info [ " mp " ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return None NEW_LINE DEDENT file_contents = io . BytesIO ( data ) NEW_LINE head = file_contents . read ( 8 ) NEW_LINE endianness = ' > ' if head [ : 4 ] == b' \x4d\x4d\x00\x2a ' else ' < ' NEW_LINE try : NEW_LINE INDENT info = TiffImagePlugin . ImageFileDirectory_v2 ( head ) NEW_LINE info . load ( file_contents ) NEW_LINE mp = dict ( info ) NEW_LINE DEDENT except : NEW_LINE INDENT raise SyntaxError ( " malformed ▁ MP ▁ Index ▁ ( unreadable ▁ directory ) " ) NEW_LINE DEDENT try : NEW_LINE INDENT quant = mp [ 0xB001 ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise SyntaxError ( " malformed ▁ MP ▁ Index ▁ ( no ▁ number ▁ of ▁ images ) " ) NEW_LINE DEDENT mpentries = [ ] NEW_LINE try : NEW_LINE INDENT rawmpentries = mp [ 0xB002 ] NEW_LINE for entrynum in range ( 0 , quant ) : NEW_LINE INDENT unpackedentry = unpack_from ( ' { } LLLHH ' . format ( endianness ) , rawmpentries , entrynum * 16 ) NEW_LINE labels = ( ' Attribute ' , ' Size ' , ' DataOffset ' , ' EntryNo1' , ' EntryNo2' ) NEW_LINE mpentry = dict ( zip ( labels , unpackedentry ) ) NEW_LINE mpentryattr = { ' DependentParentImageFlag ' : bool ( mpentry [ ' Attribute ' ] & ( 1 << 31 ) ) , ' DependentChildImageFlag ' : bool ( mpentry [ ' Attribute ' ] & ( 1 << 30 ) ) , ' RepresentativeImageFlag ' : bool ( mpentry [ ' Attribute ' ] & ( 1 << 29 ) ) , ' Reserved ' : ( mpentry [ ' Attribute ' ] & ( 3 << 27 ) ) >> 27 , ' ImageDataFormat ' : ( mpentry [ ' Attribute ' ] & ( 7 << 24 ) ) >> 24 , ' MPType ' : mpentry [ ' Attribute ' ] & 0x00FFFFFF } NEW_LINE if mpentryattr [ ' ImageDataFormat ' ] == 0 : NEW_LINE INDENT mpentryattr [ ' ImageDataFormat ' ] = ' JPEG ' NEW_LINE DEDENT else : NEW_LINE INDENT raise SyntaxError ( " unsupported ▁ picture ▁ format ▁ in ▁ MPO " ) NEW_LINE DEDENT mptypemap = { 0x000000 : ' Undefined ' , 0x010001 : ' Large ▁ Thumbnail ▁ ( VGA ▁ Equivalent ) ' , 0x010002 : ' Large ▁ Thumbnail ▁ ( Full ▁ HD ▁ Equivalent ) ' , 0x020001 : ' Multi - Frame ▁ Image ▁ ( Panorama ) ' , 0x020002 : ' Multi - Frame ▁ Image : ▁ ( Disparity ) ' , 0x020003 : ' Multi - Frame ▁ Image : ▁ ( Multi - Angle ) ' , 0x030000 : ' Baseline ▁ MP ▁ Primary ▁ Image ' } NEW_LINE mpentryattr [ ' MPType ' ] = mptypemap . get ( mpentryattr [ ' MPType ' ] , ' Unknown ' ) NEW_LINE mpentry [ ' Attribute ' ] = mpentryattr NEW_LINE mpentries . append ( mpentry ) NEW_LINE DEDENT mp [ 0xB002 ] = mpentries NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise SyntaxError ( " malformed ▁ MP ▁ Index ▁ ( bad ▁ MP ▁ Entry ) " ) NEW_LINE DEDENT return mp NEW_LINE DEDENT RAWMODE = { "1" : " L " , " L " : " L " , " RGB " : " RGB " , " RGBA " : " RGB " , " RGBX " : " RGB " , " CMYK " : " CMYK ; I " , " YCbCr " : " YCbCr " , } NEW_LINE zigzag_index = ( 0 , 1 , 5 , 6 , 14 , 15 , 27 , 28 , 2 , 4 , 7 , 13 , 16 , 26 , 29 , 42 , 3 , 8 , 12 , 17 , 25 , 30 , 41 , 43 , 9 , 11 , 18 , 24 , 31 , 40 , 44 , 53 , 10 , 19 , 23 , 32 , 39 , 45 , 52 , 54 , 20 , 22 , 33 , 38 , 46 , 51 , 55 , 60 , 21 , 34 , 37 , 47 , 50 , 56 , 59 , 61 , 35 , 36 , 48 , 49 , 57 , 58 , 62 , 63 ) NEW_LINE samplings = { ( 1 , 1 , 1 , 1 , 1 , 1 ) : 0 , ( 2 , 1 , 1 , 1 , 1 , 1 ) : 1 , ( 2 , 2 , 1 , 1 , 1 , 1 ) : 2 , } NEW_LINE def convert_dict_qtables ( qtables ) : NEW_LINE INDENT qtables = [ qtables [ key ] for key in range ( len ( qtables ) ) if key in qtables ] NEW_LINE for idx , table in enumerate ( qtables ) : NEW_LINE INDENT qtables [ idx ] = [ table [ i ] for i in zigzag_index ] NEW_LINE DEDENT return qtables NEW_LINE DEDENT def get_sampling ( im ) : NEW_LINE INDENT if not hasattr ( im , ' layers ' ) or im . layers in ( 1 , 4 ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT sampling = im . layer [ 0 ] [ 1 : 3 ] + im . layer [ 1 ] [ 1 : 3 ] + im . layer [ 2 ] [ 1 : 3 ] NEW_LINE return samplings . get ( sampling , - 1 ) NEW_LINE DEDENT def _save ( im , fp , filename ) : NEW_LINE INDENT try : NEW_LINE INDENT rawmode = RAWMODE [ im . mode ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT raise IOError ( " cannot ▁ write ▁ mode ▁ % s ▁ as ▁ JPEG " % im . mode ) NEW_LINE DEDENT if im . mode == ' RGBA ' : NEW_LINE INDENT warnings . warn ( ' You ▁ are ▁ saving ▁ RGBA ▁ image ▁ as ▁ JPEG . ▁ The ▁ alpha ▁ channel ▁ will ▁ be ▁ ' ' discarded . ▁ This ▁ conversion ▁ is ▁ deprecated ▁ and ▁ will ▁ be ▁ disabled ▁ ' ' in ▁ Pillow ▁ 3.7 . ▁ Please , ▁ convert ▁ the ▁ image ▁ to ▁ RGB ▁ explicitly . ' , DeprecationWarning ) NEW_LINE DEDENT info = im . encoderinfo NEW_LINE dpi = [ int ( round ( x ) ) for x in info . get ( " dpi " , ( 0 , 0 ) ) ] NEW_LINE quality = info . get ( " quality " , 0 ) NEW_LINE subsampling = info . get ( " subsampling " , - 1 ) NEW_LINE qtables = info . get ( " qtables " ) NEW_LINE if quality == " keep " : NEW_LINE INDENT quality = 0 NEW_LINE subsampling = " keep " NEW_LINE qtables = " keep " NEW_LINE DEDENT elif quality in presets : NEW_LINE INDENT preset = presets [ quality ] NEW_LINE quality = 0 NEW_LINE subsampling = preset . get ( ' subsampling ' , - 1 ) NEW_LINE qtables = preset . get ( ' quantization ' ) NEW_LINE DEDENT elif not isinstance ( quality , int ) : NEW_LINE INDENT raise ValueError ( " Invalid ▁ quality ▁ setting " ) NEW_LINE DEDENT else : NEW_LINE INDENT if subsampling in presets : NEW_LINE INDENT subsampling = presets [ subsampling ] . get ( ' subsampling ' , - 1 ) NEW_LINE DEDENT if isStringType ( qtables ) and qtables in presets : NEW_LINE INDENT qtables = presets [ qtables ] . get ( ' quantization ' ) NEW_LINE DEDENT DEDENT if subsampling == "4:4:4" : NEW_LINE INDENT subsampling = 0 NEW_LINE DEDENT elif subsampling == "4:2:2" : NEW_LINE INDENT subsampling = 1 NEW_LINE DEDENT elif subsampling == "4:1:1" : NEW_LINE INDENT subsampling = 2 NEW_LINE DEDENT elif subsampling == " keep " : NEW_LINE INDENT if im . format != " JPEG " : NEW_LINE INDENT raise ValueError ( " Cannot ▁ use ▁ ' keep ' ▁ when ▁ original ▁ image ▁ is ▁ not ▁ a ▁ JPEG " ) NEW_LINE DEDENT subsampling = get_sampling ( im ) NEW_LINE DEDENT def validate_qtables ( qtables ) : NEW_LINE INDENT if qtables is None : NEW_LINE INDENT return qtables NEW_LINE DEDENT if isStringType ( qtables ) : NEW_LINE INDENT try : NEW_LINE INDENT lines = [ int ( num ) for line in qtables . splitlines ( ) for num in line . split ( ' # ' , 1 ) [ 0 ] . split ( ) ] NEW_LINE DEDENT except ValueError : NEW_LINE INDENT raise ValueError ( " Invalid ▁ quantization ▁ table " ) NEW_LINE DEDENT else : NEW_LINE INDENT qtables = [ lines [ s : s + 64 ] for s in range ( 0 , len ( lines ) , 64 ) ] NEW_LINE DEDENT DEDENT if isinstance ( qtables , ( tuple , list , dict ) ) : NEW_LINE INDENT if isinstance ( qtables , dict ) : NEW_LINE INDENT qtables = convert_dict_qtables ( qtables ) NEW_LINE DEDENT elif isinstance ( qtables , tuple ) : NEW_LINE INDENT qtables = list ( qtables ) NEW_LINE DEDENT if not ( 0 < len ( qtables ) < 5 ) : NEW_LINE INDENT raise ValueError ( " None ▁ or ▁ too ▁ many ▁ quantization ▁ tables " ) NEW_LINE DEDENT for idx , table in enumerate ( qtables ) : NEW_LINE INDENT try : NEW_LINE INDENT if len ( table ) != 64 : NEW_LINE INDENT raise NEW_LINE DEDENT table = array . array ( ' B ' , table ) NEW_LINE DEDENT except TypeError : NEW_LINE INDENT raise ValueError ( " Invalid ▁ quantization ▁ table " ) NEW_LINE DEDENT else : NEW_LINE INDENT qtables [ idx ] = list ( table ) NEW_LINE DEDENT DEDENT return qtables NEW_LINE DEDENT DEDENT if qtables == " keep " : NEW_LINE INDENT if im . format != " JPEG " : NEW_LINE INDENT raise ValueError ( " Cannot ▁ use ▁ ' keep ' ▁ when ▁ original ▁ image ▁ is ▁ not ▁ a ▁ JPEG " ) NEW_LINE DEDENT qtables = getattr ( im , " quantization " , None ) NEW_LINE DEDENT qtables = validate_qtables ( qtables ) NEW_LINE extra = b" " NEW_LINE icc_profile = info . get ( " icc _ profile " ) NEW_LINE if icc_profile : NEW_LINE INDENT ICC_OVERHEAD_LEN = 14 NEW_LINE MAX_BYTES_IN_MARKER = 65533 NEW_LINE MAX_DATA_BYTES_IN_MARKER = MAX_BYTES_IN_MARKER - ICC_OVERHEAD_LEN NEW_LINE markers = [ ] NEW_LINE while icc_profile : NEW_LINE INDENT markers . append ( icc_profile [ : MAX_DATA_BYTES_IN_MARKER ] ) NEW_LINE icc_profile = icc_profile [ MAX_DATA_BYTES_IN_MARKER : ] NEW_LINE DEDENT i = 1 NEW_LINE for marker in markers : NEW_LINE INDENT size = struct . pack ( " > H " , 2 + ICC_OVERHEAD_LEN + len ( marker ) ) NEW_LINE extra += ( b" \xFF\xE2" + size + b" ICC _ PROFILE\0" + o8 ( i ) + o8 ( len ( markers ) ) + marker ) NEW_LINE i += 1 NEW_LINE DEDENT DEDENT progressive = info . get ( " progressive " , False ) or \NEW_LINE info . get ( " progression " , False ) NEW_LINE optimize = info . get ( " optimize " , False ) NEW_LINE im . encoderconfig = ( quality , progressive , info . get ( " smooth " , 0 ) , optimize , info . get ( " streamtype " , 0 ) , dpi [ 0 ] , dpi [ 1 ] , subsampling , qtables , extra , info . get ( " exif " , b" " ) ) NEW_LINE bufsize = 0 NEW_LINE if optimize or progressive : NEW_LINE INDENT if im . mode == ' CMYK ' : NEW_LINE INDENT bufsize = 4 * im . size [ 0 ] * im . size [ 1 ] NEW_LINE DEDENT elif quality >= 95 or quality == 0 : NEW_LINE INDENT bufsize = 2 * im . size [ 0 ] * im . size [ 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT bufsize = im . size [ 0 ] * im . size [ 1 ] NEW_LINE DEDENT DEDENT bufsize = max ( ImageFile . MAXBLOCK , bufsize , len ( info . get ( " exif " , b" " ) ) + 5 ) NEW_LINE ImageFile . _save ( im , fp , [ ( " jpeg " , ( 0 , 0 ) + im . size , 0 , rawmode ) ] , bufsize ) NEW_LINE DEDENT def _save_cjpeg ( im , fp , filename ) : NEW_LINE INDENT import os NEW_LINE import subprocess NEW_LINE tempfile = im . _dump ( ) NEW_LINE subprocess . check_call ( [ " cjpeg " , " - outfile " , filename , tempfile ] ) NEW_LINE try : NEW_LINE INDENT os . unlink ( tempfile ) NEW_LINE DEDENT except OSError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT def jpeg_factory ( fp = None , filename = None ) : NEW_LINE INDENT im = JpegImageFile ( fp , filename ) NEW_LINE try : NEW_LINE INDENT mpheader = im . _getmp ( ) NEW_LINE if mpheader [ 45057 ] > 1 : NEW_LINE INDENT from . MpoImagePlugin import MpoImageFile NEW_LINE im = MpoImageFile ( fp , filename ) NEW_LINE DEDENT DEDENT except ( TypeError , IndexError ) : NEW_LINE INDENT pass NEW_LINE DEDENT except SyntaxError : NEW_LINE INDENT warnings . warn ( " Image ▁ appears ▁ to ▁ be ▁ a ▁ malformed ▁ MPO ▁ file , ▁ it ▁ will ▁ be ▁ " " interpreted ▁ as ▁ a ▁ base ▁ JPEG ▁ file " ) NEW_LINE DEDENT return im NEW_LINE DEDENT Image . register_open ( JpegImageFile . format , jpeg_factory , _accept ) NEW_LINE Image . register_save ( JpegImageFile . format , _save ) NEW_LINE Image . register_extension ( JpegImageFile . format , " . jfif " ) NEW_LINE Image . register_extension ( JpegImageFile . format , " . jpe " ) NEW_LINE Image . register_extension ( JpegImageFile . format , " . jpg " ) NEW_LINE Image . register_extension ( JpegImageFile . format , " . jpeg " ) NEW_LINE Image . register_mime ( JpegImageFile . format , " image / jpeg " ) NEW_LINE
 from __future__ import absolute_import NEW_LINE from django import template NEW_LINE from django . conf import settings NEW_LINE from django . contrib import comments NEW_LINE from django . contrib . auth . decorators import login_required , permission_required NEW_LINE from django . contrib . comments import signals NEW_LINE from django . contrib . comments . views . utils import next_redirect , confirmation_view NEW_LINE from django . shortcuts import get_object_or_404 , render_to_response NEW_LINE from django . views . decorators . csrf import csrf_protect NEW_LINE @ csrf_protect NEW_LINE @ login_required NEW_LINE def flag ( request , comment_id , next = None ) : NEW_LINE INDENT comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE if request . method == ' POST ' : NEW_LINE INDENT perform_flag ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - flag - done ' , c = comment . pk ) NEW_LINE DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / flag . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE DEDENT DEDENT @ csrf_protect NEW_LINE @ permission_required ( " comments . can _ moderate " ) NEW_LINE def delete ( request , comment_id , next = None ) : NEW_LINE INDENT comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE if request . method == ' POST ' : NEW_LINE INDENT perform_delete ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - delete - done ' , c = comment . pk ) NEW_LINE DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / delete . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE DEDENT DEDENT @ csrf_protect NEW_LINE @ permission_required ( " comments . can _ moderate " ) NEW_LINE def approve ( request , comment_id , next = None ) : NEW_LINE INDENT comment = get_object_or_404 ( comments . get_model ( ) , pk = comment_id , site__pk = settings . SITE_ID ) NEW_LINE if request . method == ' POST ' : NEW_LINE INDENT perform_approve ( request , comment ) NEW_LINE return next_redirect ( request , fallback = next or ' comments - approve - done ' , c = comment . pk ) NEW_LINE DEDENT else : NEW_LINE INDENT return render_to_response ( ' comments / approve . html ' , { ' comment ' : comment , " next " : next } , template . RequestContext ( request ) ) NEW_LINE DEDENT DEDENT def perform_flag ( request , comment ) : NEW_LINE INDENT flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . SUGGEST_REMOVAL ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE DEDENT def perform_delete ( request , comment ) : NEW_LINE INDENT flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . MODERATOR_DELETION ) NEW_LINE comment . is_removed = True NEW_LINE comment . save ( ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE DEDENT def perform_approve ( request , comment ) : NEW_LINE INDENT flag , created = comments . models . CommentFlag . objects . get_or_create ( comment = comment , user = request . user , flag = comments . models . CommentFlag . MODERATOR_APPROVAL , ) NEW_LINE comment . is_removed = False NEW_LINE comment . is_public = True NEW_LINE comment . save ( ) NEW_LINE signals . comment_was_flagged . send ( sender = comment . __class__ , comment = comment , flag = flag , created = created , request = request , ) NEW_LINE DEDENT flag_done = confirmation_view ( template = " comments / flagged . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ flagged " ▁ success ▁ page . ' ) NEW_LINE delete_done = confirmation_view ( template = " comments / deleted . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ deleted " ▁ success ▁ page . ' ) NEW_LINE approve_done = confirmation_view ( template = " comments / approved . html " , doc = ' Displays ▁ a ▁ " comment ▁ was ▁ approved " ▁ success ▁ page . ' ) NEW_LINE
 from abc import ABCMeta , abstractmethod NEW_LINE import sys NEW_LINE __all__ = [ " Hashable " , " Iterable " , " Iterator " , " Sized " , " Container " , " Callable " , " Set " , " MutableSet " , " Mapping " , " MutableMapping " , " MappingView " , " KeysView " , " ItemsView " , " ValuesView " , " Sequence " , " MutableSequence " , " ByteString " , ] NEW_LINE bytes_iterator = type ( iter ( b' ' ) ) NEW_LINE bytearray_iterator = type ( iter ( bytearray ( ) ) ) NEW_LINE dict_keyiterator = type ( iter ( { } . keys ( ) ) ) NEW_LINE dict_valueiterator = type ( iter ( { } . values ( ) ) ) NEW_LINE dict_itemiterator = type ( iter ( { } . items ( ) ) ) NEW_LINE list_iterator = type ( iter ( [ ] ) ) NEW_LINE list_reverseiterator = type ( iter ( reversed ( [ ] ) ) ) NEW_LINE range_iterator = type ( iter ( range ( 0 ) ) ) NEW_LINE set_iterator = type ( iter ( set ( ) ) ) NEW_LINE str_iterator = type ( iter ( " " ) ) NEW_LINE tuple_iterator = type ( iter ( ( ) ) ) NEW_LINE zip_iterator = type ( iter ( zip ( ) ) ) NEW_LINE dict_keys = type ( { } . keys ( ) ) NEW_LINE dict_values = type ( { } . values ( ) ) NEW_LINE dict_items = type ( { } . items ( ) ) NEW_LINE mappingproxy = type ( type . __dict__ ) NEW_LINE class Hashable ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __hash__ ( self ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Hashable : NEW_LINE INDENT for B in C . __mro__ : NEW_LINE INDENT if " _ _ hash _ _ " in B . __dict__ : NEW_LINE INDENT if B . __dict__ [ " _ _ hash _ _ " ] : NEW_LINE INDENT return True NEW_LINE DEDENT break NEW_LINE DEDENT DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Iterable ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __iter__ ( self ) : NEW_LINE INDENT while False : NEW_LINE INDENT yield None NEW_LINE DEDENT DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Iterable : NEW_LINE INDENT if any ( " _ _ iter _ _ " in B . __dict__ for B in C . __mro__ ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Iterator ( Iterable ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __next__ ( self ) : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT def __iter__ ( self ) : NEW_LINE INDENT return self NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Iterator : NEW_LINE INDENT if ( any ( " _ _ next _ _ " in B . __dict__ for B in C . __mro__ ) and any ( " _ _ iter _ _ " in B . __dict__ for B in C . __mro__ ) ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT Iterator . register ( bytes_iterator ) NEW_LINE Iterator . register ( bytearray_iterator ) NEW_LINE Iterator . register ( dict_keyiterator ) NEW_LINE Iterator . register ( dict_valueiterator ) NEW_LINE Iterator . register ( dict_itemiterator ) NEW_LINE Iterator . register ( list_iterator ) NEW_LINE Iterator . register ( list_reverseiterator ) NEW_LINE Iterator . register ( range_iterator ) NEW_LINE Iterator . register ( set_iterator ) NEW_LINE Iterator . register ( str_iterator ) NEW_LINE Iterator . register ( tuple_iterator ) NEW_LINE Iterator . register ( zip_iterator ) NEW_LINE class Sized ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __len__ ( self ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Sized : NEW_LINE INDENT if any ( " _ _ len _ _ " in B . __dict__ for B in C . __mro__ ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Container ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __contains__ ( self , x ) : NEW_LINE INDENT return False NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Container : NEW_LINE INDENT if any ( " _ _ contains _ _ " in B . __dict__ for B in C . __mro__ ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Callable ( metaclass = ABCMeta ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __call__ ( self , * args , ** kwds ) : NEW_LINE INDENT return False NEW_LINE DEDENT @ classmethod NEW_LINE def __subclasshook__ ( cls , C ) : NEW_LINE INDENT if cls is Callable : NEW_LINE INDENT if any ( " _ _ call _ _ " in B . __dict__ for B in C . __mro__ ) : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return NotImplemented NEW_LINE DEDENT DEDENT class Set ( Sized , Iterable , Container ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE def __le__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT if len ( self ) > len ( other ) : NEW_LINE INDENT return False NEW_LINE DEDENT for elem in self : NEW_LINE INDENT if elem not in other : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def __lt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return len ( self ) < len ( other ) and self . __le__ ( other ) NEW_LINE DEDENT def __gt__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return other < self NEW_LINE DEDENT def __ge__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return other <= self NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return len ( self ) == len ( other ) and self . __le__ ( other ) NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT return not ( self == other ) NEW_LINE DEDENT @ classmethod NEW_LINE def _from_iterable ( cls , it ) : NEW_LINE INDENT return cls ( it ) NEW_LINE DEDENT def __and__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Iterable ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return self . _from_iterable ( value for value in other if value in self ) NEW_LINE DEDENT def isdisjoint ( self , other ) : NEW_LINE INDENT for value in other : NEW_LINE INDENT if value in self : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def __or__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Iterable ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT chain = ( e for s in ( self , other ) for e in s ) NEW_LINE return self . _from_iterable ( chain ) NEW_LINE DEDENT def __sub__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT if not isinstance ( other , Iterable ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT other = self . _from_iterable ( other ) NEW_LINE DEDENT return self . _from_iterable ( value for value in self if value not in other ) NEW_LINE DEDENT def __xor__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Set ) : NEW_LINE INDENT if not isinstance ( other , Iterable ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT other = self . _from_iterable ( other ) NEW_LINE DEDENT return ( self - other ) | ( other - self ) NEW_LINE DEDENT def _hash ( self ) : NEW_LINE INDENT MAX = sys . maxsize NEW_LINE MASK = 2 * MAX + 1 NEW_LINE n = len ( self ) NEW_LINE h = 1927868237 * ( n + 1 ) NEW_LINE h &= MASK NEW_LINE for x in self : NEW_LINE INDENT hx = hash ( x ) NEW_LINE h ^= ( hx ^ ( hx << 16 ) ^ 89869747 ) * 3644798167 NEW_LINE h &= MASK NEW_LINE DEDENT h = h * 69069 + 907133923 NEW_LINE h &= MASK NEW_LINE if h > MAX : NEW_LINE INDENT h -= MASK + 1 NEW_LINE DEDENT if h == - 1 : NEW_LINE INDENT h = 590923713 NEW_LINE DEDENT return h NEW_LINE DEDENT DEDENT Set . register ( frozenset ) NEW_LINE class MutableSet ( Set ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def add ( self , value ) : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT @ abstractmethod NEW_LINE def discard ( self , value ) : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT def remove ( self , value ) : NEW_LINE INDENT if value not in self : NEW_LINE INDENT raise KeyError ( value ) NEW_LINE DEDENT self . discard ( value ) NEW_LINE DEDENT def pop ( self ) : NEW_LINE INDENT it = iter ( self ) NEW_LINE try : NEW_LINE INDENT value = next ( it ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT self . discard ( value ) NEW_LINE return value NEW_LINE DEDENT def clear ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT while True : NEW_LINE INDENT self . pop ( ) NEW_LINE DEDENT DEDENT except KeyError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT def __ior__ ( self , it ) : NEW_LINE INDENT for value in it : NEW_LINE INDENT self . add ( value ) NEW_LINE DEDENT return self NEW_LINE DEDENT def __iand__ ( self , it ) : NEW_LINE INDENT for value in ( self - it ) : NEW_LINE INDENT self . discard ( value ) NEW_LINE DEDENT return self NEW_LINE DEDENT def __ixor__ ( self , it ) : NEW_LINE INDENT if it is self : NEW_LINE INDENT self . clear ( ) NEW_LINE DEDENT else : NEW_LINE INDENT if not isinstance ( it , Set ) : NEW_LINE INDENT it = self . _from_iterable ( it ) NEW_LINE DEDENT for value in it : NEW_LINE INDENT if value in self : NEW_LINE INDENT self . discard ( value ) NEW_LINE DEDENT else : NEW_LINE INDENT self . add ( value ) NEW_LINE DEDENT DEDENT DEDENT return self NEW_LINE DEDENT def __isub__ ( self , it ) : NEW_LINE INDENT if it is self : NEW_LINE INDENT self . clear ( ) NEW_LINE DEDENT else : NEW_LINE INDENT for value in it : NEW_LINE INDENT self . discard ( value ) NEW_LINE DEDENT DEDENT return self NEW_LINE DEDENT DEDENT MutableSet . register ( set ) NEW_LINE class Mapping ( Sized , Iterable , Container ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __getitem__ ( self , key ) : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT def get ( self , key , default = None ) : NEW_LINE INDENT try : NEW_LINE INDENT return self [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return default NEW_LINE DEDENT DEDENT def __contains__ ( self , key ) : NEW_LINE INDENT try : NEW_LINE INDENT self [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT def keys ( self ) : NEW_LINE INDENT return KeysView ( self ) NEW_LINE DEDENT def items ( self ) : NEW_LINE INDENT return ItemsView ( self ) NEW_LINE DEDENT def values ( self ) : NEW_LINE INDENT return ValuesView ( self ) NEW_LINE DEDENT def __eq__ ( self , other ) : NEW_LINE INDENT if not isinstance ( other , Mapping ) : NEW_LINE INDENT return NotImplemented NEW_LINE DEDENT return dict ( self . items ( ) ) == dict ( other . items ( ) ) NEW_LINE DEDENT def __ne__ ( self , other ) : NEW_LINE INDENT return not ( self == other ) NEW_LINE DEDENT DEDENT Mapping . register ( mappingproxy ) NEW_LINE class MappingView ( Sized ) : NEW_LINE INDENT def __init__ ( self , mapping ) : NEW_LINE INDENT self . _mapping = mapping NEW_LINE DEDENT def __len__ ( self ) : NEW_LINE INDENT return len ( self . _mapping ) NEW_LINE DEDENT def __repr__ ( self ) : NEW_LINE INDENT return ' { 0 . _ _ class _ _ . _ _ name _ _ } ( { 0 . _ mapping ! r } ) ' . format ( self ) NEW_LINE DEDENT DEDENT class KeysView ( MappingView , Set ) : NEW_LINE INDENT @ classmethod NEW_LINE def _from_iterable ( self , it ) : NEW_LINE INDENT return set ( it ) NEW_LINE DEDENT def __contains__ ( self , key ) : NEW_LINE INDENT return key in self . _mapping NEW_LINE DEDENT def __iter__ ( self ) : NEW_LINE INDENT for key in self . _mapping : NEW_LINE INDENT yield key NEW_LINE DEDENT DEDENT DEDENT KeysView . register ( dict_keys ) NEW_LINE class ItemsView ( MappingView , Set ) : NEW_LINE INDENT @ classmethod NEW_LINE def _from_iterable ( self , it ) : NEW_LINE INDENT return set ( it ) NEW_LINE DEDENT def __contains__ ( self , item ) : NEW_LINE INDENT key , value = item NEW_LINE try : NEW_LINE INDENT v = self . _mapping [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return v == value NEW_LINE DEDENT DEDENT def __iter__ ( self ) : NEW_LINE INDENT for key in self . _mapping : NEW_LINE INDENT yield ( key , self . _mapping [ key ] ) NEW_LINE DEDENT DEDENT DEDENT ItemsView . register ( dict_items ) NEW_LINE class ValuesView ( MappingView ) : NEW_LINE INDENT def __contains__ ( self , value ) : NEW_LINE INDENT for key in self . _mapping : NEW_LINE INDENT if value == self . _mapping [ key ] : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def __iter__ ( self ) : NEW_LINE INDENT for key in self . _mapping : NEW_LINE INDENT yield self . _mapping [ key ] NEW_LINE DEDENT DEDENT DEDENT ValuesView . register ( dict_values ) NEW_LINE class MutableMapping ( Mapping ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __setitem__ ( self , key , value ) : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT @ abstractmethod NEW_LINE def __delitem__ ( self , key ) : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT __marker = object ( ) NEW_LINE def pop ( self , key , default = __marker ) : NEW_LINE INDENT try : NEW_LINE INDENT value = self [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT if default is self . __marker : NEW_LINE INDENT raise NEW_LINE DEDENT return default NEW_LINE DEDENT else : NEW_LINE INDENT del self [ key ] NEW_LINE return value NEW_LINE DEDENT DEDENT def popitem ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT key = next ( iter ( self ) ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT raise KeyError NEW_LINE DEDENT value = self [ key ] NEW_LINE del self [ key ] NEW_LINE return key , value NEW_LINE DEDENT def clear ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT while True : NEW_LINE INDENT self . popitem ( ) NEW_LINE DEDENT DEDENT except KeyError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT def update ( * args , ** kwds ) : NEW_LINE INDENT if len ( args ) > 2 : NEW_LINE INDENT raise TypeError ( " update ( ) ▁ takes ▁ at ▁ most ▁ 2 ▁ positional ▁ " " arguments ▁ ( { } ▁ given ) " . format ( len ( args ) ) ) NEW_LINE DEDENT elif not args : NEW_LINE INDENT raise TypeError ( " update ( ) ▁ takes ▁ at ▁ least ▁ 1 ▁ argument ▁ ( 0 ▁ given ) " ) NEW_LINE DEDENT self = args [ 0 ] NEW_LINE other = args [ 1 ] if len ( args ) >= 2 else ( ) NEW_LINE if isinstance ( other , Mapping ) : NEW_LINE INDENT for key in other : NEW_LINE INDENT self [ key ] = other [ key ] NEW_LINE DEDENT DEDENT elif hasattr ( other , " keys " ) : NEW_LINE INDENT for key in other . keys ( ) : NEW_LINE INDENT self [ key ] = other [ key ] NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT for key , value in other : NEW_LINE INDENT self [ key ] = value NEW_LINE DEDENT DEDENT for key , value in kwds . items ( ) : NEW_LINE INDENT self [ key ] = value NEW_LINE DEDENT DEDENT def setdefault ( self , key , default = None ) : NEW_LINE INDENT try : NEW_LINE INDENT return self [ key ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT self [ key ] = default NEW_LINE DEDENT return default NEW_LINE DEDENT DEDENT MutableMapping . register ( dict ) NEW_LINE class Sequence ( Sized , Iterable , Container ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __getitem__ ( self , index ) : NEW_LINE INDENT raise IndexError NEW_LINE DEDENT def __iter__ ( self ) : NEW_LINE INDENT i = 0 NEW_LINE try : NEW_LINE INDENT while True : NEW_LINE INDENT v = self [ i ] NEW_LINE yield v NEW_LINE i += 1 NEW_LINE DEDENT DEDENT except IndexError : NEW_LINE INDENT return NEW_LINE DEDENT DEDENT def __contains__ ( self , value ) : NEW_LINE INDENT for v in self : NEW_LINE INDENT if v == value : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT def __reversed__ ( self ) : NEW_LINE INDENT for i in reversed ( range ( len ( self ) ) ) : NEW_LINE INDENT yield self [ i ] NEW_LINE DEDENT DEDENT def index ( self , value ) : NEW_LINE INDENT for i , v in enumerate ( self ) : NEW_LINE INDENT if v == value : NEW_LINE INDENT return i NEW_LINE DEDENT DEDENT raise ValueError NEW_LINE DEDENT def count ( self , value ) : NEW_LINE INDENT return sum ( 1 for v in self if v == value ) NEW_LINE DEDENT DEDENT Sequence . register ( tuple ) NEW_LINE Sequence . register ( str ) NEW_LINE Sequence . register ( range ) NEW_LINE class ByteString ( Sequence ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE DEDENT ByteString . register ( bytes ) NEW_LINE ByteString . register ( bytearray ) NEW_LINE class MutableSequence ( Sequence ) : NEW_LINE INDENT __slots__ = ( ) NEW_LINE @ abstractmethod NEW_LINE def __setitem__ ( self , index , value ) : NEW_LINE INDENT raise IndexError NEW_LINE DEDENT @ abstractmethod NEW_LINE def __delitem__ ( self , index ) : NEW_LINE INDENT raise IndexError NEW_LINE DEDENT @ abstractmethod NEW_LINE def insert ( self , index , value ) : NEW_LINE INDENT raise IndexError NEW_LINE DEDENT def append ( self , value ) : NEW_LINE INDENT self . insert ( len ( self ) , value ) NEW_LINE DEDENT def clear ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT while True : NEW_LINE INDENT self . pop ( ) NEW_LINE DEDENT DEDENT except IndexError : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT def reverse ( self ) : NEW_LINE INDENT n = len ( self ) NEW_LINE for i in range ( n // 2 ) : NEW_LINE INDENT self [ i ] , self [ n - i - 1 ] = self [ n - i - 1 ] , self [ i ] NEW_LINE DEDENT DEDENT def extend ( self , values ) : NEW_LINE INDENT for v in values : NEW_LINE INDENT self . append ( v ) NEW_LINE DEDENT DEDENT def pop ( self , index = - 1 ) : NEW_LINE INDENT v = self [ index ] NEW_LINE del self [ index ] NEW_LINE return v NEW_LINE DEDENT def remove ( self , value ) : NEW_LINE INDENT del self [ self . index ( value ) ] NEW_LINE DEDENT def __iadd__ ( self , values ) : NEW_LINE INDENT self . extend ( values ) NEW_LINE return self NEW_LINE DEDENT DEDENT MutableSequence . register ( list ) NEW_LINE MutableSequence . register ( bytearray ) NEW_LINE
 import os , sys NEW_LINE sys . path . append ( os . environ [ ' PERF _ EXEC _ PATH ' ] + ' / scripts / python / Perf - Trace - Util / lib / Perf / Trace ' ) NEW_LINE from Util import * NEW_LINE process_names = { } NEW_LINE thread_thislock = { } NEW_LINE thread_blocktime = { } NEW_LINE lock_waits = { } NEW_LINE process_names = { } NEW_LINE def syscalls__sys_enter_futex ( event , ctxt , cpu , s , ns , tid , comm , nr , uaddr , op , val , utime , uaddr2 , val3 ) : NEW_LINE INDENT cmd = op & FUTEX_CMD_MASK NEW_LINE if cmd != FUTEX_WAIT : NEW_LINE INDENT return NEW_LINE DEDENT process_names [ tid ] = comm NEW_LINE thread_thislock [ tid ] = uaddr NEW_LINE thread_blocktime [ tid ] = nsecs ( s , ns ) NEW_LINE DEDENT def syscalls__sys_exit_futex ( event , ctxt , cpu , s , ns , tid , comm , nr , ret ) : NEW_LINE INDENT if thread_blocktime . has_key ( tid ) : NEW_LINE INDENT elapsed = nsecs ( s , ns ) - thread_blocktime [ tid ] NEW_LINE add_stats ( lock_waits , ( tid , thread_thislock [ tid ] ) , elapsed ) NEW_LINE del thread_blocktime [ tid ] NEW_LINE del thread_thislock [ tid ] NEW_LINE DEDENT DEDENT def trace_begin ( ) : NEW_LINE INDENT print " Press ▁ control + C ▁ to ▁ stop ▁ and ▁ show ▁ the ▁ summary " NEW_LINE DEDENT def trace_end ( ) : NEW_LINE INDENT for ( tid , lock ) in lock_waits : NEW_LINE INDENT min , max , avg , count = lock_waits [ tid , lock ] NEW_LINE print " % s [ % d ] ▁ lock ▁ % x ▁ contended ▁ % d ▁ times , ▁ % d ▁ avg ▁ ns " % \NEW_LINE ( process_names [ tid ] , tid , lock , count , avg ) NEW_LINE DEDENT DEDENT
 from . . . schema import Table , MetaData , Column NEW_LINE from . . . orm import synonym as _orm_synonym , \NEW_LINE comparable_property , \NEW_LINE interfaces , properties , attributes NEW_LINE from . . . orm . util import polymorphic_union NEW_LINE from . . . orm . base import _mapper_or_none NEW_LINE from . . . util import OrderedDict , hybridmethod , hybridproperty NEW_LINE from . . . import util NEW_LINE from . . . import exc NEW_LINE import weakref NEW_LINE from . base import _as_declarative , \NEW_LINE _declarative_constructor , \NEW_LINE _DeferredMapperConfig , _add_attribute NEW_LINE from . clsregistry import _class_resolver NEW_LINE def instrument_declarative ( cls , registry , metadata ) : NEW_LINE INDENT if ' _ decl _ class _ registry ' in cls . __dict__ : NEW_LINE INDENT raise exc . InvalidRequestError ( " Class ▁ % r ▁ already ▁ has ▁ been ▁ " " instrumented ▁ declaratively " % cls ) NEW_LINE DEDENT cls . _decl_class_registry = registry NEW_LINE cls . metadata = metadata NEW_LINE _as_declarative ( cls , cls . __name__ , cls . __dict__ ) NEW_LINE DEDENT def has_inherited_table ( cls ) : NEW_LINE INDENT for class_ in cls . __mro__ [ 1 : ] : NEW_LINE INDENT if getattr ( class_ , ' _ _ table _ _ ' , None ) is not None : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT return False NEW_LINE DEDENT class DeclarativeMeta ( type ) : NEW_LINE INDENT def __init__ ( cls , classname , bases , dict_ ) : NEW_LINE INDENT if ' _ decl _ class _ registry ' not in cls . __dict__ : NEW_LINE INDENT _as_declarative ( cls , classname , cls . __dict__ ) NEW_LINE DEDENT type . __init__ ( cls , classname , bases , dict_ ) NEW_LINE DEDENT def __setattr__ ( cls , key , value ) : NEW_LINE INDENT _add_attribute ( cls , key , value ) NEW_LINE DEDENT DEDENT def synonym_for ( name , map_column = False ) : NEW_LINE INDENT def decorate ( fn ) : NEW_LINE INDENT return _orm_synonym ( name , map_column = map_column , descriptor = fn ) NEW_LINE DEDENT return decorate NEW_LINE DEDENT def comparable_using ( comparator_factory ) : NEW_LINE INDENT def decorate ( fn ) : NEW_LINE INDENT return comparable_property ( comparator_factory , fn ) NEW_LINE DEDENT return decorate NEW_LINE DEDENT class declared_attr ( interfaces . _MappedAttribute , property ) : NEW_LINE INDENT def __init__ ( self , fget , cascading = False ) : NEW_LINE INDENT super ( declared_attr , self ) . __init__ ( fget ) NEW_LINE self . __doc__ = fget . __doc__ NEW_LINE self . _cascading = cascading NEW_LINE DEDENT def __get__ ( desc , self , cls ) : NEW_LINE INDENT reg = cls . __dict__ . get ( ' _ sa _ declared _ attr _ reg ' , None ) NEW_LINE if reg is None : NEW_LINE INDENT manager = attributes . manager_of_class ( cls ) NEW_LINE if manager is None : NEW_LINE INDENT util . warn ( " Unmanaged ▁ access ▁ of ▁ declarative ▁ attribute ▁ % s ▁ from ▁ " " non - mapped ▁ class ▁ % s " % ( desc . fget . __name__ , cls . __name__ ) ) NEW_LINE DEDENT return desc . fget ( cls ) NEW_LINE DEDENT if reg is None : NEW_LINE INDENT return desc . fget ( cls ) NEW_LINE DEDENT elif desc in reg : NEW_LINE INDENT return reg [ desc ] NEW_LINE DEDENT else : NEW_LINE INDENT reg [ desc ] = obj = desc . fget ( cls ) NEW_LINE return obj NEW_LINE DEDENT DEDENT @ hybridmethod NEW_LINE def _stateful ( cls , ** kw ) : NEW_LINE INDENT return _stateful_declared_attr ( ** kw ) NEW_LINE DEDENT @ hybridproperty NEW_LINE def cascading ( cls ) : NEW_LINE INDENT return cls . _stateful ( cascading = True ) NEW_LINE DEDENT DEDENT class _stateful_declared_attr ( declared_attr ) : NEW_LINE INDENT def __init__ ( self , ** kw ) : NEW_LINE INDENT self . kw = kw NEW_LINE DEDENT def _stateful ( self , ** kw ) : NEW_LINE INDENT new_kw = self . kw . copy ( ) NEW_LINE new_kw . update ( kw ) NEW_LINE return _stateful_declared_attr ( ** new_kw ) NEW_LINE DEDENT def __call__ ( self , fn ) : NEW_LINE INDENT return declared_attr ( fn , ** self . kw ) NEW_LINE DEDENT DEDENT def declarative_base ( bind = None , metadata = None , mapper = None , cls = object , name = ' Base ' , constructor = _declarative_constructor , class_registry = None , metaclass = DeclarativeMeta ) : NEW_LINE INDENT lcl_metadata = metadata or MetaData ( ) NEW_LINE if bind : NEW_LINE INDENT lcl_metadata . bind = bind NEW_LINE DEDENT if class_registry is None : NEW_LINE INDENT class_registry = weakref . WeakValueDictionary ( ) NEW_LINE DEDENT bases = not isinstance ( cls , tuple ) and ( cls , ) or cls NEW_LINE class_dict = dict ( _decl_class_registry = class_registry , metadata = lcl_metadata ) NEW_LINE if constructor : NEW_LINE INDENT class_dict [ ' _ _ init _ _ ' ] = constructor NEW_LINE DEDENT if mapper : NEW_LINE INDENT class_dict [ ' _ _ mapper _ cls _ _ ' ] = mapper NEW_LINE DEDENT return metaclass ( name , bases , class_dict ) NEW_LINE DEDENT def as_declarative ( ** kw ) : NEW_LINE INDENT def decorate ( cls ) : NEW_LINE INDENT kw [ ' cls ' ] = cls NEW_LINE kw [ ' name ' ] = cls . __name__ NEW_LINE return declarative_base ( ** kw ) NEW_LINE DEDENT return decorate NEW_LINE DEDENT class ConcreteBase ( object ) : NEW_LINE INDENT @ classmethod NEW_LINE def _create_polymorphic_union ( cls , mappers ) : NEW_LINE INDENT return polymorphic_union ( OrderedDict ( ( mp . polymorphic_identity , mp . local_table ) for mp in mappers ) , ' type ' , ' pjoin ' ) NEW_LINE DEDENT @ classmethod NEW_LINE def __declare_first__ ( cls ) : NEW_LINE INDENT m = cls . __mapper__ NEW_LINE if m . with_polymorphic : NEW_LINE INDENT return NEW_LINE DEDENT mappers = list ( m . self_and_descendants ) NEW_LINE pjoin = cls . _create_polymorphic_union ( mappers ) NEW_LINE m . _set_with_polymorphic ( ( " * " , pjoin ) ) NEW_LINE m . _set_polymorphic_on ( pjoin . c . type ) NEW_LINE DEDENT DEDENT class AbstractConcreteBase ( ConcreteBase ) : NEW_LINE INDENT __no_table__ = True NEW_LINE @ classmethod NEW_LINE def __declare_first__ ( cls ) : NEW_LINE INDENT cls . _sa_decl_prepare_nocascade ( ) NEW_LINE DEDENT @ classmethod NEW_LINE def _sa_decl_prepare_nocascade ( cls ) : NEW_LINE INDENT if getattr ( cls , ' _ _ mapper _ _ ' , None ) : NEW_LINE INDENT return NEW_LINE DEDENT to_map = _DeferredMapperConfig . config_for_cls ( cls ) NEW_LINE mappers = [ ] NEW_LINE stack = list ( cls . __subclasses__ ( ) ) NEW_LINE while stack : NEW_LINE INDENT klass = stack . pop ( ) NEW_LINE stack . extend ( klass . __subclasses__ ( ) ) NEW_LINE mn = _mapper_or_none ( klass ) NEW_LINE if mn is not None : NEW_LINE INDENT mappers . append ( mn ) NEW_LINE DEDENT DEDENT pjoin = cls . _create_polymorphic_union ( mappers ) NEW_LINE declared_cols = set ( to_map . declared_columns ) NEW_LINE for k , v in list ( to_map . properties . items ( ) ) : NEW_LINE INDENT if v in declared_cols : NEW_LINE INDENT to_map . properties [ k ] = pjoin . c [ v . key ] NEW_LINE DEDENT DEDENT to_map . local_table = pjoin NEW_LINE m_args = to_map . mapper_args_fn or dict NEW_LINE def mapper_args ( ) : NEW_LINE INDENT args = m_args ( ) NEW_LINE args [ ' polymorphic _ on ' ] = pjoin . c . type NEW_LINE return args NEW_LINE DEDENT to_map . mapper_args_fn = mapper_args NEW_LINE m = to_map . map ( ) NEW_LINE for scls in cls . __subclasses__ ( ) : NEW_LINE INDENT sm = _mapper_or_none ( scls ) NEW_LINE if sm and sm . concrete and cls in scls . __bases__ : NEW_LINE INDENT sm . _set_concrete_base ( m ) NEW_LINE DEDENT DEDENT DEDENT DEDENT class DeferredReflection ( object ) : NEW_LINE INDENT @ classmethod NEW_LINE def prepare ( cls , engine ) : NEW_LINE INDENT to_map = _DeferredMapperConfig . classes_for_base ( cls ) NEW_LINE for thingy in to_map : NEW_LINE INDENT cls . _sa_decl_prepare ( thingy . local_table , engine ) NEW_LINE thingy . map ( ) NEW_LINE mapper = thingy . cls . __mapper__ NEW_LINE metadata = mapper . class_ . metadata NEW_LINE for rel in mapper . _props . values ( ) : NEW_LINE INDENT if isinstance ( rel , properties . RelationshipProperty ) and \NEW_LINE rel . secondary is not None : NEW_LINE INDENT if isinstance ( rel . secondary , Table ) : NEW_LINE INDENT cls . _reflect_table ( rel . secondary , engine ) NEW_LINE DEDENT elif isinstance ( rel . secondary , _class_resolver ) : NEW_LINE INDENT rel . secondary . _resolvers += ( cls . _sa_deferred_table_resolver ( engine , metadata ) , ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT @ classmethod NEW_LINE def _sa_deferred_table_resolver ( cls , engine , metadata ) : NEW_LINE INDENT def _resolve ( key ) : NEW_LINE INDENT t1 = Table ( key , metadata ) NEW_LINE cls . _reflect_table ( t1 , engine ) NEW_LINE return t1 NEW_LINE DEDENT return _resolve NEW_LINE DEDENT @ classmethod NEW_LINE def _sa_decl_prepare ( cls , local_table , engine ) : NEW_LINE INDENT if local_table is not None : NEW_LINE INDENT cls . _reflect_table ( local_table , engine ) NEW_LINE DEDENT DEDENT @ classmethod NEW_LINE def _reflect_table ( cls , table , engine ) : NEW_LINE INDENT Table ( table . name , table . metadata , extend_existing = True , autoload_replace = False , autoload = True , autoload_with = engine , schema = table . schema ) NEW_LINE DEDENT DEDENT
 import ctypes , random , unittest , sys NEW_LINE from django . contrib . gis . geos import * NEW_LINE from django . contrib . gis . geos . base import gdal , numpy , GEOSBase NEW_LINE from django . contrib . gis . geos . libgeos import GEOS_PREPARE NEW_LINE from django . contrib . gis . geometry . test_data import TestDataMixin NEW_LINE class GEOSTest ( unittest . TestCase , TestDataMixin ) : NEW_LINE INDENT @ property NEW_LINE def null_srid ( self ) : NEW_LINE INDENT info = geos_version_info ( ) NEW_LINE if info [ ' version ' ] == '3.0.0' and info [ ' release _ candidate ' ] : NEW_LINE INDENT return - 1 NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT def test00_base ( self ) : NEW_LINE INDENT class FakeGeom1 ( GEOSBase ) : NEW_LINE INDENT pass NEW_LINE DEDENT c_float_p = ctypes . POINTER ( ctypes . c_float ) NEW_LINE class FakeGeom2 ( GEOSBase ) : NEW_LINE INDENT ptr_type = c_float_p NEW_LINE DEDENT fg1 = FakeGeom1 ( ) NEW_LINE fg2 = FakeGeom2 ( ) NEW_LINE fg1 . ptr = ctypes . c_void_p ( ) NEW_LINE fg1 . ptr = None NEW_LINE fg2 . ptr = c_float_p ( ctypes . c_float ( 5.23 ) ) NEW_LINE fg2 . ptr = None NEW_LINE for fg in ( fg1 , fg2 ) : NEW_LINE INDENT self . assertRaises ( GEOSException , fg . _get_ptr ) NEW_LINE DEDENT bad_ptrs = ( 5 , ctypes . c_char_p ( ' foobar ' ) ) NEW_LINE for bad_ptr in bad_ptrs : NEW_LINE INDENT self . assertRaises ( TypeError , fg1 . _set_ptr , bad_ptr ) NEW_LINE self . assertRaises ( TypeError , fg2 . _set_ptr , bad_ptr ) NEW_LINE DEDENT DEDENT def test01a_wkt ( self ) : NEW_LINE INDENT for g in self . geometries . wkt_out : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( g . ewkt , geom . wkt ) NEW_LINE DEDENT DEDENT def test01b_hex ( self ) : NEW_LINE INDENT for g in self . geometries . hex_wkt : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( g . hex , geom . hex ) NEW_LINE DEDENT DEDENT def test01b_hexewkb ( self ) : NEW_LINE INDENT from binascii import a2b_hex NEW_LINE ogc_hex = '01010000000000000000000000000000000000F03F ' NEW_LINE hexewkb_2d = '0101000020E61000000000000000000000000000000000F03F ' NEW_LINE hexewkb_3d = '01010000A0E61000000000000000000000000000000000F03F0000000000000040' NEW_LINE pnt_2d = Point ( 0 , 1 , srid = 4326 ) NEW_LINE pnt_3d = Point ( 0 , 1 , 2 , srid = 4326 ) NEW_LINE self . assertEqual ( ogc_hex , pnt_2d . hex ) NEW_LINE self . assertEqual ( ogc_hex , pnt_3d . hex ) NEW_LINE self . assertEqual ( hexewkb_2d , pnt_2d . hexewkb ) NEW_LINE if GEOS_PREPARE : NEW_LINE INDENT self . assertEqual ( hexewkb_3d , pnt_3d . hexewkb ) NEW_LINE self . assertEqual ( True , GEOSGeometry ( hexewkb_3d ) . hasz ) NEW_LINE DEDENT else : NEW_LINE INDENT try : NEW_LINE INDENT hexewkb = pnt_3d . hexewkb NEW_LINE DEDENT except GEOSException : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Should ▁ have ▁ raised ▁ GEOSException . ' ) NEW_LINE DEDENT DEDENT self . assertEqual ( buffer ( a2b_hex ( hexewkb_2d ) ) , pnt_2d . ewkb ) NEW_LINE if GEOS_PREPARE : NEW_LINE INDENT self . assertEqual ( buffer ( a2b_hex ( hexewkb_3d ) ) , pnt_3d . ewkb ) NEW_LINE DEDENT else : NEW_LINE INDENT try : NEW_LINE INDENT ewkb = pnt_3d . ewkb NEW_LINE DEDENT except GEOSException : NEW_LINE INDENT pass NEW_LINE DEDENT else : NEW_LINE INDENT self . fail ( ' Should ▁ have ▁ raised ▁ GEOSException ' ) NEW_LINE DEDENT DEDENT self . assertEqual ( 4326 , GEOSGeometry ( hexewkb_2d ) . srid ) NEW_LINE DEDENT def test01c_kml ( self ) : NEW_LINE INDENT for tg in self . geometries . wkt_out : NEW_LINE INDENT geom = fromstr ( tg . wkt ) NEW_LINE kml = getattr ( tg , ' kml ' , False ) NEW_LINE if kml : NEW_LINE INDENT self . assertEqual ( kml , geom . kml ) NEW_LINE DEDENT DEDENT DEDENT def test01d_errors ( self ) : NEW_LINE INDENT print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ ERROR ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE for err in self . geometries . errors : NEW_LINE INDENT try : NEW_LINE INDENT g = fromstr ( err . wkt ) NEW_LINE DEDENT except ( GEOSException , ValueError ) : NEW_LINE INDENT pass NEW_LINE DEDENT DEDENT self . assertRaises ( GEOSException , GEOSGeometry , buffer ( '0' ) ) NEW_LINE print " \n END ▁ - ▁ expecting ▁ GEOS _ ERROR ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE class NotAGeometry ( object ) : NEW_LINE INDENT pass NEW_LINE DEDENT self . assertRaises ( TypeError , GEOSGeometry , NotAGeometry ( ) ) NEW_LINE self . assertRaises ( TypeError , GEOSGeometry , None ) NEW_LINE DEDENT def test01e_wkb ( self ) : NEW_LINE INDENT from binascii import b2a_hex NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT geom = fromstr ( g . wkt ) NEW_LINE wkb = geom . wkb NEW_LINE self . assertEqual ( b2a_hex ( wkb ) . upper ( ) , g . hex ) NEW_LINE DEDENT DEDENT def test01f_create_hex ( self ) : NEW_LINE INDENT for g in self . geometries . hex_wkt : NEW_LINE INDENT geom_h = GEOSGeometry ( g . hex ) NEW_LINE geom_t = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( geom_t . wkt , geom_h . wkt ) NEW_LINE DEDENT DEDENT def test01g_create_wkb ( self ) : NEW_LINE INDENT from binascii import a2b_hex NEW_LINE for g in self . geometries . hex_wkt : NEW_LINE INDENT wkb = buffer ( a2b_hex ( g . hex ) ) NEW_LINE geom_h = GEOSGeometry ( wkb ) NEW_LINE geom_t = fromstr ( g . wkt ) NEW_LINE self . assertEqual ( geom_t . wkt , geom_h . wkt ) NEW_LINE DEDENT DEDENT def test01h_ewkt ( self ) : NEW_LINE INDENT srid = 32140 NEW_LINE for p in self . geometries . polygons : NEW_LINE INDENT ewkt = ' SRID = % d ; % s ' % ( srid , p . wkt ) NEW_LINE poly = fromstr ( ewkt ) NEW_LINE self . assertEqual ( srid , poly . srid ) NEW_LINE self . assertEqual ( srid , poly . shell . srid ) NEW_LINE self . assertEqual ( srid , fromstr ( poly . ewkt ) . srid ) NEW_LINE DEDENT DEDENT def test01i_json ( self ) : NEW_LINE INDENT if not gdal or not gdal . GEOJSON : NEW_LINE INDENT return NEW_LINE DEDENT for g in self . geometries . json_geoms : NEW_LINE INDENT geom = GEOSGeometry ( g . wkt ) NEW_LINE if not hasattr ( g , ' not _ equal ' ) : NEW_LINE INDENT self . assertEqual ( g . json , geom . json ) NEW_LINE self . assertEqual ( g . json , geom . geojson ) NEW_LINE DEDENT self . assertEqual ( GEOSGeometry ( g . wkt ) , GEOSGeometry ( geom . json ) ) NEW_LINE DEDENT DEDENT def test01k_fromfile ( self ) : NEW_LINE INDENT from StringIO import StringIO NEW_LINE ref_pnt = GEOSGeometry ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE wkt_f = StringIO ( ) NEW_LINE wkt_f . write ( ref_pnt . wkt ) NEW_LINE wkb_f = StringIO ( ) NEW_LINE wkb_f . write ( str ( ref_pnt . wkb ) ) NEW_LINE for fh in ( wkt_f , wkb_f ) : NEW_LINE INDENT fh . seek ( 0 ) NEW_LINE pnt = fromfile ( fh ) NEW_LINE self . assertEqual ( ref_pnt , pnt ) NEW_LINE DEDENT DEDENT def test01k_eq ( self ) : NEW_LINE INDENT p = fromstr ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE self . assertEqual ( p , p . wkt ) NEW_LINE self . assertNotEqual ( p , ' foo ' ) NEW_LINE ls = fromstr ( ' LINESTRING ( 0 ▁ 0 , ▁ 1 ▁ 1 , ▁ 5 ▁ 5 ) ' ) NEW_LINE self . assertEqual ( ls , ls . wkt ) NEW_LINE self . assertNotEqual ( p , ' bar ' ) NEW_LINE for g in ( p , ls ) : NEW_LINE INDENT self . assertNotEqual ( g , None ) NEW_LINE self . assertNotEqual ( g , { ' foo ' : ' bar ' } ) NEW_LINE self . assertNotEqual ( g , False ) NEW_LINE DEDENT DEDENT def test02a_points ( self ) : NEW_LINE INDENT prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for p in self . geometries . points : NEW_LINE INDENT pnt = fromstr ( p . wkt ) NEW_LINE self . assertEqual ( pnt . geom_type , ' Point ' ) NEW_LINE self . assertEqual ( pnt . geom_typeid , 0 ) NEW_LINE self . assertEqual ( p . x , pnt . x ) NEW_LINE self . assertEqual ( p . y , pnt . y ) NEW_LINE self . assertEqual ( True , pnt == fromstr ( p . wkt ) ) NEW_LINE self . assertEqual ( False , pnt == prev ) NEW_LINE self . assertAlmostEqual ( p . x , pnt . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( p . y , pnt . tuple [ 1 ] , 9 ) NEW_LINE if hasattr ( p , ' z ' ) : NEW_LINE INDENT self . assertEqual ( True , pnt . hasz ) NEW_LINE self . assertEqual ( p . z , pnt . z ) NEW_LINE self . assertEqual ( p . z , pnt . tuple [ 2 ] , 9 ) NEW_LINE tup_args = ( p . x , p . y , p . z ) NEW_LINE set_tup1 = ( 2.71 , 3.14 , 5.23 ) NEW_LINE set_tup2 = ( 5.23 , 2.71 , 3.14 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( False , pnt . hasz ) NEW_LINE self . assertEqual ( None , pnt . z ) NEW_LINE tup_args = ( p . x , p . y ) NEW_LINE set_tup1 = ( 2.71 , 3.14 ) NEW_LINE set_tup2 = ( 3.14 , 2.71 ) NEW_LINE DEDENT self . assertEqual ( p . centroid , pnt . centroid . tuple ) NEW_LINE pnt2 = Point ( tup_args ) NEW_LINE pnt3 = Point ( * tup_args ) NEW_LINE self . assertEqual ( True , pnt == pnt2 ) NEW_LINE self . assertEqual ( True , pnt == pnt3 ) NEW_LINE pnt . y = 3.14 NEW_LINE pnt . x = 2.71 NEW_LINE self . assertEqual ( 3.14 , pnt . y ) NEW_LINE self . assertEqual ( 2.71 , pnt . x ) NEW_LINE pnt . tuple = set_tup1 NEW_LINE self . assertEqual ( set_tup1 , pnt . tuple ) NEW_LINE pnt . coords = set_tup2 NEW_LINE self . assertEqual ( set_tup2 , pnt . coords ) NEW_LINE prev = pnt NEW_LINE DEDENT DEDENT def test02b_multipoints ( self ) : NEW_LINE INDENT for mp in self . geometries . multipoints : NEW_LINE INDENT mpnt = fromstr ( mp . wkt ) NEW_LINE self . assertEqual ( mpnt . geom_type , ' MultiPoint ' ) NEW_LINE self . assertEqual ( mpnt . geom_typeid , 4 ) NEW_LINE self . assertAlmostEqual ( mp . centroid [ 0 ] , mpnt . centroid . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( mp . centroid [ 1 ] , mpnt . centroid . tuple [ 1 ] , 9 ) NEW_LINE self . assertRaises ( GEOSIndexError , mpnt . __getitem__ , len ( mpnt ) ) NEW_LINE self . assertEqual ( mp . centroid , mpnt . centroid . tuple ) NEW_LINE self . assertEqual ( mp . coords , tuple ( m . tuple for m in mpnt ) ) NEW_LINE for p in mpnt : NEW_LINE INDENT self . assertEqual ( p . geom_type , ' Point ' ) NEW_LINE self . assertEqual ( p . geom_typeid , 0 ) NEW_LINE self . assertEqual ( p . empty , False ) NEW_LINE self . assertEqual ( p . valid , True ) NEW_LINE DEDENT DEDENT DEDENT def test03a_linestring ( self ) : NEW_LINE INDENT prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for l in self . geometries . linestrings : NEW_LINE INDENT ls = fromstr ( l . wkt ) NEW_LINE self . assertEqual ( ls . geom_type , ' LineString ' ) NEW_LINE self . assertEqual ( ls . geom_typeid , 1 ) NEW_LINE self . assertEqual ( ls . empty , False ) NEW_LINE self . assertEqual ( ls . ring , False ) NEW_LINE if hasattr ( l , ' centroid ' ) : NEW_LINE INDENT self . assertEqual ( l . centroid , ls . centroid . tuple ) NEW_LINE DEDENT if hasattr ( l , ' tup ' ) : NEW_LINE INDENT self . assertEqual ( l . tup , ls . tuple ) NEW_LINE DEDENT self . assertEqual ( True , ls == fromstr ( l . wkt ) ) NEW_LINE self . assertEqual ( False , ls == prev ) NEW_LINE self . assertRaises ( GEOSIndexError , ls . __getitem__ , len ( ls ) ) NEW_LINE prev = ls NEW_LINE self . assertEqual ( ls , LineString ( ls . tuple ) ) NEW_LINE self . assertEqual ( ls , LineString ( * ls . tuple ) ) NEW_LINE self . assertEqual ( ls , LineString ( [ list ( tup ) for tup in ls . tuple ] ) ) NEW_LINE self . assertEqual ( ls . wkt , LineString ( * tuple ( Point ( tup ) for tup in ls . tuple ) ) . wkt ) NEW_LINE if numpy : NEW_LINE INDENT self . assertEqual ( ls , LineString ( numpy . array ( ls . tuple ) ) ) NEW_LINE DEDENT DEDENT DEDENT def test03b_multilinestring ( self ) : NEW_LINE INDENT prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for l in self . geometries . multilinestrings : NEW_LINE INDENT ml = fromstr ( l . wkt ) NEW_LINE self . assertEqual ( ml . geom_type , ' MultiLineString ' ) NEW_LINE self . assertEqual ( ml . geom_typeid , 5 ) NEW_LINE self . assertAlmostEqual ( l . centroid [ 0 ] , ml . centroid . x , 9 ) NEW_LINE self . assertAlmostEqual ( l . centroid [ 1 ] , ml . centroid . y , 9 ) NEW_LINE self . assertEqual ( True , ml == fromstr ( l . wkt ) ) NEW_LINE self . assertEqual ( False , ml == prev ) NEW_LINE prev = ml NEW_LINE for ls in ml : NEW_LINE INDENT self . assertEqual ( ls . geom_type , ' LineString ' ) NEW_LINE self . assertEqual ( ls . geom_typeid , 1 ) NEW_LINE self . assertEqual ( ls . empty , False ) NEW_LINE DEDENT self . assertRaises ( GEOSIndexError , ml . __getitem__ , len ( ml ) ) NEW_LINE self . assertEqual ( ml . wkt , MultiLineString ( * tuple ( s . clone ( ) for s in ml ) ) . wkt ) NEW_LINE self . assertEqual ( ml , MultiLineString ( * tuple ( LineString ( s . tuple ) for s in ml ) ) ) NEW_LINE DEDENT DEDENT def test04_linearring ( self ) : NEW_LINE INDENT for rr in self . geometries . linearrings : NEW_LINE INDENT lr = fromstr ( rr . wkt ) NEW_LINE self . assertEqual ( lr . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( lr . geom_typeid , 2 ) NEW_LINE self . assertEqual ( rr . n_p , len ( lr ) ) NEW_LINE self . assertEqual ( True , lr . valid ) NEW_LINE self . assertEqual ( False , lr . empty ) NEW_LINE self . assertEqual ( lr , LinearRing ( lr . tuple ) ) NEW_LINE self . assertEqual ( lr , LinearRing ( * lr . tuple ) ) NEW_LINE self . assertEqual ( lr , LinearRing ( [ list ( tup ) for tup in lr . tuple ] ) ) NEW_LINE if numpy : NEW_LINE INDENT self . assertEqual ( lr , LinearRing ( numpy . array ( lr . tuple ) ) ) NEW_LINE DEDENT DEDENT DEDENT def test05a_polygons ( self ) : NEW_LINE INDENT bbox = ( - 180 , - 90 , 180 , 90 ) NEW_LINE p = Polygon . from_bbox ( bbox ) NEW_LINE self . assertEqual ( bbox , p . extent ) NEW_LINE prev = fromstr ( ' POINT ( 0 ▁ 0 ) ' ) NEW_LINE for p in self . geometries . polygons : NEW_LINE INDENT poly = fromstr ( p . wkt ) NEW_LINE self . assertEqual ( poly . geom_type , ' Polygon ' ) NEW_LINE self . assertEqual ( poly . geom_typeid , 3 ) NEW_LINE self . assertEqual ( poly . empty , False ) NEW_LINE self . assertEqual ( poly . ring , False ) NEW_LINE self . assertEqual ( p . n_i , poly . num_interior_rings ) NEW_LINE self . assertEqual ( p . n_i + 1 , len ( poly ) ) NEW_LINE self . assertEqual ( p . n_p , poly . num_points ) NEW_LINE self . assertAlmostEqual ( p . area , poly . area , 9 ) NEW_LINE self . assertAlmostEqual ( p . centroid [ 0 ] , poly . centroid . tuple [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( p . centroid [ 1 ] , poly . centroid . tuple [ 1 ] , 9 ) NEW_LINE self . assertEqual ( True , poly == fromstr ( p . wkt ) ) NEW_LINE self . assertEqual ( False , poly == prev ) NEW_LINE self . assertEqual ( True , poly != prev ) NEW_LINE ring = poly . exterior_ring NEW_LINE self . assertEqual ( ring . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( ring . geom_typeid , 2 ) NEW_LINE if p . ext_ring_cs : NEW_LINE INDENT self . assertEqual ( p . ext_ring_cs , ring . tuple ) NEW_LINE self . assertEqual ( p . ext_ring_cs , poly [ 0 ] . tuple ) NEW_LINE DEDENT self . assertRaises ( GEOSIndexError , poly . __getitem__ , len ( poly ) ) NEW_LINE self . assertRaises ( GEOSIndexError , poly . __setitem__ , len ( poly ) , False ) NEW_LINE self . assertRaises ( GEOSIndexError , poly . __getitem__ , - 1 * len ( poly ) - 1 ) NEW_LINE for r in poly : NEW_LINE INDENT self . assertEqual ( r . geom_type , ' LinearRing ' ) NEW_LINE self . assertEqual ( r . geom_typeid , 2 ) NEW_LINE DEDENT self . assertRaises ( TypeError , Polygon . __init__ , 0 , [ 1 , 2 , 3 ] ) NEW_LINE self . assertRaises ( TypeError , Polygon . __init__ , ' foo ' ) NEW_LINE rings = tuple ( r for r in poly ) NEW_LINE self . assertEqual ( poly , Polygon ( rings [ 0 ] , rings [ 1 : ] ) ) NEW_LINE ring_tuples = tuple ( r . tuple for r in poly ) NEW_LINE self . assertEqual ( poly , Polygon ( * ring_tuples ) ) NEW_LINE self . assertEqual ( poly . wkt , Polygon ( * tuple ( r for r in poly ) ) . wkt ) NEW_LINE self . assertEqual ( poly . wkt , Polygon ( * tuple ( LinearRing ( r . tuple ) for r in poly ) ) . wkt ) NEW_LINE DEDENT DEDENT def test05b_multipolygons ( self ) : NEW_LINE INDENT print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE prev = fromstr ( ' POINT ▁ ( 0 ▁ 0 ) ' ) NEW_LINE for mp in self . geometries . multipolygons : NEW_LINE INDENT mpoly = fromstr ( mp . wkt ) NEW_LINE self . assertEqual ( mpoly . geom_type , ' MultiPolygon ' ) NEW_LINE self . assertEqual ( mpoly . geom_typeid , 6 ) NEW_LINE self . assertEqual ( mp . valid , mpoly . valid ) NEW_LINE if mp . valid : NEW_LINE INDENT self . assertEqual ( mp . num_geom , mpoly . num_geom ) NEW_LINE self . assertEqual ( mp . n_p , mpoly . num_coords ) NEW_LINE self . assertEqual ( mp . num_geom , len ( mpoly ) ) NEW_LINE self . assertRaises ( GEOSIndexError , mpoly . __getitem__ , len ( mpoly ) ) NEW_LINE for p in mpoly : NEW_LINE INDENT self . assertEqual ( p . geom_type , ' Polygon ' ) NEW_LINE self . assertEqual ( p . geom_typeid , 3 ) NEW_LINE self . assertEqual ( p . valid , True ) NEW_LINE DEDENT self . assertEqual ( mpoly . wkt , MultiPolygon ( * tuple ( poly . clone ( ) for poly in mpoly ) ) . wkt ) NEW_LINE DEDENT DEDENT print " \n END ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE DEDENT def test06a_memory_hijinks ( self ) : NEW_LINE INDENT poly = fromstr ( self . geometries . polygons [ 1 ] . wkt ) NEW_LINE ring1 = poly [ 0 ] NEW_LINE ring2 = poly [ 1 ] NEW_LINE del ring1 NEW_LINE del ring2 NEW_LINE ring1 = poly [ 0 ] NEW_LINE ring2 = poly [ 1 ] NEW_LINE del poly NEW_LINE s1 , s2 = str ( ring1 ) , str ( ring2 ) NEW_LINE DEDENT def test08_coord_seq ( self ) : NEW_LINE INDENT for p in self . geometries . polygons : NEW_LINE INDENT if p . ext_ring_cs : NEW_LINE INDENT poly = fromstr ( p . wkt ) NEW_LINE cs = poly . exterior_ring . coord_seq NEW_LINE self . assertEqual ( p . ext_ring_cs , cs . tuple ) NEW_LINE self . assertEqual ( len ( p . ext_ring_cs ) , len ( cs ) ) NEW_LINE for i in xrange ( len ( p . ext_ring_cs ) ) : NEW_LINE INDENT c1 = p . ext_ring_cs [ i ] NEW_LINE c2 = cs [ i ] NEW_LINE self . assertEqual ( c1 , c2 ) NEW_LINE if len ( c1 ) == 2 : NEW_LINE INDENT tset = ( 5 , 23 ) NEW_LINE DEDENT else : NEW_LINE INDENT tset = ( 5 , 23 , 8 ) NEW_LINE DEDENT cs [ i ] = tset NEW_LINE for j in range ( len ( tset ) ) : NEW_LINE INDENT cs [ i ] = tset NEW_LINE self . assertEqual ( tset [ j ] , cs [ i ] [ j ] ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT def test09_relate_pattern ( self ) : NEW_LINE INDENT g = fromstr ( ' POINT ▁ ( 0 ▁ 0 ) ' ) NEW_LINE self . assertRaises ( GEOSException , g . relate_pattern , 0 , ' invalid ▁ pattern , ▁ yo ' ) NEW_LINE for rg in self . geometries . relate_geoms : NEW_LINE INDENT a = fromstr ( rg . wkt_a ) NEW_LINE b = fromstr ( rg . wkt_b ) NEW_LINE self . assertEqual ( rg . result , a . relate_pattern ( b , rg . pattern ) ) NEW_LINE self . assertEqual ( rg . pattern , a . relate ( b ) ) NEW_LINE DEDENT DEDENT def test10_intersection ( self ) : NEW_LINE INDENT for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE i1 = fromstr ( self . geometries . intersect_geoms [ i ] . wkt ) NEW_LINE self . assertEqual ( True , a . intersects ( b ) ) NEW_LINE i2 = a . intersection ( b ) NEW_LINE self . assertEqual ( i1 , i2 ) NEW_LINE self . assertEqual ( i1 , a & b ) NEW_LINE a &= b NEW_LINE self . assertEqual ( i1 , a ) NEW_LINE DEDENT DEDENT def test11_union ( self ) : NEW_LINE INDENT for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE u1 = fromstr ( self . geometries . union_geoms [ i ] . wkt ) NEW_LINE u2 = a . union ( b ) NEW_LINE self . assertEqual ( u1 , u2 ) NEW_LINE self . assertEqual ( u1 , a | b ) NEW_LINE a |= b NEW_LINE self . assertEqual ( u1 , a ) NEW_LINE DEDENT DEDENT def test12_difference ( self ) : NEW_LINE INDENT for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE d1 = fromstr ( self . geometries . diff_geoms [ i ] . wkt ) NEW_LINE d2 = a . difference ( b ) NEW_LINE self . assertEqual ( d1 , d2 ) NEW_LINE self . assertEqual ( d1 , a - b ) NEW_LINE a -= b NEW_LINE self . assertEqual ( d1 , a ) NEW_LINE DEDENT DEDENT def test13_symdifference ( self ) : NEW_LINE INDENT for i in xrange ( len ( self . geometries . topology_geoms ) ) : NEW_LINE INDENT a = fromstr ( self . geometries . topology_geoms [ i ] . wkt_a ) NEW_LINE b = fromstr ( self . geometries . topology_geoms [ i ] . wkt_b ) NEW_LINE d1 = fromstr ( self . geometries . sdiff_geoms [ i ] . wkt ) NEW_LINE d2 = a . sym_difference ( b ) NEW_LINE self . assertEqual ( d1 , d2 ) NEW_LINE self . assertEqual ( d1 , a ^ b ) NEW_LINE a ^= b NEW_LINE self . assertEqual ( d1 , a ) NEW_LINE DEDENT DEDENT def test14_buffer ( self ) : NEW_LINE INDENT for bg in self . geometries . buffer_geoms : NEW_LINE INDENT g = fromstr ( bg . wkt ) NEW_LINE exp_buf = fromstr ( bg . buffer_wkt ) NEW_LINE quadsegs = bg . quadsegs NEW_LINE width = bg . width NEW_LINE self . assertRaises ( ctypes . ArgumentError , g . buffer , width , float ( quadsegs ) ) NEW_LINE buf = g . buffer ( width , quadsegs ) NEW_LINE self . assertEqual ( exp_buf . num_coords , buf . num_coords ) NEW_LINE self . assertEqual ( len ( exp_buf ) , len ( buf ) ) NEW_LINE for j in xrange ( len ( exp_buf ) ) : NEW_LINE INDENT exp_ring = exp_buf [ j ] NEW_LINE buf_ring = buf [ j ] NEW_LINE self . assertEqual ( len ( exp_ring ) , len ( buf_ring ) ) NEW_LINE for k in xrange ( len ( exp_ring ) ) : NEW_LINE INDENT self . assertAlmostEqual ( exp_ring [ k ] [ 0 ] , buf_ring [ k ] [ 0 ] , 9 ) NEW_LINE self . assertAlmostEqual ( exp_ring [ k ] [ 1 ] , buf_ring [ k ] [ 1 ] , 9 ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def test15_srid ( self ) : NEW_LINE INDENT pnt = Point ( 5 , 23 , srid = 4326 ) NEW_LINE self . assertEqual ( 4326 , pnt . srid ) NEW_LINE pnt . srid = 3084 NEW_LINE self . assertEqual ( 3084 , pnt . srid ) NEW_LINE self . assertRaises ( ctypes . ArgumentError , pnt . set_srid , '4326' ) NEW_LINE poly = fromstr ( self . geometries . polygons [ 1 ] . wkt , srid = 4269 ) NEW_LINE self . assertEqual ( 4269 , poly . srid ) NEW_LINE for ring in poly : NEW_LINE INDENT self . assertEqual ( 4269 , ring . srid ) NEW_LINE DEDENT poly . srid = 4326 NEW_LINE self . assertEqual ( 4326 , poly . shell . srid ) NEW_LINE gc = GeometryCollection ( Point ( 5 , 23 ) , LineString ( ( 0 , 0 ) , ( 1.5 , 1.5 ) , ( 3 , 3 ) ) , srid = 32021 ) NEW_LINE self . assertEqual ( 32021 , gc . srid ) NEW_LINE for i in range ( len ( gc ) ) : NEW_LINE INDENT self . assertEqual ( 32021 , gc [ i ] . srid ) NEW_LINE DEDENT hex = '0101000020E610000000000000000014400000000000003740' NEW_LINE p1 = fromstr ( hex ) NEW_LINE self . assertEqual ( 4326 , p1 . srid ) NEW_LINE exp_srid = self . null_srid NEW_LINE p2 = fromstr ( p1 . hex ) NEW_LINE self . assertEqual ( exp_srid , p2 . srid ) NEW_LINE p3 = fromstr ( p1 . hex , srid = - 1 ) NEW_LINE self . assertEqual ( - 1 , p3 . srid ) NEW_LINE DEDENT def test16_mutable_geometries ( self ) : NEW_LINE INDENT for p in self . geometries . polygons : NEW_LINE INDENT poly = fromstr ( p . wkt ) NEW_LINE self . assertRaises ( TypeError , poly . __setitem__ , 0 , LineString ( ( 1 , 1 ) , ( 2 , 2 ) ) ) NEW_LINE shell_tup = poly . shell . tuple NEW_LINE new_coords = [ ] NEW_LINE for point in shell_tup : NEW_LINE INDENT new_coords . append ( ( point [ 0 ] + 500. , point [ 1 ] + 500. ) ) NEW_LINE DEDENT new_shell = LinearRing ( * tuple ( new_coords ) ) NEW_LINE poly . exterior_ring = new_shell NEW_LINE s = str ( new_shell ) NEW_LINE self . assertEqual ( poly . exterior_ring , new_shell ) NEW_LINE self . assertEqual ( poly [ 0 ] , new_shell ) NEW_LINE DEDENT for tg in self . geometries . multipoints : NEW_LINE INDENT mp = fromstr ( tg . wkt ) NEW_LINE for i in range ( len ( mp ) ) : NEW_LINE INDENT pnt = mp [ i ] NEW_LINE new = Point ( random . randint ( 1 , 100 ) , random . randint ( 1 , 100 ) ) NEW_LINE mp [ i ] = new NEW_LINE s = str ( new ) NEW_LINE self . assertEqual ( mp [ i ] , new ) NEW_LINE self . assertEqual ( mp [ i ] . wkt , new . wkt ) NEW_LINE self . assertNotEqual ( pnt , mp [ i ] ) NEW_LINE DEDENT DEDENT for tg in self . geometries . multipolygons : NEW_LINE INDENT mpoly = fromstr ( tg . wkt ) NEW_LINE for i in xrange ( len ( mpoly ) ) : NEW_LINE INDENT poly = mpoly [ i ] NEW_LINE old_poly = mpoly [ i ] NEW_LINE for j in xrange ( len ( poly ) ) : NEW_LINE INDENT r = poly [ j ] NEW_LINE for k in xrange ( len ( r ) ) : NEW_LINE INDENT r [ k ] = ( r [ k ] [ 0 ] + 500. , r [ k ] [ 1 ] + 500. ) NEW_LINE DEDENT poly [ j ] = r NEW_LINE DEDENT self . assertNotEqual ( mpoly [ i ] , poly ) NEW_LINE mpoly [ i ] = poly NEW_LINE s = str ( poly ) NEW_LINE self . assertEqual ( mpoly [ i ] , poly ) NEW_LINE self . assertNotEqual ( mpoly [ i ] , old_poly ) NEW_LINE DEDENT DEDENT NEW_LINE DEDENT def test17_threed ( self ) : NEW_LINE INDENT pnt = Point ( 2 , 3 , 8 ) NEW_LINE self . assertEqual ( ( 2. , 3. , 8. ) , pnt . coords ) NEW_LINE self . assertRaises ( TypeError , pnt . set_coords , ( 1. , 2. ) ) NEW_LINE pnt . coords = ( 1. , 2. , 3. ) NEW_LINE self . assertEqual ( ( 1. , 2. , 3. ) , pnt . coords ) NEW_LINE ls = LineString ( ( 2. , 3. , 8. ) , ( 50. , 250. , - 117. ) ) NEW_LINE self . assertEqual ( ( ( 2. , 3. , 8. ) , ( 50. , 250. , - 117. ) ) , ls . tuple ) NEW_LINE self . assertRaises ( TypeError , ls . __setitem__ , 0 , ( 1. , 2. ) ) NEW_LINE ls [ 0 ] = ( 1. , 2. , 3. ) NEW_LINE self . assertEqual ( ( 1. , 2. , 3. ) , ls [ 0 ] ) NEW_LINE DEDENT def test18_distance ( self ) : NEW_LINE INDENT pnt = Point ( 0 , 0 ) NEW_LINE self . assertEqual ( 0.0 , pnt . distance ( Point ( 0 , 0 ) ) ) NEW_LINE self . assertEqual ( 1.0 , pnt . distance ( Point ( 0 , 1 ) ) ) NEW_LINE self . assertAlmostEqual ( 1.41421356237 , pnt . distance ( Point ( 1 , 1 ) ) , 11 ) NEW_LINE ls1 = LineString ( ( 0 , 0 ) , ( 1 , 1 ) , ( 2 , 2 ) ) NEW_LINE ls2 = LineString ( ( 5 , 2 ) , ( 6 , 1 ) , ( 7 , 0 ) ) NEW_LINE self . assertEqual ( 3 , ls1 . distance ( ls2 ) ) NEW_LINE DEDENT def test19_length ( self ) : NEW_LINE INDENT pnt = Point ( 0 , 0 ) NEW_LINE self . assertEqual ( 0.0 , pnt . length ) NEW_LINE ls = LineString ( ( 0 , 0 ) , ( 1 , 1 ) ) NEW_LINE self . assertAlmostEqual ( 1.41421356237 , ls . length , 11 ) NEW_LINE poly = Polygon ( LinearRing ( ( 0 , 0 ) , ( 0 , 1 ) , ( 1 , 1 ) , ( 1 , 0 ) , ( 0 , 0 ) ) ) NEW_LINE self . assertEqual ( 4.0 , poly . length ) NEW_LINE mpoly = MultiPolygon ( poly . clone ( ) , poly ) NEW_LINE self . assertEqual ( 8.0 , mpoly . length ) NEW_LINE DEDENT def test20a_emptyCollections ( self ) : NEW_LINE INDENT gc1 = GeometryCollection ( [ ] ) NEW_LINE gc2 = fromstr ( ' GEOMETRYCOLLECTION ▁ EMPTY ' ) NEW_LINE pnt = fromstr ( ' POINT ▁ EMPTY ' ) NEW_LINE ls = fromstr ( ' LINESTRING ▁ EMPTY ' ) NEW_LINE poly = fromstr ( ' POLYGON ▁ EMPTY ' ) NEW_LINE mls = fromstr ( ' MULTILINESTRING ▁ EMPTY ' ) NEW_LINE mpoly1 = fromstr ( ' MULTIPOLYGON ▁ EMPTY ' ) NEW_LINE mpoly2 = MultiPolygon ( ( ) ) NEW_LINE for g in [ gc1 , gc2 , pnt , ls , poly , mls , mpoly1 , mpoly2 ] : NEW_LINE INDENT self . assertEqual ( True , g . empty ) NEW_LINE if isinstance ( g , Polygon ) : NEW_LINE INDENT self . assertEqual ( 1 , len ( g ) ) NEW_LINE self . assertEqual ( 1 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g [ 0 ] ) ) NEW_LINE DEDENT elif isinstance ( g , ( Point , LineString ) ) : NEW_LINE INDENT self . assertEqual ( 1 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( 0 , g . num_geom ) NEW_LINE self . assertEqual ( 0 , len ( g ) ) NEW_LINE DEDENT if isinstance ( g , Point ) : NEW_LINE INDENT self . assertRaises ( GEOSIndexError , g . get_x ) NEW_LINE DEDENT elif isinstance ( g , Polygon ) : NEW_LINE INDENT lr = g . shell NEW_LINE self . assertEqual ( ' LINEARRING ▁ EMPTY ' , lr . wkt ) NEW_LINE self . assertEqual ( 0 , len ( lr ) ) NEW_LINE self . assertEqual ( True , lr . empty ) NEW_LINE self . assertRaises ( GEOSIndexError , lr . __getitem__ , 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertRaises ( GEOSIndexError , g . __getitem__ , 0 ) NEW_LINE DEDENT DEDENT DEDENT def test20b_collections_of_collections ( self ) : NEW_LINE INDENT coll = [ mp . wkt for mp in self . geometries . multipolygons if mp . valid ] NEW_LINE coll . extend ( [ mls . wkt for mls in self . geometries . multilinestrings ] ) NEW_LINE coll . extend ( [ p . wkt for p in self . geometries . polygons ] ) NEW_LINE coll . extend ( [ mp . wkt for mp in self . geometries . multipoints ] ) NEW_LINE gc_wkt = ' GEOMETRYCOLLECTION ( % s ) ' % ' , ' . join ( coll ) NEW_LINE gc1 = GEOSGeometry ( gc_wkt ) NEW_LINE gc2 = GeometryCollection ( * tuple ( g for g in gc1 ) ) NEW_LINE self . assertEqual ( gc1 , gc2 ) NEW_LINE DEDENT def test21_test_gdal ( self ) : NEW_LINE INDENT if not gdal . HAS_GDAL : NEW_LINE INDENT return NEW_LINE DEDENT g1 = fromstr ( ' POINT ( 5 ▁ 23 ) ' ) NEW_LINE self . assertEqual ( True , isinstance ( g1 . ogr , gdal . OGRGeometry ) ) NEW_LINE self . assertEqual ( g1 . srs , None ) NEW_LINE g2 = fromstr ( ' LINESTRING ( 0 ▁ 0 , ▁ 5 ▁ 5 , ▁ 23 ▁ 23 ) ' , srid = 4326 ) NEW_LINE self . assertEqual ( True , isinstance ( g2 . ogr , gdal . OGRGeometry ) ) NEW_LINE self . assertEqual ( True , isinstance ( g2 . srs , gdal . SpatialReference ) ) NEW_LINE self . assertEqual ( g2 . hex , g2 . ogr . hex ) NEW_LINE self . assertEqual ( ' WGS ▁ 84' , g2 . srs . name ) NEW_LINE DEDENT def test22_copy ( self ) : NEW_LINE INDENT import django . utils . copycompat as copy NEW_LINE poly = GEOSGeometry ( ' POLYGON ( (0 ▁ 0 , ▁ 0 ▁ 23 , ▁ 23 ▁ 23 , ▁ 23 ▁ 0 , ▁ 0 ▁ 0 ) , ▁ ( 5 ▁ 5 , ▁ 5 ▁ 10 , ▁ 10 ▁ 10 , ▁ 10 ▁ 5 , ▁ 5 ▁ 5 ) ) ' ) NEW_LINE cpy1 = copy . copy ( poly ) NEW_LINE cpy2 = copy . deepcopy ( poly ) NEW_LINE self . assertNotEqual ( poly . _ptr , cpy1 . _ptr ) NEW_LINE self . assertNotEqual ( poly . _ptr , cpy2 . _ptr ) NEW_LINE DEDENT def test23_transform ( self ) : NEW_LINE INDENT if not gdal . HAS_GDAL : NEW_LINE INDENT return NEW_LINE DEDENT orig = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE trans = GEOSGeometry ( ' POINT ▁ ( 992385.4472045 ▁ 481455.4944650 ) ' , 2774 ) NEW_LINE t1 , t2 , t3 = orig . clone ( ) , orig . clone ( ) , orig . clone ( ) NEW_LINE t1 . transform ( trans . srid ) NEW_LINE t2 . transform ( gdal . SpatialReference ( ' EPSG : 2774' ) ) NEW_LINE ct = gdal . CoordTransform ( gdal . SpatialReference ( ' WGS84' ) , gdal . SpatialReference ( 2774 ) ) NEW_LINE t3 . transform ( ct ) NEW_LINE k1 = orig . clone ( ) NEW_LINE k2 = k1 . transform ( trans . srid , clone = True ) NEW_LINE self . assertEqual ( k1 , orig ) NEW_LINE self . assertNotEqual ( k1 , k2 ) NEW_LINE prec = 3 NEW_LINE for p in ( t1 , t2 , t3 , k2 ) : NEW_LINE INDENT self . assertAlmostEqual ( trans . x , p . x , prec ) NEW_LINE self . assertAlmostEqual ( trans . y , p . y , prec ) NEW_LINE DEDENT DEDENT def test23_transform_noop ( self ) : NEW_LINE INDENT if gdal . HAS_GDAL : NEW_LINE INDENT g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE gt = g . tuple NEW_LINE g . transform ( 4326 ) NEW_LINE self . assertEqual ( g . tuple , gt ) NEW_LINE self . assertEqual ( g . srid , 4326 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE g1 = g . transform ( 4326 , clone = True ) NEW_LINE self . assertEqual ( g1 . tuple , g . tuple ) NEW_LINE self . assertEqual ( g1 . srid , 4326 ) NEW_LINE self . assert_ ( g1 is not g , " Clone ▁ didn ' t ▁ happen " ) NEW_LINE DEDENT old_has_gdal = gdal . HAS_GDAL NEW_LINE try : NEW_LINE INDENT gdal . HAS_GDAL = False NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE gt = g . tuple NEW_LINE g . transform ( 4326 ) NEW_LINE self . assertEqual ( g . tuple , gt ) NEW_LINE self . assertEqual ( g . srid , 4326 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE g1 = g . transform ( 4326 , clone = True ) NEW_LINE self . assertEqual ( g1 . tuple , g . tuple ) NEW_LINE self . assertEqual ( g1 . srid , 4326 ) NEW_LINE self . assert_ ( g1 is not g , " Clone ▁ didn ' t ▁ happen " ) NEW_LINE DEDENT finally : NEW_LINE INDENT gdal . HAS_GDAL = old_has_gdal NEW_LINE DEDENT DEDENT def test23_transform_nosrid ( self ) : NEW_LINE INDENT import warnings NEW_LINE print " \n BEGIN ▁ - ▁ expecting ▁ Warnings ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE try : NEW_LINE INDENT warnings . simplefilter ( ' once ' , UserWarning ) NEW_LINE warnings . simplefilter ( ' once ' , FutureWarning ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE g . transform ( 2774 ) NEW_LINE self . assertEqual ( g . tuple , ( - 104.609 , 38.255 ) ) NEW_LINE self . assertEqual ( g . srid , None ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE g1 = g . transform ( 2774 , clone = True ) NEW_LINE self . assert_ ( g1 is None ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE g . transform ( 2774 ) NEW_LINE self . assertEqual ( g . tuple , ( - 104.609 , 38.255 ) ) NEW_LINE self . assertEqual ( g . srid , - 1 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE g1 = g . transform ( 2774 , clone = True ) NEW_LINE self . assert_ ( g1 is None ) NEW_LINE DEDENT finally : NEW_LINE INDENT warnings . simplefilter ( ' default ' , UserWarning ) NEW_LINE warnings . simplefilter ( ' default ' , FutureWarning ) NEW_LINE DEDENT print " \n END ▁ - ▁ expecting ▁ Warnings ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE try : NEW_LINE INDENT warnings . simplefilter ( ' error ' , FutureWarning ) NEW_LINE warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = None ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 , clone = True ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , srid = - 1 ) NEW_LINE self . assertRaises ( FutureWarning , g . transform , 2774 , clone = True ) NEW_LINE DEDENT finally : NEW_LINE INDENT warnings . simplefilter ( ' default ' , FutureWarning ) NEW_LINE warnings . simplefilter ( ' default ' , UserWarning ) NEW_LINE DEDENT DEDENT def test23_transform_nogdal ( self ) : NEW_LINE INDENT old_has_gdal = gdal . HAS_GDAL NEW_LINE try : NEW_LINE INDENT gdal . HAS_GDAL = False NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE self . assertRaises ( GEOSException , g . transform , 2774 ) NEW_LINE g = GEOSGeometry ( ' POINT ▁ ( -104.609 ▁ 38.255 ) ' , 4326 ) NEW_LINE self . assertRaises ( GEOSException , g . transform , 2774 , clone = True ) NEW_LINE DEDENT finally : NEW_LINE INDENT gdal . HAS_GDAL = old_has_gdal NEW_LINE DEDENT DEDENT def test24_extent ( self ) : NEW_LINE INDENT mp = MultiPoint ( Point ( 5 , 23 ) , Point ( 0 , 0 ) , Point ( 10 , 50 ) ) NEW_LINE self . assertEqual ( ( 0.0 , 0.0 , 10.0 , 50.0 ) , mp . extent ) NEW_LINE pnt = Point ( 5.23 , 17.8 ) NEW_LINE self . assertEqual ( ( 5.23 , 17.8 , 5.23 , 17.8 ) , pnt . extent ) NEW_LINE poly = fromstr ( self . geometries . polygons [ 3 ] . wkt ) NEW_LINE ring = poly . shell NEW_LINE x , y = ring . x , ring . y NEW_LINE xmin , ymin = min ( x ) , min ( y ) NEW_LINE xmax , ymax = max ( x ) , max ( y ) NEW_LINE self . assertEqual ( ( xmin , ymin , xmax , ymax ) , poly . extent ) NEW_LINE DEDENT def test25_pickle ( self ) : NEW_LINE INDENT import pickle , cPickle NEW_LINE def get_geoms ( lst , srid = None ) : NEW_LINE INDENT return [ GEOSGeometry ( tg . wkt , srid ) for tg in lst ] NEW_LINE DEDENT tgeoms = get_geoms ( self . geometries . points ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . multilinestrings , 4326 ) ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . polygons , 3084 ) ) NEW_LINE tgeoms . extend ( get_geoms ( self . geometries . multipolygons , 900913 ) ) NEW_LINE no_srid = self . null_srid == - 1 NEW_LINE for geom in tgeoms : NEW_LINE INDENT s1 , s2 = cPickle . dumps ( geom ) , pickle . dumps ( geom ) NEW_LINE g1 , g2 = cPickle . loads ( s1 ) , pickle . loads ( s2 ) NEW_LINE for tmpg in ( g1 , g2 ) : NEW_LINE INDENT self . assertEqual ( geom , tmpg ) NEW_LINE if not no_srid : NEW_LINE INDENT self . assertEqual ( geom . srid , tmpg . srid ) NEW_LINE DEDENT DEDENT DEDENT DEDENT def test26_prepared ( self ) : NEW_LINE INDENT if not GEOS_PREPARE : NEW_LINE INDENT return NEW_LINE DEDENT mpoly = GEOSGeometry ( ' MULTIPOLYGON ( ( ( 0 ▁ 0,0 ▁ 5,5 ▁ 5,5 ▁ 0,0 ▁ 0 ) ) , ( (5 ▁ 5,5 ▁ 10,10 ▁ 10,10 ▁ 5,5 ▁ 5 ) ) ) ' ) NEW_LINE prep = mpoly . prepared NEW_LINE pnts = [ Point ( 5 , 5 ) , Point ( 7.5 , 7.5 ) , Point ( 2.5 , 7.5 ) ] NEW_LINE covers = [ True , True , False ] NEW_LINE for pnt , c in zip ( pnts , covers ) : NEW_LINE INDENT self . assertEqual ( mpoly . contains ( pnt ) , prep . contains ( pnt ) ) NEW_LINE self . assertEqual ( mpoly . intersects ( pnt ) , prep . intersects ( pnt ) ) NEW_LINE self . assertEqual ( c , prep . covers ( pnt ) ) NEW_LINE DEDENT DEDENT def test26_line_merge ( self ) : NEW_LINE INDENT ref_geoms = ( fromstr ( ' LINESTRING ( 1 ▁ 1 , ▁ 1 ▁ 1 , ▁ 3 ▁ 3 ) ' ) , fromstr ( ' MULTILINESTRING ( (1 ▁ 1 , ▁ 3 ▁ 3 ) , ▁ ( 3 ▁ 3 , ▁ 4 ▁ 2 ) ) ' ) , ) NEW_LINE ref_merged = ( fromstr ( ' LINESTRING ( 1 ▁ 1 , ▁ 3 ▁ 3 ) ' ) , fromstr ( ' LINESTRING ▁ ( 1 ▁ 1 , ▁ 3 ▁ 3 , ▁ 4 ▁ 2 ) ' ) , ) NEW_LINE for geom , merged in zip ( ref_geoms , ref_merged ) : NEW_LINE INDENT self . assertEqual ( merged , geom . merged ) NEW_LINE DEDENT DEDENT def test27_valid_reason ( self ) : NEW_LINE INDENT if not GEOS_PREPARE : NEW_LINE INDENT return NEW_LINE DEDENT g = GEOSGeometry ( " POINT ( 0 ▁ 0 ) " ) NEW_LINE self . assert_ ( g . valid ) NEW_LINE self . assert_ ( isinstance ( g . valid_reason , basestring ) ) NEW_LINE self . assertEqual ( g . valid_reason , " Valid ▁ Geometry " ) NEW_LINE print " \n BEGIN ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE g = GEOSGeometry ( " LINESTRING ( 0 ▁ 0 , ▁ 0 ▁ 0 ) " ) NEW_LINE self . assert_ ( not g . valid ) NEW_LINE self . assert_ ( isinstance ( g . valid_reason , basestring ) ) NEW_LINE self . assert_ ( g . valid_reason . startswith ( " Too ▁ few ▁ points ▁ in ▁ geometry ▁ component " ) ) NEW_LINE print " \n END ▁ - ▁ expecting ▁ GEOS _ NOTICE ; ▁ safe ▁ to ▁ ignore . \n " NEW_LINE DEDENT DEDENT def suite ( ) : NEW_LINE INDENT s = unittest . TestSuite ( ) NEW_LINE s . addTest ( unittest . makeSuite ( GEOSTest ) ) NEW_LINE return s NEW_LINE DEDENT def run ( verbosity = 2 ) : NEW_LINE INDENT unittest . TextTestRunner ( verbosity = verbosity ) . run ( suite ( ) ) NEW_LINE DEDENT
 from xml . etree . ElementTree import parse NEW_LINE from pywebhdfs . webhdfs import PyWebHdfsClient , errors , _raise_pywebhdfs_exception NEW_LINE import getpass NEW_LINE import types NEW_LINE import requests , httplib NEW_LINE class PyWebHdfsClientWithChmod ( PyWebHdfsClient ) : NEW_LINE INDENT def chmod ( self , path , permission ) : NEW_LINE INDENT uri = self . _create_uri ( path , " SETPERMISSION " , permission = permission ) NEW_LINE response = requests . put ( uri , allow_redirects = True ) NEW_LINE if not response . status_code == httplib . OK : NEW_LINE INDENT _raise_pywebhdfs_exception ( response . status_code , response . text ) NEW_LINE DEDENT return True NEW_LINE DEDENT DEDENT class HdfsConfig ( object ) : NEW_LINE INDENT def __init__ ( self , filename ) : NEW_LINE INDENT self . conf = { } NEW_LINE tree = parse ( filename ) NEW_LINE for property in tree . getroot ( ) . getiterator ( ' property ' ) : NEW_LINE INDENT self . conf [ property . find ( ' name ' ) . text ] = property . find ( ' value ' ) . text NEW_LINE DEDENT DEDENT def get ( self , key ) : NEW_LINE INDENT return self . conf . get ( key ) NEW_LINE DEDENT DEDENT def get_hdfs_client_from_conf ( conf ) : NEW_LINE INDENT hostport = conf . get ( ' dfs . namenode . http - address ' ) NEW_LINE if hostport is None : NEW_LINE INDENT raise Exception ( " dfs . namenode . http - address ▁ not ▁ found ▁ in ▁ config " ) NEW_LINE DEDENT host , port = hostport . split ( " : " ) NEW_LINE return get_hdfs_client ( host = host , port = port ) NEW_LINE DEDENT def __pyweb_hdfs_client_exists ( self , path ) : NEW_LINE INDENT try : NEW_LINE INDENT self . get_file_dir_status ( path ) NEW_LINE DEDENT except errors . FileNotFound : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE DEDENT def get_hdfs_client ( host , port , user_name = getpass . getuser ( ) ) : NEW_LINE INDENT hdfs_client = PyWebHdfsClientWithChmod ( host = host , port = port , user_name = user_name ) NEW_LINE hdfs_client . exists = types . MethodType ( __pyweb_hdfs_client_exists , hdfs_client ) NEW_LINE return hdfs_client NEW_LINE DEDENT
 from __future__ import print_function NEW_LINE from builtins import str NEW_LINE from builtins import range NEW_LINE import sys NEW_LINE sys . path . insert ( 1 , " . . / . . / . . / " ) NEW_LINE import h2o NEW_LINE from tests import pyunit_utils NEW_LINE from h2o . estimators . pca import H2OPrincipalComponentAnalysisEstimator as H2OPCA NEW_LINE def pca_arrests ( ) : NEW_LINE INDENT print ( " Importing ▁ USArrests . csv ▁ data . . . " ) NEW_LINE arrestsH2O = h2o . upload_file ( pyunit_utils . locate ( " smalldata / pca _ test / USArrests . csv " ) ) NEW_LINE print ( " Testing ▁ to ▁ see ▁ whether ▁ the ▁ trained ▁ PCA ▁ are ▁ essentially ▁ the ▁ same ▁ using ▁ different ▁ implementation . . . " ) NEW_LINE eigenvector_standard = None NEW_LINE for impl in [ " MTJ _ EVD _ DENSEMATRIX " , " MTJ _ EVD _ SYMMMATRIX " , " MTJ _ SVD _ DENSEMATRIX " , " JAMA " ] : NEW_LINE INDENT print ( " Run ▁ PCA ▁ with ▁ implementation : ▁ " + impl ) NEW_LINE model = H2OPCA ( k = 4 , pca_impl = impl , seed = 1234 ) NEW_LINE model . train ( x = list ( range ( 4 ) ) , training_frame = arrestsH2O ) NEW_LINE eigenvectors = model . _model_json [ " output " ] [ " eigenvectors " ] NEW_LINE if eigenvector_standard is not None : NEW_LINE INDENT pyunit_utils . assert_H2OTwoDimTable_equal ( eigenvector_standard , eigenvectors , model . _model_json [ " output " ] [ " names " ] , tolerance = 1e-6 , check_sign = True , check_all = False ) NEW_LINE DEDENT else : NEW_LINE INDENT eigenvector_standard = eigenvectors NEW_LINE DEDENT DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT pyunit_utils . standalone_test ( pca_arrests ) NEW_LINE DEDENT else : NEW_LINE INDENT pca_arrests ( ) NEW_LINE DEDENT
 import os NEW_LINE import fsui NEW_LINE from fsbc . paths import Paths NEW_LINE from fsgs . FSGSDirectories import FSGSDirectories NEW_LINE from . launcher_config import LauncherConfig NEW_LINE from . launcher_settings import LauncherSettings NEW_LINE from . ui . Constants import Constants NEW_LINE class GamePaths ( object ) : NEW_LINE INDENT @ staticmethod NEW_LINE def current ( ) : NEW_LINE INDENT model = LauncherConfig . get ( " amiga _ model " ) NEW_LINE if model . startswith ( " CD32" ) : NEW_LINE INDENT platform = " CD32" NEW_LINE DEDENT elif model == " CDTV " : NEW_LINE INDENT platform = " CDTV " NEW_LINE DEDENT else : NEW_LINE INDENT platform = " Amiga " NEW_LINE DEDENT name = LauncherSettings . get ( " config _ name " ) NEW_LINE uuid = LauncherConfig . get ( " x _ game _ uuid " ) NEW_LINE return GamePaths ( name , platform , uuid ) NEW_LINE DEDENT def __init__ ( self , name , platform , uuid ) : NEW_LINE INDENT self . uuid = uuid NEW_LINE self . config_name = name NEW_LINE if " ( " in name : NEW_LINE INDENT parts = name . split ( " ( " , 1 ) NEW_LINE self . name , self . variant = parts NEW_LINE self . name = self . name . strip ( ) NEW_LINE self . variant = self . variant . strip ( ) NEW_LINE if self . variant . endswith ( " ) " ) : NEW_LINE INDENT self . variant = self . variant [ : - 1 ] NEW_LINE DEDENT self . variant = self . variant . replace ( " ) ▁ ( " , " , ▁ " ) NEW_LINE self . variant = self . variant . replace ( " ) ( " , " , ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT self . name = name NEW_LINE self . variant = " " NEW_LINE DEDENT self . platform = platform NEW_LINE DEDENT def get_name ( self ) : NEW_LINE INDENT return self . name NEW_LINE DEDENT def get_variant ( self ) : NEW_LINE INDENT return self . variant NEW_LINE DEDENT @ staticmethod NEW_LINE def get_override_path ( name ) : NEW_LINE INDENT path = LauncherConfig . get ( name ) NEW_LINE if not path : NEW_LINE INDENT return " " NEW_LINE DEDENT path = Paths . expand_path ( path ) NEW_LINE return path NEW_LINE DEDENT def get_screenshot_path ( self , number ) : NEW_LINE INDENT if number == 0 : NEW_LINE INDENT sha1 = LauncherConfig . get ( " title _ sha1" ) NEW_LINE DEDENT else : NEW_LINE INDENT sha1 = LauncherConfig . get ( " screen { 0 } _ sha1" . format ( number ) ) NEW_LINE DEDENT if sha1 : NEW_LINE INDENT return " sha1 : " + sha1 NEW_LINE DEDENT if number == 0 : NEW_LINE INDENT path = self . get_override_path ( " title _ image " ) NEW_LINE DEDENT else : NEW_LINE INDENT path = self . get_override_path ( " screen { 0 } _ image " . format ( number ) ) NEW_LINE DEDENT if path and os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT if self . uuid : NEW_LINE INDENT if number == 0 : NEW_LINE INDENT name = " title . png " NEW_LINE DEDENT else : NEW_LINE INDENT name = " screen { 0 } . png " . format ( number ) NEW_LINE DEDENT paths = FSGSDirectories . get_images_dirs ( ) NEW_LINE for dir_ in paths : NEW_LINE INDENT p = os . path . join ( dir_ , self . platform , " Images " , self . uuid [ : 2 ] , self . uuid , name ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT return p NEW_LINE DEDENT p = os . path . join ( dir_ , self . platform , " Thumbnails " , self . uuid [ : 2 ] , self . uuid , name ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT return p NEW_LINE DEDENT DEDENT DEDENT letter = self . get_letter ( self . name ) NEW_LINE if not letter : NEW_LINE INDENT return None NEW_LINE DEDENT name = self . name NEW_LINE if number == 0 : NEW_LINE INDENT override_dir = LauncherConfig . get ( " titles _ dir " ) NEW_LINE if override_dir : NEW_LINE INDENT paths = [ Paths . expand_path ( override_dir ) ] NEW_LINE DEDENT else : NEW_LINE INDENT paths = FSGSDirectories . get_titles_dirs ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT override_dir = LauncherConfig . get ( " screenshots _ dir " ) NEW_LINE if override_dir : NEW_LINE INDENT paths = [ Paths . expand_path ( override_dir ) ] NEW_LINE DEDENT else : NEW_LINE INDENT paths = FSGSDirectories . get_screenshots_dirs ( ) NEW_LINE DEDENT DEDENT if number >= 2 : NEW_LINE INDENT name = " { 0 } _ {1 } " . format ( name , number ) NEW_LINE DEDENT for dir_ in paths : NEW_LINE INDENT path = os . path . join ( dir_ , letter , name + " . png " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , letter , name + " . gif " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , name + " . png " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , letter , name + " . gif " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def load_screenshot ( self , number ) : NEW_LINE INDENT path = self . get_screenshot_path ( number ) NEW_LINE if path : NEW_LINE INDENT return fsui . Image ( path ) NEW_LINE DEDENT DEDENT def load_screenshot_preview ( self , number ) : NEW_LINE INDENT image = self . load_screenshot ( number ) NEW_LINE if image is None : NEW_LINE INDENT return image NEW_LINE DEDENT if image . size == Constants . SCREEN_SIZE : NEW_LINE INDENT return image NEW_LINE DEDENT if image . size [ 0 ] < 400 : NEW_LINE INDENT image . resize ( ( image . size [ 0 ] * 2 , image . size [ 1 ] * 2 ) , fsui . Image . NEAREST ) NEW_LINE DEDENT image . resize ( Constants . SCREEN_SIZE ) NEW_LINE return image NEW_LINE DEDENT def get_cover_path ( self ) : NEW_LINE INDENT sha1 = LauncherConfig . get ( " front _ sha1" ) NEW_LINE if sha1 : NEW_LINE INDENT return " sha1 : " + sha1 NEW_LINE DEDENT path = self . get_override_path ( " cover _ image " ) NEW_LINE if path and os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT if self . uuid : NEW_LINE INDENT paths = FSGSDirectories . get_images_dirs ( ) NEW_LINE for dir_ in paths : NEW_LINE INDENT p = os . path . join ( dir_ , self . platform , " Images " , self . uuid [ : 2 ] , self . uuid , " front . png " ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT return p NEW_LINE DEDENT p = os . path . join ( dir_ , self . platform , " Thumbnails " , self . uuid [ : 2 ] , self . uuid , " front . png " ) NEW_LINE if os . path . exists ( p ) : NEW_LINE INDENT return p NEW_LINE DEDENT DEDENT DEDENT letter = self . get_letter ( self . name ) NEW_LINE if not letter : NEW_LINE INDENT return None NEW_LINE DEDENT name = self . name NEW_LINE override_dir = LauncherConfig . get ( " covers _ dir " ) NEW_LINE if override_dir : NEW_LINE INDENT paths = [ Paths . expand_path ( override_dir ) ] NEW_LINE DEDENT else : NEW_LINE INDENT paths = FSGSDirectories . get_covers_dirs ( ) NEW_LINE DEDENT for dir_ in paths : NEW_LINE INDENT path = os . path . join ( dir_ , letter , name + " . jpg " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , letter , name + " . png " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , name + " . jpg " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( dir_ , name + " . png " ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def load_cover ( self ) : NEW_LINE INDENT path = self . get_cover_path ( ) NEW_LINE print ( path ) NEW_LINE if path : NEW_LINE INDENT return fsui . Image ( path ) NEW_LINE DEDENT DEDENT def load_cover_preview ( self ) : NEW_LINE INDENT image = self . load_cover ( ) NEW_LINE if image is None : NEW_LINE INDENT return image NEW_LINE DEDENT image . resize ( Constants . COVER_SIZE ) NEW_LINE return image NEW_LINE DEDENT def get_theme_path ( self ) : NEW_LINE INDENT letter = self . get_letter ( self . name ) NEW_LINE if not letter : NEW_LINE INDENT return None NEW_LINE DEDENT paths = FSGSDirectories . get_themes_dirs ( ) NEW_LINE for dir_ in paths : NEW_LINE INDENT path = os . path . join ( dir_ , letter , self . name ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT def _get_state_dir ( self ) : NEW_LINE INDENT config_name = self . config_name NEW_LINE if not config_name : NEW_LINE INDENT config_name = " Default " NEW_LINE DEDENT from . netplay . netplay import Netplay NEW_LINE if Netplay . current ( ) : NEW_LINE INDENT config_name = LauncherConfig . get ( " _ _ netplay _ state _ dir _ name " ) NEW_LINE if not config_name : NEW_LINE INDENT netplay_game = LauncherConfig . get ( " _ _ netplay _ game " ) NEW_LINE if netplay_game : NEW_LINE INDENT config_name = " Net ▁ Play ▁ ( {0 } ) " . format ( netplay_game ) NEW_LINE DEDENT DEDENT DEDENT letter = self . get_letter ( config_name ) NEW_LINE if not letter : NEW_LINE INDENT config_name = " Default " NEW_LINE letter = self . get_letter ( config_name ) NEW_LINE DEDENT path = os . path . join ( FSGSDirectories . get_save_states_dir ( ) , letter , config_name ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT return path NEW_LINE DEDENT path = os . path . join ( FSGSDirectories . get_save_states_dir ( ) , config_name ) NEW_LINE return path NEW_LINE DEDENT def get_state_dir ( self ) : NEW_LINE INDENT state_dir = self . _get_state_dir ( ) NEW_LINE if not os . path . exists ( state_dir ) : NEW_LINE INDENT os . makedirs ( state_dir ) NEW_LINE DEDENT return state_dir NEW_LINE DEDENT @ staticmethod NEW_LINE def get_letter ( name ) : NEW_LINE INDENT letter_name = name . upper ( ) NEW_LINE if letter_name . startswith ( " THE ▁ " ) : NEW_LINE INDENT letter_name = letter_name [ 4 : ] NEW_LINE DEDENT if letter_name . startswith ( " A ▁ " ) : NEW_LINE INDENT letter_name = letter_name [ 2 : ] NEW_LINE DEDENT for i in range ( len ( letter_name ) ) : NEW_LINE INDENT letter = letter_name [ i ] NEW_LINE if letter in "01234567890" : NEW_LINE INDENT letter = "0" NEW_LINE break NEW_LINE DEDENT if letter in " ABCDEFGHIJKLMNOPQRSTUVWXYZ " : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT return letter NEW_LINE DEDENT DEDENT
 DOCUMENTATION = ''' STRNEWLINE STRNEWLINE module : ▁ pagerduty STRNEWLINE short _ description : ▁ Create ▁ PagerDuty ▁ maintenance ▁ windows STRNEWLINE description : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ This ▁ module ▁ will ▁ let ▁ you ▁ create ▁ PagerDuty ▁ maintenance ▁ windows STRNEWLINE version _ added : ▁ " 1.2 " STRNEWLINE author : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Andrew ▁ Newdigate ▁ ( @ suprememoocow ) " STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Dylan ▁ Silva ▁ ( @ thaumos ) " STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Justin ▁ Johns " STRNEWLINE ▁ ▁ ▁ ▁ - ▁ " Bruce ▁ Pennypacker " STRNEWLINE requirements : STRNEWLINE ▁ ▁ ▁ ▁ - ▁ PagerDuty ▁ API ▁ access STRNEWLINE options : STRNEWLINE ▁ ▁ ▁ ▁ state : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Create ▁ a ▁ maintenance ▁ window ▁ or ▁ get ▁ a ▁ list ▁ of ▁ ongoing ▁ windows . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ▁ " running " , ▁ " started " , ▁ " ongoing " , ▁ " absent " ▁ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ name : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ PagerDuty ▁ unique ▁ subdomain . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ user : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ PagerDuty ▁ user ▁ ID . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ passwd : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ PagerDuty ▁ user ▁ password . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ token : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ pagerduty ▁ token , ▁ generated ▁ on ▁ the ▁ pagerduty ▁ site . ▁ Can ▁ be ▁ used ▁ instead ▁ of STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ user / passwd ▁ combination . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ ' 1.8 ' STRNEWLINE ▁ ▁ ▁ ▁ requester _ id : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ ID ▁ of ▁ user ▁ making ▁ the ▁ request . ▁ Only ▁ needed ▁ when ▁ using ▁ a ▁ token ▁ and ▁ creating ▁ a ▁ maintenance _ window . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ true STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ ' 1.8 ' STRNEWLINE ▁ ▁ ▁ ▁ service : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ A ▁ comma ▁ separated ▁ list ▁ of ▁ PagerDuty ▁ service ▁ IDs . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ null STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ▁ services ▁ ] STRNEWLINE ▁ ▁ ▁ ▁ hours : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Length ▁ of ▁ maintenance ▁ window ▁ in ▁ hours . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ 1 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ minutes : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Maintenance ▁ window ▁ in ▁ minutes ▁ ( this ▁ is ▁ added ▁ to ▁ the ▁ hours ) . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ 0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ ' 1.8 ' STRNEWLINE ▁ ▁ ▁ ▁ desc : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ Short ▁ description ▁ of ▁ maintenance ▁ window . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ Created ▁ by ▁ Ansible STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ aliases : ▁ [ ] STRNEWLINE ▁ ▁ ▁ ▁ validate _ certs : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ description : STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ - ▁ If ▁ C ( no ) , ▁ SSL ▁ certificates ▁ will ▁ not ▁ be ▁ validated . ▁ This ▁ should ▁ only ▁ be ▁ used STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ on ▁ personally ▁ controlled ▁ sites ▁ using ▁ self - signed ▁ certificates . STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ required : ▁ false STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ default : ▁ ' yes ' STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ choices : ▁ [ ' yes ' , ▁ ' no ' ] STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ version _ added : ▁ 1.5.1 STRNEWLINE ''' NEW_LINE EXAMPLES = ''' STRNEWLINE # ▁ List ▁ ongoing ▁ maintenance ▁ windows ▁ using ▁ a ▁ user / passwd STRNEWLINE - ▁ pagerduty : ▁ name = companyabc ▁ user = example @ example . com ▁ passwd = password123 ▁ state = ongoing STRNEWLINE STRNEWLINE # ▁ List ▁ ongoing ▁ maintenance ▁ windows ▁ using ▁ a ▁ token STRNEWLINE - ▁ pagerduty : ▁ name = companyabc ▁ token = xxxxxxxxxxxxxx ▁ state = ongoing STRNEWLINE STRNEWLINE # ▁ Create ▁ a ▁ 1 ▁ hour ▁ maintenance ▁ window ▁ for ▁ service ▁ FOO123 , ▁ using ▁ a ▁ user / passwd STRNEWLINE - ▁ pagerduty : ▁ name = companyabc STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ user = example @ example . com STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ passwd = password123 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state = running STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ service = FOO123 STRNEWLINE STRNEWLINE # ▁ Create ▁ a ▁ 5 ▁ minute ▁ maintenance ▁ window ▁ for ▁ service ▁ FOO123 , ▁ using ▁ a ▁ token STRNEWLINE - ▁ pagerduty : ▁ name = companyabc STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ token = xxxxxxxxxxxxxx STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ hours = 0 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ minutes = 5 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state = running STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ service = FOO123 STRNEWLINE STRNEWLINE STRNEWLINE # ▁ Create ▁ a ▁ 4 ▁ hour ▁ maintenance ▁ window ▁ for ▁ service ▁ FOO123 ▁ with ▁ the ▁ description ▁ " deployment " . STRNEWLINE - ▁ pagerduty : ▁ name = companyabc STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ user = example @ example . com STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ passwd = password123 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state = running STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ service = FOO123 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ hours = 4 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ desc = deployment STRNEWLINE ▁ ▁ register : ▁ pd _ window STRNEWLINE STRNEWLINE # ▁ Delete ▁ the ▁ previous ▁ maintenance ▁ window STRNEWLINE - ▁ pagerduty : ▁ name = companyabc STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ user = example @ example . com STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ passwd = password123 STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ state = absent STRNEWLINE ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ ▁ service = { { ▁ pd _ window . result . maintenance _ window . id ▁ } } STRNEWLINE ''' NEW_LINE import datetime NEW_LINE import base64 NEW_LINE def auth_header ( user , passwd , token ) : NEW_LINE INDENT if token : NEW_LINE INDENT return " Token ▁ token = % s " % token NEW_LINE DEDENT auth = base64 . encodestring ( ' % s : % s ' % ( user , passwd ) ) . replace ( ' \n ' , ' ' ) NEW_LINE return " Basic ▁ % s " % auth NEW_LINE DEDENT def ongoing ( module , name , user , passwd , token ) : NEW_LINE INDENT url = " https : / / " + name + " . pagerduty . com / api / v1 / maintenance _ windows / ongoing " NEW_LINE headers = { " Authorization " : auth_header ( user , passwd , token ) } NEW_LINE response , info = fetch_url ( module , url , headers = headers ) NEW_LINE if info [ ' status ' ] != 200 : NEW_LINE INDENT module . fail_json ( msg = " failed ▁ to ▁ lookup ▁ the ▁ ongoing ▁ window : ▁ % s " % info [ ' msg ' ] ) NEW_LINE DEDENT try : NEW_LINE INDENT json_out = json . loads ( response . read ( ) ) NEW_LINE DEDENT except : NEW_LINE INDENT json_out = " " NEW_LINE DEDENT return False , json_out , False NEW_LINE DEDENT def create ( module , name , user , passwd , token , requester_id , service , hours , minutes , desc ) : NEW_LINE INDENT now = datetime . datetime . utcnow ( ) NEW_LINE later = now + datetime . timedelta ( hours = int ( hours ) , minutes = int ( minutes ) ) NEW_LINE start = now . strftime ( " % Y - % m - % dT % H : % M : % SZ " ) NEW_LINE end = later . strftime ( " % Y - % m - % dT % H : % M : % SZ " ) NEW_LINE url = " https : / / " + name + " . pagerduty . com / api / v1 / maintenance _ windows " NEW_LINE headers = { ' Authorization ' : auth_header ( user , passwd , token ) , ' Content - Type ' : ' application / json ' , } NEW_LINE request_data = { ' maintenance _ window ' : { ' start _ time ' : start , ' end _ time ' : end , ' description ' : desc , ' service _ ids ' : service } } NEW_LINE if requester_id : NEW_LINE INDENT request_data [ ' requester _ id ' ] = requester_id NEW_LINE DEDENT else : NEW_LINE INDENT if token : NEW_LINE INDENT module . fail_json ( msg = " requester _ id ▁ is ▁ required ▁ when ▁ using ▁ a ▁ token " ) NEW_LINE DEDENT DEDENT data = json . dumps ( request_data ) NEW_LINE response , info = fetch_url ( module , url , data = data , headers = headers , method = ' POST ' ) NEW_LINE if info [ ' status ' ] != 200 : NEW_LINE INDENT module . fail_json ( msg = " failed ▁ to ▁ create ▁ the ▁ window : ▁ % s " % info [ ' msg ' ] ) NEW_LINE DEDENT try : NEW_LINE INDENT json_out = json . loads ( response . read ( ) ) NEW_LINE DEDENT except : NEW_LINE INDENT json_out = " " NEW_LINE DEDENT return False , json_out , True NEW_LINE DEDENT def absent ( module , name , user , passwd , token , requester_id , service ) : NEW_LINE INDENT url = " https : / / " + name + " . pagerduty . com / api / v1 / maintenance _ windows / " + service [ 0 ] NEW_LINE headers = { ' Authorization ' : auth_header ( user , passwd , token ) , ' Content - Type ' : ' application / json ' , } NEW_LINE request_data = { } NEW_LINE if requester_id : NEW_LINE INDENT request_data [ ' requester _ id ' ] = requester_id NEW_LINE DEDENT else : NEW_LINE INDENT if token : NEW_LINE INDENT module . fail_json ( msg = " requester _ id ▁ is ▁ required ▁ when ▁ using ▁ a ▁ token " ) NEW_LINE DEDENT DEDENT data = json . dumps ( request_data ) NEW_LINE response , info = fetch_url ( module , url , data = data , headers = headers , method = ' DELETE ' ) NEW_LINE if info [ ' status ' ] != 200 : NEW_LINE INDENT module . fail_json ( msg = " failed ▁ to ▁ delete ▁ the ▁ window : ▁ % s " % info [ ' msg ' ] ) NEW_LINE DEDENT try : NEW_LINE INDENT json_out = json . loads ( response . read ( ) ) NEW_LINE DEDENT except : NEW_LINE INDENT json_out = " " NEW_LINE DEDENT return False , json_out , True NEW_LINE DEDENT def main ( ) : NEW_LINE INDENT module = AnsibleModule ( argument_spec = dict ( state = dict ( required = True , choices = [ ' running ' , ' started ' , ' ongoing ' , ' absent ' ] ) , name = dict ( required = True ) , user = dict ( required = False ) , passwd = dict ( required = False ) , token = dict ( required = False ) , service = dict ( required = False , type = ' list ' , aliases = [ " services " ] ) , requester_id = dict ( required = False ) , hours = dict ( default = '1' , required = False ) , minutes = dict ( default = '0' , required = False ) , desc = dict ( default = ' Created ▁ by ▁ Ansible ' , required = False ) , validate_certs = dict ( default = ' yes ' , type = ' bool ' ) , ) ) NEW_LINE state = module . params [ ' state ' ] NEW_LINE name = module . params [ ' name ' ] NEW_LINE user = module . params [ ' user ' ] NEW_LINE passwd = module . params [ ' passwd ' ] NEW_LINE token = module . params [ ' token ' ] NEW_LINE service = module . params [ ' service ' ] NEW_LINE hours = module . params [ ' hours ' ] NEW_LINE minutes = module . params [ ' minutes ' ] NEW_LINE token = module . params [ ' token ' ] NEW_LINE desc = module . params [ ' desc ' ] NEW_LINE requester_id = module . params [ ' requester _ id ' ] NEW_LINE if not token and not ( user or passwd ) : NEW_LINE INDENT module . fail_json ( msg = " neither ▁ user ▁ and ▁ passwd ▁ nor ▁ token ▁ specified " ) NEW_LINE DEDENT if state == " running " or state == " started " : NEW_LINE INDENT if not service : NEW_LINE INDENT module . fail_json ( msg = " service ▁ not ▁ specified " ) NEW_LINE DEDENT ( rc , out , changed ) = create ( module , name , user , passwd , token , requester_id , service , hours , minutes , desc ) NEW_LINE if rc == 0 : NEW_LINE INDENT changed = True NEW_LINE DEDENT DEDENT if state == " ongoing " : NEW_LINE INDENT ( rc , out , changed ) = ongoing ( module , name , user , passwd , token ) NEW_LINE DEDENT if state == " absent " : NEW_LINE INDENT ( rc , out , changed ) = absent ( module , name , user , passwd , token , requester_id , service ) NEW_LINE DEDENT if rc != 0 : NEW_LINE INDENT module . fail_json ( msg = " failed " , result = out ) NEW_LINE DEDENT module . exit_json ( msg = " success " , result = out , changed = changed ) NEW_LINE DEDENT from ansible . module_utils . basic import * NEW_LINE from ansible . module_utils . urls import * NEW_LINE main ( ) NEW_LINE
 import functools NEW_LINE import os NEW_LINE from django . contrib . admin . options import ModelAdmin NEW_LINE from django . contrib . admin . sites import AdminSite NEW_LINE from django . test import TestCase NEW_LINE from django . db import models , transaction NEW_LINE from django . contrib . auth . models import User NEW_LINE from django . db . models import Q NEW_LINE from django . conf import settings NEW_LINE from django import VERSION as DJANGO_VERSION NEW_LINE from treebeard import numconv NEW_LINE from treebeard . exceptions import InvalidPosition , InvalidMoveToDescendant , \NEW_LINE PathOverflow , MissingNodeOrderBy NEW_LINE from treebeard . mp_tree import MP_Node NEW_LINE from treebeard . al_tree import AL_Node NEW_LINE from treebeard . ns_tree import NS_Node NEW_LINE from treebeard . forms import MoveNodeForm NEW_LINE HAS_DJANGO_AUTH = ' django . contrib . auth ' in settings . INSTALLED_APPS NEW_LINE BASE_DATA = [ { ' data ' : { ' desc ' : '1' } } , { ' data ' : { ' desc ' : '2' } , ' children ' : [ { ' data ' : { ' desc ' : '21' } } , { ' data ' : { ' desc ' : '22' } } , { ' data ' : { ' desc ' : '23' } , ' children ' : [ { ' data ' : { ' desc ' : '231' } } , ] } , { ' data ' : { ' desc ' : '24' } } , ] } , { ' data ' : { ' desc ' : '3' } } , { ' data ' : { ' desc ' : '4' } , ' children ' : [ { ' data ' : { ' desc ' : '41' } } , ] } , ] NEW_LINE class MP_TestNode ( MP_Node ) : NEW_LINE INDENT steplen = 3 NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeSomeDep ( models . Model ) : NEW_LINE INDENT node = models . ForeignKey ( MP_TestNode ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class NS_TestNode ( NS_Node ) : NEW_LINE INDENT desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class NS_TestNodeSomeDep ( models . Model ) : NEW_LINE INDENT node = models . ForeignKey ( NS_TestNode ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class AL_TestNode ( AL_Node ) : NEW_LINE INDENT parent = models . ForeignKey ( ' self ' , related_name = ' children _ set ' , null = True , db_index = True ) NEW_LINE sib_order = models . PositiveIntegerField ( ) NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class AL_TestNodeSomeDep ( models . Model ) : NEW_LINE INDENT node = models . ForeignKey ( AL_TestNode ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeSorted ( MP_Node ) : NEW_LINE INDENT steplen = 1 NEW_LINE node_order_by = [ ' val1' , ' val2' , ' desc ' ] NEW_LINE val1 = models . IntegerField ( ) NEW_LINE val2 = models . IntegerField ( ) NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class NS_TestNodeSorted ( NS_Node ) : NEW_LINE INDENT node_order_by = [ ' val1' , ' val2' , ' desc ' ] NEW_LINE val1 = models . IntegerField ( ) NEW_LINE val2 = models . IntegerField ( ) NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class AL_TestNodeSorted ( AL_Node ) : NEW_LINE INDENT parent = models . ForeignKey ( ' self ' , related_name = ' children _ set ' , null = True , db_index = True ) NEW_LINE node_order_by = [ ' val1' , ' val2' , ' desc ' ] NEW_LINE val1 = models . IntegerField ( ) NEW_LINE val2 = models . IntegerField ( ) NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeAlphabet ( MP_Node ) : NEW_LINE INDENT steplen = 2 NEW_LINE numval = models . IntegerField ( ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeSmallStep ( MP_Node ) : NEW_LINE INDENT steplen = 1 NEW_LINE alphabet = '0123456789' NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeSortedAutoNow ( MP_Node ) : NEW_LINE INDENT desc = models . CharField ( max_length = 255 ) NEW_LINE created = models . DateTimeField ( auto_now_add = True ) NEW_LINE node_order_by = [ ' created ' ] NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT class MP_TestNodeShortPath ( MP_Node ) : NEW_LINE INDENT steplen = 1 NEW_LINE alphabet = '01234' NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT MP_TestNodeShortPath . _meta . get_field ( ' path ' ) . max_length = 4 NEW_LINE if DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT class MP_TestNode_Proxy ( MP_TestNode ) : NEW_LINE INDENT class Meta : NEW_LINE INDENT proxy = True NEW_LINE DEDENT DEDENT class NS_TestNode_Proxy ( NS_TestNode ) : NEW_LINE INDENT class Meta : NEW_LINE INDENT proxy = True NEW_LINE DEDENT DEDENT class AL_TestNode_Proxy ( AL_TestNode ) : NEW_LINE INDENT class Meta : NEW_LINE INDENT proxy = True NEW_LINE DEDENT DEDENT DEDENT class MP_TestSortedNodeShortPath ( MP_Node ) : NEW_LINE INDENT steplen = 1 NEW_LINE alphabet = '01234' NEW_LINE desc = models . CharField ( max_length = 255 ) NEW_LINE node_order_by = [ ' desc ' ] NEW_LINE def __unicode__ ( self ) : NEW_LINE INDENT return ' Node ▁ % d ' % self . id NEW_LINE DEDENT DEDENT MP_TestSortedNodeShortPath . _meta . get_field ( ' path ' ) . max_length = 4 NEW_LINE if HAS_DJANGO_AUTH : NEW_LINE INDENT class MP_TestIssue14 ( MP_Node ) : NEW_LINE INDENT name = models . CharField ( max_length = 255 ) NEW_LINE users = models . ManyToManyField ( User ) NEW_LINE DEDENT DEDENT def testtype ( treetype , proxy ) : NEW_LINE INDENT def decorator ( f ) : NEW_LINE INDENT @ functools . wraps ( f ) NEW_LINE def _testtype ( self ) : NEW_LINE INDENT { ' MP ' : self . set_MP , ' AL ' : self . set_AL , ' NS ' : self . set_NS } [ treetype ] ( proxy ) NEW_LINE try : NEW_LINE INDENT f ( self ) NEW_LINE DEDENT finally : NEW_LINE INDENT transaction . rollback ( ) NEW_LINE self . model = None NEW_LINE self . sorted_model = None NEW_LINE self . dep_model = None NEW_LINE DEDENT DEDENT return _testtype NEW_LINE DEDENT return decorator NEW_LINE DEDENT def _load_test_methods ( cls , proxy = True ) : NEW_LINE INDENT if proxy and DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT proxyopts = ( False , True ) NEW_LINE DEDENT else : NEW_LINE INDENT proxyopts = ( False , ) NEW_LINE DEDENT for m in dir ( cls ) : NEW_LINE INDENT if not m . startswith ( ' _ multi _ ' ) : NEW_LINE INDENT continue NEW_LINE DEDENT for t in ( ' MP ' , ' AL ' , ' NS ' ) : NEW_LINE INDENT for p in proxyopts : NEW_LINE INDENT deco = testtype ( t , p ) NEW_LINE name = ' test _ % s % s _ % s ' % ( t . lower ( ) , ' _ proxy ' if p else ' ' , m . split ( ' _ ' , 2 ) [ 2 ] ) NEW_LINE setattr ( cls , name , deco ( getattr ( cls , m ) ) ) NEW_LINE DEDENT DEDENT DEDENT DEDENT class TestTreeBase ( TestCase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT self . set_MP ( ) NEW_LINE self . unchanged = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE DEDENT def set_MP ( self , proxy = False ) : NEW_LINE INDENT if proxy and DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT self . model = MP_TestNode_Proxy NEW_LINE DEDENT else : NEW_LINE INDENT self . model = MP_TestNode NEW_LINE DEDENT self . sorted_model = MP_TestNodeSorted NEW_LINE self . dep_model = MP_TestNodeSomeDep NEW_LINE DEDENT def set_NS ( self , proxy = False ) : NEW_LINE INDENT if proxy and DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT self . model = NS_TestNode_Proxy NEW_LINE DEDENT else : NEW_LINE INDENT self . model = NS_TestNode NEW_LINE DEDENT self . sorted_model = NS_TestNodeSorted NEW_LINE self . dep_model = NS_TestNodeSomeDep NEW_LINE DEDENT def set_AL ( self , proxy = False ) : NEW_LINE INDENT if proxy and DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT self . model = AL_TestNode_Proxy NEW_LINE DEDENT else : NEW_LINE INDENT self . model = AL_TestNode NEW_LINE DEDENT self . sorted_model = AL_TestNodeSorted NEW_LINE self . dep_model = AL_TestNodeSomeDep NEW_LINE DEDENT def got ( self ) : NEW_LINE INDENT nsmodels = [ NS_TestNode ] NEW_LINE if DJANGO_VERSION >= ( 1 , 1 ) : NEW_LINE INDENT nsmodels . append ( NS_TestNode_Proxy ) NEW_LINE DEDENT if self . model in nsmodels : NEW_LINE INDENT d = { } NEW_LINE for tree_id , lft , rgt in self . model . objects . values_list ( ' tree _ id ' , ' lft ' , ' rgt ' ) : NEW_LINE INDENT d . setdefault ( tree_id , [ ] ) . extend ( [ lft , rgt ] ) NEW_LINE DEDENT for tree_id , got_edges in d . items ( ) : NEW_LINE INDENT self . assertEqual ( len ( got_edges ) , max ( got_edges ) ) NEW_LINE good_edges = range ( 1 , len ( got_edges ) + 1 ) NEW_LINE self . assertEqual ( sorted ( got_edges ) , good_edges ) NEW_LINE DEDENT DEDENT return [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( ) ] NEW_LINE DEDENT def _assert_get_annotated_list ( self , expected , parent = None ) : NEW_LINE INDENT got = [ ( obj [ 0 ] . desc , obj [ 1 ] [ ' open ' ] , obj [ 1 ] [ ' close ' ] , obj [ 1 ] [ ' level ' ] ) for obj in self . model . get_annotated_list ( parent ) ] NEW_LINE self . assertEqual ( expected , got ) NEW_LINE DEDENT DEDENT class TestEmptyTree ( TestTreeBase ) : NEW_LINE INDENT def _multi_load_bulk_empty ( self ) : NEW_LINE INDENT ids = self . model . load_bulk ( BASE_DATA ) NEW_LINE got_descs = [ obj . desc for obj in self . model . objects . filter ( id__in = ids ) ] NEW_LINE expected_descs = [ x [ 0 ] for x in self . unchanged ] NEW_LINE self . assertEqual ( sorted ( got_descs ) , sorted ( expected_descs ) ) NEW_LINE self . assertEqual ( self . got ( ) , self . unchanged ) NEW_LINE DEDENT def _multi_dump_bulk_empty ( self ) : NEW_LINE INDENT self . assertEqual ( self . model . dump_bulk ( ) , [ ] ) NEW_LINE DEDENT def _multi_add_root_empty ( self ) : NEW_LINE INDENT self . model . add_root ( desc = '1' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_get_root_nodes_empty ( self ) : NEW_LINE INDENT got = self . model . get_root_nodes ( ) NEW_LINE expected = [ ] NEW_LINE self . assertEqual ( [ node . desc for node in got ] , expected ) NEW_LINE DEDENT def _multi_get_first_root_node_empty ( self ) : NEW_LINE INDENT got = self . model . get_first_root_node ( ) NEW_LINE self . assertEqual ( got , None ) NEW_LINE DEDENT def _multi_get_last_root_node_empty ( self ) : NEW_LINE INDENT got = self . model . get_last_root_node ( ) NEW_LINE self . assertEqual ( got , None ) NEW_LINE DEDENT def _multi_get_tree ( self ) : NEW_LINE INDENT got = list ( self . model . get_tree ( ) ) NEW_LINE self . assertEqual ( got , [ ] ) NEW_LINE DEDENT def _multi_get_annotated_list ( self ) : NEW_LINE INDENT expected = [ ] NEW_LINE self . _assert_get_annotated_list ( expected ) NEW_LINE DEDENT DEDENT class TestNonEmptyTree ( TestTreeBase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT super ( TestNonEmptyTree , self ) . setUp ( ) NEW_LINE MP_TestNode . load_bulk ( BASE_DATA ) NEW_LINE AL_TestNode . load_bulk ( BASE_DATA ) NEW_LINE NS_TestNode . load_bulk ( BASE_DATA ) NEW_LINE DEDENT DEDENT class TestClassMethods ( TestNonEmptyTree ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT super ( TestClassMethods , self ) . setUp ( ) NEW_LINE DEDENT def _multi_load_bulk_existing ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 231' ) NEW_LINE ids = self . model . load_bulk ( BASE_DATA , node ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 4 ) , ( u' 1' , 4 , 0 ) , ( u' 2' , 4 , 4 ) , ( u' 21' , 5 , 0 ) , ( u' 22' , 5 , 0 ) , ( u' 23' , 5 , 1 ) , ( u' 231' , 6 , 0 ) , ( u' 24' , 5 , 0 ) , ( u' 3' , 4 , 0 ) , ( u' 4' , 4 , 1 ) , ( u' 41' , 5 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE expected_descs = [ u' 1' , u' 2' , u' 21' , u' 22' , u' 23' , u' 231' , u' 24' , u' 3' , u' 4' , u' 41' ] NEW_LINE got_descs = [ obj . desc for obj in self . model . objects . filter ( id__in = ids ) ] NEW_LINE self . assertEqual ( sorted ( got_descs ) , sorted ( expected_descs ) ) NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_get_tree_all ( self ) : NEW_LINE INDENT got = [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( ) ] NEW_LINE self . assertEqual ( got , self . unchanged ) NEW_LINE DEDENT def _multi_dump_bulk_all ( self ) : NEW_LINE INDENT self . assertEqual ( self . model . dump_bulk ( keep_ids = False ) , BASE_DATA ) NEW_LINE DEDENT def _multi_get_tree_node ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 231' ) NEW_LINE self . model . load_bulk ( BASE_DATA , node ) NEW_LINE node = self . model . objects . get ( pk = node . id ) NEW_LINE got = [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( node ) ] NEW_LINE expected = [ ( u' 231' , 3 , 4 ) , ( u' 1' , 4 , 0 ) , ( u' 2' , 4 , 4 ) , ( u' 21' , 5 , 0 ) , ( u' 22' , 5 , 0 ) , ( u' 23' , 5 , 1 ) , ( u' 231' , 6 , 0 ) , ( u' 24' , 5 , 0 ) , ( u' 3' , 4 , 0 ) , ( u' 4' , 4 , 1 ) , ( u' 41' , 5 , 0 ) ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT def _multi_get_tree_leaf ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 1' ) NEW_LINE self . assertEqual ( 0 , node . get_children_count ( ) ) NEW_LINE got = [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( node ) ] NEW_LINE expected = [ ( u' 1' , 1 , 0 ) ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT def _multi_get_annotated_list_all ( self ) : NEW_LINE INDENT expected = [ ( u' 1' , True , [ ] , 0 ) , ( u' 2' , False , [ ] , 0 ) , ( u' 21' , True , [ ] , 1 ) , ( u' 22' , False , [ ] , 1 ) , ( u' 23' , False , [ ] , 1 ) , ( u' 231' , True , [ 0 ] , 2 ) , ( u' 24' , False , [ 0 ] , 1 ) , ( u' 3' , False , [ ] , 0 ) , ( u' 4' , False , [ ] , 0 ) , ( u' 41' , True , [ 0 , 1 ] , 1 ) ] NEW_LINE self . _assert_get_annotated_list ( expected ) NEW_LINE DEDENT def _multi_get_annotated_list_node ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 2' ) NEW_LINE expected = [ ( u' 2' , True , [ ] , 0 ) , ( u' 21' , True , [ ] , 1 ) , ( u' 22' , False , [ ] , 1 ) , ( u' 23' , False , [ ] , 1 ) , ( u' 231' , True , [ 0 ] , 2 ) , ( u' 24' , False , [ 0 , 1 ] , 1 ) ] NEW_LINE self . _assert_get_annotated_list ( expected , node ) NEW_LINE DEDENT def _multi_get_annotated_list_leaf ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 1' ) NEW_LINE expected = [ ( u' 1' , True , [ 0 ] , 0 ) ] NEW_LINE self . _assert_get_annotated_list ( expected , node ) NEW_LINE DEDENT def _multi_dump_bulk_node ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 231' ) NEW_LINE self . model . load_bulk ( BASE_DATA , node ) NEW_LINE node = self . model . objects . get ( pk = node . id ) NEW_LINE got = self . model . dump_bulk ( node , False ) NEW_LINE expected = [ { ' data ' : { ' desc ' : u' 231' } , ' children ' : BASE_DATA } ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT def _multi_load_and_dump_bulk_keeping_ids ( self ) : NEW_LINE INDENT exp = self . model . dump_bulk ( keep_ids = True ) NEW_LINE self . model . objects . all ( ) . delete ( ) NEW_LINE self . model . load_bulk ( exp , None , True ) NEW_LINE got = self . model . dump_bulk ( keep_ids = True ) NEW_LINE self . assertEqual ( got , exp ) NEW_LINE got = [ ( o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . model . get_tree ( ) ] NEW_LINE self . assertEqual ( got , self . unchanged ) NEW_LINE DEDENT def _multi_get_root_nodes ( self ) : NEW_LINE INDENT got = self . model . get_root_nodes ( ) NEW_LINE expected = [ '1' , '2' , '3' , '4' ] NEW_LINE self . assertEqual ( [ node . desc for node in got ] , expected ) NEW_LINE DEDENT def _multi_get_first_root_node ( self ) : NEW_LINE INDENT got = self . model . get_first_root_node ( ) NEW_LINE self . assertEqual ( got . desc , '1' ) NEW_LINE DEDENT def _multi_get_last_root_node ( self ) : NEW_LINE INDENT got = self . model . get_last_root_node ( ) NEW_LINE self . assertEqual ( got . desc , '4' ) NEW_LINE DEDENT def _multi_add_root ( self ) : NEW_LINE INDENT obj = self . model . add_root ( desc = '5' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE self . assertEqual ( self . model . get_last_root_node ( ) . desc , '5' ) NEW_LINE DEDENT DEDENT class TestSimpleNodeMethods ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_is_root ( self ) : NEW_LINE INDENT data = [ ( '2' , True ) , ( '1' , True ) , ( '4' , True ) , ( '21' , False ) , ( '24' , False ) , ( '22' , False ) , ( '231' , False ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT got = self . model . objects . get ( desc = desc ) . is_root ( ) NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT def _multi_is_leaf ( self ) : NEW_LINE INDENT data = [ ( '2' , False ) , ( '23' , False ) , ( '231' , True ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT got = self . model . objects . get ( desc = desc ) . is_leaf ( ) NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT def _multi_get_root ( self ) : NEW_LINE INDENT data = [ ( '2' , '2' ) , ( '1' , '1' ) , ( '4' , '4' ) , ( '21' , '2' ) , ( '24' , '2' ) , ( '22' , '2' ) , ( '231' , '2' ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_root ( ) NEW_LINE self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT def _multi_get_parent ( self ) : NEW_LINE INDENT data = [ ( '2' , None ) , ( '1' , None ) , ( '4' , None ) , ( '21' , '2' ) , ( '24' , '2' ) , ( '22' , '2' ) , ( '231' , '23' ) , ] NEW_LINE data = dict ( data ) NEW_LINE objs = { } NEW_LINE for desc , expected in data . items ( ) : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) NEW_LINE parent = node . get_parent ( ) NEW_LINE if expected : NEW_LINE INDENT self . assertEqual ( parent . desc , expected ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( parent , None ) NEW_LINE DEDENT objs [ desc ] = node NEW_LINE node . _parent_obj = ' CORRUPTED ! ! ! ' NEW_LINE DEDENT for desc , expected in data . items ( ) : NEW_LINE INDENT node = objs [ desc ] NEW_LINE parent = node . get_parent ( True ) NEW_LINE if expected : NEW_LINE INDENT self . assertEqual ( parent . desc , expected ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( parent , None ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_children ( self ) : NEW_LINE INDENT data = [ ( '2' , [ '21' , '22' , '23' , '24' ] ) , ( '23' , [ '231' ] ) , ( '231' , [ ] ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT children = self . model . objects . get ( desc = desc ) . get_children ( ) NEW_LINE self . assertEqual ( [ node . desc for node in children ] , expected ) NEW_LINE DEDENT DEDENT def _multi_get_children_count ( self ) : NEW_LINE INDENT data = [ ( '2' , 4 ) , ( '23' , 1 ) , ( '231' , 0 ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT got = self . model . objects . get ( desc = desc ) . get_children_count ( ) NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT def _multi_get_siblings ( self ) : NEW_LINE INDENT data = [ ( '2' , [ '1' , '2' , '3' , '4' ] ) , ( '21' , [ '21' , '22' , '23' , '24' ] ) , ( '231' , [ '231' ] ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT siblings = self . model . objects . get ( desc = desc ) . get_siblings ( ) NEW_LINE self . assertEqual ( [ node . desc for node in siblings ] , expected ) NEW_LINE DEDENT DEDENT def _multi_get_first_sibling ( self ) : NEW_LINE INDENT data = [ ( '2' , '1' ) , ( '1' , '1' ) , ( '4' , '1' ) , ( '21' , '21' ) , ( '24' , '21' ) , ( '22' , '21' ) , ( '231' , '231' ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_first_sibling ( ) NEW_LINE self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT def _multi_get_prev_sibling ( self ) : NEW_LINE INDENT data = [ ( '2' , '1' ) , ( '1' , None ) , ( '4' , '3' ) , ( '21' , None ) , ( '24' , '23' ) , ( '22' , '21' ) , ( '231' , None ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_prev_sibling ( ) NEW_LINE if expected is None : NEW_LINE INDENT self . assertEqual ( node , None ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_next_sibling ( self ) : NEW_LINE INDENT data = [ ( '2' , '3' ) , ( '1' , '2' ) , ( '4' , None ) , ( '21' , '22' ) , ( '24' , None ) , ( '22' , '23' ) , ( '231' , None ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_next_sibling ( ) NEW_LINE if expected is None : NEW_LINE INDENT self . assertEqual ( node , None ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_last_sibling ( self ) : NEW_LINE INDENT data = [ ( '2' , '4' ) , ( '1' , '4' ) , ( '4' , '4' ) , ( '21' , '24' ) , ( '24' , '24' ) , ( '22' , '24' ) , ( '231' , '231' ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_last_sibling ( ) NEW_LINE self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT def _multi_get_first_child ( self ) : NEW_LINE INDENT data = [ ( '2' , '21' ) , ( '21' , None ) , ( '23' , '231' ) , ( '231' , None ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_first_child ( ) NEW_LINE if expected is None : NEW_LINE INDENT self . assertEqual ( node , None ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_last_child ( self ) : NEW_LINE INDENT data = [ ( '2' , '24' ) , ( '21' , None ) , ( '23' , '231' ) , ( '231' , None ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT node = self . model . objects . get ( desc = desc ) . get_last_child ( ) NEW_LINE if expected is None : NEW_LINE INDENT self . assertEqual ( node , None ) NEW_LINE DEDENT else : NEW_LINE INDENT self . assertEqual ( node . desc , expected ) NEW_LINE DEDENT DEDENT DEDENT def _multi_get_ancestors ( self ) : NEW_LINE INDENT data = [ ( '2' , [ ] ) , ( '21' , [ '2' ] ) , ( '231' , [ '2' , '23' ] ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT nodes = self . model . objects . get ( desc = desc ) . get_ancestors ( ) NEW_LINE self . assertEqual ( [ node . desc for node in nodes ] , expected ) NEW_LINE DEDENT DEDENT def _multi_get_descendants ( self ) : NEW_LINE INDENT data = [ ( '2' , [ '21' , '22' , '23' , '231' , '24' ] ) , ( '23' , [ '231' ] ) , ( '231' , [ ] ) , ( '1' , [ ] ) , ( '4' , [ '41' ] ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT nodes = self . model . objects . get ( desc = desc ) . get_descendants ( ) NEW_LINE self . assertEqual ( [ node . desc for node in nodes ] , expected ) NEW_LINE DEDENT DEDENT def _multi_get_descendant_count ( self ) : NEW_LINE INDENT data = [ ( '2' , 5 ) , ( '23' , 1 ) , ( '231' , 0 ) , ( '1' , 0 ) , ( '4' , 1 ) , ] NEW_LINE for desc , expected in data : NEW_LINE INDENT got = self . model . objects . get ( desc = desc ) . get_descendant_count ( ) NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT def _multi_is_sibling_of ( self ) : NEW_LINE INDENT data = [ ( '2' , '2' , True ) , ( '2' , '1' , True ) , ( '21' , '2' , False ) , ( '231' , '2' , False ) , ( '22' , '23' , True ) , ( '231' , '23' , False ) , ( '231' , '231' , True ) , ] NEW_LINE for desc1 , desc2 , expected in data : NEW_LINE INDENT node1 = self . model . objects . get ( desc = desc1 ) NEW_LINE node2 = self . model . objects . get ( desc = desc2 ) NEW_LINE self . assertEqual ( node1 . is_sibling_of ( node2 ) , expected ) NEW_LINE DEDENT DEDENT def _multi_is_child_of ( self ) : NEW_LINE INDENT data = [ ( '2' , '2' , False ) , ( '2' , '1' , False ) , ( '21' , '2' , True ) , ( '231' , '2' , False ) , ( '231' , '23' , True ) , ( '231' , '231' , False ) , ] NEW_LINE for desc1 , desc2 , expected in data : NEW_LINE INDENT node1 = self . model . objects . get ( desc = desc1 ) NEW_LINE node2 = self . model . objects . get ( desc = desc2 ) NEW_LINE self . assertEqual ( node1 . is_child_of ( node2 ) , expected ) NEW_LINE DEDENT DEDENT def _multi_is_descendant_of ( self ) : NEW_LINE INDENT data = [ ( '2' , '2' , False ) , ( '2' , '1' , False ) , ( '21' , '2' , True ) , ( '231' , '2' , True ) , ( '231' , '23' , True ) , ( '231' , '231' , False ) , ] NEW_LINE for desc1 , desc2 , expected in data : NEW_LINE INDENT node1 = self . model . objects . get ( desc = desc1 ) NEW_LINE node2 = self . model . objects . get ( desc = desc2 ) NEW_LINE self . assertEqual ( node1 . is_descendant_of ( node2 ) , expected ) NEW_LINE DEDENT DEDENT DEDENT class TestAddChild ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_add_child_to_leaf ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . add_child ( desc = '2311' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 1 ) , ( u' 2311' , 4 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_child_to_node ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 2' ) . add_child ( desc = '25' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 25' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestAddSibling ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_add_sibling_invalid_pos ( self ) : NEW_LINE INDENT method = self . model . objects . get ( desc = u' 231' ) . add_sibling NEW_LINE self . assertRaises ( InvalidPosition , method , ' invalid _ pos ' ) NEW_LINE DEDENT def _multi_add_sibling_missing_nodeorderby ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u' 2' ) NEW_LINE method = node_wchildren . add_sibling NEW_LINE self . assertRaises ( MissingNodeOrderBy , method , ' sorted - sibling ' , desc = ' aaa ' ) NEW_LINE DEDENT def _multi_add_sibling_last_root ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u' 2' ) NEW_LINE obj = node_wchildren . add_sibling ( ' last - sibling ' , desc = '5' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE self . assertEqual ( node_wchildren . get_last_sibling ( ) . desc , u' 5' ) NEW_LINE DEDENT def _multi_add_sibling_last ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 231' ) NEW_LINE obj = node . add_sibling ( ' last - sibling ' , desc = '232' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 3 ) NEW_LINE self . assertEqual ( node . get_last_sibling ( ) . desc , u' 232' ) NEW_LINE DEDENT def _multi_add_sibling_first_root ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u' 2' ) NEW_LINE obj = node_wchildren . add_sibling ( ' first - sibling ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u' new ' , 1 , 0 ) , ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_first ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u' 23' ) NEW_LINE obj = node_wchildren . add_sibling ( ' first - sibling ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 2 ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' new ' , 2 , 0 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_left_root ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u' 2' ) NEW_LINE obj = node_wchildren . add_sibling ( ' left ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' new ' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_left ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u' 23' ) NEW_LINE obj = node_wchildren . add_sibling ( ' left ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 2 ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' new ' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_left_noleft_root ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 1' ) NEW_LINE obj = node . add_sibling ( ' left ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u' new ' , 1 , 0 ) , ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_left_noleft ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 231' ) NEW_LINE obj = node . add_sibling ( ' left ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 3 ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 2 ) , ( u' new ' , 3 , 0 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_right_root ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u' 2' ) NEW_LINE obj = node_wchildren . add_sibling ( ' right ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' new ' , 1 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_right ( self ) : NEW_LINE INDENT node_wchildren = self . model . objects . get ( desc = u' 23' ) NEW_LINE obj = node_wchildren . add_sibling ( ' right ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 2 ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' new ' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_right_noright_root ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 4' ) NEW_LINE obj = node . add_sibling ( ' right ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 1 ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) , ( u' new ' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_sibling_right_noright ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 231' ) NEW_LINE obj = node . add_sibling ( ' right ' , desc = ' new ' ) NEW_LINE self . assertEqual ( obj . get_depth ( ) , 3 ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 2 ) , ( u' 231' , 3 , 0 ) , ( u' new ' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestDelete ( TestNonEmptyTree ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT super ( TestDelete , self ) . setUp ( ) NEW_LINE for node in self . model . objects . all ( ) : NEW_LINE INDENT self . dep_model ( node = node ) . save ( ) NEW_LINE DEDENT DEDENT def _multi_delete_leaf ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . delete ( ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_node ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 23' ) . delete ( ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 3 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 2' ) . delete ( ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_filter_root_nodes ( self ) : NEW_LINE INDENT self . model . objects . filter ( desc__in = ( '2' , '3' ) ) . delete ( ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_filter_children ( self ) : NEW_LINE INDENT self . model . objects . filter ( desc__in = ( '2' , '23' , '231' ) ) . delete ( ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_nonexistant_nodes ( self ) : NEW_LINE INDENT self . model . objects . filter ( desc__in = ( ' ZZZ ' , ' XXX ' ) ) . delete ( ) NEW_LINE self . assertEqual ( self . got ( ) , self . unchanged ) NEW_LINE DEDENT def _multi_delete_same_node_twice ( self ) : NEW_LINE INDENT self . model . objects . filter ( desc__in = ( '2' , '2' ) ) . delete ( ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_delete_all_root_nodes ( self ) : NEW_LINE INDENT self . model . get_root_nodes ( ) . delete ( ) NEW_LINE count = self . model . objects . count ( ) NEW_LINE self . assertEqual ( count , 0 ) NEW_LINE DEDENT def _multi_delete_all_nodes ( self ) : NEW_LINE INDENT self . model . objects . all ( ) . delete ( ) NEW_LINE count = self . model . objects . count ( ) NEW_LINE self . assertEqual ( count , 0 ) NEW_LINE DEDENT DEDENT class TestMoveErrors ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_invalid_pos ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 231' ) NEW_LINE self . assertRaises ( InvalidPosition , node . move , node , ' invalid _ pos ' ) NEW_LINE DEDENT def _multi_move_to_descendant ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 2' ) NEW_LINE target = self . model . objects . get ( desc = u' 231' ) NEW_LINE self . assertRaises ( InvalidMoveToDescendant , node . move , target , ' first - sibling ' ) NEW_LINE DEDENT def _multi_move_missing_nodeorderby ( self ) : NEW_LINE INDENT node = self . model . objects . get ( desc = u' 231' ) NEW_LINE self . assertRaises ( MissingNodeOrderBy , node . move , node , ' sorted - child ' ) NEW_LINE self . assertRaises ( MissingNodeOrderBy , node . move , node , ' sorted - sibling ' ) NEW_LINE DEDENT DEDENT class TestMoveSortedErrors ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_nonsorted_move_in_sorted ( self ) : NEW_LINE INDENT node = self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' zxy ' ) NEW_LINE self . assertRaises ( InvalidPosition , node . move , node , ' left ' ) NEW_LINE DEDENT DEDENT class TestMoveLeafRoot ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_leaf_last_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 2' ) , ' last - sibling ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) , ( u' 231' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_first_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 2' ) , ' first - sibling ' ) NEW_LINE expected = [ ( u' 231' , 1 , 0 ) , ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_left_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 2' ) , ' left ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 231' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_right_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 2' ) , ' right ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 231' , 1 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_last_child_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 2' ) , ' last - child ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 231' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_first_child_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 2' ) , ' first - child ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 231' , 2 , 0 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestMoveLeaf ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_leaf_last_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 22' ) , ' last - sibling ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 231' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_first_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 22' ) , ' first - sibling ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 231' , 2 , 0 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_left_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 22' ) , ' left ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 231' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_right_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 22' ) , ' right ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 231' , 2 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_left_sibling_itself ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 231' ) , ' left ' ) NEW_LINE self . assertEqual ( self . got ( ) , self . unchanged ) NEW_LINE DEDENT def _multi_move_leaf_last_child ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 22' ) , ' last - child ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_leaf_first_child ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = u' 231' ) . move ( self . model . objects . get ( desc = u' 22' ) , ' first - child ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 23' , 2 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestMoveBranchRoot ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_branch_first_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' first - sibling ' ) NEW_LINE expected = [ ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) , ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_last_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' last - sibling ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' left ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_right_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' right ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_noleft_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) . get_first_sibling ( ) , ' left ' ) NEW_LINE expected = [ ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) , ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_right_noright_sibling_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) . get_last_sibling ( ) , ' right ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) , ( u' 4' , 1 , 1 ) , ( u' 41' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_first_child_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' first - child ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 4' , 2 , 1 ) , ( u' 41' , 3 , 0 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_last_child_root ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '2' ) , ' last - child ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 4' , 2 , 1 ) , ( u' 41' , 3 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestMoveBranch ( TestNonEmptyTree ) : NEW_LINE INDENT def _multi_move_branch_first_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' first - sibling ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 4' , 2 , 1 ) , ( u' 41' , 3 , 0 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_last_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' last - sibling ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 4' , 2 , 1 ) , ( u' 41' , 3 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' left ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 4' , 2 , 1 ) , ( u' 41' , 3 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_right_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' right ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 4' , 2 , 1 ) , ( u' 41' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_noleft_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) . get_first_sibling ( ) , ' left ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 4' , 2 , 1 ) , ( u' 41' , 3 , 0 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_right_noright_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) . get_last_sibling ( ) , ' right ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 5 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 1 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 4' , 2 , 1 ) , ( u' 41' , 3 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_left_itself_sibling ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '4' ) , ' left ' ) NEW_LINE self . assertEqual ( self . got ( ) , self . unchanged ) NEW_LINE DEDENT def _multi_move_branch_first_child ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' first - child ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 2 ) , ( u' 4' , 3 , 1 ) , ( u' 41' , 4 , 0 ) , ( u' 231' , 3 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_branch_last_child ( self ) : NEW_LINE INDENT self . model . objects . get ( desc = '4' ) . move ( self . model . objects . get ( desc = '23' ) , ' last - child ' ) NEW_LINE expected = [ ( u' 1' , 1 , 0 ) , ( u' 2' , 1 , 4 ) , ( u' 21' , 2 , 0 ) , ( u' 22' , 2 , 0 ) , ( u' 23' , 2 , 2 ) , ( u' 231' , 3 , 0 ) , ( u' 4' , 3 , 1 ) , ( u' 41' , 4 , 0 ) , ( u' 24' , 2 , 0 ) , ( u' 3' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestTreeSorted ( TestTreeBase ) : NEW_LINE INDENT def got ( self ) : NEW_LINE INDENT return [ ( o . val1 , o . val2 , o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in self . sorted_model . get_tree ( ) ] NEW_LINE DEDENT def _multi_add_root_sorted ( self ) : NEW_LINE INDENT self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' zxy ' ) NEW_LINE self . sorted_model . add_root ( val1 = 1 , val2 = 4 , desc = ' bcd ' ) NEW_LINE self . sorted_model . add_root ( val1 = 2 , val2 = 5 , desc = ' zxy ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE self . sorted_model . add_root ( val1 = 4 , val2 = 1 , desc = ' fgh ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE self . sorted_model . add_root ( val1 = 2 , val2 = 2 , desc = ' qwe ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 2 , desc = ' vcx ' ) NEW_LINE expected = [ ( 1 , 4 , u' bcd ' , 1 , 0 ) , ( 2 , 2 , u' qwe ' , 1 , 0 ) , ( 2 , 5 , u' zxy ' , 1 , 0 ) , ( 3 , 2 , u' vcx ' , 1 , 0 ) , ( 3 , 3 , u' abc ' , 1 , 0 ) , ( 3 , 3 , u' abc ' , 1 , 0 ) , ( 3 , 3 , u' zxy ' , 1 , 0 ) , ( 4 , 1 , u' fgh ' , 1 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_child_root_sorted ( self ) : NEW_LINE INDENT root = self . sorted_model . add_root ( val1 = 0 , val2 = 0 , desc = ' aaa ' ) NEW_LINE root . add_child ( val1 = 3 , val2 = 3 , desc = ' zxy ' ) NEW_LINE root . add_child ( val1 = 1 , val2 = 4 , desc = ' bcd ' ) NEW_LINE root . add_child ( val1 = 2 , val2 = 5 , desc = ' zxy ' ) NEW_LINE root . add_child ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE root . add_child ( val1 = 4 , val2 = 1 , desc = ' fgh ' ) NEW_LINE root . add_child ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE root . add_child ( val1 = 2 , val2 = 2 , desc = ' qwe ' ) NEW_LINE root . add_child ( val1 = 3 , val2 = 2 , desc = ' vcx ' ) NEW_LINE expected = [ ( 0 , 0 , u' aaa ' , 1 , 8 ) , ( 1 , 4 , u' bcd ' , 2 , 0 ) , ( 2 , 2 , u' qwe ' , 2 , 0 ) , ( 2 , 5 , u' zxy ' , 2 , 0 ) , ( 3 , 2 , u' vcx ' , 2 , 0 ) , ( 3 , 3 , u' abc ' , 2 , 0 ) , ( 3 , 3 , u' abc ' , 2 , 0 ) , ( 3 , 3 , u' zxy ' , 2 , 0 ) , ( 4 , 1 , u' fgh ' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_add_child_nonroot_sorted ( self ) : NEW_LINE INDENT get_node = lambda node_id : self . sorted_model . objects . get ( pk = node_id ) NEW_LINE root_id = self . sorted_model . add_root ( val1 = 0 , val2 = 0 , desc = ' a ' ) . id NEW_LINE node_id = get_node ( root_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' ac ' ) . id NEW_LINE get_node ( root_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' aa ' ) NEW_LINE get_node ( root_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' av ' ) NEW_LINE get_node ( node_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' aca ' ) NEW_LINE get_node ( node_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' acc ' ) NEW_LINE get_node ( node_id ) . add_child ( val1 = 0 , val2 = 0 , desc = ' acb ' ) NEW_LINE expected = [ ( 0 , 0 , u' a ' , 1 , 3 ) , ( 0 , 0 , u' aa ' , 2 , 0 ) , ( 0 , 0 , u' ac ' , 2 , 3 ) , ( 0 , 0 , u' aca ' , 3 , 0 ) , ( 0 , 0 , u' acb ' , 3 , 0 ) , ( 0 , 0 , u' acc ' , 3 , 0 ) , ( 0 , 0 , u' av ' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT def _multi_move_sorted ( self ) : NEW_LINE INDENT self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' zxy ' ) NEW_LINE self . sorted_model . add_root ( val1 = 1 , val2 = 4 , desc = ' bcd ' ) NEW_LINE self . sorted_model . add_root ( val1 = 2 , val2 = 5 , desc = ' zxy ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE self . sorted_model . add_root ( val1 = 4 , val2 = 1 , desc = ' fgh ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 3 , desc = ' abc ' ) NEW_LINE self . sorted_model . add_root ( val1 = 2 , val2 = 2 , desc = ' qwe ' ) NEW_LINE self . sorted_model . add_root ( val1 = 3 , val2 = 2 , desc = ' vcx ' ) NEW_LINE root_nodes = self . sorted_model . get_root_nodes ( ) NEW_LINE target = root_nodes [ 0 ] NEW_LINE for node in root_nodes [ 1 : ] : NEW_LINE INDENT node = self . sorted_model . objects . get ( pk = node . id ) NEW_LINE target = self . sorted_model . objects . get ( pk = target . id ) NEW_LINE node . move ( target , ' sorted - child ' ) NEW_LINE DEDENT expected = [ ( 1 , 4 , u' bcd ' , 1 , 7 ) , ( 2 , 2 , u' qwe ' , 2 , 0 ) , ( 2 , 5 , u' zxy ' , 2 , 0 ) , ( 3 , 2 , u' vcx ' , 2 , 0 ) , ( 3 , 3 , u' abc ' , 2 , 0 ) , ( 3 , 3 , u' abc ' , 2 , 0 ) , ( 3 , 3 , u' zxy ' , 2 , 0 ) , ( 4 , 1 , u' fgh ' , 2 , 0 ) ] NEW_LINE self . assertEqual ( self . got ( ) , expected ) NEW_LINE DEDENT DEDENT class TestMP_TreeAlphabet ( TestCase ) : NEW_LINE INDENT def test_alphabet ( self ) : NEW_LINE INDENT if not os . getenv ( ' TREEBEARD _ TEST _ ALPHABET ' , False ) : NEW_LINE INDENT return NEW_LINE DEDENT basealpha = numconv . BASE85 NEW_LINE got_err = False NEW_LINE last_good = None NEW_LINE for alphabetlen in range ( 35 , len ( basealpha ) + 1 ) : NEW_LINE INDENT alphabet = basealpha [ 0 : alphabetlen ] NEW_LINE expected = [ alphabet [ 0 ] + char for char in alphabet [ 1 : ] ] NEW_LINE expected . extend ( [ alphabet [ 1 ] + char for char in alphabet ] ) NEW_LINE expected . append ( alphabet [ 2 ] + alphabet [ 0 ] ) NEW_LINE MP_TestNodeAlphabet . objects . all ( ) . delete ( ) NEW_LINE MP_TestNodeAlphabet . alphabet = alphabet NEW_LINE for pos in range ( len ( alphabet ) * 2 ) : NEW_LINE INDENT try : NEW_LINE INDENT MP_TestNodeAlphabet . add_root ( numval = pos ) NEW_LINE DEDENT except : NEW_LINE INDENT got_err = True NEW_LINE break NEW_LINE DEDENT DEDENT if got_err : NEW_LINE INDENT break NEW_LINE DEDENT got = [ obj . path for obj in MP_TestNodeAlphabet . objects . all ( ) ] NEW_LINE if got != expected : NEW_LINE INDENT got_err = True NEW_LINE DEDENT last_good = alphabet NEW_LINE DEDENT print ' \n The ▁ best ▁ BASE85 ▁ based ▁ alphabet ▁ for ▁ your ▁ setup ▁ is : ▁ % s ' \NEW_LINE % ( last_good , ) NEW_LINE DEDENT DEDENT class TestHelpers ( TestTreeBase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT for model in ( MP_TestNode , AL_TestNode , NS_TestNode ) : NEW_LINE INDENT model . load_bulk ( BASE_DATA ) NEW_LINE for node in model . get_root_nodes ( ) : NEW_LINE INDENT model . load_bulk ( BASE_DATA , node ) NEW_LINE DEDENT model . add_root ( desc = '5' ) NEW_LINE DEDENT DEDENT def _multi_descendants_group_count_root ( self ) : NEW_LINE INDENT expected = [ ( o . desc , o . get_descendant_count ( ) ) for o in self . model . get_root_nodes ( ) ] NEW_LINE got = [ ( o . desc , o . descendants_count ) for o in self . model . get_descendants_group_count ( ) ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT def _multi_descendants_group_count_node ( self ) : NEW_LINE INDENT parent = self . model . get_root_nodes ( ) . get ( desc = '2' ) NEW_LINE expected = [ ( o . desc , o . get_descendant_count ( ) ) for o in parent . get_children ( ) ] NEW_LINE got = [ ( o . desc , o . descendants_count ) for o in self . model . get_descendants_group_count ( parent ) ] NEW_LINE self . assertEqual ( got , expected ) NEW_LINE DEDENT DEDENT class TestMP_TreeSortedAutoNow ( TestCase ) : NEW_LINE INDENT def test_sorted_by_autonow_workaround ( self ) : NEW_LINE INDENT import datetime NEW_LINE for i in range ( 1 , 5 ) : NEW_LINE INDENT MP_TestNodeSortedAutoNow . add_root ( desc = ' node % d ' % ( i , ) , created = datetime . datetime . now ( ) ) NEW_LINE DEDENT DEDENT def test_sorted_by_autonow_FAIL ( self ) : NEW_LINE INDENT MP_TestNodeSortedAutoNow . add_root ( desc = ' node1' ) NEW_LINE self . assertRaises ( ValueError , MP_TestNodeSortedAutoNow . add_root , desc = ' node2' ) NEW_LINE DEDENT DEDENT class TestMP_TreeStepOverflow ( TestCase ) : NEW_LINE INDENT def test_add_root ( self ) : NEW_LINE INDENT method = MP_TestNodeSmallStep . add_root NEW_LINE for i in range ( 1 , 10 ) : NEW_LINE INDENT method ( ) NEW_LINE DEDENT self . assertRaises ( PathOverflow , method ) NEW_LINE DEDENT def test_add_child ( self ) : NEW_LINE INDENT root = MP_TestNodeSmallStep . add_root ( ) NEW_LINE method = root . add_child NEW_LINE for i in range ( 1 , 10 ) : NEW_LINE INDENT method ( ) NEW_LINE DEDENT self . assertRaises ( PathOverflow , method ) NEW_LINE DEDENT def test_add_sibling ( self ) : NEW_LINE INDENT root = MP_TestNodeSmallStep . add_root ( ) NEW_LINE for i in range ( 1 , 10 ) : NEW_LINE INDENT root . add_child ( ) NEW_LINE DEDENT method = root . get_last_child ( ) . add_sibling NEW_LINE positions = ( ' first - sibling ' , ' left ' , ' right ' , ' last - sibling ' ) NEW_LINE for pos in positions : NEW_LINE INDENT self . assertRaises ( PathOverflow , method , pos ) NEW_LINE DEDENT DEDENT def test_move ( self ) : NEW_LINE INDENT root = MP_TestNodeSmallStep . add_root ( ) NEW_LINE for i in range ( 1 , 10 ) : NEW_LINE INDENT root . add_child ( ) NEW_LINE DEDENT newroot = MP_TestNodeSmallStep . add_root ( ) NEW_LINE targets = [ ( root , [ ' first - child ' , ' last - child ' ] ) , ( root . get_first_child ( ) , [ ' first - sibling ' , ' left ' , ' right ' , ' last - sibling ' ] ) ] NEW_LINE for target , positions in targets : NEW_LINE INDENT for pos in positions : NEW_LINE INDENT self . assertRaises ( PathOverflow , newroot . move , target , pos ) NEW_LINE DEDENT DEDENT DEDENT DEDENT class TestMP_TreeShortPath ( TestCase ) : NEW_LINE INDENT def test_short_path ( self ) : NEW_LINE INDENT obj = MP_TestNodeShortPath . add_root ( ) NEW_LINE obj = obj . add_child ( ) . add_child ( ) . add_child ( ) NEW_LINE self . assertRaises ( PathOverflow , obj . add_child ) NEW_LINE DEDENT DEDENT class TestMP_TreeFindProblems ( TestTreeBase ) : NEW_LINE INDENT def test_find_problems ( self ) : NEW_LINE INDENT model = MP_TestNodeAlphabet NEW_LINE model . alphabet = '01234' NEW_LINE model ( path = '01' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '1' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '111' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = ' abcd ' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = ' qa # $ % ! ' , depth = 1 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '0201' , depth = 2 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '020201' , depth = 3 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '03' , depth = 1 , numchild = 2 , numval = 0 ) . save ( ) NEW_LINE model ( path = '0301' , depth = 2 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE model ( path = '030102' , depth = 3 , numchild = 10 , numval = 0 ) . save ( ) NEW_LINE model ( path = '04' , depth = 10 , numchild = 1 , numval = 0 ) . save ( ) NEW_LINE model ( path = '0401' , depth = 20 , numchild = 0 , numval = 0 ) . save ( ) NEW_LINE evil_chars , bad_steplen , orphans , wrong_depth , wrong_numchild = \NEW_LINE model . find_problems ( ) NEW_LINE self . assertEqual ( [ ' abcd ' , ' qa # $ % ! ' ] , [ o . path for o in model . objects . filter ( id__in = evil_chars ) ] ) NEW_LINE self . assertEqual ( [ '1' , '111' ] , [ o . path for o in model . objects . filter ( id__in = bad_steplen ) ] ) NEW_LINE self . assertEqual ( [ '0201' , '020201' ] , [ o . path for o in model . objects . filter ( id__in = orphans ) ] ) NEW_LINE self . assertEqual ( [ '03' , '0301' , '030102' ] , [ o . path for o in model . objects . filter ( id__in = wrong_numchild ) ] ) NEW_LINE self . assertEqual ( [ '04' , '0401' ] , [ o . path for o in model . objects . filter ( id__in = wrong_depth ) ] ) NEW_LINE DEDENT DEDENT class TestMP_TreeFix ( TestTreeBase ) : NEW_LINE INDENT def setUp ( self ) : NEW_LINE INDENT super ( TestMP_TreeFix , self ) . setUp ( ) NEW_LINE self . expected_no_holes = { MP_TestNodeShortPath : [ ( u' 1' , u' b ' , 1 , 2 ) , ( u' 11' , u' u' , 2 , 1 ) , ( u' 111' , u' i ' , 3 , 1 ) , ( u' 1111' , u' e ' , 4 , 0 ) , ( u' 12' , u' o ' , 2 , 0 ) , ( u' 2' , u' d ' , 1 , 0 ) , ( u' 3' , u' g ' , 1 , 0 ) , ( u' 4' , u' a ' , 1 , 4 ) , ( u' 41' , u' a ' , 2 , 0 ) , ( u' 42' , u' a ' , 2 , 0 ) , ( u' 43' , u' u' , 2 , 1 ) , ( u' 431' , u' i ' , 3 , 1 ) , ( u' 4311' , u' e ' , 4 , 0 ) , ( u' 44' , u' o ' , 2 , 0 ) ] , MP_TestSortedNodeShortPath : [ ( u' 1' , u' a ' , 1 , 4 ) , ( u' 11' , u' a ' , 2 , 0 ) , ( u' 12' , u' a ' , 2 , 0 ) , ( u' 13' , u' o ' , 2 , 0 ) , ( u' 14' , u' u' , 2 , 1 ) , ( u' 141' , u' i ' , 3 , 1 ) , ( u' 1411' , u' e ' , 4 , 0 ) , ( u' 2' , u' b ' , 1 , 2 ) , ( u' 21' , u' o ' , 2 , 0 ) , ( u' 22' , u' u' , 2 , 1 ) , ( u' 221' , u' i ' , 3 , 1 ) , ( u' 2211' , u' e ' , 4 , 0 ) , ( u' 3' , u' d ' , 1 , 0 ) , ( u' 4' , u' g ' , 1 , 0 ) ] } NEW_LINE self . expected_with_holes = { MP_TestNodeShortPath : [ ( u' 1' , u' b ' , 1L , 2L ) , ( u' 13' , u' u' , 2L , 1L ) , ( u' 134' , u' i ' , 3L , 1L ) , ( u' 1343' , u' e ' , 4L , 0L ) , ( u' 14' , u' o ' , 2L , 0L ) , ( u' 2' , u' d ' , 1L , 0L ) , ( u' 3' , u' g ' , 1L , 0L ) , ( u' 4' , u' a ' , 1L , 4L ) , ( u' 41' , u' a ' , 2L , 0L ) , ( u' 42' , u' a ' , 2L , 0L ) , ( u' 43' , u' u' , 2L , 1L ) , ( u' 434' , u' i ' , 3L , 1L ) , ( u' 4343' , u' e ' , 4L , 0L ) , ( u' 44' , u' o ' , 2L , 0L ) ] , MP_TestSortedNodeShortPath : [ ( u' 1' , u' b ' , 1L , 2L ) , ( u' 13' , u' u' , 2L , 1L ) , ( u' 134' , u' i ' , 3L , 1L ) , ( u' 1343' , u' e ' , 4L , 0L ) , ( u' 14' , u' o ' , 2L , 0L ) , ( u' 2' , u' d ' , 1L , 0L ) , ( u' 3' , u' g ' , 1L , 0L ) , ( u' 4' , u' a ' , 1L , 4L ) , ( u' 41' , u' a ' , 2L , 0L ) , ( u' 42' , u' a ' , 2L , 0L ) , ( u' 43' , u' u' , 2L , 1L ) , ( u' 434' , u' i ' , 3L , 1L ) , ( u' 4343' , u' e ' , 4L , 0L ) , ( u' 44' , u' o ' , 2L , 0L ) ] } NEW_LINE DEDENT def got ( self , model ) : NEW_LINE INDENT return [ ( o . path , o . desc , o . get_depth ( ) , o . get_children_count ( ) ) for o in model . get_tree ( ) ] NEW_LINE DEDENT def add_broken_test_data ( self , model ) : NEW_LINE INDENT model ( path = '4' , depth = 2 , numchild = 2 , desc = ' a ' ) . save ( ) NEW_LINE model ( path = '13' , depth = 1000 , numchild = 0 , desc = ' u ' ) . save ( ) NEW_LINE model ( path = '14' , depth = 4 , numchild = 500 , desc = ' o ' ) . save ( ) NEW_LINE model ( path = '134' , depth = 321 , numchild = 543 , desc = ' i ' ) . save ( ) NEW_LINE model ( path = '1343' , depth = 321 , numchild = 543 , desc = ' e ' ) . save ( ) NEW_LINE model ( path = '42' , depth = 1 , numchild = 1 , desc = ' a ' ) . save ( ) NEW_LINE model ( path = '43' , depth = 1000 , numchild = 0 , desc = ' u ' ) . save ( ) NEW_LINE model ( path = '44' , depth = 4 , numchild = 500 , desc = ' o ' ) . save ( ) NEW_LINE model ( path = '434' , depth = 321 , numchild = 543 , desc = ' i ' ) . save ( ) NEW_LINE model ( path = '4343' , depth = 321 , numchild = 543 , desc = ' e ' ) . save ( ) NEW_LINE model ( path = '41' , depth = 1 , numchild = 1 , desc = ' a ' ) . save ( ) NEW_LINE model ( path = '3' , depth = 221 , numchild = 322 , desc = ' g ' ) . save ( ) NEW_LINE model ( path = '1' , depth = 10 , numchild = 3 , desc = ' b ' ) . save ( ) NEW_LINE model ( path = '2' , depth = 10 , numchild = 3 , desc = ' d ' ) . save ( ) NEW_LINE DEDENT def test_fix_tree_non_destructive ( self ) : NEW_LINE INDENT for model in ( MP_TestNodeShortPath , MP_TestSortedNodeShortPath ) : NEW_LINE INDENT self . add_broken_test_data ( model ) NEW_LINE model . fix_tree ( destructive = False ) NEW_LINE self . assertEqual ( self . got ( model ) , self . expected_with_holes [ model ] ) NEW_LINE model . find_problems ( ) NEW_LINE DEDENT DEDENT def test_fix_tree_destructive ( self ) : NEW_LINE INDENT for model in ( MP_TestNodeShortPath , MP_TestSortedNodeShortPath ) : NEW_LINE INDENT self . add_broken_test_data ( model ) NEW_LINE model . fix_tree ( destructive = True ) NEW_LINE self . assertEqual ( self . got ( model ) , self . expected_no_holes [ model ] ) NEW_LINE model . find_problems ( ) NEW_LINE DEDENT DEDENT DEDENT class TestIssues ( TestCase ) : NEW_LINE INDENT def test_many_to_many_django_user_anonymous ( self ) : NEW_LINE INDENT if not HAS_DJANGO_AUTH : NEW_LINE INDENT self . fail ( ' this ▁ test ▁ needs ▁ django . contrib . auth ▁ in ▁ INSTALLED _ APPS ' ) NEW_LINE DEDENT anonuserobj = None NEW_LINE def qs_check ( qs , expected ) : NEW_LINE INDENT self . assertEqual ( [ o . name for o in qs ] , expected ) NEW_LINE DEDENT user = User . objects . create_user ( ' test _ user ' , ' test @ example . com ' , ' testpasswd ' ) NEW_LINE user . save ( ) NEW_LINE root = MP_TestIssue14 . add_root ( name = " the ▁ root ▁ node " ) NEW_LINE root . add_child ( name = " first " ) NEW_LINE second = root . add_child ( name = " second " ) NEW_LINE qs_check ( root . get_children ( ) , [ ' first ' , ' second ' ] ) NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) ) , [ ' first ' ] ) NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( users = user ) ) , [ ] ) NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) | Q ( users = user ) ) , [ ' first ' ] ) NEW_LINE user = anonuserobj NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) | Q ( users = user ) ) , [ ' first ' , ' second ' ] ) NEW_LINE user = User . objects . get ( username = " test _ user " ) NEW_LINE second . users . add ( user ) NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) | Q ( users = user ) ) , [ ' first ' , ' second ' ] ) NEW_LINE user = anonuserobj NEW_LINE qs_check ( root . get_children ( ) . filter ( Q ( name = " first " ) | Q ( users = user ) ) , [ ' first ' ] ) NEW_LINE DEDENT DEDENT class TestModelAdmin ( ModelAdmin ) : NEW_LINE INDENT form = MoveNodeForm NEW_LINE DEDENT class TestMoveNodeForm ( TestTreeBase ) : NEW_LINE INDENT tpl = ( u' < tr > < th > < label ▁ for = " id _ _ position " > Position : < / label > < / th > ' ' < td > < select ▁ name = " _ position " ▁ id = " id _ _ position " > \n ' ' < option ▁ value = " first - child " > First ▁ child ▁ of < / option > \n ' ' < option ▁ value = " left " > Before < / option > \n ' ' < option ▁ value = " right " > After < / option > \n ' ' < / select > < / td > < / tr > \n ' ' < tr > < th > < label ▁ for = " id _ _ ref _ node _ id " > Relative ▁ to : < / label > ' ' < / th > < td > < select ▁ name = " _ ref _ node _ id " ▁ id = " id _ _ ref _ node _ id " > \n ' ' < option ▁ value = " 0 " > - - ▁ root ▁ - - < / option > \n ' ) NEW_LINE def _multi_form_html_root_node ( self ) : NEW_LINE INDENT self . model . load_bulk ( BASE_DATA ) NEW_LINE node = self . model . get_tree ( ) [ 0 ] NEW_LINE form = MoveNodeForm ( instance = node ) NEW_LINE rtpl = self . tpl NEW_LINE self . assertEqual ( [ ' _ position ' , ' _ ref _ node _ id ' ] , form . base_fields . keys ( ) ) NEW_LINE for obj in self . model . get_tree ( ) : NEW_LINE INDENT if node != obj or obj . is_descendant_of ( node ) : NEW_LINE INDENT rtpl += ' < option ▁ value = " % d " > % sNode ▁ % d < / option > \n ' % ( obj . id , ' . ▁ . ▁ ' * ( obj . get_depth ( ) - 1 ) , obj . id ) NEW_LINE DEDENT DEDENT rtpl += ' < / select > < / td > < / tr > ' NEW_LINE formstr = unicode ( form ) . replace ( u' ▁ selected = " selected " ' , u' ' ) NEW_LINE self . assertEqual ( rtpl , formstr ) NEW_LINE DEDENT def _multi_form_html_leaf_node ( self ) : NEW_LINE INDENT self . model . load_bulk ( BASE_DATA ) NEW_LINE nodes = list ( self . model . get_tree ( ) ) NEW_LINE node = nodes [ - 1 ] NEW_LINE form = MoveNodeForm ( instance = node ) NEW_LINE rtpl = self . tpl NEW_LINE self . assertEqual ( [ ' _ position ' , ' _ ref _ node _ id ' ] , form . base_fields . keys ( ) ) NEW_LINE for obj in self . model . get_tree ( ) : NEW_LINE INDENT if node != obj or obj . is_descendant_of ( node ) : NEW_LINE INDENT rtpl += ' < option ▁ value = " % d " > % sNode ▁ % d < / option > \n ' % ( obj . id , ' . ▁ . ▁ ' * ( obj . get_depth ( ) - 1 ) , obj . id ) NEW_LINE DEDENT DEDENT rtpl += ' < / select > < / td > < / tr > ' NEW_LINE formstr = unicode ( form ) . replace ( u' ▁ selected = " selected " ' , u' ' ) NEW_LINE self . assertEqual ( rtpl , formstr ) NEW_LINE DEDENT def _multi_admin_html ( self ) : NEW_LINE INDENT tpl = ( ' < tr > < th > < label ▁ for = " id _ desc " > Desc : < / label > ' ' < / th > < td > < input ▁ id = " id _ desc " ▁ type = " text " ▁ class = " vTextField " ▁ ' ' name = " desc " ▁ maxlength = " 255 " ▁ / > < / td > < / tr > \n ' ' < tr > < th > < label ▁ for = " id _ _ position " > Position : < / label > < / th > ' ' < td > < select ▁ name = " _ position " ▁ id = " id _ _ position " > \n ' ' < option ▁ value = " first - child " > First ▁ child ▁ of < / option > \n ' ' < option ▁ value = " left " > Before < / option > \n ' ' < option ▁ value = " right " > After < / option > \n ' ' < / select > < / td > < / tr > \n ' ' < tr > < th > < label ▁ for = " id _ _ ref _ node _ id " > Relative ▁ to : < / label > ' ' < / th > < td > < select ▁ name = " _ ref _ node _ id " ▁ id = " id _ _ ref _ node _ id " > \n ' ' < option ▁ value = " 0 " > - - ▁ root ▁ - - < / option > \n ' ' < option ▁ value = " % d " > Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > Node ▁ % d < / option > \n ' ' < option ▁ value = " % d " > . ▁ . ▁ Node ▁ % d < / option > \n ' ' < / select > < / td > < / tr > ' ) NEW_LINE request = None NEW_LINE self . model . load_bulk ( BASE_DATA ) NEW_LINE for node in self . model . objects . all ( ) : NEW_LINE INDENT site = AdminSite ( ) NEW_LINE ma = TestModelAdmin ( self . model , site ) NEW_LINE self . assertEqual ( [ ' desc ' , ' _ position ' , ' _ ref _ node _ id ' ] , ma . get_form ( request ) . base_fields . keys ( ) ) NEW_LINE self . assertEqual ( [ ( None , { ' fields ' : [ ' desc ' , ' _ position ' , ' _ ref _ node _ id ' ] } ) ] , ma . get_fieldsets ( request ) ) NEW_LINE self . assertEqual ( [ ( None , { ' fields ' : [ ' desc ' , ' _ position ' , ' _ ref _ node _ id ' ] } ) ] , ma . get_fieldsets ( request , node ) ) NEW_LINE form = ma . get_form ( request ) ( ) NEW_LINE ids = [ ] NEW_LINE for obj in self . model . get_tree ( ) : NEW_LINE INDENT ids . extend ( [ obj . id ] * 2 ) NEW_LINE DEDENT self . assertEqual ( tpl % tuple ( ids ) , unicode ( form ) ) NEW_LINE DEDENT DEDENT DEDENT _load_test_methods ( TestMoveNodeForm ) NEW_LINE _load_test_methods ( TestEmptyTree ) NEW_LINE _load_test_methods ( TestClassMethods ) NEW_LINE _load_test_methods ( TestSimpleNodeMethods ) NEW_LINE _load_test_methods ( TestAddChild ) NEW_LINE _load_test_methods ( TestAddSibling ) NEW_LINE _load_test_methods ( TestDelete ) NEW_LINE _load_test_methods ( TestMoveErrors ) NEW_LINE _load_test_methods ( TestMoveLeafRoot ) NEW_LINE _load_test_methods ( TestMoveLeaf ) NEW_LINE _load_test_methods ( TestMoveBranchRoot ) NEW_LINE _load_test_methods ( TestMoveBranch ) NEW_LINE _load_test_methods ( TestHelpers ) NEW_LINE _load_test_methods ( TestMoveSortedErrors , proxy = False ) NEW_LINE _load_test_methods ( TestTreeSorted , proxy = False ) NEW_LINE
 def my_func ( p1 = 1 ) -> object : NEW_LINE INDENT return p1 NEW_LINE DEDENT d = my_func ( 1 ) NEW_LINE
